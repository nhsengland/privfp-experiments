{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from data_ingestion import load_llm_data\n",
    "from universal_ner import upload_quantised_universal_ner, get_universal_ner_entity, generate_patients_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../../models/quantized_q4_1.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = .\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 3\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_1:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_1\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.95 GiB (5.03 BPW) \n",
      "llm_load_print_meta: general.name     = .\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4042.39 MiB, ( 4042.45 / 10922.67)\n",
      "llm_load_tensors: system memory used  = 4041.79 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/scarlettkynoch/miniconda3/envs/ner_pipeline/lib/python3.8/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   256.00 MiB, ( 4300.02 / 10922.67)\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 4300.03 / 10922.67)\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 73.69 MiB\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    70.50 MiB, ( 4370.52 / 10922.67)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brandon McLaughlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /    11 runs   (    0.09 ms per token, 10752.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1937.91 ms /   160 tokens (   12.11 ms per token,    82.56 tokens per second)\n",
      "llama_print_timings:        eval time =     898.69 ms /    10 runs   (   89.87 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    2864.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"568 968 0803\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    15 runs   (    0.26 ms per token,  3825.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.68 ms /    14 runs   (   80.83 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1444.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.07 ms /    23 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =     114.73 ms /     1 runs   (  114.73 ms per token,     8.72 tokens per second)\n",
      "llama_print_timings:       total time =     371.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     8 runs   (    0.15 ms per token,  6688.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =     575.62 ms /     7 runs   (   82.23 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     850.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Esteban Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /    12 runs   (    0.28 ms per token,  3589.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.98 ms /   150 tokens (    7.75 ms per token,   129.09 tokens per second)\n",
      "llama_print_timings:        eval time =     881.93 ms /    11 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2100.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"201 826 4805\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    15 runs   (    0.18 ms per token,  5440.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    25 tokens (   10.07 ms per token,    99.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.80 ms /    14 runs   (   80.70 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1429.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     9 runs   (    0.27 ms per token,  3773.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.61 ms /    23 tokens (   10.85 ms per token,    92.14 tokens per second)\n",
      "llama_print_timings:        eval time =     656.56 ms /     8 runs   (   82.07 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     943.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7722.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.94 ms /    24 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =      80.46 ms /     1 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     335.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ervin O'Connell\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    20 runs   (    0.26 ms per token,  3814.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.01 ms /   155 tokens (    7.55 ms per token,   132.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1520.68 ms /    19 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2780.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"862 334 6633\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /    15 runs   (    0.14 ms per token,  7253.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.04 ms /    25 tokens (   10.12 ms per token,    98.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.88 ms /    14 runs   (   82.71 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1448.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     7 runs   (    0.13 ms per token,  7909.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    23 tokens (   10.96 ms per token,    91.20 tokens per second)\n",
      "llama_print_timings:        eval time =     488.56 ms /     6 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     757.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.05 ms /     8 runs   (    0.13 ms per token,  7597.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.16 ms /    24 tokens (   10.46 ms per token,    95.56 tokens per second)\n",
      "llama_print_timings:        eval time =     573.58 ms /     7 runs   (   81.94 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     846.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Pam Boehm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     8 runs   (    0.12 ms per token,  8583.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.75 ms /   135 tokens (    8.57 ms per token,   116.71 tokens per second)\n",
      "llama_print_timings:        eval time =     606.75 ms /     7 runs   (   86.68 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =    1781.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"639 189 7032\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    15 runs   (    0.19 ms per token,  5215.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    25 tokens (   10.03 ms per token,    99.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.71 ms /    14 runs   (   82.12 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1456.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     9 runs   (    0.11 ms per token,  8955.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.27 ms /    23 tokens (   10.97 ms per token,    91.17 tokens per second)\n",
      "llama_print_timings:        eval time =     665.95 ms /     8 runs   (   83.24 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     939.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    24 tokens (   10.42 ms per token,    95.96 tokens per second)\n",
      "llama_print_timings:        eval time =      96.80 ms /     1 runs   (   96.80 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     351.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mirta Mosciski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /    11 runs   (    0.27 ms per token,  3741.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.91 ms /   135 tokens (    8.48 ms per token,   117.91 tokens per second)\n",
      "llama_print_timings:        eval time =     785.76 ms /    10 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1987.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"231 157 0705\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    15 runs   (    0.32 ms per token,  3137.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    25 tokens (   10.03 ms per token,    99.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.12 ms /    14 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1434.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     5 runs   (    0.28 ms per token,  3589.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.89 ms /    23 tokens (   10.86 ms per token,    92.04 tokens per second)\n",
      "llama_print_timings:        eval time =     323.39 ms /     4 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     599.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     8 runs   (    0.29 ms per token,  3407.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =     558.95 ms /     7 runs   (   79.85 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     846.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Pierre Hyatt\", \"Doctor Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    18 runs   (    0.32 ms per token,  3152.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.84 ms /   185 tokens (    7.54 ms per token,   132.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.85 ms /    17 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    2838.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"476 859 5816\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    15 runs   (    0.31 ms per token,  3215.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.89 ms /    25 tokens (   10.12 ms per token,    98.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.26 ms /    14 runs   (   78.88 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1444.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     9 runs   (    0.24 ms per token,  4100.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    23 tokens (   10.92 ms per token,    91.59 tokens per second)\n",
      "llama_print_timings:        eval time =     641.91 ms /     8 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     938.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     8 runs   (    0.39 ms per token,  2538.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    24 tokens (   10.48 ms per token,    95.40 tokens per second)\n",
      "llama_print_timings:        eval time =     547.99 ms /     7 runs   (   78.28 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     846.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Angela Collier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    10 runs   (    0.34 ms per token,  2947.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.03 ms /   167 tokens (    8.25 ms per token,   121.19 tokens per second)\n",
      "llama_print_timings:        eval time =     702.00 ms /     9 runs   (   78.00 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2138.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"590 161 4272\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    15 runs   (    0.31 ms per token,  3248.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.16 ms /    14 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1442.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.12 ms /     8 runs   (    0.14 ms per token,  7136.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =     588.53 ms /     7 runs   (   84.08 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     859.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    16 runs   (    0.19 ms per token,  5268.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.46 ms /    24 tokens (   10.73 ms per token,    93.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1405.03 ms /    15 runs   (   93.67 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =    1772.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shannon Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     9 runs   (    0.33 ms per token,  3053.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1209.90 ms /   148 tokens (    8.18 ms per token,   122.32 tokens per second)\n",
      "llama_print_timings:        eval time =     742.16 ms /     8 runs   (   92.77 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    2000.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"122 273 9962\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    15 runs   (    0.48 ms per token,  2081.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.34 ms /    25 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.34 ms /    14 runs   (   84.81 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    1545.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     7 runs   (    0.32 ms per token,  3165.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    23 tokens (   11.02 ms per token,    90.76 tokens per second)\n",
      "llama_print_timings:        eval time =     567.62 ms /     6 runs   (   94.60 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     850.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /     8 runs   (    0.49 ms per token,  2039.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.68 ms /    24 tokens (   10.74 ms per token,    93.14 tokens per second)\n",
      "llama_print_timings:        eval time =     594.51 ms /     7 runs   (   84.93 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     902.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Delmy Halvorson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     9 runs   (    0.35 ms per token,  2856.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.64 ms /   153 tokens (    7.73 ms per token,   129.37 tokens per second)\n",
      "llama_print_timings:        eval time =     668.72 ms /     8 runs   (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    1905.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 774 0304\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    15 runs   (    0.39 ms per token,  2589.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.36 ms /    25 tokens (   10.37 ms per token,    96.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1190.42 ms /    14 runs   (   85.03 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    1531.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     6 runs   (    0.33 ms per token,  3069.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     418.60 ms /     5 runs   (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     699.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    11 runs   (    0.52 ms per token,  1940.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.88 ms /    24 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =     817.97 ms /    10 runs   (   81.80 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1145.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Myra Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /    11 runs   (    0.17 ms per token,  5901.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.05 ms /   158 tokens (    7.45 ms per token,   134.23 tokens per second)\n",
      "llama_print_timings:        eval time =     834.81 ms /    10 runs   (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    2048.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 855 311 5624\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    19 runs   (    0.14 ms per token,  7335.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    25 tokens (   10.15 ms per token,    98.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1463.52 ms /    18 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1763.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     9 runs   (    0.13 ms per token,  7846.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.20 ms /    23 tokens (   10.92 ms per token,    91.56 tokens per second)\n",
      "llama_print_timings:        eval time =     668.30 ms /     8 runs   (   83.54 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     942.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /    11 runs   (    0.14 ms per token,  7227.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    24 tokens (   10.48 ms per token,    95.44 tokens per second)\n",
      "llama_print_timings:        eval time =     820.22 ms /    10 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1098.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cristy Robel\", \"Dr Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    15 runs   (    0.15 ms per token,  6541.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.06 ms /   178 tokens (    7.89 ms per token,   126.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.32 ms /    14 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2619.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 251 4401\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    15 runs   (    0.21 ms per token,  4665.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.77 ms /    25 tokens (   10.27 ms per token,    97.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.31 ms /    14 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1418.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     6 runs   (    0.23 ms per token,  4294.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.88 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     390.79 ms /     5 runs   (   78.16 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =     666.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     7 runs   (    0.11 ms per token,  9138.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =     497.63 ms /     6 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     765.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Dorie Baumbach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /    11 runs   (    0.30 ms per token,  3303.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.34 ms /   167 tokens (    8.29 ms per token,   120.64 tokens per second)\n",
      "llama_print_timings:        eval time =     799.78 ms /    10 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2240.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"447 249 2567\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    15 runs   (    0.32 ms per token,  3145.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.90 ms /    25 tokens (   10.04 ms per token,    99.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.40 ms /    14 runs   (   78.60 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1432.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     9 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     644.16 ms /     8 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     924.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     8 runs   (    0.15 ms per token,  6525.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =     566.90 ms /     7 runs   (   80.99 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     838.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Deidra Corkery\", \"Almeda Okuneva\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    17 runs   (    0.27 ms per token,  3750.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1612.23 ms /   202 tokens (    7.98 ms per token,   125.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1278.28 ms /    16 runs   (   79.89 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2968.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"328 659 9956\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    15 runs   (    0.27 ms per token,  3724.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.62 ms /    25 tokens (   10.06 ms per token,    99.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.39 ms /    14 runs   (   78.31 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1415.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     7 runs   (    0.15 ms per token,  6542.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.33 ms /    23 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =     484.53 ms /     6 runs   (   80.76 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     755.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6688.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    24 tokens (   10.53 ms per token,    94.96 tokens per second)\n",
      "llama_print_timings:        eval time =      78.89 ms /     1 runs   (   78.89 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     336.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Wendell Oberbrunner\", \"Dr. Ivette Wunsch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    20 runs   (    0.21 ms per token,  4698.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.22 ms /   178 tokens (    7.85 ms per token,   127.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1518.64 ms /    19 runs   (   79.93 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2995.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 595 1633\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    15 runs   (    0.17 ms per token,  5816.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.29 ms /    14 runs   (   89.16 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    1545.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     8 runs   (    0.14 ms per token,  7380.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.49 ms /    23 tokens (   10.98 ms per token,    91.09 tokens per second)\n",
      "llama_print_timings:        eval time =     569.41 ms /     7 runs   (   81.34 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     843.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     7 runs   (    0.11 ms per token,  8816.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.64 ms /    24 tokens (   10.53 ms per token,    95.00 tokens per second)\n",
      "llama_print_timings:        eval time =     485.79 ms /     6 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     754.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ethan Kutch\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /    14 runs   (    0.20 ms per token,  4931.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.10 ms /   142 tokens (    8.09 ms per token,   123.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1034.13 ms /    13 runs   (   79.55 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2235.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 126 7519\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    15 runs   (    0.25 ms per token,  4060.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.60 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.48 ms /    14 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1428.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =      78.77 ms /     1 runs   (   78.77 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     333.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     8 runs   (    0.17 ms per token,  5784.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.11 ms /    24 tokens (   10.38 ms per token,    96.34 tokens per second)\n",
      "llama_print_timings:        eval time =     569.24 ms /     7 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     840.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lupe Cassin\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /    17 runs   (    0.10 ms per token, 10041.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.27 ms /   157 tokens (    7.46 ms per token,   134.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1546.10 ms /    16 runs   (   96.63 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =    2760.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"120 506 4336\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /    15 runs   (    0.15 ms per token,  6762.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.82 ms /    25 tokens (   10.23 ms per token,    97.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.77 ms /    14 runs   (   88.06 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    1531.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"74 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     7 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.28 ms /    23 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     511.80 ms /     6 runs   (   85.30 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =     782.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6060.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.21 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =      89.74 ms /     1 runs   (   89.74 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     345.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Logan Schaden\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /    10 runs   (    0.31 ms per token,  3193.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.94 ms /   143 tokens (    8.06 ms per token,   124.03 tokens per second)\n",
      "llama_print_timings:        eval time =     699.15 ms /     9 runs   (   77.68 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1903.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"169 421 2926\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    15 runs   (    0.21 ms per token,  4766.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.15 ms /    25 tokens (   10.05 ms per token,    99.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.81 ms /    14 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1433.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6493.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =      81.67 ms /     1 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     338.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     8 runs   (    0.19 ms per token,  5358.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.35 ms /    24 tokens (   10.39 ms per token,    96.25 tokens per second)\n",
      "llama_print_timings:        eval time =     560.87 ms /     7 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     833.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jaime Sauer\", \"Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    15 runs   (    0.19 ms per token,  5360.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.00 ms /   145 tokens (    7.94 ms per token,   125.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.08 ms /    14 runs   (   83.15 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    2367.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"355 112 3923\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    15 runs   (    0.18 ms per token,  5639.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    25 tokens (   10.04 ms per token,    99.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.15 ms /    14 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1427.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     5 runs   (    0.12 ms per token,  8403.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =     321.75 ms /     4 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     584.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     8 runs   (    0.12 ms per token,  8492.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.31 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =     613.36 ms /     7 runs   (   87.62 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     883.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Reggie Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     7 runs   (    0.17 ms per token,  5775.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.03 ms /   134 tokens (    8.62 ms per token,   116.01 tokens per second)\n",
      "llama_print_timings:        eval time =     518.03 ms /     6 runs   (   86.34 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1695.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 367 0222\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /    15 runs   (    0.17 ms per token,  6000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.61 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1203.72 ms /    14 runs   (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1509.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     7 runs   (    0.17 ms per token,  6013.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.24 ms /    23 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =     522.25 ms /     6 runs   (   87.04 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     793.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     8 runs   (    0.26 ms per token,  3851.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.30 ms /    24 tokens (   10.39 ms per token,    96.27 tokens per second)\n",
      "llama_print_timings:        eval time =     566.24 ms /     7 runs   (   80.89 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     849.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Luann Hills\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    16 runs   (    0.40 ms per token,  2484.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1618.89 ms /   194 tokens (    8.34 ms per token,   119.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.32 ms /    15 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2902.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 395 1923\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    15 runs   (    0.33 ms per token,  3047.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    25 tokens (   10.11 ms per token,    98.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.62 ms /    14 runs   (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1461.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     9 runs   (    0.24 ms per token,  4249.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    23 tokens (   10.91 ms per token,    91.67 tokens per second)\n",
      "llama_print_timings:        eval time =     630.51 ms /     8 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     915.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =      81.24 ms /     1 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     339.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Meta Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     6 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.33 ms /   140 tokens (    8.17 ms per token,   122.45 tokens per second)\n",
      "llama_print_timings:        eval time =     396.83 ms /     5 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1573.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 201 4341\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    15 runs   (    0.17 ms per token,  5985.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.45 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.49 ms /    14 runs   (   84.46 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1478.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     6 runs   (    0.11 ms per token,  9049.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.68 ms /    23 tokens (   11.12 ms per token,    89.95 tokens per second)\n",
      "llama_print_timings:        eval time =     408.82 ms /     5 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     677.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.45 ms /    24 tokens (   11.60 ms per token,    86.19 tokens per second)\n",
      "llama_print_timings:        eval time =     127.37 ms /     1 runs   (  127.37 ms per token,     7.85 tokens per second)\n",
      "llama_print_timings:       total time =     432.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Louis Considine\", \"Dr. Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    19 runs   (    0.38 ms per token,  2636.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.22 ms /   159 tokens (    7.48 ms per token,   133.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1481.57 ms /    18 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2810.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"850 729 2109\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    15 runs   (    0.35 ms per token,  2829.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1286.07 ms /    14 runs   (   91.86 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =    1625.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     7 runs   (    0.29 ms per token,  3444.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     586.04 ms /     6 runs   (   97.67 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     868.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     8 runs   (    0.35 ms per token,  2867.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.24 ms /    24 tokens (   10.63 ms per token,    94.03 tokens per second)\n",
      "llama_print_timings:        eval time =     644.14 ms /     7 runs   (   92.02 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     952.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Danilo Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /     9 runs   (    0.49 ms per token,  2023.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3055.50 ms /   376 tokens (    8.13 ms per token,   123.06 tokens per second)\n",
      "llama_print_timings:        eval time =     701.92 ms /     8 runs   (   87.74 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    3816.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"359 865 0271\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /    15 runs   (    0.31 ms per token,  3271.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.43 ms /    25 tokens (   10.34 ms per token,    96.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1241.92 ms /    14 runs   (   88.71 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    1577.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5797.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.66 ms /    23 tokens (   11.07 ms per token,    90.32 tokens per second)\n",
      "llama_print_timings:        eval time =      91.74 ms /     1 runs   (   91.74 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =     353.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"health\", \"social care needs\", \"anxiety\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    15 runs   (    0.39 ms per token,  2561.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.33 ms /    24 tokens (   10.76 ms per token,    92.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.58 ms /    14 runs   (   95.18 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =    1684.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Herman Von\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     6 runs   (    0.35 ms per token,  2877.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.68 ms /   161 tokens (    8.63 ms per token,   115.85 tokens per second)\n",
      "llama_print_timings:        eval time =     412.88 ms /     5 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1832.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 889 0744\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    15 runs   (    0.43 ms per token,  2307.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.71 ms /    25 tokens (   10.11 ms per token,    98.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1317.82 ms /    14 runs   (   94.13 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =    1652.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4123.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.25 ms /    23 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =      83.38 ms /     1 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     342.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    11 runs   (    0.42 ms per token,  2366.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    24 tokens (   10.46 ms per token,    95.57 tokens per second)\n",
      "llama_print_timings:        eval time =     823.97 ms /    10 runs   (   82.40 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1148.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wade Ondricka\", \"Dr. Lloyd Wuckert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    19 runs   (    0.48 ms per token,  2083.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.95 ms /   152 tokens (    7.64 ms per token,   130.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.47 ms /    18 runs   (   81.03 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2771.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"270 156 8089\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    15 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    25 tokens (   10.08 ms per token,    99.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.98 ms /    14 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1482.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =     677.44 ms /     8 runs   (   84.68 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     986.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /     8 runs   (    0.57 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.38 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =     593.63 ms /     7 runs   (   84.80 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =     896.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Walton Conroy\", \"Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /    14 runs   (    0.33 ms per token,  3009.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1905.04 ms /   240 tokens (    7.94 ms per token,   125.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.53 ms /    13 runs   (   87.73 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    3119.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"781 485 9913\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2512.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.67 ms /    25 tokens (   10.23 ms per token,    97.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1276.11 ms /    14 runs   (   91.15 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =    1612.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.20 ms /    23 tokens (   11.10 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =      97.44 ms /     1 runs   (   97.44 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =     356.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     8 runs   (    0.34 ms per token,  2939.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    24 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =     581.05 ms /     7 runs   (   83.01 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     877.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Barney Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /     9 runs   (    0.53 ms per token,  1893.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.92 ms /   186 tokens (    7.56 ms per token,   132.20 tokens per second)\n",
      "llama_print_timings:        eval time =     633.12 ms /     8 runs   (   79.14 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2105.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"229 118 4234\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    15 runs   (    0.56 ms per token,  1789.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.89 ms /    25 tokens (   10.08 ms per token,    99.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.04 ms /    14 runs   (   79.72 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1481.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1945.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =     477.90 ms /     6 runs   (   79.65 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     776.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =      80.38 ms /     1 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     337.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Felton Ryan\", \"Doctor Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.75 ms /   158 tokens (    7.37 ms per token,   135.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1224.83 ms /    15 runs   (   81.66 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    2510.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"546 932 4334\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2366.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.55 ms /    25 tokens (   10.18 ms per token,    98.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.64 ms /    14 runs   (   83.26 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1511.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     9 runs   (    0.37 ms per token,  2728.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    23 tokens (   11.01 ms per token,    90.84 tokens per second)\n",
      "llama_print_timings:        eval time =     685.61 ms /     8 runs   (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     987.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5586.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.55 ms /    24 tokens (   10.56 ms per token,    94.66 tokens per second)\n",
      "llama_print_timings:        eval time =      85.96 ms /     1 runs   (   85.96 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     346.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ezra Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.73 ms /   139 tokens (    8.29 ms per token,   120.58 tokens per second)\n",
      "llama_print_timings:        eval time =     664.47 ms /     8 runs   (   83.06 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1876.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"326 138 7517\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    15 runs   (    0.29 ms per token,  3389.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.85 ms /    25 tokens (   10.19 ms per token,    98.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.89 ms /    14 runs   (   93.21 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =    1639.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"25-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     9 runs   (    0.28 ms per token,  3522.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.46 ms /    23 tokens (   10.93 ms per token,    91.46 tokens per second)\n",
      "llama_print_timings:        eval time =     720.46 ms /     8 runs   (   90.06 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    1018.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.80 ms /    24 tokens (   11.24 ms per token,    88.96 tokens per second)\n",
      "llama_print_timings:        eval time =     104.36 ms /     1 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =     381.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Darwin Aufderhar\", \"Dr. Clayton Jast\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    17 runs   (    0.24 ms per token,  4159.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.99 ms /   177 tokens (    7.95 ms per token,   125.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1423.40 ms /    16 runs   (   88.96 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    2953.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 946 0098\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /    15 runs   (    0.22 ms per token,  4626.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.58 ms /    25 tokens (   10.34 ms per token,    96.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1158.56 ms /    14 runs   (   82.75 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1473.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3220.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.51 ms /    23 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =      76.41 ms /     1 runs   (   76.41 ms per token,    13.09 tokens per second)\n",
      "llama_print_timings:       total time =     336.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     7 runs   (    0.22 ms per token,  4599.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.99 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =     579.74 ms /     6 runs   (   96.62 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     861.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mauro Paucek\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /    18 runs   (    0.21 ms per token,  4741.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2953.09 ms /   379 tokens (    7.79 ms per token,   128.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1515.23 ms /    17 runs   (   89.13 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    4566.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"183 236 1107\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2616.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.41 ms /    25 tokens (   10.94 ms per token,    91.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1370.65 ms /    14 runs   (   97.90 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =    1756.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5847.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.57 ms /    23 tokens (   11.11 ms per token,    89.99 tokens per second)\n",
      "llama_print_timings:        eval time =      90.60 ms /     1 runs   (   90.60 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     352.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.15 ms /    24 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =     133.96 ms /     1 runs   (  133.96 ms per token,     7.47 tokens per second)\n",
      "llama_print_timings:       total time =     414.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Odis Heidenreich\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    17 runs   (    0.49 ms per token,  2036.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.96 ms /   170 tokens (    8.31 ms per token,   120.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1359.30 ms /    16 runs   (   84.96 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    2887.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     6 runs   (    0.15 ms per token,  6586.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.72 ms /    25 tokens (   10.35 ms per token,    96.63 tokens per second)\n",
      "llama_print_timings:        eval time =     530.00 ms /     5 runs   (  106.00 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =     806.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6329.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.40 ms /    23 tokens (   11.06 ms per token,    90.41 tokens per second)\n",
      "llama_print_timings:        eval time =      86.17 ms /     1 runs   (   86.17 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     346.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2733.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =     571.44 ms /     7 runs   (   81.63 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     869.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rex Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2686.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.00 ms /   179 tokens (    7.83 ms per token,   127.68 tokens per second)\n",
      "llama_print_timings:        eval time =     657.63 ms /     8 runs   (   82.20 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    2111.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"855 236 6087\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2676.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    25 tokens (   10.09 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.61 ms /    14 runs   (   87.40 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1563.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"62-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     9 runs   (    0.29 ms per token,  3398.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.86 ms /    23 tokens (   10.99 ms per token,    90.96 tokens per second)\n",
      "llama_print_timings:        eval time =     667.88 ms /     8 runs   (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     998.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.87 ms /    24 tokens (   10.45 ms per token,    95.67 tokens per second)\n",
      "llama_print_timings:        eval time =      86.27 ms /     1 runs   (   86.27 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     343.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. My Haag\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    17 runs   (    0.37 ms per token,  2686.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.95 ms /   165 tokens (    8.64 ms per token,   115.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.52 ms /    16 runs   (   85.53 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =    2888.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"646 863 5903\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    15 runs   (    0.44 ms per token,  2253.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.62 ms /    25 tokens (   10.38 ms per token,    96.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.48 ms /    14 runs   (   84.96 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1586.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     7 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.56 ms /    23 tokens (   10.98 ms per token,    91.07 tokens per second)\n",
      "llama_print_timings:        eval time =     597.62 ms /     6 runs   (   99.60 ms per token,    10.04 tokens per second)\n",
      "llama_print_timings:       total time =     880.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /    11 runs   (    0.32 ms per token,  3170.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.17 ms /    24 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =     943.58 ms /    10 runs   (   94.36 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =    1257.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lesley Ernser\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    14 runs   (    0.32 ms per token,  3152.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.34 ms /   186 tokens (    7.60 ms per token,   131.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1052.19 ms /    13 runs   (   80.94 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2552.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 223 9424\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2704.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.87 ms /    25 tokens (   10.19 ms per token,    98.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.83 ms /    14 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1485.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     9 runs   (    0.19 ms per token,  5131.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.99 ms /    23 tokens (   11.04 ms per token,    90.55 tokens per second)\n",
      "llama_print_timings:        eval time =     785.78 ms /     8 runs   (   98.22 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =    1081.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     8 runs   (    0.32 ms per token,  3137.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    24 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =     585.85 ms /     7 runs   (   83.69 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     874.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Eusebia Sauer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    11 runs   (    0.49 ms per token,  2044.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3155.44 ms /   376 tokens (    8.39 ms per token,   119.16 tokens per second)\n",
      "llama_print_timings:        eval time =     877.22 ms /    10 runs   (   87.72 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    4105.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 704 3507\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.85 ms /    15 runs   (    0.46 ms per token,  2190.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.29 ms /    25 tokens (   10.37 ms per token,    96.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1226.95 ms /    14 runs   (   87.64 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    1596.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"72-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2635.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.65 ms /    23 tokens (   11.29 ms per token,    88.58 tokens per second)\n",
      "llama_print_timings:        eval time =     686.50 ms /     8 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     998.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\", \"Social isolation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    14 runs   (    0.23 ms per token,  4329.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.71 ms /    24 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.47 ms /    13 runs   (   89.50 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    1485.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Manual Moore\", \"Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /    13 runs   (    0.26 ms per token,  3826.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.54 ms /   180 tokens (    7.90 ms per token,   126.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1025.63 ms /    12 runs   (   85.47 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =    2522.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 591 0998\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2365.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.29 ms /    25 tokens (   10.21 ms per token,    97.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.53 ms /    14 runs   (   91.68 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =    1615.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10810.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.01 ms /    23 tokens (   11.13 ms per token,    89.84 tokens per second)\n",
      "llama_print_timings:        eval time =     105.88 ms /     1 runs   (  105.88 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =     365.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7434.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.37 ms /    24 tokens (   10.77 ms per token,    92.89 tokens per second)\n",
      "llama_print_timings:        eval time =      83.73 ms /     1 runs   (   83.73 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     347.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Isiah Lehner\", \"Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    16 runs   (    0.37 ms per token,  2669.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.20 ms /   182 tokens (    7.73 ms per token,   129.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1234.38 ms /    15 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2733.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"464 313 0197\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2648.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.15 ms /    25 tokens (   10.13 ms per token,    98.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.11 ms /    14 runs   (   84.44 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1525.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     9 runs   (    0.24 ms per token,  4147.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.08 ms /    23 tokens (   11.05 ms per token,    90.52 tokens per second)\n",
      "llama_print_timings:        eval time =     689.06 ms /     8 runs   (   86.13 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     979.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.21 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =      83.25 ms /     1 runs   (   83.25 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     342.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Colleen Kemmer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2261.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1633.29 ms /   217 tokens (    7.53 ms per token,   132.86 tokens per second)\n",
      "llama_print_timings:        eval time =     904.02 ms /    11 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    2618.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"168 761 2950\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    15 runs   (    0.36 ms per token,  2776.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.12 ms /    25 tokens (   10.16 ms per token,    98.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.91 ms /    14 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    1508.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     7 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    23 tokens (   11.00 ms per token,    90.89 tokens per second)\n",
      "llama_print_timings:        eval time =     492.81 ms /     6 runs   (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     775.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic obstructive bronchitis\", \"anemia\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    15 runs   (    0.33 ms per token,  3038.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.17 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.91 ms /    14 runs   (   89.35 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1583.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lona Cruickshank\", \"Dr. Thanh Weber\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    17 runs   (    0.37 ms per token,  2737.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.89 ms /   139 tokens (    8.48 ms per token,   117.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.91 ms /    16 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    2593.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 901 4234\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    15 runs   (    0.42 ms per token,  2376.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.24 ms /    25 tokens (   10.33 ms per token,    96.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.64 ms /    14 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1469.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4938.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.12 ms /    23 tokens (   10.92 ms per token,    91.59 tokens per second)\n",
      "llama_print_timings:        eval time =      83.53 ms /     1 runs   (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     341.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     8 runs   (    0.35 ms per token,  2821.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.07 ms /    24 tokens (   10.42 ms per token,    95.97 tokens per second)\n",
      "llama_print_timings:        eval time =     558.26 ms /     7 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     849.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Noel Herman\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    17 runs   (    0.42 ms per token,  2357.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2664.29 ms /   352 tokens (    7.57 ms per token,   132.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1343.35 ms /    16 runs   (   83.96 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    4123.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"564 185 3103\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.08 ms /    15 runs   (    0.41 ms per token,  2468.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.22 ms /    25 tokens (   10.37 ms per token,    96.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.44 ms /    14 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1508.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     9 runs   (    0.34 ms per token,  2905.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.09 ms /    23 tokens (   11.22 ms per token,    89.12 tokens per second)\n",
      "llama_print_timings:        eval time =     675.75 ms /     8 runs   (   84.47 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     989.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"anxiety\", \"domestic abuse\", \"depression\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    23 runs   (    0.40 ms per token,  2526.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.86 ms /    24 tokens (   10.83 ms per token,    92.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1841.35 ms /    22 runs   (   83.70 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    2252.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Eleonore Moore\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    15 runs   (    0.49 ms per token,  2041.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.80 ms /   185 tokens (    7.53 ms per token,   132.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.70 ms /    14 runs   (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2615.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 352 1355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    15 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.85 ms /    25 tokens (   10.11 ms per token,    98.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.68 ms /    14 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1472.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5263.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.45 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =     101.60 ms /     1 runs   (  101.60 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =     358.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /     7 runs   (    0.33 ms per token,  3004.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.54 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =     495.52 ms /     6 runs   (   82.59 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     777.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cole Monahan\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    16 runs   (    0.35 ms per token,  2830.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.64 ms /   167 tokens (    8.33 ms per token,   120.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.20 ms /    15 runs   (   86.28 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    2771.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"836 256 9640\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2349.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    25 tokens (   10.17 ms per token,    98.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.31 ms /    14 runs   (   82.52 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1498.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /     9 runs   (    0.48 ms per token,  2078.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    23 tokens (   10.99 ms per token,    91.01 tokens per second)\n",
      "llama_print_timings:        eval time =     654.98 ms /     8 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     965.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    13 runs   (    0.45 ms per token,  2245.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     982.39 ms /    12 runs   (   81.87 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1312.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Raymonde Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    10 runs   (    0.40 ms per token,  2483.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.32 ms /   191 tokens (    7.43 ms per token,   134.57 tokens per second)\n",
      "llama_print_timings:        eval time =     733.72 ms /     9 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2220.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"222 237 3271\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    15 runs   (    0.49 ms per token,  2020.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.52 ms /    25 tokens (   10.66 ms per token,    93.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.31 ms /    14 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1513.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     9 runs   (    0.29 ms per token,  3440.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.82 ms /    23 tokens (   10.99 ms per token,    90.97 tokens per second)\n",
      "llama_print_timings:        eval time =     670.14 ms /     8 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     970.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     8 runs   (    0.28 ms per token,  3631.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /    24 tokens (   10.66 ms per token,    93.83 tokens per second)\n",
      "llama_print_timings:        eval time =     581.94 ms /     7 runs   (   83.13 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     882.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Theron Langworth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /     8 runs   (    0.54 ms per token,  1866.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.89 ms /   150 tokens (    7.89 ms per token,   126.81 tokens per second)\n",
      "llama_print_timings:        eval time =     569.19 ms /     7 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1803.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 675 6694\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2365.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.69 ms /    14 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1476.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     8 runs   (    0.30 ms per token,  3329.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.00 ms /    23 tokens (   11.09 ms per token,    90.20 tokens per second)\n",
      "llama_print_timings:        eval time =     588.10 ms /     7 runs   (   84.01 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     878.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3703.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    24 tokens (   10.50 ms per token,    95.22 tokens per second)\n",
      "llama_print_timings:        eval time =      90.87 ms /     1 runs   (   90.87 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =     354.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Odis Boehm\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    15 runs   (    0.31 ms per token,  3248.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.62 ms /   161 tokens (    8.58 ms per token,   116.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1257.68 ms /    14 runs   (   89.83 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    2742.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 565 5337\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    15 runs   (    0.46 ms per token,  2158.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.58 ms /    25 tokens (   10.14 ms per token,    98.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.75 ms /    14 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1521.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /     8 runs   (    0.24 ms per token,  4108.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     577.47 ms /     7 runs   (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     865.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6600.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.67 ms /    24 tokens (   10.57 ms per token,    94.61 tokens per second)\n",
      "llama_print_timings:        eval time =      87.03 ms /     1 runs   (   87.03 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     345.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Reynaldo Marvin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    10 runs   (    0.45 ms per token,  2205.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2900.51 ms /   366 tokens (    7.92 ms per token,   126.18 tokens per second)\n",
      "llama_print_timings:        eval time =     760.64 ms /     9 runs   (   84.52 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    3726.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"686 337 6118\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    15 runs   (    0.36 ms per token,  2810.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.86 ms /    25 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.83 ms /    14 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1503.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     9 runs   (    0.29 ms per token,  3405.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.65 ms /    23 tokens (   11.12 ms per token,    89.97 tokens per second)\n",
      "llama_print_timings:        eval time =     667.61 ms /     8 runs   (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     971.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5899.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.51 ms /    24 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =      88.55 ms /     1 runs   (   88.55 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     355.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ricardo Tillman\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    17 runs   (    0.40 ms per token,  2504.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.49 ms /   172 tokens (    8.14 ms per token,   122.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.37 ms /    16 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2816.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"926 266 0702\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    15 runs   (    0.37 ms per token,  2709.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.67 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.96 ms /    14 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1492.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  4962.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.44 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =      86.91 ms /     1 runs   (   86.91 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     343.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6557.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    24 tokens (   10.54 ms per token,    94.84 tokens per second)\n",
      "llama_print_timings:        eval time =      85.22 ms /     1 runs   (   85.22 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     342.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Spencer Treutel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     9 runs   (    0.31 ms per token,  3253.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.78 ms /   136 tokens (    8.48 ms per token,   117.98 tokens per second)\n",
      "llama_print_timings:        eval time =     661.49 ms /     8 runs   (   82.69 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1860.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 396 6418\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.81 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.22 ms /    14 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1474.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     6 runs   (    0.31 ms per token,  3227.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.70 ms /    23 tokens (   10.86 ms per token,    92.11 tokens per second)\n",
      "llama_print_timings:        eval time =     406.52 ms /     5 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     686.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     8 runs   (    0.34 ms per token,  2945.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.98 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =     566.48 ms /     7 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     863.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosalba Balistreri\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    12 runs   (    0.35 ms per token,  2836.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.39 ms /   133 tokens (    8.62 ms per token,   116.02 tokens per second)\n",
      "llama_print_timings:        eval time =     887.04 ms /    11 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2106.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"877 766 2864\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    15 runs   (    0.45 ms per token,  2216.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    25 tokens (   10.07 ms per token,    99.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.68 ms /    14 runs   (   79.33 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1455.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     9 runs   (    0.34 ms per token,  2954.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.38 ms /    23 tokens (   10.84 ms per token,    92.23 tokens per second)\n",
      "llama_print_timings:        eval time =     717.19 ms /     8 runs   (   89.65 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1022.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.59 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =     101.87 ms /     1 runs   (  101.87 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =     364.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Saul Hickle\", \"Carlton Koch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /    14 runs   (    0.34 ms per token,  2908.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.98 ms /   186 tokens (    7.56 ms per token,   132.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1065.28 ms /    13 runs   (   81.94 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    2555.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"296 223 0294\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2619.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.83 ms /    25 tokens (   10.35 ms per token,    96.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.60 ms /    14 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1482.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     9 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.15 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     676.69 ms /     8 runs   (   84.59 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     964.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5319.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =      85.71 ms /     1 runs   (   85.71 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     344.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jamison Dare\", \"Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    13 runs   (    0.26 ms per token,  3787.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.32 ms /   175 tokens (    7.94 ms per token,   125.87 tokens per second)\n",
      "llama_print_timings:        eval time =     981.42 ms /    12 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    2436.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 489 5792\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2349.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.34 ms /    14 runs   (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1502.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     6 runs   (    0.27 ms per token,  3683.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    23 tokens (   10.94 ms per token,    91.38 tokens per second)\n",
      "llama_print_timings:        eval time =     411.12 ms /     5 runs   (   82.22 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     692.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8032.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.97 ms /    24 tokens (   10.71 ms per token,    93.40 tokens per second)\n",
      "llama_print_timings:        eval time =      95.25 ms /     1 runs   (   95.25 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =     357.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alphonse Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    12 runs   (    0.44 ms per token,  2291.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.65 ms /   148 tokens (    7.87 ms per token,   127.08 tokens per second)\n",
      "llama_print_timings:        eval time =     917.28 ms /    11 runs   (   83.39 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2154.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"305 184 3465\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.05 ms /    14 runs   (   80.72 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1470.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     9 runs   (    0.32 ms per token,  3150.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    23 tokens (   10.88 ms per token,    91.90 tokens per second)\n",
      "llama_print_timings:        eval time =     642.72 ms /     8 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     934.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4576.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.24 ms /    24 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =      82.95 ms /     1 runs   (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     338.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Roberta Jenkins\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2388.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.97 ms /   163 tokens (    8.43 ms per token,   118.63 tokens per second)\n",
      "llama_print_timings:        eval time =     667.47 ms /     8 runs   (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2097.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"638 551 4355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    15 runs   (    0.34 ms per token,  2970.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.33 ms /    25 tokens (   10.29 ms per token,    97.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.54 ms /    14 runs   (   90.04 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    1593.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     4 runs   (    0.26 ms per token,  3853.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.68 ms /    23 tokens (   10.99 ms per token,    91.02 tokens per second)\n",
      "llama_print_timings:        eval time =     241.66 ms /     3 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     511.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    11 runs   (    0.35 ms per token,  2851.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.11 ms /    24 tokens (   10.84 ms per token,    92.27 tokens per second)\n",
      "llama_print_timings:        eval time =     944.67 ms /    10 runs   (   94.47 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =    1269.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Garth Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    10 runs   (    0.43 ms per token,  2318.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.95 ms /   163 tokens (    8.53 ms per token,   117.19 tokens per second)\n",
      "llama_print_timings:        eval time =     730.65 ms /     9 runs   (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    2180.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 979 6136\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    15 runs   (    0.44 ms per token,  2259.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.72 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.28 ms /    14 runs   (   81.38 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1483.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     7 runs   (    0.36 ms per token,  2779.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     480.72 ms /     6 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     770.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    17 runs   (    0.31 ms per token,  3273.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1348.05 ms /    16 runs   (   84.25 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    1688.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Micaela McLaughlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    13 runs   (    0.34 ms per token,  2906.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.60 ms /   202 tokens (    8.25 ms per token,   121.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.70 ms /    12 runs   (  104.31 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =    3007.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"872 109 4607\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    15 runs   (    0.35 ms per token,  2845.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.72 ms /    25 tokens (   10.39 ms per token,    96.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1533.40 ms /    14 runs   (  109.53 ms per token,     9.13 tokens per second)\n",
      "llama_print_timings:       total time =    1881.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.37 ms per token,  2734.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.29 ms /    23 tokens (   12.36 ms per token,    80.90 tokens per second)\n",
      "llama_print_timings:        eval time =     773.79 ms /     8 runs   (   96.72 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    1109.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    13 runs   (    0.52 ms per token,  1913.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     298.97 ms /    24 tokens (   12.46 ms per token,    80.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.08 ms /    12 runs   (   98.01 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =    1557.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Tammara McDermott\", \"Doctor Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    21 runs   (    0.35 ms per token,  2819.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1281.66 ms /   157 tokens (    8.16 ms per token,   122.50 tokens per second)\n",
      "llama_print_timings:        eval time =    2282.36 ms /    20 runs   (  114.12 ms per token,     8.76 tokens per second)\n",
      "llama_print_timings:       total time =    3701.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"752 354 8769\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    15 runs   (    0.36 ms per token,  2799.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.71 ms /    25 tokens (   11.99 ms per token,    83.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1552.22 ms /    14 runs   (  110.87 ms per token,     9.02 tokens per second)\n",
      "llama_print_timings:       total time =    1935.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     6 runs   (    0.35 ms per token,  2854.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.09 ms /    23 tokens (   13.00 ms per token,    76.90 tokens per second)\n",
      "llama_print_timings:        eval time =     614.35 ms /     5 runs   (  122.87 ms per token,     8.14 tokens per second)\n",
      "llama_print_timings:       total time =     943.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     8 runs   (    0.22 ms per token,  4522.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     299.21 ms /    24 tokens (   12.47 ms per token,    80.21 tokens per second)\n",
      "llama_print_timings:        eval time =     723.63 ms /     7 runs   (  103.38 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1057.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Daryl Rosenbaum\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     8 runs   (    0.36 ms per token,  2778.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.64 ms /   140 tokens (    8.42 ms per token,   118.78 tokens per second)\n",
      "llama_print_timings:        eval time =     558.26 ms /     7 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1786.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 122 3984\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    15 runs   (    0.44 ms per token,  2273.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.17 ms /    25 tokens (   10.17 ms per token,    98.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.36 ms /    14 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1452.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.82 ms /    23 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =      97.84 ms /     1 runs   (   97.84 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =     353.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.62 ms /    24 tokens (   10.40 ms per token,    96.15 tokens per second)\n",
      "llama_print_timings:        eval time =      84.73 ms /     1 runs   (   84.73 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =     339.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ezekiel Bogan\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    15 runs   (    0.36 ms per token,  2767.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2659.19 ms /   349 tokens (    7.62 ms per token,   131.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1338.15 ms /    14 runs   (   95.58 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    4089.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 954 2980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.70 ms /    15 runs   (    0.38 ms per token,  2632.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     306.29 ms /    25 tokens (   12.25 ms per token,    81.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1441.79 ms /    14 runs   (  102.98 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1836.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6250.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.74 ms /    23 tokens (   11.16 ms per token,    89.58 tokens per second)\n",
      "llama_print_timings:        eval time =     108.58 ms /     1 runs   (  108.58 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =     371.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     8 runs   (    0.33 ms per token,  3068.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     305.52 ms /    24 tokens (   12.73 ms per token,    78.55 tokens per second)\n",
      "llama_print_timings:        eval time =     863.55 ms /     7 runs   (  123.36 ms per token,     8.11 tokens per second)\n",
      "llama_print_timings:       total time =    1208.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Jena Ruecker\", \"doctor Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    21 runs   (    0.27 ms per token,  3668.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.41 ms /   136 tokens (    8.43 ms per token,   118.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1650.99 ms /    20 runs   (   82.55 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    2899.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"521 691 9427\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    15 runs   (    0.34 ms per token,  2900.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1522.46 ms /    14 runs   (  108.75 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =    1853.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     7 runs   (    0.27 ms per token,  3668.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.36 ms /    23 tokens (   12.06 ms per token,    82.92 tokens per second)\n",
      "llama_print_timings:        eval time =     496.18 ms /     6 runs   (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     808.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    11 runs   (    0.29 ms per token,  3415.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.82 ms /    24 tokens (   12.24 ms per token,    81.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.08 ms /    10 runs   (  100.31 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =    1346.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clarence Jast\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    17 runs   (    0.30 ms per token,  3308.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.64 ms /   184 tokens (    7.63 ms per token,   130.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1334.02 ms /    16 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2832.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"285 135 3102\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    15 runs   (    0.31 ms per token,  3201.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.07 ms /    25 tokens (   10.08 ms per token,    99.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.96 ms /    14 runs   (   81.57 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1470.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     9 runs   (    0.28 ms per token,  3519.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.64 ms /    23 tokens (   10.94 ms per token,    91.40 tokens per second)\n",
      "llama_print_timings:        eval time =     646.37 ms /     8 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     941.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     8 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =     572.98 ms /     7 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     863.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mi Rogahn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /     9 runs   (    0.34 ms per token,  2910.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.04 ms /   153 tokens (    7.94 ms per token,   125.92 tokens per second)\n",
      "llama_print_timings:        eval time =     647.46 ms /     8 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1907.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"295 375 7998\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    15 runs   (    0.40 ms per token,  2515.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.62 ms /    25 tokens (   10.18 ms per token,    98.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.43 ms /    14 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1456.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     7 runs   (    0.32 ms per token,  3119.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    23 tokens (   10.93 ms per token,    91.52 tokens per second)\n",
      "llama_print_timings:        eval time =     476.48 ms /     6 runs   (   79.41 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     759.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4597.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =      83.82 ms /     1 runs   (   83.82 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     341.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Shira Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    10 runs   (    0.32 ms per token,  3121.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.03 ms /   155 tokens (    7.46 ms per token,   133.96 tokens per second)\n",
      "llama_print_timings:        eval time =     720.58 ms /     9 runs   (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1934.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"798 647 4893\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    15 runs   (    0.32 ms per token,  3111.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.63 ms /    14 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1454.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"41 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     7 runs   (    0.48 ms per token,  2063.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.94 ms /    23 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =     480.52 ms /     6 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     779.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2683.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     571.72 ms /     7 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     872.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Christina Treutel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    11 runs   (    0.38 ms per token,  2613.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1872.78 ms /   228 tokens (    8.21 ms per token,   121.74 tokens per second)\n",
      "llama_print_timings:        eval time =     837.13 ms /    10 runs   (   83.71 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    2776.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"874 976 7362\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2702.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.83 ms /    25 tokens (   10.31 ms per token,    96.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.38 ms /    14 runs   (   89.67 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1605.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     9 runs   (    0.36 ms per token,  2805.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.89 ms /    23 tokens (   10.95 ms per token,    91.31 tokens per second)\n",
      "llama_print_timings:        eval time =     658.35 ms /     8 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     963.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2574.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.04 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =      80.12 ms /     1 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     346.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marquis Pfeffer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     8 runs   (    0.50 ms per token,  1992.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.20 ms /   176 tokens (    7.90 ms per token,   126.51 tokens per second)\n",
      "llama_print_timings:        eval time =     581.47 ms /     7 runs   (   83.07 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    2032.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 912 7729\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    15 runs   (    0.56 ms per token,  1791.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.91 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.48 ms /    14 runs   (   80.25 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1492.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /     8 runs   (    0.59 ms per token,  1687.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    23 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     550.62 ms /     7 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     873.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1572.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.55 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =     469.31 ms /     6 runs   (   78.22 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =     781.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Norman Littel\", \"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.28 ms /    15 runs   (    0.69 ms per token,  1458.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.60 ms /   146 tokens (    7.96 ms per token,   125.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.78 ms /    14 runs   (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2396.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"605 825 5445\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    15 runs   (    0.52 ms per token,  1912.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.61 ms /    14 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1491.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     2 runs   (    0.41 ms per token,  2466.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =      79.40 ms /     1 runs   (   79.40 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     339.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"medical conditions\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     6 runs   (    0.51 ms per token,  1977.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =     412.25 ms /     5 runs   (   82.45 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     697.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Susan Cummings\", \"Doctor Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    19 runs   (    0.43 ms per token,  2330.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.38 ms /   191 tokens (    7.44 ms per token,   134.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1456.25 ms /    18 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    3016.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"354 521 2431\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    15 runs   (    0.47 ms per token,  2142.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.46 ms /    25 tokens (   10.18 ms per token,    98.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.17 ms /    14 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1486.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2604.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.89 ms /    23 tokens (   11.08 ms per token,    90.23 tokens per second)\n",
      "llama_print_timings:        eval time =      81.15 ms /     1 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     349.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     2 runs   (    0.35 ms per token,  2894.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.82 ms /    24 tokens (   10.53 ms per token,    94.93 tokens per second)\n",
      "llama_print_timings:        eval time =      80.44 ms /     1 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     343.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rudolf Schmitt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     8 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2621.01 ms /   331 tokens (    7.92 ms per token,   126.29 tokens per second)\n",
      "llama_print_timings:        eval time =     597.32 ms /     7 runs   (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    3268.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"528 628 8338\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2575.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.92 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.17 ms /    14 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1579.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2712.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.60 ms /    23 tokens (   11.29 ms per token,    88.60 tokens per second)\n",
      "llama_print_timings:        eval time =     689.99 ms /     8 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1002.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    11 runs   (    0.50 ms per token,  1998.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.88 ms /    24 tokens (   10.70 ms per token,    93.43 tokens per second)\n",
      "llama_print_timings:        eval time =     859.10 ms /    10 runs   (   85.91 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1189.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lamont Kuhn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     9 runs   (    0.36 ms per token,  2807.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.40 ms /   177 tokens (    7.95 ms per token,   125.76 tokens per second)\n",
      "llama_print_timings:        eval time =     725.43 ms /     8 runs   (   90.68 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =    2184.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"883 864 0266\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2618.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.83 ms /    25 tokens (   10.23 ms per token,    97.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.28 ms /    14 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1496.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     7 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    23 tokens (   10.99 ms per token,    91.00 tokens per second)\n",
      "llama_print_timings:        eval time =     480.30 ms /     6 runs   (   80.05 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     779.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /     9 runs   (    0.61 ms per token,  1642.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.08 ms /    24 tokens (   10.75 ms per token,    93.00 tokens per second)\n",
      "llama_print_timings:        eval time =     660.04 ms /     8 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     992.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Yolanda Wuckert\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.50 ms /    19 runs   (    0.61 ms per token,  1652.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.63 ms /   156 tokens (    7.52 ms per token,   132.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1472.11 ms /    18 runs   (   81.78 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    2810.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"452 999 2855\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2360.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.79 ms /    25 tokens (   10.15 ms per token,    98.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.30 ms /    14 runs   (   87.16 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    1564.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /     7 runs   (    0.33 ms per token,  3003.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.78 ms /    23 tokens (   11.21 ms per token,    89.22 tokens per second)\n",
      "llama_print_timings:        eval time =     547.97 ms /     6 runs   (   91.33 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     841.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chronic Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     8 runs   (    0.48 ms per token,  2104.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =     575.38 ms /     7 runs   (   82.20 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     881.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Calvin Stehr\", \"Dr. Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    18 runs   (    0.42 ms per token,  2378.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.46 ms /   207 tokens (    8.01 ms per token,   124.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1389.15 ms /    17 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    3166.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"749 831 1277\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.75 ms /    15 runs   (    0.58 ms per token,  1714.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.83 ms /    25 tokens (   10.39 ms per token,    96.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1188.42 ms /    14 runs   (   84.89 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    1572.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     9 runs   (    0.37 ms per token,  2727.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.15 ms /    23 tokens (   11.31 ms per token,    88.41 tokens per second)\n",
      "llama_print_timings:        eval time =     712.52 ms /     8 runs   (   89.07 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1033.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.23 ms per token,  4291.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.04 ms /    24 tokens (   11.00 ms per token,    90.90 tokens per second)\n",
      "llama_print_timings:        eval time =      88.57 ms /     1 runs   (   88.57 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     360.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rudolf Prohaska\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    17 runs   (    0.37 ms per token,  2694.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.36 ms /   140 tokens (    8.35 ms per token,   119.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1340.33 ms /    16 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    2606.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"279 306 7622\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2043.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.93 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.59 ms /    14 runs   (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1502.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     2 runs   (    0.36 ms per token,  2789.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.59 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =      83.00 ms /     1 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     343.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.28 ms per token,  3616.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.98 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =      78.47 ms /     1 runs   (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     337.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Galen Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     7 runs   (    0.47 ms per token,  2130.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.30 ms /   173 tokens (    8.02 ms per token,   124.70 tokens per second)\n",
      "llama_print_timings:        eval time =     479.61 ms /     6 runs   (   79.93 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1917.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 265 1339\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    15 runs   (    0.43 ms per token,  2309.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.28 ms /    25 tokens (   10.21 ms per token,    97.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.78 ms /    14 runs   (   80.98 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1488.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     7 runs   (    0.53 ms per token,  1894.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.09 ms /    23 tokens (   11.00 ms per token,    90.87 tokens per second)\n",
      "llama_print_timings:        eval time =     493.82 ms /     6 runs   (   82.30 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     793.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     8 runs   (    0.38 ms per token,  2609.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    24 tokens (   10.44 ms per token,    95.79 tokens per second)\n",
      "llama_print_timings:        eval time =     600.12 ms /     7 runs   (   85.73 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     896.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms.\", \"Andrea Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    13 runs   (    0.50 ms per token,  2007.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.49 ms /   188 tokens (    7.56 ms per token,   132.35 tokens per second)\n",
      "llama_print_timings:        eval time =     980.57 ms /    12 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    2483.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 909 5156\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    15 runs   (    0.49 ms per token,  2061.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.81 ms /    25 tokens (   10.31 ms per token,    96.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1202.53 ms /    14 runs   (   85.89 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1547.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     2 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.05 ms /    23 tokens (   11.26 ms per token,    88.79 tokens per second)\n",
      "llama_print_timings:        eval time =      83.55 ms /     1 runs   (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     353.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     8 runs   (    0.57 ms per token,  1758.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.78 ms /    24 tokens (   10.78 ms per token,    92.74 tokens per second)\n",
      "llama_print_timings:        eval time =     582.28 ms /     7 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     896.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms Terrell Feest\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     9 runs   (    0.40 ms per token,  2501.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2133.80 ms /   265 tokens (    8.05 ms per token,   124.19 tokens per second)\n",
      "llama_print_timings:        eval time =     679.45 ms /     8 runs   (   84.93 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    2871.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 546 5193\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    15 runs   (    0.50 ms per token,  1981.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.17 ms /    25 tokens (   10.21 ms per token,    97.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1372.07 ms /    14 runs   (   98.00 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =    1715.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     9 runs   (    0.30 ms per token,  3372.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.30 ms /    23 tokens (   11.36 ms per token,    88.02 tokens per second)\n",
      "llama_print_timings:        eval time =     686.36 ms /     8 runs   (   85.80 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     993.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     8 runs   (    0.35 ms per token,  2847.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.16 ms /    24 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =     597.06 ms /     7 runs   (   85.29 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =     900.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kathryne Wolff\", \"Doctor Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    16 runs   (    0.55 ms per token,  1812.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.93 ms /   169 tokens (    8.19 ms per token,   122.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1240.52 ms /    15 runs   (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    2760.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"790 291 9512\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    15 runs   (    0.49 ms per token,  2024.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.00 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.48 ms /    14 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1514.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     7 runs   (    0.48 ms per token,  2091.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.05 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     487.80 ms /     6 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     789.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /     8 runs   (    0.53 ms per token,  1895.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    24 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =     565.93 ms /     7 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     886.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Christopher Crona\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /     8 runs   (    0.54 ms per token,  1843.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.91 ms /   156 tokens (    7.44 ms per token,   134.49 tokens per second)\n",
      "llama_print_timings:        eval time =     627.58 ms /     7 runs   (   89.65 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1869.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"770 816 8518\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      21.03 ms /    15 runs   (    1.40 ms per token,   713.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.82 ms /    25 tokens (   10.07 ms per token,    99.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.63 ms /    14 runs   (   84.97 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1577.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     2 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    23 tokens (   10.92 ms per token,    91.60 tokens per second)\n",
      "llama_print_timings:        eval time =      93.89 ms /     1 runs   (   93.89 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =     364.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.76 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =      78.71 ms /     1 runs   (   78.71 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     340.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Melvin Tillman\", \"Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2293.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.07 ms /   160 tokens (    7.16 ms per token,   139.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.78 ms /    14 runs   (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    2408.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"539 593 8988\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    15 runs   (    0.55 ms per token,  1804.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.07 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.82 ms /    14 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    1524.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     7 runs   (    0.42 ms per token,  2394.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     508.54 ms /     6 runs   (   84.76 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =     807.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /    11 runs   (    0.37 ms per token,  2738.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    24 tokens (   10.60 ms per token,    94.31 tokens per second)\n",
      "llama_print_timings:        eval time =     903.08 ms /    10 runs   (   90.31 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1225.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Duane Abernathy\", \"Rochell Stehr\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    18 runs   (    0.45 ms per token,  2219.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1667.74 ms /   220 tokens (    7.58 ms per token,   131.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1384.20 ms /    17 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    3186.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"111 385 3040\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    15 runs   (    0.61 ms per token,  1641.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    25 tokens (   10.16 ms per token,    98.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.50 ms /    14 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1503.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     2 runs   (    0.47 ms per token,  2120.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.72 ms /    23 tokens (   10.94 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =      78.98 ms /     1 runs   (   78.98 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     343.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.33 ms per token,  3058.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.08 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =      81.48 ms /     1 runs   (   81.48 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     343.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ervin Renner\", \"Dr. Tereasa Mueller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    16 runs   (    0.41 ms per token,  2436.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.20 ms /   150 tokens (    7.75 ms per token,   128.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1222.00 ms /    15 runs   (   81.47 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2499.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 126 8977\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    15 runs   (    0.42 ms per token,  2354.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.81 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.20 ms /    14 runs   (   79.59 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1461.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     8 runs   (    0.34 ms per token,  2952.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.81 ms /    23 tokens (   10.95 ms per token,    91.34 tokens per second)\n",
      "llama_print_timings:        eval time =     576.17 ms /     7 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     867.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    12 runs   (    0.60 ms per token,  1678.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    24 tokens (   10.42 ms per token,    95.93 tokens per second)\n",
      "llama_print_timings:        eval time =     879.16 ms /    11 runs   (   79.92 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1222.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bryce D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /    11 runs   (    0.40 ms per token,  2509.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1628.46 ms /   208 tokens (    7.83 ms per token,   127.73 tokens per second)\n",
      "llama_print_timings:        eval time =     813.88 ms /    10 runs   (   81.39 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2508.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"493 447 7578\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    15 runs   (    0.50 ms per token,  2008.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.14 ms /    25 tokens (   10.17 ms per token,    98.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.35 ms /    14 runs   (   86.02 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1559.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /     9 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     280.99 ms /    23 tokens (   12.22 ms per token,    81.85 tokens per second)\n",
      "llama_print_timings:        eval time =     793.36 ms /     8 runs   (   99.17 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =    1145.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"part-time employment\", \"severe anxiety\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    14 runs   (    0.59 ms per token,  1706.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.48 ms /    24 tokens (   10.69 ms per token,    93.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.58 ms /    13 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1425.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nikita Murphy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     8 runs   (    0.41 ms per token,  2435.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.38 ms /   134 tokens (    8.65 ms per token,   115.58 tokens per second)\n",
      "llama_print_timings:        eval time =     591.94 ms /     7 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    1795.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 419 4980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    15 runs   (    0.61 ms per token,  1629.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.21 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.88 ms /    14 runs   (   80.35 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1496.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     7 runs   (    0.49 ms per token,  2030.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =     476.19 ms /     6 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     774.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     8 runs   (    0.46 ms per token,  2193.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    24 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =     579.91 ms /     7 runs   (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     870.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leslie Osinski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    10 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1685.98 ms /   197 tokens (    8.56 ms per token,   116.85 tokens per second)\n",
      "llama_print_timings:        eval time =     784.58 ms /     9 runs   (   87.18 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    2527.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"349 161 3928\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    15 runs   (    0.42 ms per token,  2361.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.21 ms /    25 tokens (   10.33 ms per token,    96.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.50 ms /    14 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1555.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2358.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =      80.60 ms /     1 runs   (   80.60 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     343.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Respiratory Function\", \"Respiratory Therapy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    16 runs   (    0.50 ms per token,  2018.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.48 ms /    24 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1330.51 ms /    15 runs   (   88.70 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    1699.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ignacio Becker\", \"Doctor Kim Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2476.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.55 ms /   141 tokens (    8.44 ms per token,   118.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1318.53 ms /    16 runs   (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2630.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"873 251 9754\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    15 runs   (    0.41 ms per token,  2461.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.57 ms /    25 tokens (   10.10 ms per token,    98.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.17 ms /    14 runs   (   82.44 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1499.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     7 runs   (    0.46 ms per token,  2182.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     493.47 ms /     6 runs   (   82.24 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     785.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =      79.50 ms /     1 runs   (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     342.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Zenobia Legros\", \"Reggie Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    18 runs   (    0.48 ms per token,  2093.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.80 ms /   182 tokens (    7.66 ms per token,   130.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1410.65 ms /    17 runs   (   82.98 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    2936.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"173 622 0471\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.14 ms /    15 runs   (    0.54 ms per token,  1841.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.89 ms /    25 tokens (   10.32 ms per token,    96.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.34 ms /    14 runs   (   79.74 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1500.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     8 runs   (    0.38 ms per token,  2640.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.86 ms /    23 tokens (   11.12 ms per token,    89.89 tokens per second)\n",
      "llama_print_timings:        eval time =     560.12 ms /     7 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     866.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     8 runs   (    0.39 ms per token,  2538.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.38 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =     562.76 ms /     7 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     868.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alphonse Simonis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    10 runs   (    0.48 ms per token,  2096.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.51 ms /   139 tokens (    8.41 ms per token,   118.95 tokens per second)\n",
      "llama_print_timings:        eval time =     726.21 ms /     9 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1969.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"278 139 8298\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    15 runs   (    0.50 ms per token,  1997.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.90 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.86 ms /    14 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1518.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     7 runs   (    0.30 ms per token,  3308.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    23 tokens (   10.95 ms per token,    91.35 tokens per second)\n",
      "llama_print_timings:        eval time =     491.20 ms /     6 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     781.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3115.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    24 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =      79.30 ms /     1 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     343.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mafalda Shanahan\", \"Dr. Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    21 runs   (    0.45 ms per token,  2216.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.92 ms /   148 tokens (    7.81 ms per token,   128.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1661.32 ms /    20 runs   (   83.07 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    2950.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"189 932 0941\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    15 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    25 tokens (   10.05 ms per token,    99.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1230.57 ms /    14 runs   (   87.90 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1587.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /     9 runs   (    0.52 ms per token,  1930.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    23 tokens (   10.94 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.13 ms /     8 runs   (   82.27 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     980.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.08 ms /    24 tokens (   10.63 ms per token,    94.09 tokens per second)\n",
      "llama_print_timings:        eval time =      78.04 ms /     1 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =     346.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rhett Fahey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    10 runs   (    0.52 ms per token,  1909.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.79 ms /   154 tokens (    7.56 ms per token,   132.33 tokens per second)\n",
      "llama_print_timings:        eval time =     712.34 ms /     9 runs   (   79.15 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1959.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"533 386 3196\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    15 runs   (    0.52 ms per token,  1935.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.70 ms /    25 tokens (   10.39 ms per token,    96.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.62 ms /    14 runs   (   81.54 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1513.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     7 runs   (    0.41 ms per token,  2462.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.53 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     481.65 ms /     6 runs   (   80.28 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     776.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2551.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.57 ms /    24 tokens (   10.52 ms per token,    95.02 tokens per second)\n",
      "llama_print_timings:        eval time =      80.75 ms /     1 runs   (   80.75 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     344.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lane Cummerata\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    18 runs   (    0.41 ms per token,  2436.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.08 ms /   168 tokens (    8.32 ms per token,   120.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1371.27 ms /    17 runs   (   80.66 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2886.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"469 664 4984\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.91 ms /    15 runs   (    0.46 ms per token,  2170.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.65 ms /    25 tokens (   10.11 ms per token,    98.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1183.48 ms /    14 runs   (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    1532.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     7 runs   (    0.37 ms per token,  2731.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.12 ms /    23 tokens (   11.57 ms per token,    86.43 tokens per second)\n",
      "llama_print_timings:        eval time =     555.75 ms /     6 runs   (   92.63 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     863.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     2 runs   (    0.33 ms per token,  3039.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.50 ms /    24 tokens (   10.73 ms per token,    93.20 tokens per second)\n",
      "llama_print_timings:        eval time =      81.73 ms /     1 runs   (   81.73 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     348.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Otilia Keeling\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    19 runs   (    0.48 ms per token,  2062.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.48 ms /   145 tokens (    7.96 ms per token,   125.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1423.88 ms /    18 runs   (   79.10 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2724.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"755 783 9490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.55 ms /    15 runs   (    0.57 ms per token,  1754.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    25 tokens (   10.05 ms per token,    99.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.39 ms /    14 runs   (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1468.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     2 runs   (    0.28 ms per token,  3603.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    23 tokens (   10.88 ms per token,    91.90 tokens per second)\n",
      "llama_print_timings:        eval time =      77.78 ms /     1 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =     337.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /     8 runs   (    0.59 ms per token,  1682.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     550.67 ms /     7 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     860.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rickie Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    10 runs   (    0.45 ms per token,  2221.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.98 ms /   137 tokens (    8.34 ms per token,   119.97 tokens per second)\n",
      "llama_print_timings:        eval time =     723.16 ms /     9 runs   (   80.35 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1943.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"555 387 7506\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    15 runs   (    0.55 ms per token,  1822.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    25 tokens (   10.02 ms per token,    99.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.62 ms /    14 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1474.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2608.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.50 ms /    23 tokens (   10.98 ms per token,    91.09 tokens per second)\n",
      "llama_print_timings:        eval time =     667.53 ms /     8 runs   (   83.44 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     976.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2554.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =      85.66 ms /     1 runs   (   85.66 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     347.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Anna Hintz\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.14 ms /    17 runs   (    0.36 ms per token,  2770.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.29 ms /   164 tokens (    8.46 ms per token,   118.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.20 ms /    16 runs   (   81.58 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2796.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"671 974 2423\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    15 runs   (    0.52 ms per token,  1914.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.86 ms /    25 tokens (   10.23 ms per token,    97.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.18 ms /    14 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1510.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     7 runs   (    0.44 ms per token,  2286.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    23 tokens (   10.98 ms per token,    91.12 tokens per second)\n",
      "llama_print_timings:        eval time =     499.13 ms /     6 runs   (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     794.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.49 ms per token,  2055.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.06 ms /    24 tokens (   10.71 ms per token,    93.36 tokens per second)\n",
      "llama_print_timings:        eval time =      83.89 ms /     1 runs   (   83.89 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     350.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kathryne Ullrich\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    10 runs   (    0.55 ms per token,  1816.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.18 ms /   163 tokens (    8.60 ms per token,   116.25 tokens per second)\n",
      "llama_print_timings:        eval time =     722.23 ms /     9 runs   (   80.25 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    2205.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 688 1306\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    15 runs   (    0.55 ms per token,  1830.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.28 ms /    25 tokens (   10.17 ms per token,    98.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.39 ms /    14 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1491.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.48 ms per token,  2066.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.77 ms /    23 tokens (   11.25 ms per token,    88.88 tokens per second)\n",
      "llama_print_timings:        eval time =      81.92 ms /     1 runs   (   81.92 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     352.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6006.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.55 ms /    24 tokens (   10.56 ms per token,    94.66 tokens per second)\n",
      "llama_print_timings:        eval time =      89.17 ms /     1 runs   (   89.17 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =     350.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stephen Collier\", \"Bernie Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    16 runs   (    0.44 ms per token,  2256.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.47 ms /   194 tokens (    8.46 ms per token,   118.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.02 ms /    15 runs   (   81.53 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2985.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"784 279 6550\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    15 runs   (    0.46 ms per token,  2155.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.27 ms /    25 tokens (   10.17 ms per token,    98.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.42 ms /    14 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1487.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1652.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    23 tokens (   11.13 ms per token,    89.82 tokens per second)\n",
      "llama_print_timings:        eval time =     475.19 ms /     6 runs   (   79.20 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     792.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3231.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    24 tokens (   10.55 ms per token,    94.76 tokens per second)\n",
      "llama_print_timings:        eval time =      78.25 ms /     1 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =     341.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Preston Vandervort\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    16 runs   (    0.52 ms per token,  1921.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.73 ms /   183 tokens (    7.65 ms per token,   130.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1216.73 ms /    15 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2751.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 851 4936\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    15 runs   (    0.64 ms per token,  1558.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.31 ms /    25 tokens (   10.13 ms per token,    98.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.45 ms /    14 runs   (   78.46 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1485.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5970.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.46 ms /    23 tokens (   10.98 ms per token,    91.10 tokens per second)\n",
      "llama_print_timings:        eval time =      85.69 ms /     1 runs   (   85.69 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     348.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    11 runs   (    0.65 ms per token,  1547.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.19 ms /    24 tokens (   10.55 ms per token,    94.79 tokens per second)\n",
      "llama_print_timings:        eval time =     816.55 ms /    10 runs   (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1164.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tatyana Haag\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /     8 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.38 ms /   146 tokens (    7.95 ms per token,   125.82 tokens per second)\n",
      "llama_print_timings:        eval time =     546.48 ms /     7 runs   (   78.07 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1775.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 683 8591\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    15 runs   (    0.58 ms per token,  1718.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.23 ms /    25 tokens (   10.21 ms per token,    97.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.28 ms /    14 runs   (   80.31 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1501.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2516.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.39 ms /    23 tokens (   10.97 ms per token,    91.13 tokens per second)\n",
      "llama_print_timings:        eval time =     633.19 ms /     8 runs   (   79.15 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     958.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     2 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.09 ms /    24 tokens (   10.80 ms per token,    92.63 tokens per second)\n",
      "llama_print_timings:        eval time =      84.07 ms /     1 runs   (   84.07 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     353.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Suk Padberg\", \"Dr.\", \"Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.65 ms /    21 runs   (    0.65 ms per token,  1538.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.27 ms /   170 tokens (    8.20 ms per token,   121.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1574.18 ms /    20 runs   (   78.71 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    3166.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"710 375 0519\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    15 runs   (    0.66 ms per token,  1512.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    25 tokens (   10.14 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.82 ms /    14 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1488.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.37 ms per token,  2734.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.08 ms /    23 tokens (   11.00 ms per token,    90.88 tokens per second)\n",
      "llama_print_timings:        eval time =     632.26 ms /     8 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =     946.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    11 runs   (    0.49 ms per token,  2026.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    24 tokens (   10.48 ms per token,    95.44 tokens per second)\n",
      "llama_print_timings:        eval time =     813.70 ms /    10 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1152.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alvaro Lesch\", \"Dr. Randy Bergstrom\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.88 ms /    19 runs   (    0.57 ms per token,  1745.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.99 ms /   155 tokens (    7.51 ms per token,   133.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1418.36 ms /    18 runs   (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    2758.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"574 614 8059\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    15 runs   (    0.54 ms per token,  1855.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.99 ms /    25 tokens (   10.12 ms per token,    98.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.97 ms /    14 runs   (   79.07 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1486.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /     9 runs   (    0.52 ms per token,  1936.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    23 tokens (   10.93 ms per token,    91.52 tokens per second)\n",
      "llama_print_timings:        eval time =     627.06 ms /     8 runs   (   78.38 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     955.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     8 runs   (    0.53 ms per token,  1887.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.64 ms /    24 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =     558.28 ms /     7 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     865.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Daryl Dach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.66 ms /    10 runs   (    0.47 ms per token,  2148.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.13 ms /   171 tokens (    8.10 ms per token,   123.45 tokens per second)\n",
      "llama_print_timings:        eval time =     712.55 ms /     9 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2174.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 582 727 9617\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.53 ms /    19 runs   (    0.61 ms per token,  1648.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.26 ms /    25 tokens (   10.13 ms per token,    98.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1435.70 ms /    18 runs   (   79.76 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1844.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     7 runs   (    0.48 ms per token,  2102.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.22 ms /    23 tokens (   11.27 ms per token,    88.73 tokens per second)\n",
      "llama_print_timings:        eval time =     493.65 ms /     6 runs   (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     804.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     2 runs   (    0.30 ms per token,  3361.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    24 tokens (   10.50 ms per token,    95.27 tokens per second)\n",
      "llama_print_timings:        eval time =      80.11 ms /     1 runs   (   80.11 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     342.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jaye Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    10 runs   (    0.41 ms per token,  2433.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.59 ms /   134 tokens (    8.55 ms per token,   116.97 tokens per second)\n",
      "llama_print_timings:        eval time =     716.46 ms /     9 runs   (   79.61 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1934.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"484 719 8232\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2162.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.38 ms /    25 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.61 ms /    14 runs   (   79.90 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1489.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /     9 runs   (    0.47 ms per token,  2120.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     634.43 ms /     8 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     951.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /     8 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =     552.43 ms /     7 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     869.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leigh Mosciski\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    16 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2999.53 ms /   373 tokens (    8.04 ms per token,   124.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1275.17 ms /    15 runs   (   85.01 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    4410.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"779 895 0751\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    15 runs   (    0.64 ms per token,  1567.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.02 ms /    25 tokens (   10.28 ms per token,    97.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.25 ms /    14 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1520.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3200.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.23 ms /    23 tokens (   11.05 ms per token,    90.47 tokens per second)\n",
      "llama_print_timings:        eval time =      81.16 ms /     1 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     346.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2600.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.46 ms /    24 tokens (   10.64 ms per token,    93.95 tokens per second)\n",
      "llama_print_timings:        eval time =      81.77 ms /     1 runs   (   81.77 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     356.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Thanh Conroy\", \"Dr.\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.45 ms /    20 runs   (    0.57 ms per token,  1747.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.67 ms /   186 tokens (    7.49 ms per token,   133.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1536.76 ms /    19 runs   (   80.88 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    3087.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"371 768 1921\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    15 runs   (    0.67 ms per token,  1487.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.15 ms /    14 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1483.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     7 runs   (    0.46 ms per token,  2163.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     476.69 ms /     6 runs   (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     767.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /     8 runs   (    0.66 ms per token,  1506.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.76 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =     545.55 ms /     7 runs   (   77.94 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     863.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Deon Zemlak\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    11 runs   (    0.50 ms per token,  1998.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.32 ms /   140 tokens (    8.19 ms per token,   122.13 tokens per second)\n",
      "llama_print_timings:        eval time =     792.08 ms /    10 runs   (   79.21 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2034.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"691 903 7516\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    15 runs   (    0.42 ms per token,  2380.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.20 ms /    25 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.32 ms /    14 runs   (   84.17 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    1524.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     9 runs   (    0.35 ms per token,  2885.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.17 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     634.12 ms /     8 runs   (   79.27 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     949.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /     8 runs   (    0.63 ms per token,  1575.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    24 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =     543.92 ms /     7 runs   (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =     862.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Katharina Dicki\", \"Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.83 ms /    15 runs   (    0.66 ms per token,  1525.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.94 ms /   173 tokens (    8.13 ms per token,   123.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.16 ms /    14 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2658.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"375 777 6466\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    15 runs   (    0.51 ms per token,  1973.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.00 ms /    25 tokens (   10.20 ms per token,    98.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.73 ms /    14 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1496.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     9 runs   (    0.46 ms per token,  2183.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.72 ms /    23 tokens (   11.34 ms per token,    88.22 tokens per second)\n",
      "llama_print_timings:        eval time =     639.46 ms /     8 runs   (   79.93 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     962.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     2 runs   (    0.53 ms per token,  1872.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.17 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =      83.34 ms /     1 runs   (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     348.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jerrold Lubowitz\", \"Damaris Funk\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    17 runs   (    0.56 ms per token,  1793.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.21 ms /   167 tokens (    8.28 ms per token,   120.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1253.14 ms /    16 runs   (   78.32 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    2788.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"793 873 3356\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2015.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.38 ms /    14 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1478.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /     9 runs   (    0.53 ms per token,  1873.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     629.47 ms /     8 runs   (   78.68 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     954.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.27 ms per token,  3766.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.71 ms /    24 tokens (   10.53 ms per token,    94.97 tokens per second)\n",
      "llama_print_timings:        eval time =      79.45 ms /     1 runs   (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     341.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Reyna Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    10 runs   (    0.59 ms per token,  1698.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3252.55 ms /   402 tokens (    8.09 ms per token,   123.60 tokens per second)\n",
      "llama_print_timings:        eval time =     734.64 ms /     9 runs   (   81.63 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    4084.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"245 786 2665\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.81 ms /    15 runs   (    0.65 ms per token,  1529.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.23 ms /    25 tokens (   10.25 ms per token,    97.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.88 ms /    14 runs   (   81.21 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1536.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /     9 runs   (    0.57 ms per token,  1752.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.74 ms /    23 tokens (   11.12 ms per token,    89.94 tokens per second)\n",
      "llama_print_timings:        eval time =     650.59 ms /     8 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     987.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.28 ms per token,  3610.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.55 ms /    24 tokens (   10.73 ms per token,    93.19 tokens per second)\n",
      "llama_print_timings:        eval time =      81.71 ms /     1 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     349.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jay Pfeffer\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    14 runs   (    0.60 ms per token,  1666.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2922.14 ms /   355 tokens (    8.23 ms per token,   121.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.78 ms /    13 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    4103.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 455 2284\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    15 runs   (    0.63 ms per token,  1580.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.77 ms /    25 tokens (   10.35 ms per token,    96.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1120.84 ms /    14 runs   (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1510.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     2 runs   (    0.36 ms per token,  2801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.27 ms /    23 tokens (   11.19 ms per token,    89.40 tokens per second)\n",
      "llama_print_timings:        eval time =      82.11 ms /     1 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     351.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3305.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.53 ms /    24 tokens (   10.73 ms per token,    93.19 tokens per second)\n",
      "llama_print_timings:        eval time =      90.94 ms /     1 runs   (   90.94 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =     359.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kim Luettgen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /     9 runs   (    0.65 ms per token,  1542.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.22 ms /   145 tokens (    7.96 ms per token,   125.63 tokens per second)\n",
      "llama_print_timings:        eval time =     629.65 ms /     8 runs   (   78.71 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1865.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"641 763 8938\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2667.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.99 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.27 ms /    14 runs   (   81.09 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1478.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"79 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     7 runs   (    0.61 ms per token,  1649.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.87 ms /    23 tokens (   11.08 ms per token,    90.24 tokens per second)\n",
      "llama_print_timings:        eval time =     472.86 ms /     6 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     786.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.23 ms /    24 tokens (   10.47 ms per token,    95.53 tokens per second)\n",
      "llama_print_timings:        eval time =     632.76 ms /     8 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     948.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kenton Cormier\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    18 runs   (    0.45 ms per token,  2215.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.47 ms /   182 tokens (    7.78 ms per token,   128.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1373.68 ms /    17 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    2922.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"842 528 1235\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.57 ms /    15 runs   (    0.64 ms per token,  1568.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.71 ms /    25 tokens (   10.19 ms per token,    98.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.43 ms /    14 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1500.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     7 runs   (    0.37 ms per token,  2669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.53 ms /    23 tokens (   10.89 ms per token,    91.81 tokens per second)\n",
      "llama_print_timings:        eval time =     477.48 ms /     6 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     773.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     2 runs   (    0.29 ms per token,  3424.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.81 ms /    24 tokens (   10.49 ms per token,    95.31 tokens per second)\n",
      "llama_print_timings:        eval time =      78.69 ms /     1 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     341.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lisabeth Goyette\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /     9 runs   (    0.47 ms per token,  2112.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.82 ms /   180 tokens (    7.73 ms per token,   129.42 tokens per second)\n",
      "llama_print_timings:        eval time =     641.75 ms /     8 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2093.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 601 7152\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    15 runs   (    0.69 ms per token,  1440.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.83 ms /    25 tokens (   10.07 ms per token,    99.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.22 ms /    14 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1487.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     2 runs   (    0.35 ms per token,  2894.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =      78.50 ms /     1 runs   (   78.50 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     339.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.27 ms per token,  3642.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =      78.70 ms /     1 runs   (   78.70 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     336.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Han Grant\", \"Doctor Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.54 ms /    16 runs   (    0.60 ms per token,  1677.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.36 ms /   155 tokens (    7.47 ms per token,   133.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.67 ms /    15 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2481.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"484 852 4052\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.80 ms /    15 runs   (    0.65 ms per token,  1529.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.72 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.99 ms /    14 runs   (   78.71 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1473.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     6 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.73 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =     399.08 ms /     5 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     684.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =      78.12 ms /     1 runs   (   78.12 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =     340.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Harry Wehner\", \"Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    13 runs   (    0.63 ms per token,  1586.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.36 ms /   161 tokens (    8.51 ms per token,   117.57 tokens per second)\n",
      "llama_print_timings:        eval time =     939.83 ms /    12 runs   (   78.32 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    2433.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"242 197 5106\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    15 runs   (    0.56 ms per token,  1773.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.42 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.24 ms /    14 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1479.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     6 runs   (    0.48 ms per token,  2086.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.84 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     391.71 ms /     5 runs   (   78.34 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     688.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     2 runs   (    0.29 ms per token,  3496.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =      78.84 ms /     1 runs   (   78.84 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     339.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marcus Grimes\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.68 ms /    17 runs   (    0.57 ms per token,  1756.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.68 ms /   203 tokens (    7.95 ms per token,   125.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.37 ms /    16 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    3034.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"227 733 6070\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    15 runs   (    0.68 ms per token,  1478.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.81 ms /    14 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1488.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /     7 runs   (    0.64 ms per token,  1553.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    23 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     474.66 ms /     6 runs   (   79.11 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     786.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.26 ms per token,  3780.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    24 tokens (   10.51 ms per token,    95.19 tokens per second)\n",
      "llama_print_timings:        eval time =      79.30 ms /     1 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     340.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raul Rutherford\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    10 runs   (    0.56 ms per token,  1800.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3088.84 ms /   394 tokens (    7.84 ms per token,   127.56 tokens per second)\n",
      "llama_print_timings:        eval time =     735.39 ms /     9 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    3898.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"868 596 1389\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    15 runs   (    0.48 ms per token,  2103.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.37 ms /    25 tokens (   10.25 ms per token,    97.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.78 ms /    14 runs   (   87.84 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1576.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     4 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.12 ms /    23 tokens (   11.05 ms per token,    90.51 tokens per second)\n",
      "llama_print_timings:        eval time =     250.94 ms /     3 runs   (   83.65 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     527.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     8 runs   (    0.57 ms per token,  1750.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.30 ms /    24 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     601.50 ms /     7 runs   (   85.93 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     927.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Maggie Abshire\", \"Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    17 runs   (    0.37 ms per token,  2723.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.66 ms /   154 tokens (    7.66 ms per token,   130.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1356.09 ms /    16 runs   (   84.76 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    2644.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"526 109 3877\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    15 runs   (    0.58 ms per token,  1728.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.37 ms /    25 tokens (   10.53 ms per token,    94.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.36 ms /    14 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1536.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2402.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.85 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     673.81 ms /     8 runs   (   84.23 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     981.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     2 runs   (    0.30 ms per token,  3384.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.12 ms /    24 tokens (   10.80 ms per token,    92.62 tokens per second)\n",
      "llama_print_timings:        eval time =      84.78 ms /     1 runs   (   84.78 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =     353.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Delmer Swift\", \"Dr. Cletus Paucek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    17 runs   (    0.51 ms per token,  1959.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.01 ms /   179 tokens (    7.92 ms per token,   126.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.47 ms /    16 runs   (   80.72 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2843.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 133 5875\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.41 ms /    15 runs   (    0.69 ms per token,  1441.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.06 ms /    14 runs   (   78.50 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1477.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     8 runs   (    0.51 ms per token,  1944.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.54 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     566.66 ms /     7 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     870.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     7 runs   (    0.52 ms per token,  1929.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.03 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     481.41 ms /     6 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     792.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tommie Kertzmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    10 runs   (    0.40 ms per token,  2476.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.74 ms /   150 tokens (    7.77 ms per token,   128.67 tokens per second)\n",
      "llama_print_timings:        eval time =     743.99 ms /     9 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1978.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 971 8297\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    15 runs   (    0.58 ms per token,  1717.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.84 ms /    14 runs   (   79.63 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1494.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     6 runs   (    0.24 ms per token,  4109.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    23 tokens (   10.99 ms per token,    90.99 tokens per second)\n",
      "llama_print_timings:        eval time =     431.81 ms /     5 runs   (   86.36 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     710.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     8 runs   (    0.40 ms per token,  2527.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.95 ms /    24 tokens (   10.41 ms per token,    96.02 tokens per second)\n",
      "llama_print_timings:        eval time =     591.39 ms /     7 runs   (   84.48 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     905.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Anh Quitzon\", \"Doctor Ciara Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    19 runs   (    0.43 ms per token,  2318.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.34 ms /   152 tokens (    7.67 ms per token,   130.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1569.72 ms /    18 runs   (   87.21 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    2848.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"816 401 4532\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    15 runs   (    0.51 ms per token,  1979.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.19 ms /    25 tokens (   10.17 ms per token,    98.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.90 ms /    14 runs   (   81.92 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1509.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /     9 runs   (    0.51 ms per token,  1974.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.83 ms /    23 tokens (   11.04 ms per token,    90.61 tokens per second)\n",
      "llama_print_timings:        eval time =     660.97 ms /     8 runs   (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     975.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /     8 runs   (    0.55 ms per token,  1821.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.08 ms /    24 tokens (   10.63 ms per token,    94.09 tokens per second)\n",
      "llama_print_timings:        eval time =     591.13 ms /     7 runs   (   84.45 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     902.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rob Nolan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     6 runs   (    0.48 ms per token,  2071.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2445.29 ms /   296 tokens (    8.26 ms per token,   121.05 tokens per second)\n",
      "llama_print_timings:        eval time =     429.16 ms /     5 runs   (   85.83 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    2916.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 372 4743\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    15 runs   (    0.55 ms per token,  1804.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.83 ms /    14 runs   (   83.06 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1546.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.32 ms per token,  3095.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.76 ms /    23 tokens (   11.12 ms per token,    89.93 tokens per second)\n",
      "llama_print_timings:        eval time =      86.45 ms /     1 runs   (   86.45 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     353.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /     8 runs   (    0.49 ms per token,  2038.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.81 ms /    24 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =     584.12 ms /     7 runs   (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     904.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Livia Monahan\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    19 runs   (    0.49 ms per token,  2033.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.64 ms /   174 tokens (    8.19 ms per token,   122.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1437.83 ms /    18 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    3016.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"835 566 8503\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.63 ms /    15 runs   (    0.64 ms per token,  1556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.69 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.10 ms /    14 runs   (   78.36 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1491.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     9 runs   (    0.36 ms per token,  2803.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =     689.15 ms /     8 runs   (   86.14 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     990.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"urinary tract infection\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     8 runs   (    0.25 ms per token,  3976.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.00 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =     584.00 ms /     7 runs   (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     872.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Roscoe Botsford\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    11 runs   (    0.43 ms per token,  2336.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2903.75 ms /   379 tokens (    7.66 ms per token,   130.52 tokens per second)\n",
      "llama_print_timings:        eval time =     819.04 ms /    10 runs   (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    3804.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"357 783 4421\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2127.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.33 ms /    25 tokens (   10.33 ms per token,    96.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.15 ms /    14 runs   (   84.44 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1557.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     9 runs   (    0.32 ms per token,  3151.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.03 ms /    23 tokens (   11.26 ms per token,    88.79 tokens per second)\n",
      "llama_print_timings:        eval time =     765.53 ms /     8 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =    1081.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.32 ms per token,  3164.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.28 ms /    24 tokens (   10.72 ms per token,    93.28 tokens per second)\n",
      "llama_print_timings:        eval time =      88.18 ms /     1 runs   (   88.18 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =     356.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chase Eichmann\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    14 runs   (    0.52 ms per token,  1922.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.55 ms /   155 tokens (    7.65 ms per token,   130.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1036.75 ms /    13 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    2333.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 553 6807\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.55 ms /    15 runs   (    0.64 ms per token,  1569.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    25 tokens (   10.13 ms per token,    98.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.63 ms /    14 runs   (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1489.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2633.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.77 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =     578.11 ms /     7 runs   (   82.59 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     878.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     8 runs   (    0.50 ms per token,  1983.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.50 ms /    24 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     558.24 ms /     7 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     883.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Erwin Schroeder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    10 runs   (    0.60 ms per token,  1656.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.96 ms /   133 tokens (    8.96 ms per token,   111.58 tokens per second)\n",
      "llama_print_timings:        eval time =     750.72 ms /     9 runs   (   83.41 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2028.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"295 958 8980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.24 ms /    15 runs   (    0.62 ms per token,  1623.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.28 ms /    25 tokens (   10.33 ms per token,    96.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.21 ms /    14 runs   (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1487.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     7 runs   (    0.33 ms per token,  3075.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    23 tokens (   10.95 ms per token,    91.33 tokens per second)\n",
      "llama_print_timings:        eval time =     482.82 ms /     6 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     774.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    11 runs   (    0.53 ms per token,  1886.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =     809.30 ms /    10 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1149.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Johnsie Muller\", \"Dr. Kim Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    19 runs   (    0.70 ms per token,  1427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.88 ms /   181 tokens (    7.72 ms per token,   129.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1421.48 ms /    18 runs   (   78.97 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    2997.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"387 374 1765\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.23 ms /    15 runs   (    0.62 ms per token,  1625.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.80 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.80 ms /    14 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1509.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     7 runs   (    0.51 ms per token,  1967.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.98 ms /    23 tokens (   10.96 ms per token,    91.28 tokens per second)\n",
      "llama_print_timings:        eval time =     479.65 ms /     6 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     784.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4728.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    24 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =      82.56 ms /     1 runs   (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     341.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Barbra O'Conner\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.23 ms /    20 runs   (    0.66 ms per token,  1511.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.07 ms /   138 tokens (    8.51 ms per token,   117.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.94 ms /    19 runs   (   79.00 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    2857.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"275 211 8024\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2162.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.68 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.25 ms /    14 runs   (   80.30 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1485.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     7 runs   (    0.29 ms per token,  3407.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.75 ms /    23 tokens (   10.95 ms per token,    91.36 tokens per second)\n",
      "llama_print_timings:        eval time =     564.38 ms /     6 runs   (   94.06 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =     852.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2891.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.16 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =     616.70 ms /     7 runs   (   88.10 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     910.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alfonso Miller\", \"Dr. Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    15 runs   (    0.54 ms per token,  1850.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.80 ms /   132 tokens (    8.79 ms per token,   113.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.83 ms /    14 runs   (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    2461.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 108 5285\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    15 runs   (    0.36 ms per token,  2771.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.30 ms /    25 tokens (   10.25 ms per token,    97.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1340.74 ms /    14 runs   (   95.77 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =    1683.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /     9 runs   (    0.59 ms per token,  1688.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.90 ms /    23 tokens (   12.43 ms per token,    80.45 tokens per second)\n",
      "llama_print_timings:        eval time =     787.58 ms /     8 runs   (   98.45 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    1138.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2890.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.44 ms /    24 tokens (   10.48 ms per token,    95.45 tokens per second)\n",
      "llama_print_timings:        eval time =     649.21 ms /     7 runs   (   92.74 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =     938.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Chet Nikolaus\", \"Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    15 runs   (    0.41 ms per token,  2452.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.20 ms /   154 tokens (    7.96 ms per token,   125.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.16 ms /    14 runs   (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    2531.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"437 703 1629\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1882.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.43 ms /    25 tokens (   10.30 ms per token,    97.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.48 ms /    14 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1506.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     9 runs   (    0.37 ms per token,  2697.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.19 ms /    23 tokens (   11.01 ms per token,    90.84 tokens per second)\n",
      "llama_print_timings:        eval time =     685.20 ms /     8 runs   (   85.65 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =     996.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    14 runs   (    0.44 ms per token,  2269.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.93 ms /    24 tokens (   11.21 ms per token,    89.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1055.72 ms /    13 runs   (   81.21 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1428.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brant Schaden\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.92 ms /    17 runs   (    0.58 ms per token,  1713.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.54 ms /   149 tokens (    7.84 ms per token,   127.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1309.36 ms /    16 runs   (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    2606.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 691 6541\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    15 runs   (    0.50 ms per token,  2010.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.66 ms /    25 tokens (   10.15 ms per token,    98.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.58 ms /    14 runs   (   83.68 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    1528.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2883.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.84 ms /    23 tokens (   10.99 ms per token,    90.97 tokens per second)\n",
      "llama_print_timings:        eval time =     627.38 ms /     7 runs   (   89.63 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =     919.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8510.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.62 ms /    24 tokens (   11.86 ms per token,    84.32 tokens per second)\n",
      "llama_print_timings:        eval time =     105.57 ms /     1 runs   (  105.57 ms per token,     9.47 tokens per second)\n",
      "llama_print_timings:       total time =     395.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jordan Pollich\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    16 runs   (    0.41 ms per token,  2422.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.38 ms /   166 tokens (    8.87 ms per token,   112.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1271.15 ms /    15 runs   (   84.74 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    2842.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 618 0995\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    15 runs   (    0.46 ms per token,  2164.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.32 ms /    25 tokens (   10.13 ms per token,    98.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1183.72 ms /    14 runs   (   84.55 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    1522.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     8 runs   (    0.50 ms per token,  1995.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.64 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =     558.88 ms /     7 runs   (   79.84 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     870.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.23 ms per token,  4282.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    24 tokens (   10.48 ms per token,    95.40 tokens per second)\n",
      "llama_print_timings:        eval time =      81.63 ms /     1 runs   (   81.63 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     342.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Elida Veum\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     7 runs   (    0.48 ms per token,  2096.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2462.89 ms /   308 tokens (    8.00 ms per token,   125.06 tokens per second)\n",
      "llama_print_timings:        eval time =     502.43 ms /     6 runs   (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    3011.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 415 0139\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    15 runs   (    0.47 ms per token,  2113.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.07 ms /    25 tokens (   10.24 ms per token,    97.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.83 ms /    14 runs   (   87.20 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    1574.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     2 runs   (    0.45 ms per token,  2214.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.14 ms /    23 tokens (   11.01 ms per token,    90.86 tokens per second)\n",
      "llama_print_timings:        eval time =      96.80 ms /     1 runs   (   96.80 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     360.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /     8 runs   (    0.56 ms per token,  1791.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.98 ms /    24 tokens (   11.12 ms per token,    89.90 tokens per second)\n",
      "llama_print_timings:        eval time =     594.12 ms /     7 runs   (   84.87 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     925.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rosella Green\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     7 runs   (    0.36 ms per token,  2768.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.61 ms /   167 tokens (    8.42 ms per token,   118.81 tokens per second)\n",
      "llama_print_timings:        eval time =     575.09 ms /     6 runs   (   95.85 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    2038.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 659 6406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    15 runs   (    0.46 ms per token,  2166.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.05 ms /    25 tokens (   10.40 ms per token,    96.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.73 ms /    14 runs   (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1527.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     6 runs   (    0.47 ms per token,  2149.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    23 tokens (   10.99 ms per token,    90.99 tokens per second)\n",
      "llama_print_timings:        eval time =     402.99 ms /     5 runs   (   80.60 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     698.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6211.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    24 tokens (   10.46 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      88.78 ms /     1 runs   (   88.78 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     345.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hong Haley\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2563.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.95 ms /   144 tokens (    8.16 ms per token,   122.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1211.04 ms /    15 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2488.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"276 697 1899\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    15 runs   (    0.48 ms per token,  2064.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.46 ms /    25 tokens (   10.18 ms per token,    98.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.33 ms /    14 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1493.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.36 ms /    23 tokens (   10.84 ms per token,    92.24 tokens per second)\n",
      "llama_print_timings:        eval time =     634.52 ms /     8 runs   (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     945.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.13 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =      81.13 ms /     1 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     337.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Vicente Beahan\", \"Doctor Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    17 runs   (    0.38 ms per token,  2663.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.00 ms /   180 tokens (    7.88 ms per token,   126.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1385.76 ms /    16 runs   (   86.61 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    2912.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"232 522 6183\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    15 runs   (    0.62 ms per token,  1612.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.76 ms /    25 tokens (   10.15 ms per token,    98.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.74 ms /    14 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1495.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2701.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.33 ms /    23 tokens (   11.01 ms per token,    90.79 tokens per second)\n",
      "llama_print_timings:        eval time =     636.02 ms /     8 runs   (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     946.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5249.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.01 ms /    24 tokens (   10.46 ms per token,    95.61 tokens per second)\n",
      "llama_print_timings:        eval time =      83.08 ms /     1 runs   (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     340.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jackie Predovic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /    10 runs   (    0.46 ms per token,  2174.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.34 ms /   224 tokens (    7.34 ms per token,   136.31 tokens per second)\n",
      "llama_print_timings:        eval time =     741.33 ms /     9 runs   (   82.37 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    2453.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"612 597 0730\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    15 runs   (    0.40 ms per token,  2477.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.84 ms /    25 tokens (   10.15 ms per token,    98.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.67 ms /    14 runs   (   79.69 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1466.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5934.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =      90.69 ms /     1 runs   (   90.69 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =     347.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Childhood asthma\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2680.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    24 tokens (   10.48 ms per token,    95.40 tokens per second)\n",
      "llama_print_timings:        eval time =     560.02 ms /     7 runs   (   80.00 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     862.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Buddy Little\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    16 runs   (    0.51 ms per token,  1975.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.60 ms /   167 tokens (    8.24 ms per token,   121.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.35 ms /    15 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2704.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"450 204 0273\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    15 runs   (    0.56 ms per token,  1772.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    25 tokens (   10.12 ms per token,    98.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.76 ms /    14 runs   (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1486.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     5 runs   (    0.37 ms per token,  2682.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    23 tokens (   10.92 ms per token,    91.54 tokens per second)\n",
      "llama_print_timings:        eval time =     319.11 ms /     4 runs   (   79.78 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     600.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2315.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    24 tokens (   10.46 ms per token,    95.59 tokens per second)\n",
      "llama_print_timings:        eval time =     561.53 ms /     7 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     862.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Grayce Considine\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.04 ms /    11 runs   (    0.64 ms per token,  1563.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.84 ms /   137 tokens (    8.34 ms per token,   119.88 tokens per second)\n",
      "llama_print_timings:        eval time =     789.05 ms /    10 runs   (   78.90 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    2022.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"177 185 3785\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    15 runs   (    0.44 ms per token,  2287.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.97 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.94 ms /    14 runs   (   83.92 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    1534.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /     9 runs   (    0.49 ms per token,  2034.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =     637.14 ms /     8 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     955.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"anemia\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     5 runs   (    0.48 ms per token,  2081.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.55 ms /    24 tokens (   10.69 ms per token,    93.55 tokens per second)\n",
      "llama_print_timings:        eval time =     327.59 ms /     4 runs   (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     616.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Floy D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    12 runs   (    0.54 ms per token,  1838.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3254.84 ms /   388 tokens (    8.39 ms per token,   119.21 tokens per second)\n",
      "llama_print_timings:        eval time =     893.17 ms /    11 runs   (   81.20 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    4258.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 347 378 8402\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.44 ms /    19 runs   (    0.65 ms per token,  1527.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.78 ms /    25 tokens (   10.27 ms per token,    97.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1479.13 ms /    18 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1906.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /     9 runs   (    0.45 ms per token,  2239.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.34 ms /    23 tokens (   11.10 ms per token,    90.07 tokens per second)\n",
      "llama_print_timings:        eval time =     662.96 ms /     8 runs   (   82.87 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     981.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.27 ms /    24 tokens (   10.80 ms per token,    92.57 tokens per second)\n",
      "llama_print_timings:        eval time =      85.19 ms /     1 runs   (   85.19 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     355.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Petra Upton\", \"Dr. Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.59 ms /    18 runs   (    0.59 ms per token,  1699.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1664.83 ms /   212 tokens (    7.85 ms per token,   127.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.87 ms /    17 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    3194.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 906 2012\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    15 runs   (    0.60 ms per token,  1678.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.20 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.33 ms /    14 runs   (   79.59 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1502.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     7 runs   (    0.33 ms per token,  3058.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.15 ms /    23 tokens (   10.92 ms per token,    91.58 tokens per second)\n",
      "llama_print_timings:        eval time =     482.58 ms /     6 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     774.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4716.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =      80.51 ms /     1 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     339.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Landon Schroeder\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.31 ms /    17 runs   (    0.67 ms per token,  1503.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.57 ms /   158 tokens (    7.33 ms per token,   136.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1275.25 ms /    16 runs   (   79.70 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    2579.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"546 507 5173\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    15 runs   (    0.46 ms per token,  2193.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.91 ms /    25 tokens (   10.16 ms per token,    98.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.30 ms /    14 runs   (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1518.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2402.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.75 ms /    23 tokens (   11.29 ms per token,    88.55 tokens per second)\n",
      "llama_print_timings:        eval time =     670.77 ms /     8 runs   (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     982.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2281.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.04 ms /    24 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =     603.04 ms /     7 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     901.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Erin Champlin\", \"Dr Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    18 runs   (    0.48 ms per token,  2073.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.75 ms /   200 tokens (    8.21 ms per token,   121.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1423.60 ms /    17 runs   (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    3198.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"863 775 4730\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    15 runs   (    0.60 ms per token,  1660.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.50 ms /    25 tokens (   10.18 ms per token,    98.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.57 ms /    14 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1492.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     8 runs   (    0.49 ms per token,  2044.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.90 ms /    23 tokens (   11.00 ms per token,    90.95 tokens per second)\n",
      "llama_print_timings:        eval time =     551.40 ms /     7 runs   (   78.77 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     867.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.59 ms /    24 tokens (   10.57 ms per token,    94.64 tokens per second)\n",
      "llama_print_timings:        eval time =      86.01 ms /     1 runs   (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     347.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Betsey Satterfield\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    11 runs   (    0.59 ms per token,  1706.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.26 ms /   135 tokens (    8.51 ms per token,   117.47 tokens per second)\n",
      "llama_print_timings:        eval time =     785.16 ms /    10 runs   (   78.52 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    2036.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"249 937 0755\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    15 runs   (    0.59 ms per token,  1687.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.32 ms /    25 tokens (   10.13 ms per token,    98.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.38 ms /    14 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1490.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     5 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.08 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     312.36 ms /     4 runs   (   78.09 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =     597.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5479.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.83 ms /    24 tokens (   10.58 ms per token,    94.55 tokens per second)\n",
      "llama_print_timings:        eval time =      96.50 ms /     1 runs   (   96.50 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     356.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Katina Gerhold\", \"Doctor Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    17 runs   (    0.32 ms per token,  3166.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.13 ms /   150 tokens (    7.89 ms per token,   126.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1380.84 ms /    16 runs   (   86.30 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    2657.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"115 274 8841\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    15 runs   (    0.41 ms per token,  2440.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.96 ms /    25 tokens (   10.40 ms per token,    96.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.63 ms /    14 runs   (   87.69 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    1576.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     7 runs   (    0.30 ms per token,  3344.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =     504.56 ms /     6 runs   (   84.09 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     792.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     8 runs   (    0.40 ms per token,  2479.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.80 ms /    24 tokens (   10.66 ms per token,    93.83 tokens per second)\n",
      "llama_print_timings:        eval time =     600.21 ms /     7 runs   (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     904.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hwa Berge\", \"Doctor Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2691.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2737.39 ms /   349 tokens (    7.84 ms per token,   127.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1456.32 ms /    17 runs   (   85.67 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    4317.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"278 347 6239\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    15 runs   (    0.40 ms per token,  2483.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.38 ms /    25 tokens (   10.26 ms per token,    97.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.69 ms /    14 runs   (   86.76 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1559.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6410.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.14 ms /    23 tokens (   11.05 ms per token,    90.50 tokens per second)\n",
      "llama_print_timings:        eval time =      87.45 ms /     1 runs   (   87.45 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     349.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    11 runs   (    0.39 ms per token,  2541.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    24 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =     843.23 ms /    10 runs   (   84.32 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =    1169.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alvaro Kertzmann\", \"Dr Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    17 runs   (    0.35 ms per token,  2889.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2745.83 ms /   345 tokens (    7.96 ms per token,   125.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1372.62 ms /    16 runs   (   85.79 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    4229.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 182 4708\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    15 runs   (    0.53 ms per token,  1871.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.54 ms /    25 tokens (   10.26 ms per token,    97.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.27 ms /    14 runs   (   83.09 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1528.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3696.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.34 ms /    23 tokens (   11.36 ms per token,    88.01 tokens per second)\n",
      "llama_print_timings:        eval time =      85.79 ms /     1 runs   (   85.79 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     355.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    11 runs   (    0.35 ms per token,  2851.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    24 tokens (   10.68 ms per token,    93.66 tokens per second)\n",
      "llama_print_timings:        eval time =     829.39 ms /    10 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1149.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Aurelio Barrows\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    10 runs   (    0.45 ms per token,  2217.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.14 ms /   153 tokens (    7.66 ms per token,   130.53 tokens per second)\n",
      "llama_print_timings:        eval time =     725.62 ms /     9 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1968.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"414 494 3924\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    15 runs   (    0.31 ms per token,  3214.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.04 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.75 ms /    14 runs   (   82.27 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1479.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3477.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.34 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     560.92 ms /     6 runs   (   93.49 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     844.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     8 runs   (    0.39 ms per token,  2563.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    24 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =     576.46 ms /     7 runs   (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Arlie McGlynn\", \"Kristopher Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    18 runs   (    0.58 ms per token,  1727.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.34 ms /   162 tokens (    8.58 ms per token,   116.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1360.76 ms /    17 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2906.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"327 727 4771\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.45 ms /    15 runs   (    0.56 ms per token,  1775.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.88 ms /    25 tokens (   10.12 ms per token,    98.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.80 ms /    14 runs   (   79.56 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1484.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     2 runs   (    0.29 ms per token,  3395.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.18 ms /    23 tokens (   10.92 ms per token,    91.57 tokens per second)\n",
      "llama_print_timings:        eval time =      80.61 ms /     1 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     340.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     8 runs   (    0.50 ms per token,  1987.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =     558.40 ms /     7 runs   (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     861.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Trey Prohaska\", \"Dr. Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2697.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.12 ms /   203 tokens (    8.08 ms per token,   123.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.45 ms /    14 runs   (   82.46 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2900.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"490 117 3360\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    15 runs   (    0.43 ms per token,  2305.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.95 ms /    25 tokens (   10.36 ms per token,    96.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.35 ms /    14 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1495.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     7 runs   (    0.45 ms per token,  2199.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     472.06 ms /     6 runs   (   78.68 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     778.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /     8 runs   (    0.35 ms per token,  2853.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.56 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     568.13 ms /     7 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     864.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rolf Orn\", \"Doctor Eldon Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    18 runs   (    0.46 ms per token,  2153.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.35 ms /   172 tokens (    8.04 ms per token,   124.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.07 ms /    17 runs   (   79.24 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2865.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"199 288 5236\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2512.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1202.88 ms /    14 runs   (   85.92 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1543.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /     9 runs   (    0.45 ms per token,  2203.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.97 ms /    23 tokens (   11.30 ms per token,    88.47 tokens per second)\n",
      "llama_print_timings:        eval time =     711.21 ms /     8 runs   (   88.90 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1030.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.47 ms /    24 tokens (   10.64 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =      97.33 ms /     1 runs   (   97.33 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =     359.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Beatrice Littel\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    18 runs   (    0.50 ms per token,  2013.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.87 ms /   154 tokens (    7.63 ms per token,   131.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1385.84 ms /    17 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2690.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"892 189 2474\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.66 ms /    15 runs   (    0.91 ms per token,  1098.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    25 tokens (   10.14 ms per token,    98.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.99 ms /    14 runs   (   83.93 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    1548.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2387.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    23 tokens (   11.04 ms per token,    90.55 tokens per second)\n",
      "llama_print_timings:        eval time =     684.45 ms /     8 runs   (   85.56 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =     995.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    24 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_print_timings:        eval time =     100.62 ms /     1 runs   (  100.62 ms per token,     9.94 tokens per second)\n",
      "llama_print_timings:       total time =     366.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Beatris Feest\", \"Doctor Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.92 ms /    18 runs   (    0.61 ms per token,  1648.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.60 ms /   203 tokens (    8.23 ms per token,   121.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1367.85 ms /    17 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    3213.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"440 905 7206\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    15 runs   (    0.61 ms per token,  1650.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.81 ms /    25 tokens (   10.15 ms per token,    98.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.32 ms /    14 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1514.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    23 tokens (   10.92 ms per token,    91.54 tokens per second)\n",
      "llama_print_timings:        eval time =      86.11 ms /     1 runs   (   86.11 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     348.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /     8 runs   (    0.58 ms per token,  1720.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =     551.21 ms /     7 runs   (   78.74 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     874.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Charlott Bergstrom\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.21 ms /    20 runs   (    0.56 ms per token,  1784.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.52 ms /   147 tokens (    8.02 ms per token,   124.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1536.20 ms /    19 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2865.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"166 819 4979\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    15 runs   (    0.61 ms per token,  1647.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.26 ms /    25 tokens (   10.21 ms per token,    97.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.12 ms /    14 runs   (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1531.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"72-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /     9 runs   (    0.50 ms per token,  2011.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.30 ms /    23 tokens (   11.14 ms per token,    89.74 tokens per second)\n",
      "llama_print_timings:        eval time =     653.55 ms /     8 runs   (   81.69 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     964.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.68 ms /    24 tokens (   10.45 ms per token,    95.74 tokens per second)\n",
      "llama_print_timings:        eval time =      88.08 ms /     1 runs   (   88.08 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     345.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Nickole Konopelski\", \"Dr.\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    24 runs   (    0.41 ms per token,  2434.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.34 ms /   150 tokens (    7.80 ms per token,   128.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1855.29 ms /    23 runs   (   80.66 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    3184.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"753 859 9608\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2269.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1180.80 ms /    14 runs   (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =    1529.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     7 runs   (    0.46 ms per token,  2167.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     536.72 ms /     6 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     830.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3210.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    24 tokens (   10.54 ms per token,    94.87 tokens per second)\n",
      "llama_print_timings:        eval time =      88.76 ms /     1 runs   (   88.76 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     348.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Curtis Schulist\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /     9 runs   (    0.49 ms per token,  2043.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3240.37 ms /   391 tokens (    8.29 ms per token,   120.67 tokens per second)\n",
      "llama_print_timings:        eval time =     654.49 ms /     8 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    3971.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"407 892 6053\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1951.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.85 ms /    25 tokens (   10.27 ms per token,    97.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.62 ms /    14 runs   (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1523.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     7 runs   (    0.40 ms per token,  2529.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    23 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =     501.87 ms /     6 runs   (   83.64 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     803.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     8 runs   (    0.27 ms per token,  3768.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.03 ms /    24 tokens (   10.83 ms per token,    92.30 tokens per second)\n",
      "llama_print_timings:        eval time =     596.53 ms /     7 runs   (   85.22 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     896.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Cassie Mertz\", \"Dr.\", \"Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    23 runs   (    0.50 ms per token,  1987.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1887.08 ms /   228 tokens (    8.28 ms per token,   120.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1798.50 ms /    22 runs   (   81.75 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    3864.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"735 869 5162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    15 runs   (    0.43 ms per token,  2326.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.15 ms /    25 tokens (   10.21 ms per token,    97.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.33 ms /    14 runs   (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    1531.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.72 ms /    23 tokens (   11.29 ms per token,    88.56 tokens per second)\n",
      "llama_print_timings:        eval time =      84.56 ms /     1 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     355.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     2 runs   (    0.52 ms per token,  1937.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.82 ms /    24 tokens (   10.91 ms per token,    91.67 tokens per second)\n",
      "llama_print_timings:        eval time =      83.38 ms /     1 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     357.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     2 runs   (    0.37 ms per token,  2699.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1907.74 ms /   233 tokens (    8.19 ms per token,   122.13 tokens per second)\n",
      "llama_print_timings:        eval time =      84.56 ms /     1 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    2002.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"479 664 5598\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    15 runs   (    0.52 ms per token,  1918.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.17 ms /    25 tokens (   10.17 ms per token,    98.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.82 ms /    14 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1499.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /     9 runs   (    0.50 ms per token,  1984.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.57 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     674.05 ms /     8 runs   (   84.26 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     986.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.86 ms /    24 tokens (   10.95 ms per token,    91.30 tokens per second)\n",
      "llama_print_timings:        eval time =      86.71 ms /     1 runs   (   86.71 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     358.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Davida Predovic\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    17 runs   (    0.62 ms per token,  1606.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1658.42 ms /   221 tokens (    7.50 ms per token,   133.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.72 ms /    16 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    3104.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 232 4477\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    15 runs   (    0.52 ms per token,  1927.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.44 ms /    25 tokens (   10.14 ms per token,    98.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.02 ms /    14 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1504.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     9 runs   (    0.35 ms per token,  2839.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.93 ms /    23 tokens (   11.00 ms per token,    90.93 tokens per second)\n",
      "llama_print_timings:        eval time =     662.68 ms /     8 runs   (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     966.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     2 runs   (    0.28 ms per token,  3552.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.54 ms /    24 tokens (   11.02 ms per token,    90.72 tokens per second)\n",
      "llama_print_timings:        eval time =      85.06 ms /     1 runs   (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     358.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Bernard Nienow\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     9 runs   (    0.46 ms per token,  2184.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.07 ms /   148 tokens (    8.05 ms per token,   124.15 tokens per second)\n",
      "llama_print_timings:        eval time =     640.87 ms /     8 runs   (   80.11 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1903.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 272 0275\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    15 runs   (    0.56 ms per token,  1787.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.70 ms /    25 tokens (   10.11 ms per token,    98.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.46 ms /    14 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1493.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     6 runs   (    0.30 ms per token,  3382.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.21 ms /    23 tokens (   11.31 ms per token,    88.39 tokens per second)\n",
      "llama_print_timings:        eval time =     422.75 ms /     5 runs   (   84.55 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     713.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    11 runs   (    0.54 ms per token,  1851.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =     803.90 ms /    10 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1169.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Beatris Thompson\", \"doctor Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.95 ms /    19 runs   (    0.58 ms per token,  1735.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.97 ms /   159 tokens (    7.47 ms per token,   133.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1424.28 ms /    18 runs   (   79.13 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2787.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"165 542 2930\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    15 runs   (    0.44 ms per token,  2283.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    25 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.77 ms /    14 runs   (   82.20 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1503.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     8 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.10 ms /    23 tokens (   10.96 ms per token,    91.23 tokens per second)\n",
      "llama_print_timings:        eval time =     581.00 ms /     7 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     886.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3125.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.05 ms /    24 tokens (   11.00 ms per token,    90.89 tokens per second)\n",
      "llama_print_timings:        eval time =      88.55 ms /     1 runs   (   88.55 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     362.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Russel Aufderhar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    10 runs   (    0.40 ms per token,  2475.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.12 ms /   155 tokens (    7.67 ms per token,   130.46 tokens per second)\n",
      "llama_print_timings:        eval time =     755.51 ms /     9 runs   (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    2014.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 495 5015\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    15 runs   (    0.52 ms per token,  1913.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.96 ms /    25 tokens (   10.60 ms per token,    94.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.89 ms /    14 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1508.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     9 runs   (    0.40 ms per token,  2487.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.84 ms /    23 tokens (   11.17 ms per token,    89.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.78 ms /     8 runs   (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     985.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4201.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.01 ms /    24 tokens (   10.79 ms per token,    92.66 tokens per second)\n",
      "llama_print_timings:        eval time =      84.10 ms /     1 runs   (   84.10 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     351.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lorraine Gleichner\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.82 ms /    18 runs   (    0.55 ms per token,  1832.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1199.87 ms /   154 tokens (    7.79 ms per token,   128.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.90 ms /    17 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2731.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"345 873 8687\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    15 runs   (    0.58 ms per token,  1709.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.50 ms /    14 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1494.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /     9 runs   (    0.61 ms per token,  1651.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =     630.21 ms /     8 runs   (   78.78 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     957.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     2 runs   (    0.29 ms per token,  3472.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      81.13 ms /     1 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     340.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leonard Barrows\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     8 runs   (    0.49 ms per token,  2058.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.42 ms /   132 tokens (    8.95 ms per token,   111.73 tokens per second)\n",
      "llama_print_timings:        eval time =     576.47 ms /     7 runs   (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1814.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"423 614 3892\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    15 runs   (    0.55 ms per token,  1807.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.87 ms /    25 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.41 ms /    14 runs   (   79.24 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1498.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /     9 runs   (    0.50 ms per token,  2012.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    23 tokens (   10.93 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     639.59 ms /     8 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     955.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.25 ms per token,  4073.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.01 ms /    24 tokens (   10.88 ms per token,    91.95 tokens per second)\n",
      "llama_print_timings:        eval time =      94.72 ms /     1 runs   (   94.72 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     363.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Trena Hills\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    18 runs   (    0.47 ms per token,  2146.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.79 ms /   150 tokens (    7.94 ms per token,   125.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.49 ms /    17 runs   (   79.85 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2683.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     6 runs   (    0.55 ms per token,  1805.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.72 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =     411.21 ms /     5 runs   (   82.24 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     708.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =      79.58 ms /     1 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     336.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /     8 runs   (    0.44 ms per token,  2296.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     558.31 ms /     7 runs   (   79.76 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     863.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Librada Mertz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     9 runs   (    0.44 ms per token,  2259.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.48 ms /   149 tokens (    7.74 ms per token,   129.17 tokens per second)\n",
      "llama_print_timings:        eval time =     631.08 ms /     8 runs   (   78.88 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1849.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 396 5575\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    15 runs   (    0.63 ms per token,  1580.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.63 ms /    25 tokens (   10.47 ms per token,    95.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.27 ms /    14 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1507.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.25 ms per token,  4048.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.01 ms /    23 tokens (   10.96 ms per token,    91.27 tokens per second)\n",
      "llama_print_timings:        eval time =      80.13 ms /     1 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     340.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     8 runs   (    0.40 ms per token,  2492.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.76 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =     557.50 ms /     7 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     864.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kerry Ward\", \"Brandon Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    14 runs   (    0.48 ms per token,  2086.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.44 ms /   149 tokens (    7.92 ms per token,   126.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.17 ms /    13 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2333.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 205 8833\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    15 runs   (    0.46 ms per token,  2178.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.71 ms /    25 tokens (   10.15 ms per token,    98.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.32 ms /    14 runs   (   82.59 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1501.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     7 runs   (    0.38 ms per token,  2663.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.54 ms /    23 tokens (   11.33 ms per token,    88.28 tokens per second)\n",
      "llama_print_timings:        eval time =     495.03 ms /     6 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     801.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.21 ms per token,  4830.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.01 ms /    24 tokens (   10.42 ms per token,    96.00 tokens per second)\n",
      "llama_print_timings:        eval time =      80.00 ms /     1 runs   (   80.00 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     337.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Bethany Kuhlman\", \"Dr.\", \"Nikia Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.80 ms /    23 runs   (    0.60 ms per token,  1667.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.27 ms /   157 tokens (    7.42 ms per token,   134.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1726.85 ms /    22 runs   (   78.49 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    3116.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"230 102 6346\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2043.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1116.91 ms /    14 runs   (   79.78 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1472.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.31 ms per token,  3267.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.60 ms /    23 tokens (   11.37 ms per token,    87.92 tokens per second)\n",
      "llama_print_timings:        eval time =      85.01 ms /     1 runs   (   85.01 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     357.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     2 runs   (    0.36 ms per token,  2747.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.73 ms /    24 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =      80.88 ms /     1 runs   (   80.88 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     345.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Noe Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     9 runs   (    0.49 ms per token,  2053.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.97 ms /   140 tokens (    8.44 ms per token,   118.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.15 ms /     8 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1894.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"839 984 2002\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    15 runs   (    0.58 ms per token,  1710.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.74 ms /    25 tokens (   10.15 ms per token,    98.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.67 ms /    14 runs   (   78.48 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1483.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /     7 runs   (    0.63 ms per token,  1590.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     467.63 ms /     6 runs   (   77.94 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     775.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /     8 runs   (    0.60 ms per token,  1677.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    24 tokens (   10.49 ms per token,    95.36 tokens per second)\n",
      "llama_print_timings:        eval time =     546.17 ms /     7 runs   (   78.02 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =     857.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Arnulfo Morissette PhD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    13 runs   (    0.58 ms per token,  1714.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.99 ms /   177 tokens (    7.94 ms per token,   125.89 tokens per second)\n",
      "llama_print_timings:        eval time =     942.67 ms /    12 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2469.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"594 831 1488\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    15 runs   (    0.47 ms per token,  2110.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.46 ms /    25 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.71 ms /    14 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1487.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"87-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     9 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.07 ms /    23 tokens (   11.31 ms per token,    88.44 tokens per second)\n",
      "llama_print_timings:        eval time =     661.48 ms /     8 runs   (   82.69 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     982.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    12 runs   (    0.36 ms per token,  2814.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.88 ms /    24 tokens (   10.58 ms per token,    94.53 tokens per second)\n",
      "llama_print_timings:        eval time =     915.00 ms /    11 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1254.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Genny Brekke\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    15 runs   (    0.43 ms per token,  2322.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.09 ms /   176 tokens (    8.07 ms per token,   123.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.57 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    2686.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 165 6032\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    15 runs   (    0.53 ms per token,  1904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.49 ms /    25 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.54 ms /    14 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1524.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4228.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.10 ms /    23 tokens (   11.35 ms per token,    88.09 tokens per second)\n",
      "llama_print_timings:        eval time =      83.74 ms /     1 runs   (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     353.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     6 runs   (    0.26 ms per token,  3785.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.64 ms /    24 tokens (   10.57 ms per token,    94.62 tokens per second)\n",
      "llama_print_timings:        eval time =     413.23 ms /     5 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     695.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Laronda Wolf\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    18 runs   (    0.52 ms per token,  1935.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.09 ms /   179 tokens (    7.92 ms per token,   126.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1381.50 ms /    17 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    2928.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"191 848 3406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    15 runs   (    0.52 ms per token,  1920.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.23 ms /    25 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.97 ms /    14 runs   (   81.64 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1499.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2634.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.34 ms /    23 tokens (   11.28 ms per token,    88.69 tokens per second)\n",
      "llama_print_timings:        eval time =     658.53 ms /     8 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     966.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     8 runs   (    0.55 ms per token,  1825.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.51 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =     553.22 ms /     7 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =     861.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo Crist\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /     7 runs   (    0.39 ms per token,  2592.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3011.81 ms /   369 tokens (    8.16 ms per token,   122.52 tokens per second)\n",
      "llama_print_timings:        eval time =     520.53 ms /     6 runs   (   86.75 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    3582.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"460 934 5153\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    15 runs   (    0.49 ms per token,  2031.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.29 ms /    25 tokens (   10.37 ms per token,    96.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.62 ms /    14 runs   (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1539.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2607.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.37 ms /    23 tokens (   11.15 ms per token,    89.71 tokens per second)\n",
      "llama_print_timings:        eval time =     658.74 ms /     8 runs   (   82.34 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     975.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.43 ms /    24 tokens (   10.68 ms per token,    93.59 tokens per second)\n",
      "llama_print_timings:        eval time =      82.83 ms /     1 runs   (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     348.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Pierre Lubowitz\", \"Dr Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    17 runs   (    0.46 ms per token,  2155.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3156.24 ms /   395 tokens (    7.99 ms per token,   125.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1398.90 ms /    16 runs   (   87.43 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    4676.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"249 158 2820\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2127.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.41 ms /    25 tokens (   10.78 ms per token,    92.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.01 ms /    14 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    1545.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     5 runs   (    0.42 ms per token,  2355.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.62 ms /    23 tokens (   11.20 ms per token,    89.28 tokens per second)\n",
      "llama_print_timings:        eval time =     335.27 ms /     4 runs   (   83.82 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     620.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.01 ms /    11 runs   (    0.55 ms per token,  1829.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.18 ms /    24 tokens (   10.72 ms per token,    93.32 tokens per second)\n",
      "llama_print_timings:        eval time =     863.43 ms /    10 runs   (   86.34 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1195.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2840.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1888.41 ms /   227 tokens (    8.32 ms per token,   120.21 tokens per second)\n",
      "llama_print_timings:        eval time =      85.59 ms /     1 runs   (   85.59 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1982.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 728 0532\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    15 runs   (    0.42 ms per token,  2381.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    25 tokens (   10.10 ms per token,    98.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.86 ms /    14 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1485.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     2 runs   (    0.37 ms per token,  2702.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.21 ms /    23 tokens (   11.14 ms per token,    89.77 tokens per second)\n",
      "llama_print_timings:        eval time =      81.89 ms /     1 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     348.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli urinary tract infection\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    14 runs   (    0.48 ms per token,  2096.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.87 ms /    24 tokens (   10.66 ms per token,    93.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.52 ms /    13 runs   (   88.89 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1498.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cliff O'Reilly\", \"Doctor Leoma Jaskolski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    19 runs   (    0.38 ms per token,  2621.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.29 ms /   186 tokens (    7.54 ms per token,   132.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1487.63 ms /    18 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    3002.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 326 6601\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    15 runs   (    0.25 ms per token,  3952.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.84 ms /    25 tokens (   10.19 ms per token,    98.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1228.33 ms /    14 runs   (   87.74 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    1531.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     6 runs   (    0.16 ms per token,  6237.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.62 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     406.49 ms /     5 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     675.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /    11 runs   (    0.13 ms per token,  7596.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    24 tokens (   10.50 ms per token,    95.22 tokens per second)\n",
      "llama_print_timings:        eval time =     812.87 ms /    10 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1089.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Augustus Herman\", \"Doctor Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /    16 runs   (    0.24 ms per token,  4146.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.38 ms /   171 tokens (    8.12 ms per token,   123.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.62 ms /    15 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2641.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 593 495 3201\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    19 runs   (    0.17 ms per token,  5919.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.61 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1438.11 ms /    18 runs   (   79.90 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1743.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     7 runs   (    0.12 ms per token,  8323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.07 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     491.44 ms /     6 runs   (   81.91 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     757.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     6 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =     405.82 ms /     5 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     669.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dana Schumm\", \"Bernie Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    14 runs   (    0.21 ms per token,  4871.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.99 ms /   181 tokens (    7.73 ms per token,   129.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1027.50 ms /    13 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2475.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"759 101 5229\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    15 runs   (    0.21 ms per token,  4725.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    25 tokens (   10.13 ms per token,    98.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.06 ms /    14 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1421.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.95 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =      81.44 ms /     1 runs   (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     336.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.19 ms per token,  5390.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.13 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =      88.40 ms /     1 runs   (   88.40 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     344.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Kiyoko Schmidt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /    10 runs   (    0.14 ms per token,  7072.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     917.70 ms /   128 tokens (    7.17 ms per token,   139.48 tokens per second)\n",
      "llama_print_timings:        eval time =     721.49 ms /     9 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1663.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"343 402 7925\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    15 runs   (    0.17 ms per token,  5742.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    25 tokens (   10.02 ms per token,    99.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.12 ms /    14 runs   (   79.15 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1409.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     7 runs   (    0.17 ms per token,  5737.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.42 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     472.40 ms /     6 runs   (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     745.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     8 runs   (    0.22 ms per token,  4624.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =     556.61 ms /     7 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     835.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Shameka Nitzsche\", \"Doctor Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    18 runs   (    0.17 ms per token,  5825.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.30 ms /   180 tokens (    7.75 ms per token,   129.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1373.48 ms /    17 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    2827.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 607 0525\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    15 runs   (    0.21 ms per token,  4774.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.89 ms /    25 tokens (   10.12 ms per token,    98.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.25 ms /    14 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1412.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.08 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     109.99 ms /     1 runs   (  109.99 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =     363.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     7 runs   (    0.16 ms per token,  6369.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.49 ms /    24 tokens (   10.52 ms per token,    95.05 tokens per second)\n",
      "llama_print_timings:        eval time =     476.18 ms /     6 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     747.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tressie Frami\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    20 runs   (    0.21 ms per token,  4775.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.83 ms /   160 tokens (    7.17 ms per token,   139.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1519.71 ms /    19 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2741.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     6 runs   (    0.13 ms per token,  7884.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.93 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =     414.51 ms /     5 runs   (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     680.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     9 runs   (    0.13 ms per token,  7929.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     639.61 ms /     8 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     912.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     8 runs   (    0.26 ms per token,  3848.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =     540.43 ms /     7 runs   (   77.20 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =     827.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Joshua Rice\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    17 runs   (    0.22 ms per token,  4615.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.73 ms /   158 tokens (    7.40 ms per token,   135.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1273.09 ms /    16 runs   (   79.57 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2506.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 346 9026\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    15 runs   (    0.23 ms per token,  4433.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.40 ms /    25 tokens (   10.18 ms per token,    98.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.13 ms /    14 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1421.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     7 runs   (    0.15 ms per token,  6616.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.10 ms /    23 tokens (   10.96 ms per token,    91.23 tokens per second)\n",
      "llama_print_timings:        eval time =     495.34 ms /     6 runs   (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     764.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /    11 runs   (    0.15 ms per token,  6462.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.38 ms /    24 tokens (   10.39 ms per token,    96.24 tokens per second)\n",
      "llama_print_timings:        eval time =     803.34 ms /    10 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1084.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Georgiann Shields\", \"Dr. Willian Batz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    20 runs   (    0.13 ms per token,  7550.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.38 ms /   151 tokens (    7.66 ms per token,   130.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1538.55 ms /    19 runs   (   80.98 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2742.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"777 312 2501\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    15 runs   (    0.19 ms per token,  5309.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.84 ms /    25 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.45 ms /    14 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1427.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     5 runs   (    0.27 ms per token,  3773.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.24 ms /    23 tokens (   10.84 ms per token,    92.28 tokens per second)\n",
      "llama_print_timings:        eval time =     308.86 ms /     4 runs   (   77.21 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =     579.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     8 runs   (    0.33 ms per token,  3059.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.93 ms /    24 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =     546.74 ms /     7 runs   (   78.11 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =     839.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Aleida Morar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /    10 runs   (    0.13 ms per token,  7751.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.64 ms /   146 tokens (    7.90 ms per token,   126.56 tokens per second)\n",
      "llama_print_timings:        eval time =     747.47 ms /     9 runs   (   83.05 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1928.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 466 8126\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /    15 runs   (    0.24 ms per token,  4231.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.73 ms /    25 tokens (   10.03 ms per token,    99.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.84 ms /    14 runs   (   82.20 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1464.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     7 runs   (    0.25 ms per token,  3934.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.59 ms /    23 tokens (   10.85 ms per token,    92.15 tokens per second)\n",
      "llama_print_timings:        eval time =     466.60 ms /     6 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =     753.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.19 ms per token,  5167.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.85 ms /    24 tokens (   10.41 ms per token,    96.06 tokens per second)\n",
      "llama_print_timings:        eval time =      78.75 ms /     1 runs   (   78.75 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     335.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raymond Collier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     8 runs   (    0.31 ms per token,  3182.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.74 ms /   160 tokens (    7.22 ms per token,   138.56 tokens per second)\n",
      "llama_print_timings:        eval time =     551.69 ms /     7 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1752.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"562 467 4873\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    15 runs   (    0.15 ms per token,  6530.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.29 ms /    25 tokens (   10.05 ms per token,    99.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1415.36 ms /    14 runs   (  101.10 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =    1712.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     7 runs   (    0.23 ms per token,  4391.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.02 ms /    23 tokens (   11.17 ms per token,    89.49 tokens per second)\n",
      "llama_print_timings:        eval time =     685.98 ms /     6 runs   (  114.33 ms per token,     8.75 tokens per second)\n",
      "llama_print_timings:       total time =     993.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    24 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =     100.29 ms /     1 runs   (  100.29 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     363.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marcelo Morar\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    18 runs   (    0.47 ms per token,  2107.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.91 ms /   146 tokens (    8.01 ms per token,   124.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1381.89 ms /    17 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2672.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"430 268 7673\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.73 ms /    15 runs   (    0.58 ms per token,  1717.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.21 ms /    14 runs   (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1480.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6535.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.35 ms /    23 tokens (   10.88 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =      86.82 ms /     1 runs   (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =     344.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /     7 runs   (    0.65 ms per token,  1540.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.34 ms /    24 tokens (   10.39 ms per token,    96.25 tokens per second)\n",
      "llama_print_timings:        eval time =     470.91 ms /     6 runs   (   78.49 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     778.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rex Jones\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     8 runs   (    0.40 ms per token,  2478.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.05 ms /   151 tokens (    7.66 ms per token,   130.62 tokens per second)\n",
      "llama_print_timings:        eval time =     561.57 ms /     7 runs   (   80.22 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1766.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"292 402 9366\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    15 runs   (    0.36 ms per token,  2807.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.24 ms /    25 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.96 ms /    14 runs   (   79.14 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1442.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /     9 runs   (    0.46 ms per token,  2178.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     633.38 ms /     8 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     949.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /     8 runs   (    0.56 ms per token,  1783.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.86 ms /    24 tokens (   10.45 ms per token,    95.67 tokens per second)\n",
      "llama_print_timings:        eval time =     546.31 ms /     7 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =     857.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Zachariah Emmerich\", \"Dr. Kristopher Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.66 ms /    19 runs   (    0.56 ms per token,  1782.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.09 ms /   172 tokens (    8.01 ms per token,   124.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1410.10 ms /    18 runs   (   78.34 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    2951.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"204 405 0365\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.68 ms /    15 runs   (    0.58 ms per token,  1727.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.06 ms /    25 tokens (   10.08 ms per token,    99.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.45 ms /    14 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1486.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.19 ms per token,  5194.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    23 tokens (   10.96 ms per token,    91.23 tokens per second)\n",
      "llama_print_timings:        eval time =      92.23 ms /     1 runs   (   92.23 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =     352.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4504.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    24 tokens (   10.43 ms per token,    95.89 tokens per second)\n",
      "llama_print_timings:        eval time =      80.42 ms /     1 runs   (   80.42 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     337.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Bettina Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /     9 runs   (    0.56 ms per token,  1781.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.31 ms /   151 tokens (    7.65 ms per token,   130.70 tokens per second)\n",
      "llama_print_timings:        eval time =     628.41 ms /     8 runs   (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1867.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"238 498 7224\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    15 runs   (    0.59 ms per token,  1691.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.35 ms /    25 tokens (   10.09 ms per token,    99.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.48 ms /    14 runs   (   78.39 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1481.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     7 runs   (    0.25 ms per token,  4002.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.07 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     479.86 ms /     6 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     766.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4796.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =      79.64 ms /     1 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     338.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Dian Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    10 runs   (    0.55 ms per token,  1827.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.96 ms /   139 tokens (    8.24 ms per token,   121.40 tokens per second)\n",
      "llama_print_timings:        eval time =     701.46 ms /     9 runs   (   77.94 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1937.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"389 234 8672\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    15 runs   (    0.58 ms per token,  1709.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.16 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.58 ms /    14 runs   (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1479.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     5 runs   (    0.27 ms per token,  3739.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     316.83 ms /     4 runs   (   79.21 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     594.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /     8 runs   (    0.54 ms per token,  1866.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =     553.06 ms /     7 runs   (   79.01 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     862.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sydney Harvey\", \"Dr. Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.19 ms /    16 runs   (    0.64 ms per token,  1570.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.30 ms /   139 tokens (    8.25 ms per token,   121.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.65 ms /    15 runs   (   78.38 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    2471.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 244 1470\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    15 runs   (    0.67 ms per token,  1482.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.25 ms /    14 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1482.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     6 runs   (    0.33 ms per token,  2995.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.13 ms /    23 tokens (   11.09 ms per token,    90.15 tokens per second)\n",
      "llama_print_timings:        eval time =     397.24 ms /     5 runs   (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     690.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     2 runs   (    0.26 ms per token,  3883.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.98 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =      78.92 ms /     1 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     336.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Sebrina Fahey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    12 runs   (    0.71 ms per token,  1406.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.68 ms /   152 tokens (    7.61 ms per token,   131.41 tokens per second)\n",
      "llama_print_timings:        eval time =     868.93 ms /    11 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    2139.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"339 369 6545\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    15 runs   (    0.62 ms per token,  1609.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.28 ms /    14 runs   (   78.59 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1482.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     7 runs   (    0.41 ms per token,  2419.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    23 tokens (   10.94 ms per token,    91.38 tokens per second)\n",
      "llama_print_timings:        eval time =     474.01 ms /     6 runs   (   79.00 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     777.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4395.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.87 ms /    24 tokens (   10.45 ms per token,    95.67 tokens per second)\n",
      "llama_print_timings:        eval time =      80.82 ms /     1 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     339.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ethyl Hickle\", \"Dr. Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.14 ms /    20 runs   (    0.56 ms per token,  1795.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.83 ms /   152 tokens (    7.60 ms per token,   131.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1499.55 ms /    19 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    2845.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"312 672 4877\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1952.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.71 ms /    14 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1471.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /     7 runs   (    0.39 ms per token,  2551.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     470.43 ms /     6 runs   (   78.40 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     769.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /     8 runs   (    0.60 ms per token,  1668.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =     549.94 ms /     7 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     866.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Janell Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /     7 runs   (    0.42 ms per token,  2379.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.48 ms /   172 tokens (    8.01 ms per token,   124.87 tokens per second)\n",
      "llama_print_timings:        eval time =     468.40 ms /     6 runs   (   78.07 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1894.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 824 0229\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    15 runs   (    0.57 ms per token,  1743.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.65 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.73 ms /    14 runs   (   79.34 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1487.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.19 ms per token,  5194.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =      79.24 ms /     1 runs   (   79.24 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     338.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.13 ms /    24 tokens (   10.46 ms per token,    95.57 tokens per second)\n",
      "llama_print_timings:        eval time =      80.79 ms /     1 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     338.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Enoch Muller\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    17 runs   (    0.50 ms per token,  1990.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1876.64 ms /   230 tokens (    8.16 ms per token,   122.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.49 ms /    16 runs   (   79.66 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    3300.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"565 828 6161\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1810.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    25 tokens (   10.14 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.44 ms /    14 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1483.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     9 runs   (    0.51 ms per token,  1968.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    23 tokens (   10.95 ms per token,    91.33 tokens per second)\n",
      "llama_print_timings:        eval time =     630.98 ms /     8 runs   (   78.87 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     955.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     8 runs   (    0.33 ms per token,  3022.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.32 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =     559.01 ms /     7 runs   (   79.86 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     858.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Artie Lynch\", \"Shannon Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    17 runs   (    0.55 ms per token,  1818.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.91 ms /   190 tokens (    7.35 ms per token,   136.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1272.36 ms /    16 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2811.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"390 303 0377\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    15 runs   (    0.53 ms per token,  1891.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.10 ms /    14 runs   (   80.58 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1521.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     9 runs   (    0.29 ms per token,  3501.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    23 tokens (   11.01 ms per token,    90.85 tokens per second)\n",
      "llama_print_timings:        eval time =     681.66 ms /     8 runs   (   85.21 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     978.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /     8 runs   (    0.58 ms per token,  1733.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.96 ms /    24 tokens (   10.92 ms per token,    91.62 tokens per second)\n",
      "llama_print_timings:        eval time =     595.44 ms /     7 runs   (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     919.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lance Pfeffer\", \"Dr. Kristopher Crooks\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    18 runs   (    0.42 ms per token,  2372.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.56 ms /   180 tokens (    7.88 ms per token,   126.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1373.23 ms /    17 runs   (   80.78 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    2929.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"291 169 0842\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    15 runs   (    0.41 ms per token,  2451.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.23 ms /    25 tokens (   10.21 ms per token,    97.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.14 ms /    14 runs   (   82.15 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1506.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     7 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.78 ms /    23 tokens (   11.08 ms per token,    90.27 tokens per second)\n",
      "llama_print_timings:        eval time =     492.30 ms /     6 runs   (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     790.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4219.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.65 ms /    24 tokens (   10.53 ms per token,    94.99 tokens per second)\n",
      "llama_print_timings:        eval time =      79.97 ms /     1 runs   (   79.97 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     341.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Stella Watsica\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /     8 runs   (    0.55 ms per token,  1806.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2705.58 ms /   328 tokens (    8.25 ms per token,   121.23 tokens per second)\n",
      "llama_print_timings:        eval time =     569.51 ms /     7 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    3349.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 832 4895\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    15 runs   (    0.68 ms per token,  1472.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.69 ms /    25 tokens (   10.27 ms per token,    97.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.02 ms /    14 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1520.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.88 ms /    23 tokens (   11.08 ms per token,    90.24 tokens per second)\n",
      "llama_print_timings:        eval time =      81.75 ms /     1 runs   (   81.75 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     346.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     8 runs   (    0.45 ms per token,  2225.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.05 ms /    24 tokens (   10.67 ms per token,    93.73 tokens per second)\n",
      "llama_print_timings:        eval time =     563.87 ms /     7 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     878.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Fernando Purdy\", \"Dr.\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.84 ms /    20 runs   (    0.59 ms per token,  1688.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.61 ms /   183 tokens (    7.69 ms per token,   130.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1506.50 ms /    19 runs   (   79.29 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    3093.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"802 259 4927\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    15 runs   (    0.46 ms per token,  2176.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.92 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.86 ms /    14 runs   (   80.20 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1500.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2563.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.62 ms /    23 tokens (   11.16 ms per token,    89.63 tokens per second)\n",
      "llama_print_timings:        eval time =     645.43 ms /     8 runs   (   80.68 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     967.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    11 runs   (    0.63 ms per token,  1583.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.58 ms /    24 tokens (   10.52 ms per token,    95.02 tokens per second)\n",
      "llama_print_timings:        eval time =     795.07 ms /    10 runs   (   79.51 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1139.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rueben Glover\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    10 runs   (    0.34 ms per token,  2972.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2477.29 ms /   295 tokens (    8.40 ms per token,   119.08 tokens per second)\n",
      "llama_print_timings:        eval time =     740.04 ms /     9 runs   (   82.23 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    3277.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 633 7731\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2069.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.22 ms /    25 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1188.14 ms /    14 runs   (   84.87 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    1567.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     7 runs   (    0.29 ms per token,  3394.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.49 ms /    23 tokens (   11.24 ms per token,    88.98 tokens per second)\n",
      "llama_print_timings:        eval time =     502.60 ms /     6 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     800.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    13 runs   (    0.42 ms per token,  2374.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.65 ms /    24 tokens (   10.82 ms per token,    92.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.44 ms /    12 runs   (   91.45 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =    1438.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Maddie Abshire\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     8 runs   (    0.26 ms per token,  3896.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1220.48 ms /   158 tokens (    7.72 ms per token,   129.46 tokens per second)\n",
      "llama_print_timings:        eval time =     720.25 ms /     7 runs   (  102.89 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =    1979.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 952 7601\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.85 ms /    15 runs   (    0.72 ms per token,  1382.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.40 ms /    25 tokens (   10.78 ms per token,    92.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1425.36 ms /    14 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =    1829.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.19 ms /    23 tokens (   11.23 ms per token,    89.08 tokens per second)\n",
      "llama_print_timings:        eval time =     104.44 ms /     1 runs   (  104.44 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =     372.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    12 runs   (    0.28 ms per token,  3633.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.73 ms /    24 tokens (   10.82 ms per token,    92.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1193.99 ms /    11 runs   (  108.54 ms per token,     9.21 tokens per second)\n",
      "llama_print_timings:       total time =    1527.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kimber Hilpert\", \"Dr. Tracey Hamill\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    18 runs   (    0.24 ms per token,  4234.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1216.43 ms /   156 tokens (    7.80 ms per token,   128.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1735.20 ms /    17 runs   (  102.07 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =    3041.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"801 894 9109\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    15 runs   (    0.43 ms per token,  2337.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.97 ms /    25 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1266.95 ms /    14 runs   (   90.50 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    1633.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.50 ms /    23 tokens (   11.20 ms per token,    89.32 tokens per second)\n",
      "llama_print_timings:        eval time =      87.00 ms /     1 runs   (   87.00 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     351.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     8 runs   (    0.33 ms per token,  3047.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    24 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =     625.49 ms /     7 runs   (   89.36 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =     925.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Vesta Labadie\", \"Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    14 runs   (    0.35 ms per token,  2836.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.78 ms /   227 tokens (    8.59 ms per token,   116.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.44 ms /    13 runs   (   89.65 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    3196.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"712 288 1542\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    15 runs   (    0.47 ms per token,  2149.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.02 ms /    25 tokens (   10.60 ms per token,    94.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1267.50 ms /    14 runs   (   90.54 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    1624.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     5 runs   (    0.40 ms per token,  2526.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.84 ms /    23 tokens (   11.60 ms per token,    86.19 tokens per second)\n",
      "llama_print_timings:        eval time =     358.50 ms /     4 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =     648.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.07 ms /    24 tokens (   10.75 ms per token,    93.00 tokens per second)\n",
      "llama_print_timings:        eval time =     101.70 ms /     1 runs   (  101.70 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =     365.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Voncile Stamm\", \"Doctor Brandon Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    18 runs   (    0.43 ms per token,  2330.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1524.93 ms /   167 tokens (    9.13 ms per token,   109.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1574.04 ms /    17 runs   (   92.59 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =    3255.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"598 804 3779\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    15 runs   (    0.39 ms per token,  2553.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.66 ms /    25 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1268.30 ms /    14 runs   (   90.59 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =    1641.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6756.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.26 ms /    23 tokens (   11.79 ms per token,    84.79 tokens per second)\n",
      "llama_print_timings:        eval time =      98.99 ms /     1 runs   (   98.99 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     377.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4140.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.34 ms /    24 tokens (   11.39 ms per token,    87.80 tokens per second)\n",
      "llama_print_timings:        eval time =      93.71 ms /     1 runs   (   93.71 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     374.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Lorraine Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    11 runs   (    0.38 ms per token,  2598.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1016.50 ms /   124 tokens (    8.20 ms per token,   121.99 tokens per second)\n",
      "llama_print_timings:        eval time =     977.20 ms /    10 runs   (   97.72 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    2072.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"394 357 7458\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    15 runs   (    0.33 ms per token,  3045.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     276.34 ms /    25 tokens (   11.05 ms per token,    90.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.65 ms /    14 runs   (   97.33 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =    1733.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     9 runs   (    0.38 ms per token,  2643.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.94 ms /    23 tokens (   11.87 ms per token,    84.27 tokens per second)\n",
      "llama_print_timings:        eval time =     734.09 ms /     8 runs   (   91.76 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    1059.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     8 runs   (    0.32 ms per token,  3129.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.22 ms /    24 tokens (   11.72 ms per token,    85.34 tokens per second)\n",
      "llama_print_timings:        eval time =     658.89 ms /     7 runs   (   94.13 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =     983.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jasper Senger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     9 runs   (    0.34 ms per token,  2963.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1484.66 ms /   164 tokens (    9.05 ms per token,   110.46 tokens per second)\n",
      "llama_print_timings:        eval time =     716.48 ms /     8 runs   (   89.56 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    2264.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"296 772 9469\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    15 runs   (    0.33 ms per token,  2992.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.18 ms /    25 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1586.43 ms /    14 runs   (  113.32 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    1947.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     7 runs   (    0.32 ms per token,  3137.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.57 ms /    23 tokens (   12.11 ms per token,    82.56 tokens per second)\n",
      "llama_print_timings:        eval time =     607.06 ms /     6 runs   (  101.18 ms per token,     9.88 tokens per second)\n",
      "llama_print_timings:       total time =     922.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    11 runs   (    0.46 ms per token,  2175.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     275.80 ms /    24 tokens (   11.49 ms per token,    87.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.91 ms /    10 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =    1360.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Margarete Mayert\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    20 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.24 ms /   151 tokens (    7.99 ms per token,   125.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1821.98 ms /    19 runs   (   95.89 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    3169.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"736 864 9910\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    15 runs   (    0.40 ms per token,  2478.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.44 ms /    25 tokens (   10.22 ms per token,    97.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.44 ms /    14 runs   (   84.96 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1539.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.21 ms per token,  4866.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.99 ms /    23 tokens (   11.17 ms per token,    89.50 tokens per second)\n",
      "llama_print_timings:        eval time =      89.81 ms /     1 runs   (   89.81 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =     352.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5277.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    24 tokens (   10.48 ms per token,    95.42 tokens per second)\n",
      "llama_print_timings:        eval time =      82.89 ms /     1 runs   (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     340.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Quinn McClure\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    10 runs   (    0.43 ms per token,  2303.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.58 ms /   160 tokens (    7.32 ms per token,   136.57 tokens per second)\n",
      "llama_print_timings:        eval time =     734.53 ms /     9 runs   (   81.61 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1971.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"307 526 2241\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2270.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.06 ms /    25 tokens (   10.28 ms per token,    97.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.55 ms /    14 runs   (   84.11 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1527.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     9 runs   (    0.36 ms per token,  2767.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     660.59 ms /     8 runs   (   82.57 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     964.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     8 runs   (    0.23 ms per token,  4303.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.85 ms /    24 tokens (   10.79 ms per token,    92.72 tokens per second)\n",
      "llama_print_timings:        eval time =     626.12 ms /     7 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     922.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rusty Grady\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    10 runs   (    0.41 ms per token,  2419.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.43 ms /   136 tokens (    8.66 ms per token,   115.51 tokens per second)\n",
      "llama_print_timings:        eval time =     888.13 ms /     9 runs   (   98.68 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =    2121.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"558 504 2770\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2293.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.14 ms /    25 tokens (   10.97 ms per token,    91.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1364.96 ms /    14 runs   (   97.50 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    1740.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /     9 runs   (    0.39 ms per token,  2569.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.75 ms /    23 tokens (   11.29 ms per token,    88.55 tokens per second)\n",
      "llama_print_timings:        eval time =     702.90 ms /     8 runs   (   87.86 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1010.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.47 ms /    24 tokens (   10.85 ms per token,    92.14 tokens per second)\n",
      "llama_print_timings:        eval time =      94.22 ms /     1 runs   (   94.22 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     359.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cornell Gleichner\", \"Dr. Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    18 runs   (    0.38 ms per token,  2618.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3357.64 ms /   389 tokens (    8.63 ms per token,   115.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1549.74 ms /    17 runs   (   91.16 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =    5028.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"466 534 9250\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.39 ms /    15 runs   (    0.43 ms per token,  2347.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.91 ms /    25 tokens (   10.64 ms per token,    94.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1287.56 ms /    14 runs   (   91.97 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =    1653.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     5 runs   (    0.38 ms per token,  2642.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.15 ms /    23 tokens (   11.14 ms per token,    89.79 tokens per second)\n",
      "llama_print_timings:        eval time =     346.24 ms /     4 runs   (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     626.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.57 ms /     2 runs   (    0.29 ms per token,  3496.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.92 ms /    24 tokens (   11.04 ms per token,    90.59 tokens per second)\n",
      "llama_print_timings:        eval time =      94.78 ms /     1 runs   (   94.78 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     367.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Keren Mann\", \"Dr Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    16 runs   (    0.39 ms per token,  2571.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.77 ms /   149 tokens (    8.01 ms per token,   124.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1402.66 ms /    15 runs   (   93.51 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =    2718.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"442 995 0706\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2350.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.01 ms /    25 tokens (   10.36 ms per token,    96.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.77 ms /    14 runs   (  107.20 ms per token,     9.33 tokens per second)\n",
      "llama_print_timings:       total time =    1851.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.40 ms /     9 runs   (    1.04 ms per token,   957.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =     759.99 ms /     8 runs   (   95.00 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =    1074.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"complaint\", \"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.71 ms /    13 runs   (    0.36 ms per token,  2758.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.01 ms /    24 tokens (   10.63 ms per token,    94.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.88 ms /    12 runs   (   93.99 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =    1457.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gaylord Gutmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    10 runs   (    0.25 ms per token,  4065.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1445.55 ms /   172 tokens (    8.40 ms per token,   118.99 tokens per second)\n",
      "llama_print_timings:        eval time =     943.40 ms /     9 runs   (  104.82 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =    2438.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"546 727 5308\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    15 runs   (    0.41 ms per token,  2431.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.20 ms /    25 tokens (   10.33 ms per token,    96.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1306.38 ms /    14 runs   (   93.31 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =    1670.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     9 runs   (    0.23 ms per token,  4418.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.65 ms /    23 tokens (   11.68 ms per token,    85.61 tokens per second)\n",
      "llama_print_timings:        eval time =     787.42 ms /     8 runs   (   98.43 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =    1096.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.99 ms /    24 tokens (   10.79 ms per token,    92.67 tokens per second)\n",
      "llama_print_timings:        eval time =     103.57 ms /     1 runs   (  103.57 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =     370.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Marisa Heaney MD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /    12 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.71 ms /   138 tokens (    8.58 ms per token,   116.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1007.25 ms /    11 runs   (   91.57 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =    2269.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"383 778 6896\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    15 runs   (    0.62 ms per token,  1615.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.06 ms /    25 tokens (   10.36 ms per token,    96.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1433.54 ms /    14 runs   (  102.40 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =    1818.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     8 runs   (    0.35 ms per token,  2819.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.10 ms /    23 tokens (   11.44 ms per token,    87.42 tokens per second)\n",
      "llama_print_timings:        eval time =     647.80 ms /     7 runs   (   92.54 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =     950.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     8 runs   (    0.40 ms per token,  2505.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.30 ms /    24 tokens (   10.80 ms per token,    92.56 tokens per second)\n",
      "llama_print_timings:        eval time =     628.34 ms /     7 runs   (   89.76 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     930.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Janyce Littel\", \"Dr. Lynsey Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    16 runs   (    0.31 ms per token,  3248.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.27 ms /   153 tokens (    7.81 ms per token,   128.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1420.35 ms /    15 runs   (   94.69 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =    2704.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 797 4807\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    15 runs   (    0.45 ms per token,  2239.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.04 ms /    25 tokens (   10.36 ms per token,    96.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.67 ms /    14 runs   (   86.48 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1562.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     8 runs   (    0.31 ms per token,  3192.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.15 ms /    23 tokens (   11.27 ms per token,    88.75 tokens per second)\n",
      "llama_print_timings:        eval time =     620.78 ms /     7 runs   (   88.68 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     924.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6472.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.62 ms /    24 tokens (   10.69 ms per token,    93.52 tokens per second)\n",
      "llama_print_timings:        eval time =      88.55 ms /     1 runs   (   88.55 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     351.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Titus Sipes\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    16 runs   (    0.34 ms per token,  2942.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1441.02 ms /   184 tokens (    7.83 ms per token,   127.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1432.05 ms /    15 runs   (   95.47 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =    2969.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"608 568 7417\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    15 runs   (    0.42 ms per token,  2372.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    25 tokens (   10.26 ms per token,    97.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1228.61 ms /    14 runs   (   87.76 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    1577.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =      79.18 ms /     1 runs   (   79.18 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     337.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     8 runs   (    0.27 ms per token,  3649.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     586.73 ms /     7 runs   (   83.82 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     875.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rogelio Kling\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.33 ms /    17 runs   (    0.55 ms per token,  1822.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.37 ms /   163 tokens (    8.44 ms per token,   118.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.24 ms /    16 runs   (   80.89 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2794.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 238 6080\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    15 runs   (    0.55 ms per token,  1820.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.49 ms /    25 tokens (   10.10 ms per token,    99.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.29 ms /    14 runs   (   82.52 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1514.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /     9 runs   (    0.51 ms per token,  1958.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =     652.29 ms /     8 runs   (   81.54 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     971.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     8 runs   (    0.51 ms per token,  1949.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.37 ms /    24 tokens (   10.52 ms per token,    95.10 tokens per second)\n",
      "llama_print_timings:        eval time =     586.06 ms /     7 runs   (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     887.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hong Hammes\", \"Dr. Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    16 runs   (    0.52 ms per token,  1935.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.33 ms /   130 tokens (    8.79 ms per token,   113.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1203.19 ms /    15 runs   (   80.21 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2477.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"587 349 4637\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.97 ms /    15 runs   (    0.33 ms per token,  3016.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.13 ms /    14 runs   (   92.22 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =    1635.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     7 runs   (    0.36 ms per token,  2792.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.46 ms /    23 tokens (   11.06 ms per token,    90.39 tokens per second)\n",
      "llama_print_timings:        eval time =     561.74 ms /     6 runs   (   93.62 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =     858.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     2 runs   (    0.38 ms per token,  2607.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.84 ms /    24 tokens (   11.62 ms per token,    86.07 tokens per second)\n",
      "llama_print_timings:        eval time =      99.48 ms /     1 runs   (   99.48 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     390.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     2 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1472.53 ms /   165 tokens (    8.92 ms per token,   112.05 tokens per second)\n",
      "llama_print_timings:        eval time =      80.42 ms /     1 runs   (   80.42 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1563.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 803 0078\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    15 runs   (    0.53 ms per token,  1884.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.13 ms /    25 tokens (   10.17 ms per token,    98.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.85 ms /    14 runs   (   84.13 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1535.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     2 runs   (    0.24 ms per token,  4166.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    23 tokens (   10.92 ms per token,    91.60 tokens per second)\n",
      "llama_print_timings:        eval time =      81.43 ms /     1 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     340.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     7 runs   (    0.34 ms per token,  2909.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.02 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     540.70 ms /     6 runs   (   90.12 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =     835.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ward Cormier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     9 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.64 ms /   179 tokens (    8.11 ms per token,   123.31 tokens per second)\n",
      "llama_print_timings:        eval time =     673.50 ms /     8 runs   (   84.19 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    2179.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"729 566 1223\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    15 runs   (    0.44 ms per token,  2266.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.95 ms /    25 tokens (   10.16 ms per token,    98.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.19 ms /    14 runs   (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1554.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.66 ms /    23 tokens (   11.51 ms per token,    86.90 tokens per second)\n",
      "llama_print_timings:        eval time =      87.33 ms /     1 runs   (   87.33 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     359.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    16 runs   (    0.45 ms per token,  2198.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.51 ms /    24 tokens (   10.81 ms per token,    92.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.19 ms /    15 runs   (   79.81 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1583.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ramona Kerluke\", \"Riley Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.78 ms /    16 runs   (    0.61 ms per token,  1636.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.94 ms /   160 tokens (    7.31 ms per token,   136.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.61 ms /    15 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    2519.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 575 7640\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    15 runs   (    0.49 ms per token,  2050.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.28 ms /    25 tokens (   10.57 ms per token,    94.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.41 ms /    14 runs   (   83.96 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    1536.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     5 runs   (    0.43 ms per token,  2351.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    23 tokens (   10.93 ms per token,    91.46 tokens per second)\n",
      "llama_print_timings:        eval time =     331.24 ms /     4 runs   (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     612.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    11 runs   (    0.49 ms per token,  2029.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.84 ms /    24 tokens (   10.53 ms per token,    94.92 tokens per second)\n",
      "llama_print_timings:        eval time =     864.75 ms /    10 runs   (   86.48 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1186.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cathern Tromp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     9 runs   (    0.42 ms per token,  2377.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2482.71 ms /   317 tokens (    7.83 ms per token,   127.68 tokens per second)\n",
      "llama_print_timings:        eval time =     694.65 ms /     8 runs   (   86.83 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    3233.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 502 5643\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    15 runs   (    0.49 ms per token,  2051.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.70 ms /    25 tokens (   10.31 ms per token,    97.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1191.40 ms /    14 runs   (   85.10 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    1546.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5063.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.02 ms /    23 tokens (   11.09 ms per token,    90.19 tokens per second)\n",
      "llama_print_timings:        eval time =      88.92 ms /     1 runs   (   88.92 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     349.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8163.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.15 ms /    24 tokens (   11.01 ms per token,    90.86 tokens per second)\n",
      "llama_print_timings:        eval time =      94.26 ms /     1 runs   (   94.26 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     361.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wayne Lang\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     7 runs   (    0.43 ms per token,  2339.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.72 ms /   134 tokens (    8.62 ms per token,   115.95 tokens per second)\n",
      "llama_print_timings:        eval time =     498.37 ms /     6 runs   (   83.06 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1698.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"867 641 6685\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2187.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.68 ms /    25 tokens (   10.35 ms per token,    96.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.62 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1506.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     9 runs   (    0.36 ms per token,  2778.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.21 ms /    23 tokens (   11.01 ms per token,    90.84 tokens per second)\n",
      "llama_print_timings:        eval time =     639.44 ms /     8 runs   (   79.93 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     951.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    24 tokens (   10.44 ms per token,    95.78 tokens per second)\n",
      "llama_print_timings:        eval time =      81.72 ms /     1 runs   (   81.72 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     339.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Forrest Ledner\", \"Dr. Reggie Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    17 runs   (    0.45 ms per token,  2203.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1619.46 ms /   194 tokens (    8.35 ms per token,   119.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1340.35 ms /    16 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    3084.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"486 248 4573\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    15 runs   (    0.41 ms per token,  2433.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.72 ms /    25 tokens (   10.71 ms per token,    93.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1306.81 ms /    14 runs   (   93.34 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =    1667.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     9 runs   (    0.32 ms per token,  3145.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.36 ms /    23 tokens (   11.19 ms per token,    89.37 tokens per second)\n",
      "llama_print_timings:        eval time =     764.87 ms /     8 runs   (   95.61 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    1070.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.97 ms /    24 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =     116.95 ms /     1 runs   (  116.95 ms per token,     8.55 tokens per second)\n",
      "llama_print_timings:       total time =     391.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Patrick Cronin\", \"Doctor Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    17 runs   (    0.34 ms per token,  2951.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.47 ms /   174 tokens (    8.26 ms per token,   121.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1516.50 ms /    16 runs   (   94.78 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =    3051.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 842 3690\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2126.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.28 ms /    25 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1363.80 ms /    14 runs   (   97.41 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =    1733.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.81 ms /    23 tokens (   11.77 ms per token,    84.93 tokens per second)\n",
      "llama_print_timings:        eval time =      92.88 ms /     1 runs   (   92.88 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =     373.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.19 ms per token,  5361.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.88 ms /    24 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =      82.00 ms /     1 runs   (   82.00 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     338.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mose Heidenreich\", \"Doctor Cira Jakubowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    19 runs   (    0.40 ms per token,  2514.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.94 ms /   158 tokens (    7.38 ms per token,   135.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.99 ms /    18 runs   (   81.11 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2765.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 246 3344\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    15 runs   (    0.49 ms per token,  2047.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.21 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.93 ms /    14 runs   (   83.71 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    1528.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.27 ms per token,  3745.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =      85.06 ms /     1 runs   (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     343.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    11 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.88 ms /    24 tokens (   10.62 ms per token,    94.16 tokens per second)\n",
      "llama_print_timings:        eval time =     842.18 ms /    10 runs   (   84.22 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    1169.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dominique Gerlach\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    16 runs   (    0.61 ms per token,  1650.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.20 ms /   153 tokens (    7.56 ms per token,   132.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1194.54 ms /    15 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2498.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 916 9912\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1950.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.38 ms /    25 tokens (   10.10 ms per token,    99.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.48 ms /    14 runs   (   80.25 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1481.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /     8 runs   (    0.52 ms per token,  1919.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.13 ms /    23 tokens (   11.35 ms per token,    88.08 tokens per second)\n",
      "llama_print_timings:        eval time =     591.68 ms /     7 runs   (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     908.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    11 runs   (    0.32 ms per token,  3143.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.80 ms /    24 tokens (   10.66 ms per token,    93.83 tokens per second)\n",
      "llama_print_timings:        eval time =     929.81 ms /    10 runs   (   92.98 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =    1240.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /     8 runs   (    0.36 ms per token,  2808.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.82 ms /   167 tokens (    8.65 ms per token,   115.59 tokens per second)\n",
      "llama_print_timings:        eval time =     650.19 ms /     7 runs   (   92.88 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =    2136.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 632 237 5698\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.57 ms /    19 runs   (    0.45 ms per token,  2216.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.30 ms /    25 tokens (   10.69 ms per token,    93.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1691.00 ms /    18 runs   (   93.94 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =    2076.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     9 runs   (    0.36 ms per token,  2816.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.91 ms /    23 tokens (   11.43 ms per token,    87.48 tokens per second)\n",
      "llama_print_timings:        eval time =     690.88 ms /     8 runs   (   86.36 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     997.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.56 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =      85.27 ms /     1 runs   (   85.27 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     344.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ervin Leuschke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /    10 runs   (    0.35 ms per token,  2882.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.63 ms /   179 tokens (    7.85 ms per token,   127.44 tokens per second)\n",
      "llama_print_timings:        eval time =     727.76 ms /     9 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2197.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"517 247 9011\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    15 runs   (    0.40 ms per token,  2529.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.36 ms /    25 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.37 ms /    14 runs   (   87.03 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    1569.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"68\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     5 runs   (    0.35 ms per token,  2858.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.49 ms /    23 tokens (   11.37 ms per token,    87.96 tokens per second)\n",
      "llama_print_timings:        eval time =     335.89 ms /     4 runs   (   83.97 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     621.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     9 runs   (    0.51 ms per token,  1970.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     675.23 ms /     8 runs   (   84.40 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     987.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Nguyet Simonis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /    12 runs   (    0.38 ms per token,  2654.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.11 ms /   129 tokens (    8.92 ms per token,   112.16 tokens per second)\n",
      "llama_print_timings:        eval time =     988.28 ms /    11 runs   (   89.84 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    2223.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"620 378 2581\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    15 runs   (    0.42 ms per token,  2396.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.64 ms /    25 tokens (   10.11 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.90 ms /    14 runs   (   86.28 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1552.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     5 runs   (    0.32 ms per token,  3126.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.68 ms /    23 tokens (   11.29 ms per token,    88.57 tokens per second)\n",
      "llama_print_timings:        eval time =     331.22 ms /     4 runs   (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     619.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6849.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =      85.50 ms /     1 runs   (   85.50 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     341.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Norris Leffler\", \"Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    16 runs   (    0.53 ms per token,  1898.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.08 ms /   153 tokens (    7.63 ms per token,   130.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.50 ms /    15 runs   (   87.43 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2582.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"985 277 6838\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    15 runs   (    0.34 ms per token,  2903.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.95 ms /    25 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1228.54 ms /    14 runs   (   87.75 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    1584.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.31 ms per token,  3257.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.46 ms /    23 tokens (   11.32 ms per token,    88.30 tokens per second)\n",
      "llama_print_timings:        eval time =      93.24 ms /     1 runs   (   93.24 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =     361.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     8 runs   (    0.33 ms per token,  3033.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.32 ms /    24 tokens (   10.97 ms per token,    91.14 tokens per second)\n",
      "llama_print_timings:        eval time =     628.41 ms /     7 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     926.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Nedra Labadie\", \"husband\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    15 runs   (    0.39 ms per token,  2564.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.96 ms /   163 tokens (    8.59 ms per token,   116.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1183.18 ms /    14 runs   (   84.51 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    2676.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"588 834 3121\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    15 runs   (    0.56 ms per token,  1790.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    25 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.22 ms /    14 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1486.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    23 tokens (   11.01 ms per token,    90.84 tokens per second)\n",
      "llama_print_timings:        eval time =     654.35 ms /     8 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     968.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    11 runs   (    0.39 ms per token,  2584.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.91 ms /    24 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     849.38 ms /    10 runs   (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1181.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kayleigh Haag\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     9 runs   (    0.36 ms per token,  2782.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.03 ms /   142 tokens (    8.16 ms per token,   122.52 tokens per second)\n",
      "llama_print_timings:        eval time =     661.79 ms /     8 runs   (   82.72 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1870.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 233 5841\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    15 runs   (    0.57 ms per token,  1739.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.67 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.64 ms /    14 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1480.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.23 ms per token,  4444.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    23 tokens (   10.94 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =      82.45 ms /     1 runs   (   82.45 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     340.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /    12 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.20 ms /    24 tokens (   10.51 ms per token,    95.16 tokens per second)\n",
      "llama_print_timings:        eval time =     879.72 ms /    11 runs   (   79.97 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1212.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Pearly Leannon\", \"Dr. Antonette Tromp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    19 runs   (    0.37 ms per token,  2705.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.82 ms /   147 tokens (    8.11 ms per token,   123.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1647.81 ms /    18 runs   (   91.54 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =    2952.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"282 531 5900\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    15 runs   (    0.35 ms per token,  2882.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.37 ms /    25 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1351.90 ms /    14 runs   (   96.56 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =    1688.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     9 runs   (    0.28 ms per token,  3602.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.62 ms /    23 tokens (   11.11 ms per token,    89.98 tokens per second)\n",
      "llama_print_timings:        eval time =     722.63 ms /     8 runs   (   90.33 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1018.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     8 runs   (    0.48 ms per token,  2076.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.75 ms /    24 tokens (   10.74 ms per token,    93.11 tokens per second)\n",
      "llama_print_timings:        eval time =     605.50 ms /     7 runs   (   86.50 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     915.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Patrick Halvorson\", \"Dr. Lynsey Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    18 runs   (    0.41 ms per token,  2435.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.21 ms /   160 tokens (    7.38 ms per token,   135.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1579.70 ms /    17 runs   (   92.92 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =    2893.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 892 7386\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1991.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.76 ms /    25 tokens (   10.59 ms per token,    94.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1269.00 ms /    14 runs   (   90.64 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =    1630.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.30 ms per token,  3300.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    23 tokens (   10.99 ms per token,    90.99 tokens per second)\n",
      "llama_print_timings:        eval time =      84.91 ms /     1 runs   (   84.91 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     345.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    11 runs   (    0.39 ms per token,  2569.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    24 tokens (   10.50 ms per token,    95.22 tokens per second)\n",
      "llama_print_timings:        eval time =     859.57 ms /    10 runs   (   85.96 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1179.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cristopher Wiegand\", \"Dr. Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    18 runs   (    0.38 ms per token,  2666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.51 ms /   150 tokens (    7.80 ms per token,   128.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1387.62 ms /    17 runs   (   81.62 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    2673.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"746 736 4334\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    15 runs   (    0.52 ms per token,  1927.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.55 ms /    25 tokens (   10.30 ms per token,    97.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.32 ms /    14 runs   (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    1553.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     9 runs   (    0.31 ms per token,  3246.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.51 ms /    23 tokens (   10.89 ms per token,    91.81 tokens per second)\n",
      "llama_print_timings:        eval time =     661.33 ms /     8 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     958.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.56 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     589.09 ms /     7 runs   (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     890.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rowena Ward\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     9 runs   (    0.29 ms per token,  3493.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.06 ms /   152 tokens (    7.91 ms per token,   126.45 tokens per second)\n",
      "llama_print_timings:        eval time =     697.68 ms /     8 runs   (   87.21 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    1947.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"207 982 0503\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    15 runs   (    0.49 ms per token,  2033.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.63 ms /    25 tokens (   10.59 ms per token,    94.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1258.13 ms /    14 runs   (   89.87 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    1618.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     4 runs   (    0.21 ms per token,  4860.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.39 ms /    23 tokens (   11.32 ms per token,    88.33 tokens per second)\n",
      "llama_print_timings:        eval time =     266.71 ms /     3 runs   (   88.90 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     547.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.09 ms /    11 runs   (    0.28 ms per token,  3556.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    24 tokens (   10.46 ms per token,    95.61 tokens per second)\n",
      "llama_print_timings:        eval time =     877.94 ms /    10 runs   (   87.79 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    1180.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     2 runs   (    0.38 ms per token,  2663.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2842.37 ms /   339 tokens (    8.38 ms per token,   119.27 tokens per second)\n",
      "llama_print_timings:        eval time =      95.90 ms /     1 runs   (   95.90 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    2949.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"132 784 8607\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    15 runs   (    0.48 ms per token,  2082.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.37 ms /    25 tokens (   10.97 ms per token,    91.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1290.06 ms /    14 runs   (   92.15 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =    1670.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.52 ms /     2 runs   (    0.26 ms per token,  3831.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.40 ms /    23 tokens (   11.58 ms per token,    86.34 tokens per second)\n",
      "llama_print_timings:        eval time =     107.81 ms /     1 runs   (  107.81 ms per token,     9.28 tokens per second)\n",
      "llama_print_timings:       total time =     381.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     6 runs   (    0.36 ms per token,  2815.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    24 tokens (   10.64 ms per token,    94.01 tokens per second)\n",
      "llama_print_timings:        eval time =     439.62 ms /     5 runs   (   87.92 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =     728.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Steven Leannon\", \"Doctor Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    16 runs   (    0.44 ms per token,  2294.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.73 ms /   193 tokens (    8.48 ms per token,   117.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1334.61 ms /    15 runs   (   88.97 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    3082.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"466 893 5516\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    15 runs   (    0.58 ms per token,  1724.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.14 ms /    25 tokens (   10.21 ms per token,    97.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.33 ms /    14 runs   (   85.67 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    1550.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     7 runs   (    0.49 ms per token,  2048.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.90 ms /    23 tokens (   11.43 ms per token,    87.49 tokens per second)\n",
      "llama_print_timings:        eval time =     494.12 ms /     6 runs   (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     801.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    24 tokens (   10.52 ms per token,    95.08 tokens per second)\n",
      "llama_print_timings:        eval time =      82.64 ms /     1 runs   (   82.64 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     342.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lupe Smitham\", \"Alejandro Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    14 runs   (    0.46 ms per token,  2167.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.27 ms /   143 tokens (    8.06 ms per token,   124.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1049.64 ms /    13 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2307.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 403 3491\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    15 runs   (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.56 ms /    14 runs   (   88.75 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    1591.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     6 runs   (    0.28 ms per token,  3510.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.43 ms /    23 tokens (   11.11 ms per token,    90.04 tokens per second)\n",
      "llama_print_timings:        eval time =     407.09 ms /     5 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     692.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Seasonal allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    12 runs   (    0.36 ms per token,  2752.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    24 tokens (   10.50 ms per token,    95.26 tokens per second)\n",
      "llama_print_timings:        eval time =     935.50 ms /    11 runs   (   85.05 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    1257.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Iona Kub\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     6 runs   (    0.59 ms per token,  1693.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     955.34 ms /   126 tokens (    7.58 ms per token,   131.89 tokens per second)\n",
      "llama_print_timings:        eval time =     409.58 ms /     5 runs   (   81.92 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1405.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 844 1457\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    15 runs   (    0.46 ms per token,  2175.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.78 ms /    14 runs   (   89.63 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1600.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     8 runs   (    0.51 ms per token,  1973.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.91 ms /    23 tokens (   11.82 ms per token,    84.59 tokens per second)\n",
      "llama_print_timings:        eval time =     567.09 ms /     7 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =     890.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     8 runs   (    0.30 ms per token,  3305.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    24 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =     574.59 ms /     7 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     862.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jolie Hackett\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    19 runs   (    0.42 ms per token,  2387.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.63 ms /   184 tokens (    7.62 ms per token,   131.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1506.64 ms /    18 runs   (   83.70 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    3035.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"220 646 8705\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    15 runs   (    0.46 ms per token,  2195.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.90 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.23 ms /    14 runs   (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    1593.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2556.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     648.87 ms /     8 runs   (   81.11 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     953.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     2 runs   (    0.26 ms per token,  3898.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    24 tokens (   10.48 ms per token,    95.40 tokens per second)\n",
      "llama_print_timings:        eval time =      81.13 ms /     1 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     340.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Korey Kutch\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    17 runs   (    0.38 ms per token,  2605.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.35 ms /   172 tokens (    8.01 ms per token,   124.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1361.31 ms /    16 runs   (   85.08 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    2853.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 958 8671\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    15 runs   (    0.45 ms per token,  2242.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.46 ms /    25 tokens (   10.18 ms per token,    98.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.43 ms /    14 runs   (   86.46 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =    1555.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.15 ms /    23 tokens (   10.92 ms per token,    91.58 tokens per second)\n",
      "llama_print_timings:        eval time =      87.82 ms /     1 runs   (   87.82 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     343.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2256.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.68 ms /    24 tokens (   10.69 ms per token,    93.50 tokens per second)\n",
      "llama_print_timings:        eval time =     580.14 ms /     7 runs   (   82.88 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     891.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ellsworth Glover\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    17 runs   (    0.47 ms per token,  2134.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.72 ms /   156 tokens (    7.45 ms per token,   134.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1352.11 ms /    16 runs   (   84.51 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    2638.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"459 771 8981\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.38 ms /    15 runs   (    0.49 ms per token,  2032.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.57 ms /    25 tokens (   10.14 ms per token,    98.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.56 ms /    14 runs   (   82.47 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1523.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2700.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =     693.06 ms /     8 runs   (   86.63 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     994.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.20 ms per token,  5115.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    24 tokens (   10.49 ms per token,    95.34 tokens per second)\n",
      "llama_print_timings:        eval time =      82.95 ms /     1 runs   (   82.95 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     341.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Laurie Luettgen\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.31 ms /    19 runs   (    0.70 ms per token,  1427.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.57 ms /   155 tokens (    7.46 ms per token,   134.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.42 ms /    18 runs   (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2759.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"260 134 8537\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    15 runs   (    0.54 ms per token,  1838.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.48 ms /    25 tokens (   10.26 ms per token,    97.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.07 ms /    14 runs   (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1556.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     7 runs   (    0.42 ms per token,  2400.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    23 tokens (   11.00 ms per token,    90.89 tokens per second)\n",
      "llama_print_timings:        eval time =     489.55 ms /     6 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     781.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /     6 runs   (    0.43 ms per token,  2352.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.52 ms /    24 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =     430.92 ms /     5 runs   (   86.18 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     726.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Anderson McKenzie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     8 runs   (    0.35 ms per token,  2866.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.44 ms /   141 tokens (    8.41 ms per token,   118.94 tokens per second)\n",
      "llama_print_timings:        eval time =     672.60 ms /     7 runs   (   96.09 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =    1910.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 752 2666\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2162.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.08 ms /    25 tokens (   11.16 ms per token,    89.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1292.91 ms /    14 runs   (   92.35 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =    1665.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     7 runs   (    0.24 ms per token,  4196.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.81 ms /    23 tokens (   11.51 ms per token,    86.85 tokens per second)\n",
      "llama_print_timings:        eval time =     537.95 ms /     6 runs   (   89.66 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     835.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4514.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.57 ms /    24 tokens (   11.02 ms per token,    90.71 tokens per second)\n",
      "llama_print_timings:        eval time =      91.83 ms /     1 runs   (   91.83 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     363.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hana McCullough\", \"Dr. Harland Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    18 runs   (    0.37 ms per token,  2691.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.13 ms /   152 tokens (    7.78 ms per token,   128.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1484.81 ms /    17 runs   (   87.34 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    2766.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"112 247 3446\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    15 runs   (    0.42 ms per token,  2361.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.53 ms /    25 tokens (   10.14 ms per token,    98.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.52 ms /    14 runs   (   87.82 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    1567.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2714.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.76 ms /    23 tokens (   11.29 ms per token,    88.54 tokens per second)\n",
      "llama_print_timings:        eval time =     744.79 ms /     8 runs   (   93.10 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =    1049.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    18 runs   (    0.42 ms per token,  2359.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.23 ms /    24 tokens (   10.72 ms per token,    93.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1474.74 ms /    17 runs   (   86.75 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1843.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Arie Bahringer\", \"Dr. Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    19 runs   (    0.37 ms per token,  2716.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1693.08 ms /   211 tokens (    8.02 ms per token,   124.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1527.48 ms /    18 runs   (   84.86 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    3343.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"266 352 0899\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    15 runs   (    0.52 ms per token,  1941.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.41 ms /    25 tokens (   10.22 ms per token,    97.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.04 ms /    14 runs   (   83.57 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1522.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     9 runs   (    0.36 ms per token,  2803.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.94 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =     690.75 ms /     8 runs   (   86.34 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1001.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.46 ms /     2 runs   (    0.23 ms per token,  4376.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.76 ms /    24 tokens (   10.57 ms per token,    94.58 tokens per second)\n",
      "llama_print_timings:        eval time =      85.06 ms /     1 runs   (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     346.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Russel Marvin\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    17 runs   (    0.40 ms per token,  2470.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.18 ms /   144 tokens (    8.12 ms per token,   123.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1428.24 ms /    16 runs   (   89.26 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    2702.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"811 893 9861\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    15 runs   (    0.58 ms per token,  1709.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    25 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.89 ms /    14 runs   (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1516.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     8 runs   (    0.36 ms per token,  2801.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.71 ms /    23 tokens (   11.03 ms per token,    90.66 tokens per second)\n",
      "llama_print_timings:        eval time =     602.84 ms /     7 runs   (   86.12 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     902.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     5 runs   (    0.36 ms per token,  2760.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    24 tokens (   10.49 ms per token,    95.30 tokens per second)\n",
      "llama_print_timings:        eval time =     327.06 ms /     4 runs   (   81.77 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     605.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lurlene Moen\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    19 runs   (    0.45 ms per token,  2229.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1664.34 ms /   194 tokens (    8.58 ms per token,   116.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.47 ms /    18 runs   (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    3287.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"867 574 6047\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    15 runs   (    0.45 ms per token,  2231.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.30 ms /    25 tokens (   10.33 ms per token,    96.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1219.17 ms /    14 runs   (   87.08 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    1584.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"68 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     7 runs   (    0.36 ms per token,  2766.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.03 ms /    23 tokens (   11.09 ms per token,    90.19 tokens per second)\n",
      "llama_print_timings:        eval time =     532.77 ms /     6 runs   (   88.80 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     826.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    12 runs   (    0.44 ms per token,  2259.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.78 ms /    24 tokens (   11.24 ms per token,    88.96 tokens per second)\n",
      "llama_print_timings:        eval time =     955.21 ms /    11 runs   (   86.84 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    1299.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Twyla Dicki\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /     8 runs   (    0.55 ms per token,  1830.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.57 ms /   147 tokens (    8.21 ms per token,   121.83 tokens per second)\n",
      "llama_print_timings:        eval time =     595.33 ms /     7 runs   (   85.05 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    1854.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 227 9612\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    19 runs   (    0.47 ms per token,  2130.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.94 ms /    25 tokens (   10.52 ms per token,    95.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1485.26 ms /    18 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1877.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.19 ms per token,  5141.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.27 ms /    23 tokens (   11.23 ms per token,    89.05 tokens per second)\n",
      "llama_print_timings:        eval time =      90.05 ms /     1 runs   (   90.05 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =     354.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     8 runs   (    0.46 ms per token,  2159.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.20 ms /    24 tokens (   10.92 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     560.68 ms /     7 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     865.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Robt Hoeger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     8 runs   (    0.25 ms per token,  3952.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.14 ms /   171 tokens (    8.33 ms per token,   119.99 tokens per second)\n",
      "llama_print_timings:        eval time =     594.46 ms /     7 runs   (   84.92 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    2058.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 746 1314\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    15 runs   (    0.45 ms per token,  2238.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    25 tokens (   10.18 ms per token,    98.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.92 ms /    14 runs   (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1524.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3820.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.88 ms /    23 tokens (   11.08 ms per token,    90.24 tokens per second)\n",
      "llama_print_timings:        eval time =     584.52 ms /     7 runs   (   83.50 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     883.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    12 runs   (    0.43 ms per token,  2348.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.40 ms /    24 tokens (   10.56 ms per token,    94.71 tokens per second)\n",
      "llama_print_timings:        eval time =     888.01 ms /    11 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1224.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jeanice Reichert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /    10 runs   (    0.25 ms per token,  3947.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.35 ms /   160 tokens (    7.33 ms per token,   136.48 tokens per second)\n",
      "llama_print_timings:        eval time =     748.77 ms /     9 runs   (   83.20 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1968.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"502 557 5524\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    15 runs   (    0.41 ms per token,  2441.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.88 ms /    14 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1464.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     9 runs   (    0.31 ms per token,  3264.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.91 ms /    23 tokens (   10.91 ms per token,    91.67 tokens per second)\n",
      "llama_print_timings:        eval time =     657.84 ms /     8 runs   (   82.23 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     950.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.99 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =      82.26 ms /     1 runs   (   82.26 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     340.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Dale Hamill\", \"Dr. Nikia Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    17 runs   (    0.47 ms per token,  2113.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.58 ms /   185 tokens (    7.53 ms per token,   132.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1302.64 ms /    16 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    2813.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 892 392 6339\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    19 runs   (    0.48 ms per token,  2067.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    25 tokens (   10.14 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1442.25 ms /    18 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1823.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2338.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =     640.37 ms /     8 runs   (   80.05 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     950.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     8 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     557.06 ms /     7 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     851.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Freddie Zemlak\", \"Dr Eldon Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.28 ms /    17 runs   (    0.37 ms per token,  2707.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.95 ms /   174 tokens (    7.93 ms per token,   126.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1298.39 ms /    16 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    2785.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 905 3091\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    15 runs   (    0.47 ms per token,  2136.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.73 ms /    25 tokens (   10.31 ms per token,    97.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.60 ms /    14 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1499.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8583.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.19 ms /    23 tokens (   11.36 ms per token,    88.06 tokens per second)\n",
      "llama_print_timings:        eval time =      83.09 ms /     1 runs   (   83.09 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     350.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5540.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    24 tokens (   10.48 ms per token,    95.42 tokens per second)\n",
      "llama_print_timings:        eval time =      86.54 ms /     1 runs   (   86.54 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     344.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kassie Nitzsche\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    12 runs   (    0.36 ms per token,  2785.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.13 ms /   157 tokens (    7.40 ms per token,   135.10 tokens per second)\n",
      "llama_print_timings:        eval time =     886.52 ms /    11 runs   (   80.59 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2125.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"261 239 9081\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1950.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.56 ms /    14 runs   (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1514.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3829.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.55 ms /    23 tokens (   11.11 ms per token,    90.00 tokens per second)\n",
      "llama_print_timings:        eval time =     583.25 ms /     7 runs   (   83.32 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     877.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     8 runs   (    0.31 ms per token,  3241.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.22 ms /    24 tokens (   10.63 ms per token,    94.04 tokens per second)\n",
      "llama_print_timings:        eval time =     568.79 ms /     7 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     866.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jared Ledner\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    17 runs   (    0.42 ms per token,  2382.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1679.82 ms /   215 tokens (    7.81 ms per token,   127.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1306.83 ms /    16 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    3113.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"114 874 7226\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    15 runs   (    0.50 ms per token,  1990.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.04 ms /    25 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.67 ms /    14 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1520.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     6 runs   (    0.47 ms per token,  2123.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.95 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     397.30 ms /     5 runs   (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     688.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5571.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.60 ms /    24 tokens (   10.57 ms per token,    94.64 tokens per second)\n",
      "llama_print_timings:        eval time =      81.38 ms /     1 runs   (   81.38 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     341.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lawerence Cummerata\", \"Dr. Harland Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    19 runs   (    0.38 ms per token,  2641.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.62 ms /   165 tokens (    8.36 ms per token,   119.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1470.77 ms /    18 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    2964.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"319 562 1920\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    15 runs   (    0.18 ms per token,  5476.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.66 ms /    25 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.86 ms /    14 runs   (   87.42 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1618.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     7 runs   (    0.14 ms per token,  7383.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.04 ms /    23 tokens (   11.00 ms per token,    90.89 tokens per second)\n",
      "llama_print_timings:        eval time =     496.48 ms /     6 runs   (   82.75 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     773.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /    11 runs   (    0.15 ms per token,  6474.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     811.84 ms /    10 runs   (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1091.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bud Ernser\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     8 runs   (    0.10 ms per token,  9661.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3267.66 ms /   390 tokens (    8.38 ms per token,   119.35 tokens per second)\n",
      "llama_print_timings:        eval time =     604.67 ms /     7 runs   (   86.38 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    3893.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     6 runs   (    0.13 ms per token,  7416.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.13 ms /    25 tokens (   10.25 ms per token,    97.61 tokens per second)\n",
      "llama_print_timings:        eval time =     409.12 ms /     5 runs   (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     680.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9090.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    23 tokens (   11.04 ms per token,    90.56 tokens per second)\n",
      "llama_print_timings:        eval time =      95.57 ms /     1 runs   (   95.57 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =     353.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     8 runs   (    0.13 ms per token,  7952.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.81 ms /    24 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =     573.09 ms /     7 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     850.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Shawn Hudson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     7 runs   (    0.32 ms per token,  3136.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.86 ms /   137 tokens (    8.33 ms per token,   119.98 tokens per second)\n",
      "llama_print_timings:        eval time =     462.86 ms /     6 runs   (   77.14 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1648.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"859 985 0710\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    15 runs   (    0.30 ms per token,  3367.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    25 tokens (   10.14 ms per token,    98.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1080.01 ms /    14 runs   (   77.14 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1421.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     7 runs   (    0.14 ms per token,  7179.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.56 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =     495.36 ms /     6 runs   (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     764.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /     8 runs   (    0.24 ms per token,  4108.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    24 tokens (   10.67 ms per token,    93.71 tokens per second)\n",
      "llama_print_timings:        eval time =     611.37 ms /     7 runs   (   87.34 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     901.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Manda Hackett\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    12 runs   (    0.46 ms per token,  2170.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.62 ms /   149 tokens (    7.86 ms per token,   127.28 tokens per second)\n",
      "llama_print_timings:        eval time =     878.10 ms /    11 runs   (   79.83 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    2142.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"769 155 3406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    15 runs   (    0.53 ms per token,  1888.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.92 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.45 ms /    14 runs   (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1480.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5602.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    23 tokens (   10.99 ms per token,    91.00 tokens per second)\n",
      "llama_print_timings:        eval time =      82.01 ms /     1 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     341.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Seasonal allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    12 runs   (    0.25 ms per token,  4071.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     904.74 ms /    11 runs   (   82.25 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1211.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dick Koss\", \"Dr. Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    14 runs   (    0.30 ms per token,  3294.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.07 ms /   174 tokens (    8.03 ms per token,   124.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.21 ms /    13 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    2640.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\", \"999 375 8458\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.98 ms /    20 runs   (    0.50 ms per token,  2003.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.35 ms /    25 tokens (   10.37 ms per token,    96.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1571.04 ms /    19 runs   (   82.69 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1968.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.20 ms per token,  4938.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.44 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =      82.94 ms /     1 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     342.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.39 ms /     2 runs   (    0.20 ms per token,  5076.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.53 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =      83.89 ms /     1 runs   (   83.89 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     342.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bernard Morissette\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /     9 runs   (    0.50 ms per token,  2014.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.95 ms /   153 tokens (    7.67 ms per token,   130.33 tokens per second)\n",
      "llama_print_timings:        eval time =     653.12 ms /     8 runs   (   81.64 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1884.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"458 399 6851\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.88 ms /    15 runs   (    0.66 ms per token,  1517.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.65 ms /    25 tokens (   10.19 ms per token,    98.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.56 ms /    14 runs   (   78.90 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1488.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     2 runs   (    0.28 ms per token,  3597.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.82 ms /    23 tokens (   11.12 ms per token,    89.91 tokens per second)\n",
      "llama_print_timings:        eval time =      92.95 ms /     1 runs   (   92.95 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     358.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6849.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.57 ms /    24 tokens (   10.65 ms per token,    93.91 tokens per second)\n",
      "llama_print_timings:        eval time =      88.34 ms /     1 runs   (   88.34 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     347.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alexander Howell\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    15 runs   (    0.43 ms per token,  2321.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.34 ms /   159 tokens (    7.44 ms per token,   134.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.14 ms /    14 runs   (   81.72 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    2424.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 566 6434\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.93 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.02 ms /    14 runs   (   80.07 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1473.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6289.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    23 tokens (   10.92 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =      81.03 ms /     1 runs   (   81.03 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =     338.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9132.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.00 ms /    24 tokens (   10.50 ms per token,    95.24 tokens per second)\n",
      "llama_print_timings:        eval time =      81.70 ms /     1 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     338.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tanner Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     7 runs   (    0.39 ms per token,  2569.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2891.37 ms /   368 tokens (    7.86 ms per token,   127.28 tokens per second)\n",
      "llama_print_timings:        eval time =     497.98 ms /     6 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    3435.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 574 3978\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    15 runs   (    0.56 ms per token,  1795.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.88 ms /    25 tokens (   10.52 ms per token,    95.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.18 ms /    14 runs   (   82.37 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1533.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     9 runs   (    0.40 ms per token,  2480.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.97 ms /    23 tokens (   11.30 ms per token,    88.47 tokens per second)\n",
      "llama_print_timings:        eval time =     661.80 ms /     8 runs   (   82.72 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     978.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    12 runs   (    0.36 ms per token,  2814.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.82 ms /    24 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =     913.46 ms /    11 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1244.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Emile Kozey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     8 runs   (    0.35 ms per token,  2865.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.28 ms /   171 tokens (    8.19 ms per token,   122.12 tokens per second)\n",
      "llama_print_timings:        eval time =     573.90 ms /     7 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    2024.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 246 0071\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    15 runs   (    0.52 ms per token,  1909.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.54 ms /    25 tokens (   10.26 ms per token,    97.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.42 ms /    14 runs   (   81.17 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1492.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.25 ms per token,  4056.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.56 ms /    23 tokens (   11.11 ms per token,    90.00 tokens per second)\n",
      "llama_print_timings:        eval time =      84.29 ms /     1 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     347.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6578.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.17 ms /    24 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =      80.10 ms /     1 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     341.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Freeda Morissette\", \"Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    16 runs   (    0.49 ms per token,  2060.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.22 ms /   174 tokens (    8.00 ms per token,   124.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.67 ms /    15 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2717.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"830 393 5701\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    15 runs   (    0.51 ms per token,  1971.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.92 ms /    25 tokens (   10.16 ms per token,    98.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.49 ms /    14 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1494.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     9 runs   (    0.26 ms per token,  3783.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =     655.22 ms /     8 runs   (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     953.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5509.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.13 ms /    24 tokens (   10.51 ms per token,    95.19 tokens per second)\n",
      "llama_print_timings:        eval time =      85.32 ms /     1 runs   (   85.32 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =     343.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lin Dicki\", \"Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2357.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.84 ms /   144 tokens (    8.05 ms per token,   124.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.04 ms /    14 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    2402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"836 349 0510\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    15 runs   (    0.43 ms per token,  2326.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.53 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.37 ms /    14 runs   (   81.46 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1489.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5221.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.36 ms /    23 tokens (   10.84 ms per token,    92.24 tokens per second)\n",
      "llama_print_timings:        eval time =      83.18 ms /     1 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     337.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /     6 runs   (    0.37 ms per token,  2703.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.17 ms /    24 tokens (   10.47 ms per token,    95.55 tokens per second)\n",
      "llama_print_timings:        eval time =     399.54 ms /     5 runs   (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     684.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chi Schoen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     8 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.34 ms /   156 tokens (    7.60 ms per token,   131.50 tokens per second)\n",
      "llama_print_timings:        eval time =     601.26 ms /     7 runs   (   85.89 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1838.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 412 2110\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2126.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.61 ms /    25 tokens (   10.14 ms per token,    98.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.57 ms /    14 runs   (   79.83 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1485.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     6 runs   (    0.42 ms per token,  2388.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.45 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     401.90 ms /     5 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     689.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     8 runs   (    0.36 ms per token,  2741.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    24 tokens (   10.55 ms per token,    94.77 tokens per second)\n",
      "llama_print_timings:        eval time =     572.78 ms /     7 runs   (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     875.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Anette Rempel\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    16 runs   (    0.43 ms per token,  2300.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.15 ms /   175 tokens (    7.90 ms per token,   126.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.83 ms /    15 runs   (   79.06 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2690.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"395 888 9677\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    15 runs   (    0.42 ms per token,  2405.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.81 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.59 ms /    14 runs   (   81.47 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1484.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2369.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.24 ms /    23 tokens (   10.92 ms per token,    91.55 tokens per second)\n",
      "llama_print_timings:        eval time =     637.27 ms /     8 runs   (   79.66 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     946.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    11 runs   (    0.37 ms per token,  2688.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =     784.12 ms /    10 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1101.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hilton Hand\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2160.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.66 ms /   153 tokens (    7.55 ms per token,   132.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.30 ms /    14 runs   (   81.38 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2396.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"454 492 0761\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    15 runs   (    0.56 ms per token,  1790.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.13 ms /    25 tokens (   10.17 ms per token,    98.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.17 ms /    14 runs   (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1487.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /     6 runs   (    0.27 ms per token,  3708.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.20 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     392.18 ms /     5 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     673.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7968.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    24 tokens (   10.44 ms per token,    95.78 tokens per second)\n",
      "llama_print_timings:        eval time =      97.66 ms /     1 runs   (   97.66 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     354.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Daryl Osinski\", \"Dr. Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    20 runs   (    0.45 ms per token,  2205.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.49 ms /   160 tokens (    7.25 ms per token,   137.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1687.63 ms /    19 runs   (   88.82 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =    2961.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"181 639 4076\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    15 runs   (    0.52 ms per token,  1930.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.20 ms /    25 tokens (   10.17 ms per token,    98.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1276.24 ms /    14 runs   (   91.16 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =    1620.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     8 runs   (    0.33 ms per token,  3037.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.35 ms /    23 tokens (   11.10 ms per token,    90.07 tokens per second)\n",
      "llama_print_timings:        eval time =     627.70 ms /     7 runs   (   89.67 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     923.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 11834.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.22 ms /    24 tokens (   11.09 ms per token,    90.15 tokens per second)\n",
      "llama_print_timings:        eval time =     112.06 ms /     1 runs   (  112.06 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =     381.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rodrick Luettgen\", \"Dr. Reggie Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    18 runs   (    0.51 ms per token,  1976.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.59 ms /   173 tokens (    8.59 ms per token,   116.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1360.32 ms /    17 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    3002.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"541 437 1231\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2042.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.35 ms /    25 tokens (   10.17 ms per token,    98.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.22 ms /    14 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1473.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /     9 runs   (    0.52 ms per token,  1921.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     626.66 ms /     8 runs   (   78.33 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     950.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =      81.54 ms /     1 runs   (   81.54 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     338.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Tommy Conroy\", \"Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    14 runs   (    0.50 ms per token,  2015.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.03 ms /   173 tokens (    7.97 ms per token,   125.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1017.20 ms /    13 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2508.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"815 842 2310\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    15 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.51 ms /    25 tokens (   10.10 ms per token,    99.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.99 ms /    14 runs   (   78.50 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1477.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2601.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.57 ms /    23 tokens (   11.29 ms per token,    88.61 tokens per second)\n",
      "llama_print_timings:        eval time =     728.40 ms /     8 runs   (   91.05 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =    1037.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     8 runs   (    0.33 ms per token,  3016.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.52 ms /    24 tokens (   11.23 ms per token,    89.05 tokens per second)\n",
      "llama_print_timings:        eval time =     613.19 ms /     7 runs   (   87.60 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     924.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Many Larkin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    10 runs   (    0.43 ms per token,  2325.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3038.73 ms /   370 tokens (    8.21 ms per token,   121.76 tokens per second)\n",
      "llama_print_timings:        eval time =     767.50 ms /     9 runs   (   85.28 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =    3877.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"309 231 6228\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    15 runs   (    0.53 ms per token,  1890.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.93 ms /    25 tokens (   10.40 ms per token,    96.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.97 ms /    14 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1523.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2402.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.51 ms /    23 tokens (   11.20 ms per token,    89.32 tokens per second)\n",
      "llama_print_timings:        eval time =     651.58 ms /     8 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     976.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /     8 runs   (    0.54 ms per token,  1866.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.22 ms /    24 tokens (   10.63 ms per token,    94.04 tokens per second)\n",
      "llama_print_timings:        eval time =     563.89 ms /     7 runs   (   80.56 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     882.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marvin Upton\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /     7 runs   (    0.35 ms per token,  2853.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.72 ms /   172 tokens (    8.09 ms per token,   123.68 tokens per second)\n",
      "llama_print_timings:        eval time =     500.44 ms /     6 runs   (   83.41 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1930.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 621 3457\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2044.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.39 ms /    14 runs   (   86.03 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1548.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9803.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.76 ms /    23 tokens (   11.60 ms per token,    86.22 tokens per second)\n",
      "llama_print_timings:        eval time =      93.36 ms /     1 runs   (   93.36 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     371.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     7 runs   (    0.27 ms per token,  3741.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.83 ms /    24 tokens (   10.53 ms per token,    94.93 tokens per second)\n",
      "llama_print_timings:        eval time =     514.04 ms /     6 runs   (   85.67 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     797.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Felisa O'Reilly\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    12 runs   (    0.46 ms per token,  2197.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.84 ms /   188 tokens (    7.56 ms per token,   132.32 tokens per second)\n",
      "llama_print_timings:        eval time =     912.44 ms /    11 runs   (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    2405.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 373 6993\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    15 runs   (    0.57 ms per token,  1768.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    25 tokens (   10.14 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.12 ms /    14 runs   (   83.44 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1525.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     7 runs   (    0.30 ms per token,  3375.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     492.57 ms /     6 runs   (   82.10 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     778.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"depression\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    12 runs   (    0.50 ms per token,  1987.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.65 ms /    24 tokens (   10.53 ms per token,    94.99 tokens per second)\n",
      "llama_print_timings:        eval time =     867.29 ms /    11 runs   (   78.84 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1218.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Grisel Zieme\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    17 runs   (    0.37 ms per token,  2670.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.39 ms /   169 tokens (    8.21 ms per token,   121.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1445.09 ms /    16 runs   (   90.32 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    2933.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 145 9830\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.94 ms /    25 tokens (   10.32 ms per token,    96.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.04 ms /    14 runs   (   84.15 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    1529.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     5 runs   (    0.46 ms per token,  2193.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     338.24 ms /     4 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     619.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =      86.45 ms /     1 runs   (   86.45 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     350.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Burt Hane\", \"Doctor Chun Armstrong\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.20 ms /    17 runs   (    0.42 ms per token,  2361.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.34 ms /   176 tokens (    8.01 ms per token,   124.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.94 ms /    16 runs   (   81.62 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    2842.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"461 433 4547\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1991.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.30 ms /    25 tokens (   10.29 ms per token,    97.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.37 ms /    14 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1493.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     7 runs   (    0.35 ms per token,  2830.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =     487.66 ms /     6 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     787.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6349.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =      84.53 ms /     1 runs   (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     342.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Estella Dooley\", \"Dr. Carson Krajcik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    18 runs   (    0.42 ms per token,  2374.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.41 ms /   167 tokens (    8.33 ms per token,   120.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1426.73 ms /    17 runs   (   83.93 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    2935.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 535 7380\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1951.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.21 ms /    25 tokens (   10.37 ms per token,    96.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.08 ms /    14 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1508.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.23 ms /    23 tokens (   11.14 ms per token,    89.76 tokens per second)\n",
      "llama_print_timings:        eval time =      79.99 ms /     1 runs   (   79.99 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     342.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     7 runs   (    0.38 ms per token,  2606.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.94 ms /    24 tokens (   10.66 ms per token,    93.77 tokens per second)\n",
      "llama_print_timings:        eval time =     502.56 ms /     6 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     797.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Vernice Orn\", \"Dr.\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    20 runs   (    0.51 ms per token,  1976.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.12 ms /   164 tokens (    8.64 ms per token,   115.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1558.39 ms /    19 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    3119.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"847 621 0246\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    15 runs   (    0.36 ms per token,  2748.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.85 ms /    25 tokens (   10.35 ms per token,    96.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.45 ms /    14 runs   (   84.03 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1526.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     9 runs   (    0.24 ms per token,  4083.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.33 ms /    23 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =     740.46 ms /     8 runs   (   92.56 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =    1033.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11363.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    24 tokens (   10.73 ms per token,    93.18 tokens per second)\n",
      "llama_print_timings:        eval time =     114.02 ms /     1 runs   (  114.02 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =     375.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Samella Morar\", \"Doctor Jacques Quigley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    18 runs   (    0.43 ms per token,  2327.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.26 ms /   185 tokens (    7.63 ms per token,   131.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.70 ms /    17 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2908.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 823 0992\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    15 runs   (    0.52 ms per token,  1916.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.29 ms /    25 tokens (   10.17 ms per token,    98.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.43 ms /    14 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1516.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /     7 runs   (    0.39 ms per token,  2589.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.16 ms /    23 tokens (   11.05 ms per token,    90.49 tokens per second)\n",
      "llama_print_timings:        eval time =     477.23 ms /     6 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     776.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.91 ms /    24 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =      82.65 ms /     1 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     343.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Kesha Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2235.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.34 ms /   171 tokens (    8.10 ms per token,   123.44 tokens per second)\n",
      "llama_print_timings:        eval time =     793.85 ms /    10 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    2257.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"471 212 8983\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2315.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.48 ms /    25 tokens (   10.14 ms per token,    98.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.04 ms /    14 runs   (   84.43 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1536.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4410.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    23 tokens (   11.17 ms per token,    89.54 tokens per second)\n",
      "llama_print_timings:        eval time =     664.03 ms /     7 runs   (   94.86 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =     953.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    12 runs   (    0.40 ms per token,  2469.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.45 ms /    24 tokens (   10.44 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =     905.55 ms /    11 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1233.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stacee Lesch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.90 ms /    11 runs   (    0.45 ms per token,  2244.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.48 ms /   184 tokens (    7.69 ms per token,   129.99 tokens per second)\n",
      "llama_print_timings:        eval time =     803.38 ms /    10 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2300.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"942 969 2459\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    15 runs   (    0.60 ms per token,  1662.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.40 ms /    25 tokens (   10.30 ms per token,    97.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1120.92 ms /    14 runs   (   80.07 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1509.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     9 runs   (    0.45 ms per token,  2219.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.53 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     649.19 ms /     8 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     964.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    11 runs   (    0.44 ms per token,  2284.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =     804.73 ms /    10 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1119.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Dewitt Fahey\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    17 runs   (    0.46 ms per token,  2181.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.07 ms /   157 tokens (    7.41 ms per token,   134.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.10 ms /    16 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2568.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"636 983 9308\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    15 runs   (    0.43 ms per token,  2310.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.90 ms /    14 runs   (   79.85 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1458.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     9 runs   (    0.26 ms per token,  3826.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.73 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =     738.44 ms /     8 runs   (   92.31 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =    1036.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9803.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.57 ms /    24 tokens (   10.98 ms per token,    91.06 tokens per second)\n",
      "llama_print_timings:        eval time =      93.41 ms /     1 runs   (   93.41 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     362.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Johnathon Davis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     6 runs   (    0.36 ms per token,  2744.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.23 ms /   180 tokens (    8.04 ms per token,   124.38 tokens per second)\n",
      "llama_print_timings:        eval time =     420.19 ms /     5 runs   (   84.04 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1901.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 197 4927\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.20 ms /    15 runs   (    0.61 ms per token,  1630.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.43 ms /    25 tokens (   10.18 ms per token,    98.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.96 ms /    14 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1524.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     5 runs   (    0.29 ms per token,  3455.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.59 ms /    23 tokens (   11.55 ms per token,    86.60 tokens per second)\n",
      "llama_print_timings:        eval time =     331.26 ms /     4 runs   (   82.82 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     621.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    13 runs   (    0.44 ms per token,  2266.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.56 ms /    24 tokens (   10.56 ms per token,    94.65 tokens per second)\n",
      "llama_print_timings:        eval time =     959.01 ms /    12 runs   (   79.92 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1306.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo Heller\", \"Dr. Celine Pagac\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    17 runs   (    0.49 ms per token,  2038.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1425.79 ms /   189 tokens (    7.54 ms per token,   132.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.63 ms /    16 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2846.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"353 556 9535\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    15 runs   (    0.40 ms per token,  2503.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.88 ms /    25 tokens (   10.20 ms per token,    98.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.22 ms /    14 runs   (   83.80 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1516.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /     8 runs   (    0.65 ms per token,  1529.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    23 tokens (   10.95 ms per token,    91.36 tokens per second)\n",
      "llama_print_timings:        eval time =     556.69 ms /     7 runs   (   79.53 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     874.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.26 ms /    24 tokens (   10.68 ms per token,    93.66 tokens per second)\n",
      "llama_print_timings:        eval time =      95.69 ms /     1 runs   (   95.69 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =     358.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Adolph Ortiz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /     7 runs   (    0.53 ms per token,  1904.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     921.81 ms /   128 tokens (    7.20 ms per token,   138.86 tokens per second)\n",
      "llama_print_timings:        eval time =     475.37 ms /     6 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1456.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"749 901 9166\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    15 runs   (    0.34 ms per token,  2958.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.15 ms /    25 tokens (   10.13 ms per token,    98.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1187.59 ms /    14 runs   (   84.83 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    1522.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /     7 runs   (    0.42 ms per token,  2403.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.59 ms /    23 tokens (   11.07 ms per token,    90.34 tokens per second)\n",
      "llama_print_timings:        eval time =     521.45 ms /     6 runs   (   86.91 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     818.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     8 runs   (    0.28 ms per token,  3511.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.07 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =     582.91 ms /     7 runs   (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     871.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Darryl Murphy\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1993.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.51 ms /   142 tokens (    8.12 ms per token,   123.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.91 ms /    14 runs   (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2419.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"174 539 4602\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    15 runs   (    0.56 ms per token,  1790.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.11 ms /    14 runs   (   79.22 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1483.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     7 runs   (    0.42 ms per token,  2373.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.40 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     471.11 ms /     6 runs   (   78.52 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     767.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.00 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =      96.10 ms /     1 runs   (   96.10 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =     352.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Catina Pagac\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.22 ms /    19 runs   (    0.64 ms per token,  1554.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.51 ms /   165 tokens (    8.48 ms per token,   117.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1422.17 ms /    18 runs   (   79.01 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    2995.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"589 383 1119\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1950.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    25 tokens (   10.10 ms per token,    98.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.71 ms /    14 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1489.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /     9 runs   (    0.61 ms per token,  1630.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     628.32 ms /     8 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     947.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    11 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =     801.23 ms /    10 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1131.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Antoine Howell\", \"Doctor Hildegarde Johns\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.05 ms /    21 runs   (    0.53 ms per token,  1900.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.20 ms /   192 tokens (    7.21 ms per token,   138.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1605.91 ms /    20 runs   (   80.30 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    3167.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"643 664 9940\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    15 runs   (    0.68 ms per token,  1462.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.37 ms /    25 tokens (   10.13 ms per token,    98.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.38 ms /    14 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1501.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =      91.57 ms /     1 runs   (   91.57 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =     347.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6472.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.91 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      81.74 ms /     1 runs   (   81.74 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     338.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marlana Schinner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2224.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.63 ms /   166 tokens (    8.29 ms per token,   120.67 tokens per second)\n",
      "llama_print_timings:        eval time =     547.45 ms /     7 runs   (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1977.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 983 5536\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    15 runs   (    0.61 ms per token,  1627.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    25 tokens (   10.10 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.41 ms /    14 runs   (   78.46 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1478.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.50 ms /    23 tokens (   10.98 ms per token,    91.09 tokens per second)\n",
      "llama_print_timings:        eval time =     563.53 ms /     7 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     867.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     6 runs   (    0.35 ms per token,  2840.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =     400.90 ms /     5 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     684.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jamar Watsica\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    15 runs   (    0.45 ms per token,  2226.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.32 ms /   172 tokens (    8.28 ms per token,   120.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.98 ms /    14 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2667.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"392 547 3729\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.17 ms /    25 tokens (   10.13 ms per token,    98.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.97 ms /    14 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1491.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    23 tokens (   10.92 ms per token,    91.60 tokens per second)\n",
      "llama_print_timings:        eval time =      83.46 ms /     1 runs   (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     341.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4474.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.54 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =      84.86 ms /     1 runs   (   84.86 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     342.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jovita Boyer\", \"Dr. Kristopher Crooks\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    16 runs   (    0.34 ms per token,  2970.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.70 ms /   190 tokens (    7.38 ms per token,   135.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.15 ms /    15 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    2715.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 806 9796\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    15 runs   (    0.34 ms per token,  2909.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.69 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.89 ms /    14 runs   (   84.14 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1508.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2360.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.00 ms /    23 tokens (   11.00 ms per token,    90.91 tokens per second)\n",
      "llama_print_timings:        eval time =     592.74 ms /     7 runs   (   84.68 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     892.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.24 ms /    24 tokens (   10.88 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =     100.66 ms /     1 runs   (  100.66 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =     367.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Evelynn Hoppe\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.00 ms /    18 runs   (    0.61 ms per token,  1636.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3221.96 ms /   385 tokens (    8.37 ms per token,   119.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1384.54 ms /    17 runs   (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    4760.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"396 866 2257\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.34 ms /    15 runs   (    0.56 ms per token,  1798.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.13 ms /    25 tokens (   10.29 ms per token,    97.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.51 ms /    14 runs   (   81.75 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1519.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /     9 runs   (    0.59 ms per token,  1707.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.09 ms /    23 tokens (   11.09 ms per token,    90.16 tokens per second)\n",
      "llama_print_timings:        eval time =     649.09 ms /     8 runs   (   81.14 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     974.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     8 runs   (    0.52 ms per token,  1934.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.38 ms /    24 tokens (   10.68 ms per token,    93.61 tokens per second)\n",
      "llama_print_timings:        eval time =     568.89 ms /     7 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     888.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Carmella Ondricka\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.67 ms /    20 runs   (    0.63 ms per token,  1578.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.39 ms /   157 tokens (    7.39 ms per token,   135.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1492.50 ms /    19 runs   (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2844.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     6 runs   (    0.55 ms per token,  1818.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =     394.82 ms /     5 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     691.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"81-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /     9 runs   (    0.48 ms per token,  2064.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.93 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     628.00 ms /     8 runs   (   78.50 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     947.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    11 runs   (    0.40 ms per token,  2496.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =     796.03 ms /    10 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1123.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Carmine Von\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    15 runs   (    0.36 ms per token,  2779.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.15 ms /   185 tokens (    7.69 ms per token,   130.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.94 ms /    14 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2675.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"161 708 8573\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2270.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.42 ms /    25 tokens (   10.22 ms per token,    97.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.98 ms /    14 runs   (   83.86 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1522.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     9 runs   (    0.30 ms per token,  3305.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    23 tokens (   10.95 ms per token,    91.34 tokens per second)\n",
      "llama_print_timings:        eval time =     663.50 ms /     8 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     968.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.85 ms /    24 tokens (   10.74 ms per token,    93.08 tokens per second)\n",
      "llama_print_timings:        eval time =      93.69 ms /     1 runs   (   93.69 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     355.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Micheline Wilkinson MD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    13 runs   (    0.42 ms per token,  2405.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3289.71 ms /   405 tokens (    8.12 ms per token,   123.11 tokens per second)\n",
      "llama_print_timings:        eval time =     998.49 ms /    12 runs   (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    4374.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"579 551 5126\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    15 runs   (    0.53 ms per token,  1902.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.59 ms /    25 tokens (   10.34 ms per token,    96.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.26 ms /    14 runs   (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1540.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /     7 runs   (    0.47 ms per token,  2147.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.07 ms /    23 tokens (   11.09 ms per token,    90.17 tokens per second)\n",
      "llama_print_timings:        eval time =     489.73 ms /     6 runs   (   81.62 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     796.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.69 ms /    24 tokens (   10.65 ms per token,    93.87 tokens per second)\n",
      "llama_print_timings:        eval time =      84.19 ms /     1 runs   (   84.19 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     347.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Allison Kuhic\", \"Alejandro Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    18 runs   (    0.36 ms per token,  2812.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.28 ms /   187 tokens (    7.57 ms per token,   132.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1421.15 ms /    17 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    2952.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"668 729 3192\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    15 runs   (    0.41 ms per token,  2429.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.98 ms /    25 tokens (   10.40 ms per token,    96.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.46 ms /    14 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1487.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6825.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    23 tokens (   10.94 ms per token,    91.40 tokens per second)\n",
      "llama_print_timings:        eval time =      91.87 ms /     1 runs   (   91.87 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     348.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    24 tokens (   10.49 ms per token,    95.36 tokens per second)\n",
      "llama_print_timings:        eval time =      81.41 ms /     1 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     338.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Malcom Stroman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /    10 runs   (    0.39 ms per token,  2597.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.36 ms /   162 tokens (    8.59 ms per token,   116.43 tokens per second)\n",
      "llama_print_timings:        eval time =     762.18 ms /     9 runs   (   84.69 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    2202.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"673 435 6624\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    15 runs   (    0.53 ms per token,  1886.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.28 ms /    25 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.63 ms /    14 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1533.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     7 runs   (    0.32 ms per token,  3079.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.50 ms /    23 tokens (   11.50 ms per token,    86.96 tokens per second)\n",
      "llama_print_timings:        eval time =     512.52 ms /     6 runs   (   85.42 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     808.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.39 ms /    24 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =      87.84 ms /     1 runs   (   87.84 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =     360.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Stefanie Carter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     7 runs   (    0.39 ms per token,  2545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1985.25 ms /   254 tokens (    7.82 ms per token,   127.94 tokens per second)\n",
      "llama_print_timings:        eval time =     495.07 ms /     6 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    2524.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 924 9561\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    15 runs   (    0.45 ms per token,  2238.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.00 ms /    25 tokens (   10.32 ms per token,    96.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1202.74 ms /    14 runs   (   85.91 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1564.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     6 runs   (    0.24 ms per token,  4231.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.08 ms /    23 tokens (   11.70 ms per token,    85.48 tokens per second)\n",
      "llama_print_timings:        eval time =     427.52 ms /     5 runs   (   85.50 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     722.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2648.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.97 ms /    24 tokens (   10.96 ms per token,    91.26 tokens per second)\n",
      "llama_print_timings:        eval time =     609.47 ms /     7 runs   (   87.07 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     912.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ellan Ernser\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    17 runs   (    0.41 ms per token,  2411.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.00 ms /   177 tokens (    7.96 ms per token,   125.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1323.78 ms /    16 runs   (   82.74 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    2838.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"480 652 0490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    15 runs   (    0.41 ms per token,  2460.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.36 ms /    25 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.38 ms /    14 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1499.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6006.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.10 ms /    23 tokens (   11.57 ms per token,    86.43 tokens per second)\n",
      "llama_print_timings:        eval time =      88.26 ms /     1 runs   (   88.26 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     360.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6514.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.62 ms /    24 tokens (   10.98 ms per token,    91.04 tokens per second)\n",
      "llama_print_timings:        eval time =      80.80 ms /     1 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     350.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Christie Botsford\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     8 runs   (    0.27 ms per token,  3639.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.13 ms /   170 tokens (    8.41 ms per token,   118.95 tokens per second)\n",
      "llama_print_timings:        eval time =     567.48 ms /     7 runs   (   81.07 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2033.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 373 8391\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2702.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.54 ms /    25 tokens (   10.14 ms per token,    98.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.33 ms /    14 runs   (   84.45 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1519.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5970.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.11 ms /    23 tokens (   11.31 ms per token,    88.42 tokens per second)\n",
      "llama_print_timings:        eval time =      87.82 ms /     1 runs   (   87.82 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     353.75 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    11 runs   (    0.45 ms per token,  2203.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.96 ms /    24 tokens (   10.71 ms per token,    93.40 tokens per second)\n",
      "llama_print_timings:        eval time =     829.24 ms /    10 runs   (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1150.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brett Halvorson\", \"Dr. Eldon Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.46 ms /    21 runs   (    0.50 ms per token,  2008.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1215.12 ms /   156 tokens (    7.79 ms per token,   128.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1691.61 ms /    20 runs   (   84.58 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =    3035.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     6 runs   (    0.27 ms per token,  3752.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.37 ms /    25 tokens (   10.17 ms per token,    98.28 tokens per second)\n",
      "llama_print_timings:        eval time =     411.99 ms /     5 runs   (   82.40 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     691.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     7 runs   (    0.55 ms per token,  1812.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =     474.85 ms /     6 runs   (   79.14 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     771.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.59 ms /     2 runs   (    0.30 ms per token,  3384.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.86 ms /    24 tokens (   10.70 ms per token,    93.44 tokens per second)\n",
      "llama_print_timings:        eval time =      87.14 ms /     1 runs   (   87.14 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     354.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Tim Torp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     8 runs   (    0.49 ms per token,  2050.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.60 ms /   153 tokens (    7.56 ms per token,   132.28 tokens per second)\n",
      "llama_print_timings:        eval time =     564.77 ms /     7 runs   (   80.68 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1774.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"521 777 6699\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    15 runs   (    0.40 ms per token,  2501.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.69 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.67 ms /    14 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1461.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /     9 runs   (    0.48 ms per token,  2086.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    23 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     627.53 ms /     8 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     946.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.09 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =      91.81 ms /     1 runs   (   91.81 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     348.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Devin Raynor\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     7 runs   (    0.32 ms per token,  3171.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.59 ms /   167 tokens (    8.23 ms per token,   121.49 tokens per second)\n",
      "llama_print_timings:        eval time =     485.16 ms /     6 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1894.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 538 5455\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.93 ms /    15 runs   (    0.60 ms per token,  1680.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.81 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.16 ms /    14 runs   (   78.01 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1471.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    23 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =      95.32 ms /     1 runs   (   95.32 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     351.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.95 ms /    24 tokens (   10.41 ms per token,    96.02 tokens per second)\n",
      "llama_print_timings:        eval time =      80.78 ms /     1 runs   (   80.78 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     335.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Yasmine Kihn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    11 runs   (    0.61 ms per token,  1629.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.56 ms /   174 tokens (    7.93 ms per token,   126.13 tokens per second)\n",
      "llama_print_timings:        eval time =     783.45 ms /    10 runs   (   78.34 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    2249.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"200 771 3252\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    15 runs   (    0.56 ms per token,  1791.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.17 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.92 ms /    14 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1473.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     7 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.66 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =     472.74 ms /     6 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     761.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     8 runs   (    0.23 ms per token,  4376.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.32 ms /    24 tokens (   10.55 ms per token,    94.74 tokens per second)\n",
      "llama_print_timings:        eval time =     590.97 ms /     7 runs   (   84.42 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     871.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kenyetta Nienow\", \"Dr Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.12 ms /    19 runs   (    0.48 ms per token,  2083.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.92 ms /   154 tokens (    7.63 ms per token,   131.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.16 ms /    18 runs   (   81.56 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2775.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"897 415 4946\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.99 ms /    15 runs   (    0.40 ms per token,  2502.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.66 ms /    25 tokens (   10.23 ms per token,    97.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.62 ms /    14 runs   (   83.90 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    1523.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4535.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.94 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =      84.85 ms /     1 runs   (   84.85 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =     344.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    24 tokens (   10.54 ms per token,    94.87 tokens per second)\n",
      "llama_print_timings:        eval time =      84.06 ms /     1 runs   (   84.06 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     342.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Marchelle Weber\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /    10 runs   (    0.32 ms per token,  3117.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1984.12 ms /   247 tokens (    8.03 ms per token,   124.49 tokens per second)\n",
      "llama_print_timings:        eval time =     746.37 ms /     9 runs   (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    2786.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"765 777 2992\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1954.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.34 ms /    25 tokens (   10.33 ms per token,    96.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.06 ms /    14 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1505.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     9 runs   (    0.36 ms per token,  2810.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.44 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =     658.45 ms /     8 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     964.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     8 runs   (    0.24 ms per token,  4092.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.58 ms /    24 tokens (   10.69 ms per token,    93.54 tokens per second)\n",
      "llama_print_timings:        eval time =     584.34 ms /     7 runs   (   83.48 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     875.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Hugh Johnson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /     6 runs   (    0.49 ms per token,  2037.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2155.67 ms /   282 tokens (    7.64 ms per token,   130.82 tokens per second)\n",
      "llama_print_timings:        eval time =     405.58 ms /     5 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2607.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"758 551 9363\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    15 runs   (    0.54 ms per token,  1860.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    25 tokens (   10.25 ms per token,    97.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.01 ms /    14 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1500.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     7 runs   (    0.33 ms per token,  3060.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    23 tokens (   11.20 ms per token,    89.29 tokens per second)\n",
      "llama_print_timings:        eval time =     507.38 ms /     6 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     805.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.22 ms /    24 tokens (   10.72 ms per token,    93.31 tokens per second)\n",
      "llama_print_timings:        eval time =      83.60 ms /     1 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     347.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Edwardo Berge\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2656.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.65 ms /   155 tokens (    7.58 ms per token,   131.84 tokens per second)\n",
      "llama_print_timings:        eval time =     667.10 ms /     8 runs   (   83.39 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1892.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"424 974 2613\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2605.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.34 ms /    25 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.21 ms /    14 runs   (   84.44 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1521.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     8 runs   (    0.29 ms per token,  3508.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =     579.61 ms /     7 runs   (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     870.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =      90.53 ms /     1 runs   (   90.53 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =     346.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Apryl Marvin\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.98 ms /    20 runs   (    0.50 ms per token,  2004.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.78 ms /   142 tokens (    8.17 ms per token,   122.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1680.75 ms /    19 runs   (   88.46 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    2971.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"336 602 1681\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    15 runs   (    0.44 ms per token,  2262.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.19 ms /    25 tokens (   10.05 ms per token,    99.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.78 ms /    14 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1485.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     7 runs   (    0.28 ms per token,  3556.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     481.31 ms /     6 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     766.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     8 runs   (    0.48 ms per token,  2102.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.66 ms /    24 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =     548.25 ms /     7 runs   (   78.32 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     854.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Marvel Parker\", \"Dr.\", \"Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    20 runs   (    0.60 ms per token,  1679.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.36 ms /   137 tokens (    8.36 ms per token,   119.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1494.44 ms /    19 runs   (   78.65 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    2806.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"894 538 8409\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    15 runs   (    0.62 ms per token,  1617.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    25 tokens (   10.07 ms per token,    99.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.68 ms /    14 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1476.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /     9 runs   (    0.48 ms per token,  2092.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     635.72 ms /     8 runs   (   79.47 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     946.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /     8 runs   (    0.56 ms per token,  1788.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =     547.39 ms /     7 runs   (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =     854.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Michel Ledner\", \"Doctor Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    19 runs   (    0.50 ms per token,  2017.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.31 ms /   134 tokens (    8.55 ms per token,   117.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1424.66 ms /    18 runs   (   79.15 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2719.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 711 767 0761\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.25 ms /    19 runs   (    0.54 ms per token,  1853.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.73 ms /    25 tokens (   10.19 ms per token,    98.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1454.23 ms /    18 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1848.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     7 runs   (    0.37 ms per token,  2694.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     478.47 ms /     6 runs   (   79.75 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     772.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6211.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    24 tokens (   10.66 ms per token,    93.85 tokens per second)\n",
      "llama_print_timings:        eval time =      83.01 ms /     1 runs   (   83.01 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     344.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Fay Hane\", \"Dr. Ramiro Anderson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    14 runs   (    0.44 ms per token,  2247.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.82 ms /   173 tokens (    8.09 ms per token,   123.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1016.68 ms /    13 runs   (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2523.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 987 6389\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    15 runs   (    0.59 ms per token,  1685.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.09 ms /    25 tokens (   10.08 ms per token,    99.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.95 ms /    14 runs   (   79.28 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1481.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /     9 runs   (    0.51 ms per token,  1946.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     628.50 ms /     8 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     943.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5025.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    24 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =      92.08 ms /     1 runs   (   92.08 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =     352.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Damion Abernathy\", \"Dr. Santo Schuppe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    18 runs   (    0.49 ms per token,  2051.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.61 ms /   182 tokens (    7.67 ms per token,   130.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.16 ms /    17 runs   (   78.77 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    2887.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"275 965 6422\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    15 runs   (    0.47 ms per token,  2124.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.82 ms /    25 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.55 ms /    14 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1476.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     5 runs   (    0.35 ms per token,  2878.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =     314.78 ms /     4 runs   (   78.70 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     595.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6578.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.15 ms /    24 tokens (   10.46 ms per token,    95.56 tokens per second)\n",
      "llama_print_timings:        eval time =      80.74 ms /     1 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     338.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Danica Crist\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2319.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.08 ms /   144 tokens (    7.97 ms per token,   125.43 tokens per second)\n",
      "llama_print_timings:        eval time =     643.00 ms /     8 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1848.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"178 167 5319\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    15 runs   (    0.57 ms per token,  1757.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1230.64 ms /    14 runs   (   87.90 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1583.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     5 runs   (    0.33 ms per token,  3022.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.45 ms /    23 tokens (   11.11 ms per token,    90.04 tokens per second)\n",
      "llama_print_timings:        eval time =     327.23 ms /     4 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     607.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     8 runs   (    0.41 ms per token,  2426.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.82 ms /    24 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =     587.78 ms /     7 runs   (   83.97 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     889.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2528.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.61 ms /   138 tokens (    8.39 ms per token,   119.21 tokens per second)\n",
      "llama_print_timings:        eval time =      84.65 ms /     1 runs   (   84.65 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1254.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"632 642 6086\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    15 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.21 ms /    25 tokens (   10.17 ms per token,    98.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.21 ms /    14 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1503.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =      80.66 ms /     1 runs   (   80.66 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     338.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5420.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =      84.42 ms /     1 runs   (   84.42 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     342.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Iluminada Murphy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    11 runs   (    0.63 ms per token,  1589.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.74 ms /   155 tokens (    7.55 ms per token,   132.51 tokens per second)\n",
      "llama_print_timings:        eval time =     791.83 ms /    10 runs   (   79.18 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2055.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 673 309 9359\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    19 runs   (    0.58 ms per token,  1712.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.30 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1443.87 ms /    18 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1845.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5665.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =      87.18 ms /     1 runs   (   87.18 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =     346.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     9 runs   (    0.45 ms per token,  2235.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.33 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     705.44 ms /     8 runs   (   88.18 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1009.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Gianna Batz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /     8 runs   (    0.29 ms per token,  3414.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.80 ms /   181 tokens (    7.81 ms per token,   128.11 tokens per second)\n",
      "llama_print_timings:        eval time =     567.50 ms /     7 runs   (   81.07 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2021.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 598 0574\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    15 runs   (    0.42 ms per token,  2397.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.46 ms /    25 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.73 ms /    14 runs   (   82.12 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1489.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     9 runs   (    0.31 ms per token,  3272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.47 ms /    23 tokens (   10.98 ms per token,    91.10 tokens per second)\n",
      "llama_print_timings:        eval time =     723.73 ms /     8 runs   (   90.47 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    1023.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    11 runs   (    0.36 ms per token,  2801.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    24 tokens (   10.75 ms per token,    93.05 tokens per second)\n",
      "llama_print_timings:        eval time =     829.02 ms /    10 runs   (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1153.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Laurence Collier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2323.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.37 ms /   149 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
      "llama_print_timings:        eval time =     668.24 ms /     8 runs   (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1899.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"572 271 4972\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    15 runs   (    0.48 ms per token,  2099.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.08 ms /    25 tokens (   10.32 ms per token,    96.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.92 ms /    14 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1495.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /     7 runs   (    0.17 ms per token,  5977.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.09 ms /    23 tokens (   11.05 ms per token,    90.52 tokens per second)\n",
      "llama_print_timings:        eval time =     505.72 ms /     6 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     781.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6451.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.89 ms /    24 tokens (   10.70 ms per token,    93.42 tokens per second)\n",
      "llama_print_timings:        eval time =      84.57 ms /     1 runs   (   84.57 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     347.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Darren Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /    10 runs   (    0.33 ms per token,  3030.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.16 ms /   135 tokens (    8.59 ms per token,   116.36 tokens per second)\n",
      "llama_print_timings:        eval time =     738.14 ms /     9 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1950.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"840 669 4680\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    15 runs   (    0.41 ms per token,  2413.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.86 ms /    25 tokens (   10.27 ms per token,    97.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.25 ms /    14 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1477.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2353.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.52 ms /    23 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =     649.21 ms /     8 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     996.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5319.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.77 ms /    24 tokens (   10.53 ms per token,    94.95 tokens per second)\n",
      "llama_print_timings:        eval time =      88.61 ms /     1 runs   (   88.61 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     355.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tonya Stroman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.28 ms /    11 runs   (    0.57 ms per token,  1750.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.45 ms /   144 tokens (    8.00 ms per token,   125.06 tokens per second)\n",
      "llama_print_timings:        eval time =     767.29 ms /    10 runs   (   76.73 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =    2017.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"771 439 5673\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    15 runs   (    0.65 ms per token,  1539.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.26 ms /    25 tokens (   10.05 ms per token,    99.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.53 ms /    14 runs   (   77.11 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    1469.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     7 runs   (    0.28 ms per token,  3564.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     478.04 ms /     6 runs   (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     758.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     8 runs   (    0.43 ms per token,  2322.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.19 ms /    24 tokens (   10.38 ms per token,    96.31 tokens per second)\n",
      "llama_print_timings:        eval time =     550.80 ms /     7 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     855.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Scotty Hamill\", \"Dr. Thanh Weber\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.78 ms /    17 runs   (    0.69 ms per token,  1443.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.77 ms /   140 tokens (    8.17 ms per token,   122.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.64 ms /    16 runs   (   76.85 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    2544.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 408 4654\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    15 runs   (    0.63 ms per token,  1583.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.94 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1076.05 ms /    14 runs   (   76.86 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    1466.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6756.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =      82.81 ms /     1 runs   (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     338.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     6 runs   (    0.40 ms per token,  2480.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    24 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =     385.98 ms /     5 runs   (   77.20 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =     673.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Tynisha Klocko\", \"Dr. Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.10 ms /    20 runs   (    0.61 ms per token,  1652.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.57 ms /   211 tokens (    7.77 ms per token,   128.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1484.34 ms /    19 runs   (   78.12 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    3280.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"751 309 3889\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    15 runs   (    0.55 ms per token,  1832.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.32 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.27 ms /    14 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1465.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5249.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.38 ms /    23 tokens (   11.15 ms per token,    89.71 tokens per second)\n",
      "llama_print_timings:        eval time =      91.51 ms /     1 runs   (   91.51 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     355.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"social isolation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     6 runs   (    0.35 ms per token,  2822.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    24 tokens (   10.46 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =     403.92 ms /     5 runs   (   80.78 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     684.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Brett Conroy\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    15 runs   (    0.63 ms per token,  1588.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.36 ms /   176 tokens (    7.81 ms per token,   127.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1081.58 ms /    14 runs   (   77.26 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    2608.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 611 8916\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    15 runs   (    0.49 ms per token,  2025.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    25 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.33 ms /    14 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1468.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.78 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =      84.17 ms /     1 runs   (   84.17 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     339.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /     4 runs   (    0.29 ms per token,  3421.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     233.69 ms /     3 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =     505.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Loida Shanahan\", \"Dr Ciara Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    16 runs   (    0.48 ms per token,  2091.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.28 ms /   149 tokens (    7.72 ms per token,   129.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.17 ms /    15 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    2435.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 665 6349\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    15 runs   (    0.56 ms per token,  1773.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.29 ms /    14 runs   (   77.59 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    1444.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     9 runs   (    0.36 ms per token,  2790.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.06 ms /    23 tokens (   10.83 ms per token,    92.35 tokens per second)\n",
      "llama_print_timings:        eval time =     628.10 ms /     8 runs   (   78.51 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     928.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"White\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     4 runs   (    0.26 ms per token,  3784.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.80 ms /    24 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =     235.31 ms /     3 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     502.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jade Mraz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    10 runs   (    0.54 ms per token,  1835.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3096.38 ms /   393 tokens (    7.88 ms per token,   126.92 tokens per second)\n",
      "llama_print_timings:        eval time =     729.10 ms /     9 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    3914.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 530 643 7536\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    19 runs   (    0.42 ms per token,  2360.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.33 ms /    25 tokens (   10.25 ms per token,    97.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1527.67 ms /    18 runs   (   84.87 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    1909.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 11976.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.53 ms /    23 tokens (   11.11 ms per token,    90.01 tokens per second)\n",
      "llama_print_timings:        eval time =     110.02 ms /     1 runs   (  110.02 ms per token,     9.09 tokens per second)\n",
      "llama_print_timings:       total time =     370.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9756.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.57 ms /    24 tokens (   11.19 ms per token,    89.36 tokens per second)\n",
      "llama_print_timings:        eval time =      99.47 ms /     1 runs   (   99.47 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     372.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Marybelle Kohler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    11 runs   (    0.34 ms per token,  2937.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.98 ms /   179 tokens (    7.99 ms per token,   125.18 tokens per second)\n",
      "llama_print_timings:        eval time =     856.45 ms /    10 runs   (   85.64 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    2346.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"616 516 2598\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.71 ms /    15 runs   (    0.38 ms per token,  2626.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.27 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.07 ms /    14 runs   (   82.15 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1496.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10152.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    23 tokens (   11.13 ms per token,    89.88 tokens per second)\n",
      "llama_print_timings:        eval time =     106.17 ms /     1 runs   (  106.17 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =     366.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute Bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     8 runs   (    0.28 ms per token,  3533.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.37 ms /    24 tokens (   10.56 ms per token,    94.72 tokens per second)\n",
      "llama_print_timings:        eval time =     601.67 ms /     7 runs   (   85.95 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     892.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Magdalene Kreiger\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    18 runs   (    0.44 ms per token,  2257.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.19 ms /   146 tokens (    7.87 ms per token,   127.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1430.69 ms /    17 runs   (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    2706.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"296 108 6607\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    15 runs   (    0.53 ms per token,  1874.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    25 tokens (   10.02 ms per token,    99.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.20 ms /    14 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1466.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     7 runs   (    0.35 ms per token,  2878.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.63 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =     472.45 ms /     6 runs   (   78.74 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     764.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     8 runs   (    0.33 ms per token,  3069.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =     548.92 ms /     7 runs   (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     842.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Armand Halvorson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2369.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.51 ms /   160 tokens (    7.17 ms per token,   139.43 tokens per second)\n",
      "llama_print_timings:        eval time =     785.56 ms /    10 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2012.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"126 378 5060\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    15 runs   (    0.53 ms per token,  1885.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    25 tokens (   10.04 ms per token,    99.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.09 ms /    14 runs   (   78.65 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1460.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     9 runs   (    0.34 ms per token,  2898.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.75 ms /    23 tokens (   11.12 ms per token,    89.93 tokens per second)\n",
      "llama_print_timings:        eval time =     631.08 ms /     8 runs   (   78.89 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     936.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =      81.81 ms /     1 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     338.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Morgan Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     8 runs   (    0.48 ms per token,  2074.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2923.53 ms /   382 tokens (    7.65 ms per token,   130.66 tokens per second)\n",
      "llama_print_timings:        eval time =     574.21 ms /     7 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    3556.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"753 962 8975\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.42 ms /    15 runs   (    0.56 ms per token,  1781.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.45 ms /    25 tokens (   10.38 ms per token,    96.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.36 ms /    14 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1502.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4219.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.88 ms /    23 tokens (   11.39 ms per token,    87.83 tokens per second)\n",
      "llama_print_timings:        eval time =     110.76 ms /     1 runs   (  110.76 ms per token,     9.03 tokens per second)\n",
      "llama_print_timings:       total time =     378.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    11 runs   (    0.40 ms per token,  2469.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.49 ms /    24 tokens (   10.65 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =     856.26 ms /    10 runs   (   85.63 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1187.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Erin Jacobs\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /     7 runs   (    0.43 ms per token,  2307.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.39 ms /   166 tokens (    8.33 ms per token,   120.08 tokens per second)\n",
      "llama_print_timings:        eval time =     487.44 ms /     6 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1912.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 131 9628\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.70 ms /    15 runs   (    0.65 ms per token,  1547.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.47 ms /    25 tokens (   10.10 ms per token,    99.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.58 ms /    14 runs   (   77.83 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    1488.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6006.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =      78.99 ms /     1 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     336.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     7 runs   (    0.47 ms per token,  2120.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =     476.86 ms /     6 runs   (   79.48 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     778.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ross Weber\", \"Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.73 ms /    15 runs   (    0.72 ms per token,  1398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.18 ms /   160 tokens (    7.16 ms per token,   139.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.18 ms /    14 runs   (   76.73 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =    2371.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"106 368 2710\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    15 runs   (    0.49 ms per token,  2046.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    25 tokens (   10.09 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1080.03 ms /    14 runs   (   77.15 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1440.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     6 runs   (    0.35 ms per token,  2861.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    23 tokens (   10.94 ms per token,    91.38 tokens per second)\n",
      "llama_print_timings:        eval time =     397.99 ms /     5 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     689.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6060.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =      80.42 ms /     1 runs   (   80.42 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     337.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Aron Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     7 runs   (    0.40 ms per token,  2470.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.18 ms /   158 tokens (    7.32 ms per token,   136.66 tokens per second)\n",
      "llama_print_timings:        eval time =     471.63 ms /     6 runs   (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1670.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 901 7057\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    15 runs   (    0.58 ms per token,  1735.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    25 tokens (   10.05 ms per token,    99.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.33 ms /    14 runs   (   78.17 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1462.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     8 runs   (    0.45 ms per token,  2238.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.86 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     545.54 ms /     7 runs   (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     849.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.45 ms /    24 tokens (   10.48 ms per token,    95.45 tokens per second)\n",
      "llama_print_timings:        eval time =      79.60 ms /     1 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     335.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gail Runolfsdottir\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    19 runs   (    0.51 ms per token,  1951.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.24 ms /   146 tokens (    7.84 ms per token,   127.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1389.29 ms /    18 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2683.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8497284029\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.42 ms /    13 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =     943.62 ms /    12 runs   (   78.64 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1291.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     9 runs   (    0.30 ms per token,  3383.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.60 ms /    23 tokens (   10.85 ms per token,    92.15 tokens per second)\n",
      "llama_print_timings:        eval time =     623.62 ms /     8 runs   (   77.95 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     920.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /     8 runs   (    0.55 ms per token,  1805.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.98 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =     545.22 ms /     7 runs   (   77.89 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =     851.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Trevor Lueilwitz\", \"Dr Nikia Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    17 runs   (    0.57 ms per token,  1745.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.92 ms /   170 tokens (    8.09 ms per token,   123.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1234.08 ms /    16 runs   (   77.13 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    2765.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6329.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =      79.29 ms /     1 runs   (   79.29 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     336.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     7 runs   (    0.41 ms per token,  2423.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.52 ms /    23 tokens (   10.89 ms per token,    91.81 tokens per second)\n",
      "llama_print_timings:        eval time =     464.44 ms /     6 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     760.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9756.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     285.40 ms /    24 tokens (   11.89 ms per token,    84.09 tokens per second)\n",
      "llama_print_timings:        eval time =      92.08 ms /     1 runs   (   92.08 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =     396.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Terrell Steuber\", \"Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.34 ms /    19 runs   (    0.60 ms per token,  1675.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.82 ms /   159 tokens (    7.25 ms per token,   137.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1393.74 ms /    18 runs   (   77.43 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    2713.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"607 975 5921\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    15 runs   (    0.48 ms per token,  2074.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    25 tokens (   10.06 ms per token,    99.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.16 ms /    14 runs   (   78.15 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1441.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     9 runs   (    0.35 ms per token,  2831.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.95 ms /    23 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =     618.40 ms /     8 runs   (   77.30 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =     917.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5698.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.62 ms /    24 tokens (   10.40 ms per token,    96.15 tokens per second)\n",
      "llama_print_timings:        eval time =      90.87 ms /     1 runs   (   90.87 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =     346.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Keturah Greenholt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.26 ms /    13 runs   (    0.48 ms per token,  2075.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.28 ms /   189 tokens (    7.31 ms per token,   136.73 tokens per second)\n",
      "llama_print_timings:        eval time =     939.70 ms /    12 runs   (   78.31 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    2413.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 384 6058\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2294.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.38 ms /    25 tokens (   10.22 ms per token,    97.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.48 ms /    14 runs   (   78.46 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1456.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"22-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /     9 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     621.09 ms /     8 runs   (   77.64 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =     926.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5221.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =      81.33 ms /     1 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     338.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rosemarie Zboncak\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    11 runs   (    0.60 ms per token,  1676.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2393.28 ms /   315 tokens (    7.60 ms per token,   131.62 tokens per second)\n",
      "llama_print_timings:        eval time =     797.42 ms /    10 runs   (   79.74 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    3290.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 969 6797\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.25 ms /    15 runs   (    0.62 ms per token,  1621.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.29 ms /    25 tokens (   10.21 ms per token,    97.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.74 ms /    14 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1505.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.94 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =      87.01 ms /     1 runs   (   87.01 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     347.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6688.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.72 ms /    24 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =      91.08 ms /     1 runs   (   91.08 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =     356.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jamison Friesen\", \"Doctor Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    16 runs   (    0.54 ms per token,  1851.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.97 ms /   168 tokens (    8.17 ms per token,   122.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.84 ms /    15 runs   (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2665.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 635 9101\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    15 runs   (    0.55 ms per token,  1833.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    25 tokens (   10.05 ms per token,    99.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.10 ms /    14 runs   (   78.29 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1442.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4694.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.70 ms /    23 tokens (   10.86 ms per token,    92.11 tokens per second)\n",
      "llama_print_timings:        eval time =      91.80 ms /     1 runs   (   91.80 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     347.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4728.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.90 ms /    24 tokens (   10.41 ms per token,    96.04 tokens per second)\n",
      "llama_print_timings:        eval time =      83.61 ms /     1 runs   (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     339.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Emerald Kuhn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    12 runs   (    0.67 ms per token,  1499.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.29 ms /   159 tokens (    7.28 ms per token,   137.27 tokens per second)\n",
      "llama_print_timings:        eval time =     845.22 ms /    11 runs   (   76.84 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    2116.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"866 304 3070\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    15 runs   (    0.69 ms per token,  1445.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.41 ms /    14 runs   (   77.32 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    1468.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /     9 runs   (    0.53 ms per token,  1882.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.49 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     622.19 ms /     8 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =     932.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5602.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.82 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =      92.03 ms /     1 runs   (   92.03 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     349.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Eddie Kuphal\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.84 ms /    18 runs   (    0.55 ms per token,  1830.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.97 ms /   171 tokens (    8.02 ms per token,   124.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.28 ms /    17 runs   (   76.96 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =    2834.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"452 533 1685\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    15 runs   (    0.63 ms per token,  1591.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.06 ms /    25 tokens (   10.08 ms per token,    99.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.72 ms /    14 runs   (   77.69 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1473.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2268.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    23 tokens (   10.87 ms per token,    92.01 tokens per second)\n",
      "llama_print_timings:        eval time =     617.30 ms /     8 runs   (   77.16 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =     932.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5221.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    24 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =      80.53 ms /     1 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     337.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Latricia Goldner\", \"Doctor Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2235.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.58 ms /   140 tokens (    8.14 ms per token,   122.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.77 ms /    15 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    2423.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 469 2875\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    15 runs   (    0.49 ms per token,  2024.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.64 ms /    25 tokens (   10.03 ms per token,    99.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.06 ms /    14 runs   (   78.08 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1442.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     6 runs   (    0.35 ms per token,  2888.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     248.87 ms /    23 tokens (   10.82 ms per token,    92.42 tokens per second)\n",
      "llama_print_timings:        eval time =     388.06 ms /     5 runs   (   77.61 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =     671.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2391.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.49 ms /    24 tokens (   10.40 ms per token,    96.20 tokens per second)\n",
      "llama_print_timings:        eval time =     538.88 ms /     7 runs   (   76.98 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =     842.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Klara Franecki\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.47 ms /    19 runs   (    0.50 ms per token,  2006.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1608.72 ms /   199 tokens (    8.08 ms per token,   123.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1394.93 ms /    18 runs   (   77.50 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    3156.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"137 536 8888\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.79 ms /    15 runs   (    0.59 ms per token,  1706.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.36 ms /    25 tokens (   10.09 ms per token,    99.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.11 ms /    14 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1472.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /     7 runs   (    0.23 ms per token,  4337.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    23 tokens (   10.95 ms per token,    91.30 tokens per second)\n",
      "llama_print_timings:        eval time =     473.10 ms /     6 runs   (   78.85 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     756.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =      81.93 ms /     1 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     339.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Israel Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     8 runs   (    0.41 ms per token,  2458.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.42 ms /   163 tokens (    8.39 ms per token,   119.20 tokens per second)\n",
      "llama_print_timings:        eval time =     557.21 ms /     7 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1973.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"115 699 5911\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    15 runs   (    0.65 ms per token,  1547.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.90 ms /    14 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1471.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.42 ms per token,  2356.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.56 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     541.85 ms /     7 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     842.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /     8 runs   (    0.46 ms per token,  2159.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.06 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =     548.11 ms /     7 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     855.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rodrick Morissette\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2636.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     944.02 ms /   124 tokens (    7.61 ms per token,   131.35 tokens per second)\n",
      "llama_print_timings:        eval time =     688.15 ms /     8 runs   (   86.02 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1701.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 819 3651\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    15 runs   (    0.51 ms per token,  1968.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.31 ms /    25 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.25 ms /    14 runs   (   81.23 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1488.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.55 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =      92.98 ms /     1 runs   (   92.98 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     347.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     8 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.50 ms /    24 tokens (   10.40 ms per token,    96.19 tokens per second)\n",
      "llama_print_timings:        eval time =     548.60 ms /     7 runs   (   78.37 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     844.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brittani Hermiston\", \"NHS number 647 334 8716\", \"DOB 1981-10-29\", \"age 35\", \"Doctor Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      28.04 ms /    59 runs   (    0.48 ms per token,  2103.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.68 ms /   145 tokens (    7.92 ms per token,   126.34 tokens per second)\n",
      "llama_print_timings:        eval time =    4701.38 ms /    58 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    6353.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"647 334 8716\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2349.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.87 ms /    25 tokens (   10.11 ms per token,    98.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.98 ms /    14 runs   (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1526.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /     5 runs   (    0.29 ms per token,  3392.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.10 ms /    23 tokens (   10.83 ms per token,    92.33 tokens per second)\n",
      "llama_print_timings:        eval time =     330.45 ms /     4 runs   (   82.61 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     610.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     8 runs   (    0.49 ms per token,  2047.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.45 ms /    24 tokens (   10.44 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =     551.26 ms /     7 runs   (   78.75 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     854.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Neil Mertz\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    15 runs   (    0.41 ms per token,  2445.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.25 ms /   160 tokens (    7.30 ms per token,   136.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.81 ms /    14 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    2402.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 914 4949\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    15 runs   (    0.47 ms per token,  2109.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.68 ms /    14 runs   (   85.55 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =    1560.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.38 ms /     2 runs   (    0.19 ms per token,  5333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.56 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =      89.45 ms /     1 runs   (   89.45 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     345.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     4 runs   (    0.31 ms per token,  3259.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.76 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =     251.29 ms /     3 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     521.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Phil Ledner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2289.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3158.01 ms /   409 tokens (    7.72 ms per token,   129.51 tokens per second)\n",
      "llama_print_timings:        eval time =     581.53 ms /     7 runs   (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    3797.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 785 363 0212\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.97 ms /    19 runs   (    0.63 ms per token,  1587.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.11 ms /    25 tokens (   10.28 ms per token,    97.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1481.88 ms /    18 runs   (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1906.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2611.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.32 ms /    23 tokens (   11.10 ms per token,    90.08 tokens per second)\n",
      "llama_print_timings:        eval time =     660.18 ms /     8 runs   (   82.52 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     972.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2374.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.04 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     608.16 ms /     7 runs   (   86.88 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     920.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rodrick Batz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /     8 runs   (    0.50 ms per token,  1993.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3008.57 ms /   376 tokens (    8.00 ms per token,   124.98 tokens per second)\n",
      "llama_print_timings:        eval time =     564.51 ms /     7 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    3638.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 924 7868\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.03 ms /    15 runs   (    0.67 ms per token,  1495.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.92 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.84 ms /    14 runs   (   79.20 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1509.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8298.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    23 tokens (   11.06 ms per token,    90.39 tokens per second)\n",
      "llama_print_timings:        eval time =     102.28 ms /     1 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     361.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Generalized anxiety disorder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.81 ms /     9 runs   (    0.53 ms per token,  1869.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.39 ms /    24 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =     643.56 ms /     8 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     971.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cliff McKenzie\", \"Dr. Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    20 runs   (    0.53 ms per token,  1903.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1631.44 ms /   218 tokens (    7.48 ms per token,   133.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1475.47 ms /    19 runs   (   77.66 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    3278.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"554 367 8638\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    15 runs   (    0.48 ms per token,  2074.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.59 ms /    25 tokens (   10.14 ms per token,    98.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.78 ms /    14 runs   (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1448.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     8 runs   (    0.35 ms per token,  2851.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     552.70 ms /     7 runs   (   78.96 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     851.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Childhood asthma\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /     8 runs   (    0.41 ms per token,  2437.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.61 ms /    24 tokens (   10.53 ms per token,    95.01 tokens per second)\n",
      "llama_print_timings:        eval time =     577.02 ms /     7 runs   (   82.43 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     878.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jarrett Howe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /     8 runs   (    0.49 ms per token,  2053.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.96 ms /   148 tokens (    7.77 ms per token,   128.70 tokens per second)\n",
      "llama_print_timings:        eval time =     539.14 ms /     7 runs   (   77.02 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =    1746.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 483 1049\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    15 runs   (    0.44 ms per token,  2290.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    25 tokens (   10.04 ms per token,    99.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.34 ms /    14 runs   (   78.95 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1442.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     8 runs   (    0.35 ms per token,  2872.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.57 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =     545.24 ms /     7 runs   (   77.89 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =     836.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     8 runs   (    0.30 ms per token,  3338.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.51 ms /    24 tokens (   10.40 ms per token,    96.19 tokens per second)\n",
      "llama_print_timings:        eval time =     552.11 ms /     7 runs   (   78.87 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     835.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Delmar Pagac\", \"Dr. Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    18 runs   (    0.54 ms per token,  1864.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.82 ms /   152 tokens (    7.64 ms per token,   130.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1339.70 ms /    17 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    2629.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"300 773 3215\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    15 runs   (    0.42 ms per token,  2380.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.95 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.01 ms /    14 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1472.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     7 runs   (    0.44 ms per token,  2295.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    23 tokens (   11.09 ms per token,    90.18 tokens per second)\n",
      "llama_print_timings:        eval time =     500.67 ms /     6 runs   (   83.44 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     795.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.00 ms /    24 tokens (   10.54 ms per token,    94.86 tokens per second)\n",
      "llama_print_timings:        eval time =      81.55 ms /     1 runs   (   81.55 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     340.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Devorah Hegmann\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.38 ms /    21 runs   (    0.49 ms per token,  2022.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.61 ms /   184 tokens (    7.57 ms per token,   132.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1571.65 ms /    20 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    3110.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 161 4937\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    15 runs   (    0.52 ms per token,  1909.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.58 ms /    25 tokens (   10.10 ms per token,    98.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.63 ms /    14 runs   (   82.12 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1515.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     9 runs   (    0.23 ms per token,  4431.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    23 tokens (   11.01 ms per token,    90.84 tokens per second)\n",
      "llama_print_timings:        eval time =     704.51 ms /     8 runs   (   88.06 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    1001.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     8 runs   (    0.11 ms per token,  8714.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.79 ms /    24 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =     618.51 ms /     7 runs   (   88.36 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     893.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Onita Hoeger\", \"Dr. Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    18 runs   (    0.36 ms per token,  2774.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.08 ms /   154 tokens (    7.60 ms per token,   131.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1442.22 ms /    17 runs   (   84.84 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    2723.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 732 4077\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.37 ms /    15 runs   (    0.62 ms per token,  1600.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.77 ms /    25 tokens (   10.15 ms per token,    98.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.87 ms /    14 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1518.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     6 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     398.31 ms /     5 runs   (   79.66 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     683.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\", \"Chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    13 runs   (    0.55 ms per token,  1810.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =     951.51 ms /    12 runs   (   79.29 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1297.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Florence D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /    10 runs   (    0.27 ms per token,  3669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.29 ms /   162 tokens (    8.61 ms per token,   116.11 tokens per second)\n",
      "llama_print_timings:        eval time =     733.94 ms /     9 runs   (   81.55 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2171.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 926 3697\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    19 runs   (    0.41 ms per token,  2420.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1476.99 ms /    18 runs   (   82.06 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1842.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /     5 runs   (    0.27 ms per token,  3663.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.68 ms /    23 tokens (   10.90 ms per token,    91.75 tokens per second)\n",
      "llama_print_timings:        eval time =     335.63 ms /     4 runs   (   83.91 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     607.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.40 ms /    24 tokens (   10.64 ms per token,    93.97 tokens per second)\n",
      "llama_print_timings:        eval time =      99.82 ms /     1 runs   (   99.82 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =     379.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Earle Welch\", \"Dr. Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.95 ms /    18 runs   (    0.44 ms per token,  2265.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.19 ms /   142 tokens (    8.16 ms per token,   122.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1403.91 ms /    17 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    2679.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"265 364 9330\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.09 ms /    15 runs   (    0.34 ms per token,  2948.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.02 ms /    25 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1159.42 ms /    14 runs   (   82.82 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    1492.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     9 runs   (    0.29 ms per token,  3419.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.25 ms /    23 tokens (   11.14 ms per token,    89.76 tokens per second)\n",
      "llama_print_timings:        eval time =     686.49 ms /     8 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     988.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     8 runs   (    0.34 ms per token,  2957.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.58 ms /    24 tokens (   10.94 ms per token,    91.40 tokens per second)\n",
      "llama_print_timings:        eval time =     607.50 ms /     7 runs   (   86.79 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =     907.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marcelo Bruen\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    17 runs   (    0.43 ms per token,  2344.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.21 ms /   192 tokens (    7.34 ms per token,   136.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1319.03 ms /    16 runs   (   82.44 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2860.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"620 745 3748\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    15 runs   (    0.36 ms per token,  2758.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.43 ms /    25 tokens (   10.34 ms per token,    96.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1192.77 ms /    14 runs   (   85.20 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =    1539.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.15 ms /    23 tokens (   11.18 ms per token,    89.44 tokens per second)\n",
      "llama_print_timings:        eval time =      92.90 ms /     1 runs   (   92.90 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     354.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    12 runs   (    0.33 ms per token,  3066.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.77 ms /    24 tokens (   10.70 ms per token,    93.47 tokens per second)\n",
      "llama_print_timings:        eval time =     961.20 ms /    11 runs   (   87.38 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1291.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Violette Abbott\", \"Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    18 runs   (    0.41 ms per token,  2418.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1669.62 ms /   198 tokens (    8.43 ms per token,   118.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1434.91 ms /    17 runs   (   84.41 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    3227.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"664 666 9487\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    25 tokens (   10.15 ms per token,    98.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.52 ms /    14 runs   (   88.89 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1583.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     7 runs   (    0.39 ms per token,  2580.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.08 ms /    23 tokens (   11.05 ms per token,    90.52 tokens per second)\n",
      "llama_print_timings:        eval time =     483.30 ms /     6 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     777.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6472.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.91 ms /    24 tokens (   10.54 ms per token,    94.90 tokens per second)\n",
      "llama_print_timings:        eval time =      90.72 ms /     1 runs   (   90.72 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =     348.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Dennis Green\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     7 runs   (    0.37 ms per token,  2704.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.07 ms /   153 tokens (    7.60 ms per token,   131.66 tokens per second)\n",
      "llama_print_timings:        eval time =     477.22 ms /     6 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1681.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"561 399 2772\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2227.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.50 ms /    25 tokens (   10.10 ms per token,    99.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.56 ms /    14 runs   (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1498.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /     7 runs   (    0.40 ms per token,  2483.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.22 ms /    23 tokens (   10.92 ms per token,    91.55 tokens per second)\n",
      "llama_print_timings:        eval time =     477.50 ms /     6 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     770.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     8 runs   (    0.41 ms per token,  2457.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.91 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =     557.53 ms /     7 runs   (   79.65 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     850.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Kevin O'Reilly\", \"Doctor Blanche Bailey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    20 runs   (    0.41 ms per token,  2418.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1630.04 ms /   196 tokens (    8.32 ms per token,   120.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1620.56 ms /    19 runs   (   85.29 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    3389.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"698 293 3101\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.52 ms /    15 runs   (    0.37 ms per token,  2717.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.05 ms /    25 tokens (   10.16 ms per token,    98.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.46 ms /    14 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1546.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     7 runs   (    0.51 ms per token,  1942.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.54 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     470.93 ms /     6 runs   (   78.49 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =     775.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6779.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.23 ms /    24 tokens (   10.51 ms per token,    95.15 tokens per second)\n",
      "llama_print_timings:        eval time =      98.09 ms /     1 runs   (   98.09 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     366.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Pearl Larkin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    11 runs   (    0.41 ms per token,  2455.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3263.69 ms /   403 tokens (    8.10 ms per token,   123.48 tokens per second)\n",
      "llama_print_timings:        eval time =     831.58 ms /    10 runs   (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    4166.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"770 364 2899\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    15 runs   (    0.48 ms per token,  2063.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.56 ms /    25 tokens (   10.26 ms per token,    97.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.68 ms /    14 runs   (   83.26 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1524.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     9 runs   (    0.42 ms per token,  2369.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.98 ms /    23 tokens (   11.17 ms per token,    89.50 tokens per second)\n",
      "llama_print_timings:        eval time =     670.49 ms /     8 runs   (   83.81 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     986.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.75 ms /    11 runs   (    0.43 ms per token,  2315.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.51 ms /    24 tokens (   10.73 ms per token,    93.20 tokens per second)\n",
      "llama_print_timings:        eval time =     846.92 ms /    10 runs   (   84.69 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1178.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mavis Cole\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    10 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.83 ms /   146 tokens (    7.96 ms per token,   125.56 tokens per second)\n",
      "llama_print_timings:        eval time =     728.12 ms /     9 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1966.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"161 256 0092\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    15 runs   (    0.44 ms per token,  2274.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.66 ms /    25 tokens (   10.39 ms per token,    96.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.39 ms /    14 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1517.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     6 runs   (    0.43 ms per token,  2346.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.00 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     409.86 ms /     5 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     694.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"bacterial sinusitis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    16 runs   (    0.51 ms per token,  1956.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.78 ms /    24 tokens (   10.78 ms per token,    92.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1290.23 ms /    15 runs   (   86.02 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1662.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Amos Boehm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    10 runs   (    0.43 ms per token,  2338.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.67 ms /   160 tokens (    7.42 ms per token,   134.83 tokens per second)\n",
      "llama_print_timings:        eval time =     771.82 ms /     9 runs   (   85.76 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    2016.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"134 725 9122\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    15 runs   (    0.56 ms per token,  1785.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.57 ms /    25 tokens (   10.14 ms per token,    98.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.07 ms /    14 runs   (   84.08 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1544.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.50 ms /    23 tokens (   11.15 ms per token,    89.67 tokens per second)\n",
      "llama_print_timings:        eval time =     701.27 ms /     8 runs   (   87.66 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    1007.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    11 runs   (    0.58 ms per token,  1732.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    24 tokens (   10.54 ms per token,    94.84 tokens per second)\n",
      "llama_print_timings:        eval time =     816.83 ms /    10 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1152.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Sherley Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    10 runs   (    0.47 ms per token,  2115.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.96 ms /   146 tokens (    8.10 ms per token,   123.42 tokens per second)\n",
      "llama_print_timings:        eval time =     757.19 ms /     9 runs   (   84.13 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    2010.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"364 858 5407\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    15 runs   (    0.45 ms per token,  2222.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.69 ms /    25 tokens (   10.51 ms per token,    95.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.03 ms /    14 runs   (   83.79 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1560.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2303.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     635.93 ms /     8 runs   (   79.49 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     945.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /     8 runs   (    0.54 ms per token,  1854.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.39 ms /    24 tokens (   10.52 ms per token,    95.09 tokens per second)\n",
      "llama_print_timings:        eval time =     560.41 ms /     7 runs   (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     865.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lorina Strosin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /     9 runs   (    0.61 ms per token,  1644.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.22 ms /   137 tokens (    8.40 ms per token,   119.00 tokens per second)\n",
      "llama_print_timings:        eval time =     631.87 ms /     8 runs   (   78.98 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1864.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 754 1860\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    15 runs   (    0.52 ms per token,  1918.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    25 tokens (   10.13 ms per token,    98.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.35 ms /    14 runs   (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1481.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     6 runs   (    0.34 ms per token,  2921.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     403.98 ms /     5 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     693.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     8 runs   (    0.40 ms per token,  2508.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.53 ms /    24 tokens (   10.52 ms per token,    95.04 tokens per second)\n",
      "llama_print_timings:        eval time =     587.07 ms /     7 runs   (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     883.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Letisha Fahey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     9 runs   (    0.36 ms per token,  2764.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.85 ms /   165 tokens (    8.41 ms per token,   118.97 tokens per second)\n",
      "llama_print_timings:        eval time =     642.86 ms /     8 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2085.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 336 7430\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.31 ms /    15 runs   (    0.55 ms per token,  1805.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.23 ms /    25 tokens (   10.17 ms per token,    98.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.37 ms /    14 runs   (   80.88 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1498.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2268.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.56 ms /    23 tokens (   11.02 ms per token,    90.71 tokens per second)\n",
      "llama_print_timings:        eval time =     643.46 ms /     8 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     961.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary complaint\", \"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    13 runs   (    0.47 ms per token,  2140.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.92 ms /    24 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =     973.76 ms /    12 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1328.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marcellus Fisher\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    10 runs   (    0.61 ms per token,  1649.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.76 ms /   160 tokens (    7.25 ms per token,   137.84 tokens per second)\n",
      "llama_print_timings:        eval time =     714.26 ms /     9 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1965.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"532 786 1445\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.60 ms /    15 runs   (    0.57 ms per token,  1745.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.48 ms /    25 tokens (   10.50 ms per token,    95.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.87 ms /    14 runs   (   79.21 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1497.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /     9 runs   (    0.51 ms per token,  1949.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.51 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     634.61 ms /     8 runs   (   79.33 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     951.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    11 runs   (    0.40 ms per token,  2530.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    24 tokens (   10.54 ms per token,    94.88 tokens per second)\n",
      "llama_print_timings:        eval time =     797.00 ms /    10 runs   (   79.70 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1130.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Everett Mertz\", \"Doctor Jerrell Rippin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.84 ms /    18 runs   (    0.44 ms per token,  2296.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.28 ms /   184 tokens (    7.65 ms per token,   130.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1353.14 ms /    17 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2899.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 272 3591\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.85 ms /    15 runs   (    0.66 ms per token,  1523.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.14 ms /    25 tokens (   10.21 ms per token,    97.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.05 ms /    14 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1494.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =      92.56 ms /     1 runs   (   92.56 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     349.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /     8 runs   (    0.36 ms per token,  2808.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.80 ms /    24 tokens (   10.53 ms per token,    94.94 tokens per second)\n",
      "llama_print_timings:        eval time =     559.77 ms /     7 runs   (   79.97 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     865.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Keshia Gleichner\", \"Dr. Hellen Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    19 runs   (    0.58 ms per token,  1715.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2160.64 ms /   286 tokens (    7.55 ms per token,   132.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1453.28 ms /    18 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    3792.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"562 571 0139\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    15 runs   (    0.53 ms per token,  1904.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.26 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.19 ms /    14 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1507.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.50 ms /    23 tokens (   11.11 ms per token,    90.02 tokens per second)\n",
      "llama_print_timings:        eval time =      84.53 ms /     1 runs   (   84.53 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     346.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    11 runs   (    0.43 ms per token,  2308.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    24 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =     813.90 ms /    10 runs   (   81.39 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1138.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kennith Cremin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /     9 runs   (    0.59 ms per token,  1694.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.20 ms /   146 tokens (    7.94 ms per token,   125.95 tokens per second)\n",
      "llama_print_timings:        eval time =     668.43 ms /     8 runs   (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1897.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"570 605 0201\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    15 runs   (    0.50 ms per token,  2000.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.94 ms /    25 tokens (   10.16 ms per token,    98.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.29 ms /    14 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1508.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     7 runs   (    0.42 ms per token,  2391.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    23 tokens (   10.94 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =     514.74 ms /     6 runs   (   85.79 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     807.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.97 ms /    24 tokens (   10.50 ms per token,    95.25 tokens per second)\n",
      "llama_print_timings:        eval time =      93.48 ms /     1 runs   (   93.48 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     351.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jong Lueilwitz\", \"Dr Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.69 ms /    18 runs   (    0.54 ms per token,  1856.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.78 ms /   154 tokens (    7.68 ms per token,   130.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1349.65 ms /    17 runs   (   79.39 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    2683.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"280 255 6099\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.01 ms /    15 runs   (    0.73 ms per token,  1362.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    25 tokens (   10.17 ms per token,    98.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.98 ms /    14 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1495.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     7 runs   (    0.32 ms per token,  3087.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.22 ms /    23 tokens (   10.97 ms per token,    91.19 tokens per second)\n",
      "llama_print_timings:        eval time =     486.07 ms /     6 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =     773.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8032.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.66 ms /    24 tokens (   10.82 ms per token,    92.43 tokens per second)\n",
      "llama_print_timings:        eval time =     104.44 ms /     1 runs   (  104.44 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =     368.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Emelia Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    10 runs   (    0.43 ms per token,  2351.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.92 ms /   151 tokens (    7.80 ms per token,   128.19 tokens per second)\n",
      "llama_print_timings:        eval time =     768.02 ms /     9 runs   (   85.34 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    2011.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"428 395 3000\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    15 runs   (    0.45 ms per token,  2213.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    25 tokens (   10.18 ms per token,    98.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.21 ms /    14 runs   (   83.73 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1522.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /     9 runs   (    0.53 ms per token,  1879.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.69 ms /    23 tokens (   10.90 ms per token,    91.75 tokens per second)\n",
      "llama_print_timings:        eval time =     634.52 ms /     8 runs   (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     949.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    11 runs   (    0.27 ms per token,  3655.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    24 tokens (   10.50 ms per token,    95.27 tokens per second)\n",
      "llama_print_timings:        eval time =     824.58 ms /    10 runs   (   82.46 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1131.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Malik Rodriguez\", \"Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.54 ms /    17 runs   (    0.44 ms per token,  2254.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.53 ms /   149 tokens (    7.80 ms per token,   128.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1297.51 ms /    16 runs   (   81.09 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2578.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 348 8055\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    15 runs   (    0.62 ms per token,  1604.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.30 ms /    25 tokens (   10.25 ms per token,    97.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.96 ms /    14 runs   (   80.00 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1500.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2399.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.38 ms /    23 tokens (   10.89 ms per token,    91.86 tokens per second)\n",
      "llama_print_timings:        eval time =     634.38 ms /     8 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     944.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2646.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     571.77 ms /     7 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     877.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Enoch Hyatt\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.56 ms /    15 runs   (    0.50 ms per token,  1983.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.52 ms /   148 tokens (    7.79 ms per token,   128.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.39 ms /    14 runs   (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    2396.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 144 0394\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.27 ms /    19 runs   (    0.54 ms per token,  1850.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.02 ms /    25 tokens (   10.28 ms per token,    97.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1447.06 ms /    18 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1860.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     7 runs   (    0.30 ms per token,  3312.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =     484.16 ms /     6 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     773.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2653.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.52 ms /    24 tokens (   10.52 ms per token,    95.04 tokens per second)\n",
      "llama_print_timings:        eval time =     574.35 ms /     7 runs   (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     863.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gavin McCullough\", \"Dr. Carson Krajcik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    21 runs   (    0.60 ms per token,  1669.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.05 ms /   178 tokens (    7.88 ms per token,   126.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1666.15 ms /    20 runs   (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    3238.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"878 684 7894\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.50 ms /    25 tokens (   10.26 ms per token,    97.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.77 ms /    14 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1521.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /     9 runs   (    0.54 ms per token,  1850.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.36 ms /    23 tokens (   11.02 ms per token,    90.78 tokens per second)\n",
      "llama_print_timings:        eval time =     655.56 ms /     8 runs   (   81.95 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     966.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     4 runs   (    0.16 ms per token,  6441.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.61 ms /    24 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =     258.41 ms /     3 runs   (   86.14 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     522.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gabriel Corwin\", \"family members\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    12 runs   (    0.47 ms per token,  2111.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2166.62 ms /   273 tokens (    7.94 ms per token,   126.00 tokens per second)\n",
      "llama_print_timings:        eval time =     903.57 ms /    11 runs   (   82.14 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    3163.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"800 315 1515\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    15 runs   (    0.51 ms per token,  1957.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    25 tokens (   10.18 ms per token,    98.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.01 ms /    14 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1476.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6514.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.21 ms /    23 tokens (   10.97 ms per token,    91.19 tokens per second)\n",
      "llama_print_timings:        eval time =      81.45 ms /     1 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     338.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /     8 runs   (    0.36 ms per token,  2806.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.08 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =     561.56 ms /     7 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     861.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Edwardo Stanton\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.86 ms /    17 runs   (    0.52 ms per token,  1918.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.04 ms /   141 tokens (    8.12 ms per token,   123.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.83 ms /    16 runs   (   76.86 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    2522.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"853 664 6299\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    15 runs   (    0.50 ms per token,  2009.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    25 tokens (   10.12 ms per token,    98.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.10 ms /    14 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1521.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     7 runs   (    0.31 ms per token,  3183.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    23 tokens (   10.88 ms per token,    91.95 tokens per second)\n",
      "llama_print_timings:        eval time =     483.65 ms /     6 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     772.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2709.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =     580.59 ms /     7 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     875.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wilford Zemlak\", \"Dr. Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.98 ms /    19 runs   (    0.53 ms per token,  1903.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.87 ms /   162 tokens (    8.46 ms per token,   118.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.80 ms /    18 runs   (   78.71 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    2934.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"335 542 4986\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.31 ms /    15 runs   (    0.69 ms per token,  1455.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.00 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.75 ms /    14 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1476.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9174.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.82 ms /    23 tokens (   10.95 ms per token,    91.34 tokens per second)\n",
      "llama_print_timings:        eval time =      79.26 ms /     1 runs   (   79.26 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     335.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    11 runs   (    0.34 ms per token,  2981.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.68 ms /    24 tokens (   10.40 ms per token,    96.12 tokens per second)\n",
      "llama_print_timings:        eval time =     784.40 ms /    10 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1095.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Clarence Kassulke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    10 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.23 ms /   142 tokens (    8.07 ms per token,   123.99 tokens per second)\n",
      "llama_print_timings:        eval time =     697.19 ms /     9 runs   (   77.47 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    1924.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"550 971 5390\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    15 runs   (    0.48 ms per token,  2088.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.52 ms /    14 runs   (   79.18 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1459.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.52 ms /     9 runs   (    0.50 ms per token,  1992.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.19 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     631.45 ms /     8 runs   (   78.93 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     944.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    11 runs   (    0.37 ms per token,  2726.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.30 ms /    24 tokens (   10.43 ms per token,    95.89 tokens per second)\n",
      "llama_print_timings:        eval time =     796.23 ms /    10 runs   (   79.62 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1117.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Janella Hudson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /     9 runs   (    0.54 ms per token,  1867.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.87 ms /   180 tokens (    7.72 ms per token,   129.60 tokens per second)\n",
      "llama_print_timings:        eval time =     636.55 ms /     8 runs   (   79.57 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2083.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"177 806 1336\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.73 ms /    15 runs   (    0.38 ms per token,  2619.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.98 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.79 ms /    14 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1484.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     9 runs   (    0.30 ms per token,  3344.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.25 ms /    23 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =     647.82 ms /     8 runs   (   80.98 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     948.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"risk\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    11 runs   (    0.29 ms per token,  3486.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =     810.52 ms /    10 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1118.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Thurman Bechtelar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.79 ms /    10 runs   (    0.58 ms per token,  1727.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2181.49 ms /   284 tokens (    7.68 ms per token,   130.19 tokens per second)\n",
      "llama_print_timings:        eval time =     740.99 ms /     9 runs   (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2996.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 477 4045\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2277.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.91 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.25 ms /    14 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1503.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.84 ms /    23 tokens (   11.17 ms per token,    89.55 tokens per second)\n",
      "llama_print_timings:        eval time =      94.48 ms /     1 runs   (   94.48 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =     356.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     8 runs   (    0.31 ms per token,  3192.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.77 ms /    24 tokens (   10.57 ms per token,    94.58 tokens per second)\n",
      "llama_print_timings:        eval time =     586.88 ms /     7 runs   (   83.84 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     875.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Daine Koch\", \"Dr. Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.46 ms /    17 runs   (    0.56 ms per token,  1797.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1660.29 ms /   206 tokens (    8.06 ms per token,   124.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1328.55 ms /    16 runs   (   83.03 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    3105.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"218 767 2774\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.59 ms /    15 runs   (    0.51 ms per token,  1976.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    25 tokens (   10.14 ms per token,    98.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.51 ms /    14 runs   (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    1564.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     5 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.39 ms /    23 tokens (   10.97 ms per token,    91.13 tokens per second)\n",
      "llama_print_timings:        eval time =     352.38 ms /     4 runs   (   88.10 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     617.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.37 ms /    24 tokens (   10.52 ms per token,    95.10 tokens per second)\n",
      "llama_print_timings:        eval time =     100.95 ms /     1 runs   (  100.95 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =     357.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Trisha Buckridge\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.54 ms /    11 runs   (    0.50 ms per token,  1986.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.02 ms /   135 tokens (    8.56 ms per token,   116.78 tokens per second)\n",
      "llama_print_timings:        eval time =     816.31 ms /    10 runs   (   81.63 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    2054.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS Number 260 376 0510\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.82 ms /    19 runs   (    0.46 ms per token,  2153.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.39 ms /    25 tokens (   10.22 ms per token,    97.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1518.64 ms /    18 runs   (   84.37 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    1906.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     4 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     241.70 ms /     3 runs   (   80.57 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     506.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    24 tokens (   10.54 ms per token,    94.88 tokens per second)\n",
      "llama_print_timings:        eval time =     104.69 ms /     1 runs   (  104.69 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =     363.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Marisol Greenholt\", \"Dr. Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.33 ms /    22 runs   (    0.51 ms per token,  1942.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.28 ms /   174 tokens (    8.01 ms per token,   124.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1716.29 ms /    21 runs   (   81.73 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    3295.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"382 503 4418\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    15 runs   (    0.60 ms per token,  1672.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.53 ms /    25 tokens (   10.22 ms per token,    97.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.20 ms /    14 runs   (   79.87 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1490.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5847.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.82 ms /    23 tokens (   10.99 ms per token,    90.97 tokens per second)\n",
      "llama_print_timings:        eval time =      82.78 ms /     1 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     342.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     8 runs   (    0.32 ms per token,  3117.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.54 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     565.16 ms /     7 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     859.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Romona Skiles\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.65 ms /    18 runs   (    0.54 ms per token,  1866.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2897.49 ms /   362 tokens (    8.00 ms per token,   124.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1379.94 ms /    17 runs   (   81.17 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    4449.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"537 173 9636\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    15 runs   (    0.41 ms per token,  2434.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.37 ms /    25 tokens (   10.37 ms per token,    96.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.91 ms /    14 runs   (   84.21 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    1535.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     5 runs   (    0.32 ms per token,  3128.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.08 ms /    23 tokens (   11.13 ms per token,    89.82 tokens per second)\n",
      "llama_print_timings:        eval time =     329.57 ms /     4 runs   (   82.39 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     613.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     6 runs   (    0.25 ms per token,  4005.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =     416.67 ms /     5 runs   (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     697.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jeromy Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     9 runs   (    0.21 ms per token,  4851.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.58 ms /   167 tokens (    8.28 ms per token,   120.70 tokens per second)\n",
      "llama_print_timings:        eval time =     683.21 ms /     8 runs   (   85.40 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =    2104.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 700 766 5870\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.08 ms /    19 runs   (    0.53 ms per token,  1884.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.63 ms /    25 tokens (   10.39 ms per token,    96.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1428.68 ms /    18 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1842.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     7 runs   (    0.41 ms per token,  2447.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =     507.32 ms /     6 runs   (   84.55 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     804.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"full-time employment\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     8 runs   (    0.38 ms per token,  2605.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.36 ms /    24 tokens (   10.52 ms per token,    95.10 tokens per second)\n",
      "llama_print_timings:        eval time =     570.13 ms /     7 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     873.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kathern Collier\", \"Dr. Riley Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.77 ms /    19 runs   (    0.57 ms per token,  1764.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.66 ms /   143 tokens (    8.08 ms per token,   123.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1414.38 ms /    18 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2751.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"764 434 7379\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    15 runs   (    0.52 ms per token,  1933.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.06 ms /    25 tokens (   10.08 ms per token,    99.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.28 ms /    14 runs   (   79.02 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1468.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     9 runs   (    0.34 ms per token,  2949.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.43 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =     671.76 ms /     8 runs   (   83.97 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     970.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.25 ms /    24 tokens (   10.76 ms per token,    92.94 tokens per second)\n",
      "llama_print_timings:        eval time =     567.30 ms /     7 runs   (   81.04 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =     874.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alvaro Lind\", \"Dr Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    14 runs   (    0.50 ms per token,  1986.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.38 ms /   157 tokens (    7.43 ms per token,   134.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1045.65 ms /    13 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    2328.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 727 0481\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.67 ms /    15 runs   (    0.58 ms per token,  1729.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.33 ms /    25 tokens (   10.17 ms per token,    98.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.48 ms /    14 runs   (   79.61 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1482.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    23 tokens (   11.01 ms per token,    90.87 tokens per second)\n",
      "llama_print_timings:        eval time =      82.51 ms /     1 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     340.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     8 runs   (    0.33 ms per token,  3036.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.84 ms /    24 tokens (   10.66 ms per token,    93.81 tokens per second)\n",
      "llama_print_timings:        eval time =     557.04 ms /     7 runs   (   79.58 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     870.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Claude Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.36 ms /   149 tokens (    7.81 ms per token,   128.08 tokens per second)\n",
      "llama_print_timings:        eval time =     591.49 ms /     7 runs   (   84.50 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    1807.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"543 566 3899\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2108.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.95 ms /    14 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1492.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     8 runs   (    0.36 ms per token,  2794.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    23 tokens (   10.94 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     561.89 ms /     7 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     861.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.31 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =      83.40 ms /     1 runs   (   83.40 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     341.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Roscoe Lubowitz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    10 runs   (    0.47 ms per token,  2133.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.65 ms /   174 tokens (    8.04 ms per token,   124.32 tokens per second)\n",
      "llama_print_timings:        eval time =     707.59 ms /     9 runs   (   78.62 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    2180.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 482 0542\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    15 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.32 ms /    25 tokens (   10.17 ms per token,    98.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.39 ms /    14 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1503.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5698.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.29 ms /    23 tokens (   10.97 ms per token,    91.16 tokens per second)\n",
      "llama_print_timings:        eval time =      87.11 ms /     1 runs   (   87.11 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     344.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6191.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.90 ms /    24 tokens (   10.54 ms per token,    94.90 tokens per second)\n",
      "llama_print_timings:        eval time =      83.11 ms /     1 runs   (   83.11 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     340.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cherilyn Pfeffer\", \"Dr. Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    19 runs   (    0.53 ms per token,  1871.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.33 ms /   150 tokens (    7.81 ms per token,   128.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1447.51 ms /    18 runs   (   80.42 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2774.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 371 5194\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    15 runs   (    0.48 ms per token,  2063.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.16 ms /    25 tokens (   10.41 ms per token,    96.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.47 ms /    14 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1519.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     8 runs   (    0.45 ms per token,  2209.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.90 ms /    23 tokens (   11.34 ms per token,    88.16 tokens per second)\n",
      "llama_print_timings:        eval time =     597.34 ms /     7 runs   (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =     907.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     8 runs   (    0.30 ms per token,  3311.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.89 ms /    24 tokens (   11.04 ms per token,    90.60 tokens per second)\n",
      "llama_print_timings:        eval time =     584.22 ms /     7 runs   (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     891.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Sana Murazik\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.44 ms /    20 runs   (    0.47 ms per token,  2119.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.93 ms /   147 tokens (    7.98 ms per token,   125.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1518.35 ms /    19 runs   (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2851.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"333 454 7007\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    15 runs   (    0.42 ms per token,  2363.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.53 ms /    25 tokens (   10.14 ms per token,    98.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.52 ms /    14 runs   (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1510.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2265.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.74 ms /    23 tokens (   11.03 ms per token,    90.64 tokens per second)\n",
      "llama_print_timings:        eval time =     658.38 ms /     8 runs   (   82.30 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     970.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2222.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =     564.80 ms /     7 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     872.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Tula Boehm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.38 ms /    11 runs   (    0.49 ms per token,  2044.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.05 ms /   140 tokens (    8.21 ms per token,   121.84 tokens per second)\n",
      "llama_print_timings:        eval time =     781.02 ms /    10 runs   (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    2010.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"631 804 3554\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    15 runs   (    0.55 ms per token,  1820.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.66 ms /    14 runs   (   79.33 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1475.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =      84.43 ms /     1 runs   (   84.43 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     340.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     8 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.22 ms /    24 tokens (   10.38 ms per token,    96.30 tokens per second)\n",
      "llama_print_timings:        eval time =     586.74 ms /     7 runs   (   83.82 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     867.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Cristobal Hilpert\", \"Doctor Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.45 ms /    20 runs   (    0.47 ms per token,  2117.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.46 ms /   219 tokens (    7.56 ms per token,   132.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1512.39 ms /    19 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    3329.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"214 908 3248\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    15 runs   (    0.38 ms per token,  2613.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.72 ms /    14 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1465.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     9 runs   (    0.23 ms per token,  4283.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     707.39 ms /     8 runs   (   88.42 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =    1080.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9345.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.14 ms /    24 tokens (   10.51 ms per token,    95.19 tokens per second)\n",
      "llama_print_timings:        eval time =      87.16 ms /     1 runs   (   87.16 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =     348.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sheri Durgan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     9 runs   (    0.20 ms per token,  4880.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.15 ms /   159 tokens (    7.30 ms per token,   137.05 tokens per second)\n",
      "llama_print_timings:        eval time =     634.55 ms /     8 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1832.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"323 897 8400\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    15 runs   (    0.22 ms per token,  4584.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.69 ms /    25 tokens (   10.03 ms per token,    99.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.63 ms /    14 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1441.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     9 runs   (    0.25 ms per token,  4025.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.28 ms /    23 tokens (   10.84 ms per token,    92.26 tokens per second)\n",
      "llama_print_timings:        eval time =     612.03 ms /     8 runs   (   76.50 ms per token,    13.07 tokens per second)\n",
      "llama_print_timings:       total time =     904.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     8 runs   (    0.11 ms per token,  8938.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.26 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =     610.92 ms /     7 runs   (   87.27 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =     881.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Collene Schuppe\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.10 ms /    19 runs   (    0.53 ms per token,  1881.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1949.03 ms /   241 tokens (    8.09 ms per token,   123.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1449.81 ms /    18 runs   (   80.54 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    3562.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"247 241 3798\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /    15 runs   (    0.40 ms per token,  2518.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    25 tokens (   10.14 ms per token,    98.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.37 ms /    14 runs   (   79.53 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1461.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.01 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =      85.14 ms /     1 runs   (   85.14 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     341.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6410.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.99 ms /    24 tokens (   10.50 ms per token,    95.24 tokens per second)\n",
      "llama_print_timings:        eval time =      91.32 ms /     1 runs   (   91.32 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     348.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Leonora Blick\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.87 ms /    10 runs   (    0.59 ms per token,  1705.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.46 ms /   143 tokens (    8.00 ms per token,   124.95 tokens per second)\n",
      "llama_print_timings:        eval time =     693.94 ms /     9 runs   (   77.10 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    1921.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"282 139 7398\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    15 runs   (    0.52 ms per token,  1917.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.80 ms /    14 runs   (   77.91 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1457.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2640.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.53 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =     627.22 ms /     8 runs   (   78.40 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     931.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    11 runs   (    0.48 ms per token,  2062.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     796.36 ms /    10 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1119.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jenniffer Wunsch\", \"Dr. Ramiro Anderson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    18 runs   (    0.43 ms per token,  2301.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.59 ms /   151 tokens (    7.65 ms per token,   130.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1316.61 ms /    17 runs   (   77.45 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    2602.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"147 803 4958\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    15 runs   (    0.44 ms per token,  2289.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.35 ms /    25 tokens (   10.09 ms per token,    99.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.01 ms /    14 runs   (   78.00 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1446.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"68-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2387.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     632.13 ms /     8 runs   (   79.02 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     943.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     8 runs   (    0.47 ms per token,  2136.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.76 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =     574.16 ms /     7 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     872.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Ilda Ferry\", \"Dr. Celine Pagac\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    20 runs   (    0.51 ms per token,  1972.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2880.59 ms /   378 tokens (    7.62 ms per token,   131.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1603.20 ms /    19 runs   (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    4632.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"359 659 6623\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2107.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.86 ms /    25 tokens (   10.35 ms per token,    96.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.67 ms /    14 runs   (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1530.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     7 runs   (    0.30 ms per token,  3303.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.48 ms /    23 tokens (   11.11 ms per token,    90.03 tokens per second)\n",
      "llama_print_timings:        eval time =     500.82 ms /     6 runs   (   83.47 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     795.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"prediabetes\", \"anemia\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    18 runs   (    0.33 ms per token,  3032.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.07 ms /    24 tokens (   10.71 ms per token,    93.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.75 ms /    17 runs   (   84.75 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    1808.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Aldo Boyer\", \"Dr. Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.96 ms /    17 runs   (    0.53 ms per token,  1896.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.48 ms /   182 tokens (    7.79 ms per token,   128.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1287.78 ms /    16 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2827.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 398 233 1945\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.39 ms /    19 runs   (    0.49 ms per token,  2023.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1426.15 ms /    18 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1803.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /     9 runs   (    0.52 ms per token,  1928.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.96 ms /    23 tokens (   10.87 ms per token,    92.01 tokens per second)\n",
      "llama_print_timings:        eval time =     617.05 ms /     8 runs   (   77.13 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =     932.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7662.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =      92.55 ms /     1 runs   (   92.55 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     348.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Glen Stark\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     8 runs   (    0.43 ms per token,  2315.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.27 ms /   138 tokens (    8.50 ms per token,   117.62 tokens per second)\n",
      "llama_print_timings:        eval time =     543.28 ms /     7 runs   (   77.61 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    1768.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"399 883 3577\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2015.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    25 tokens (   10.05 ms per token,    99.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.82 ms /    14 runs   (   79.70 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1465.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     7 runs   (    0.33 ms per token,  3072.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.32 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     483.00 ms /     6 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     769.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     8 runs   (    0.33 ms per token,  3001.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =     547.72 ms /     7 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =     839.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Earleen Pfeffer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    12 runs   (    0.39 ms per token,  2583.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1367.87 ms /   163 tokens (    8.39 ms per token,   119.16 tokens per second)\n",
      "llama_print_timings:        eval time =     873.46 ms /    11 runs   (   79.41 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    2313.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     6 runs   (    0.20 ms per token,  4893.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =     397.43 ms /     5 runs   (   79.49 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     671.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /     9 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.13 ms /    23 tokens (   10.83 ms per token,    92.32 tokens per second)\n",
      "llama_print_timings:        eval time =     648.96 ms /     8 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     958.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    11 runs   (    0.37 ms per token,  2671.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.38 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =     806.29 ms /    10 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1120.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ilana Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.21 ms /    10 runs   (    0.52 ms per token,  1918.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.02 ms /   155 tokens (    7.52 ms per token,   132.93 tokens per second)\n",
      "llama_print_timings:        eval time =     717.82 ms /     9 runs   (   79.76 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1963.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"219 678 2134\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    15 runs   (    0.46 ms per token,  2152.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.10 ms /    25 tokens (   10.08 ms per token,    99.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.10 ms /    14 runs   (   78.86 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1461.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.48 ms /     4 runs   (    0.12 ms per token,  8350.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.30 ms /    23 tokens (   10.88 ms per token,    91.89 tokens per second)\n",
      "llama_print_timings:        eval time =     277.91 ms /     3 runs   (   92.64 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     537.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.35 ms /    24 tokens (   10.39 ms per token,    96.25 tokens per second)\n",
      "llama_print_timings:        eval time =      89.24 ms /     1 runs   (   89.24 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =     343.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Vernice Schamberger\", \"Doctor Leonarda Schumm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.20 ms /    19 runs   (    0.59 ms per token,  1696.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.27 ms /   153 tokens (    7.54 ms per token,   132.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1387.80 ms /    18 runs   (   77.10 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    2704.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"190 587 5025\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    15 runs   (    0.54 ms per token,  1846.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.36 ms /    25 tokens (   10.17 ms per token,    98.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.63 ms /    14 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1472.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"78 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     7 runs   (    0.51 ms per token,  1956.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =     462.25 ms /     6 runs   (   77.04 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =     759.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    11 runs   (    0.42 ms per token,  2404.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.44 ms /    24 tokens (   10.43 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =     803.80 ms /    10 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1122.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Eleonora Rath\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    18 runs   (    0.40 ms per token,  2526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.27 ms /   163 tokens (    8.45 ms per token,   118.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1405.84 ms /    17 runs   (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    2879.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"762 715 4236\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.03 ms /    15 runs   (    0.34 ms per token,  2982.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.25 ms /    25 tokens (   10.21 ms per token,    97.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.90 ms /    14 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1482.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     7 runs   (    0.34 ms per token,  2939.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.53 ms /    23 tokens (   10.89 ms per token,    91.81 tokens per second)\n",
      "llama_print_timings:        eval time =     495.42 ms /     6 runs   (   82.57 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     778.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    11 runs   (    0.18 ms per token,  5453.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =     872.92 ms /    10 runs   (   87.29 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =    1171.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Daniel Gottlieb\", \"Dr. Antwan Lindgren\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /    17 runs   (    0.24 ms per token,  4089.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.63 ms /   166 tokens (    8.30 ms per token,   120.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.16 ms /    16 runs   (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2704.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"647 987 0332\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    15 runs   (    0.21 ms per token,  4730.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.00 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.61 ms /    14 runs   (   78.12 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1403.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     7 runs   (    0.13 ms per token,  7633.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.13 ms /    23 tokens (   10.88 ms per token,    91.95 tokens per second)\n",
      "llama_print_timings:        eval time =     497.43 ms /     6 runs   (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     766.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9950.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    24 tokens (   10.51 ms per token,    95.19 tokens per second)\n",
      "llama_print_timings:        eval time =      87.10 ms /     1 runs   (   87.10 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     342.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cleo Leffler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /    10 runs   (    0.15 ms per token,  6578.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3005.98 ms /   376 tokens (    7.99 ms per token,   125.08 tokens per second)\n",
      "llama_print_timings:        eval time =     739.66 ms /     9 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    3776.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 853 5598\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /    15 runs   (    0.19 ms per token,  5231.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    25 tokens (   10.26 ms per token,    97.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.31 ms /    14 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1456.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8695.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.78 ms /    23 tokens (   11.08 ms per token,    90.27 tokens per second)\n",
      "llama_print_timings:        eval time =      93.63 ms /     1 runs   (   93.63 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =     353.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     8 runs   (    0.17 ms per token,  5776.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    24 tokens (   10.60 ms per token,    94.31 tokens per second)\n",
      "llama_print_timings:        eval time =     566.63 ms /     7 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     847.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tomasa Will\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     6 runs   (    0.14 ms per token,  7255.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.69 ms /   176 tokens (    7.84 ms per token,   127.57 tokens per second)\n",
      "llama_print_timings:        eval time =     478.42 ms /     5 runs   (   95.68 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =    1872.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 367 2133\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /    15 runs   (    0.12 ms per token,  8241.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.13 ms /    25 tokens (   10.09 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1288.60 ms /    14 runs   (   92.04 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =    1590.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     8 runs   (    0.10 ms per token, 10322.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    23 tokens (   11.04 ms per token,    90.55 tokens per second)\n",
      "llama_print_timings:        eval time =     625.85 ms /     7 runs   (   89.41 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     901.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10152.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.35 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     102.30 ms /     1 runs   (  102.30 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     360.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Shae Turner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     9 runs   (    0.21 ms per token,  4817.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.26 ms /   167 tokens (    8.27 ms per token,   120.99 tokens per second)\n",
      "llama_print_timings:        eval time =     618.19 ms /     8 runs   (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    2037.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"399 726 9149\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    15 runs   (    0.14 ms per token,  6928.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.13 ms /    14 runs   (   84.44 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1472.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9708.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.16 ms /    23 tokens (   11.31 ms per token,    88.41 tokens per second)\n",
      "llama_print_timings:        eval time =      86.50 ms /     1 runs   (   86.50 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     350.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    16 runs   (    0.18 ms per token,  5661.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.02 ms /    15 runs   (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1507.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Xavier Hessel\", \"Dr. Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    17 runs   (    0.48 ms per token,  2102.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.80 ms /   190 tokens (    7.43 ms per token,   134.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1286.99 ms /    16 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    2826.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 753 958 9050\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.90 ms /    19 runs   (    0.57 ms per token,  1742.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    25 tokens (   10.15 ms per token,    98.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1419.98 ms /    18 runs   (   78.89 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1812.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     9 runs   (    0.43 ms per token,  2343.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     626.81 ms /     8 runs   (   78.35 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     938.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     109.05 ms /     1 runs   (  109.05 ms per token,     9.17 tokens per second)\n",
      "llama_print_timings:       total time =     365.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Reda Moen\", \"Doctor Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    14 runs   (    0.43 ms per token,  2324.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.41 ms /   168 tokens (    8.20 ms per token,   121.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1018.25 ms /    13 runs   (   78.33 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    2500.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 549 4962\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    15 runs   (    0.43 ms per token,  2304.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    25 tokens (   10.06 ms per token,    99.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.32 ms /    14 runs   (   79.02 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1451.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     5 runs   (    0.29 ms per token,  3441.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     315.96 ms /     4 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     586.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     7 runs   (    0.20 ms per token,  4881.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =     484.00 ms /     6 runs   (   80.67 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     760.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Pat Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     9 runs   (    0.40 ms per token,  2480.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.04 ms /   142 tokens (    8.06 ms per token,   124.01 tokens per second)\n",
      "llama_print_timings:        eval time =     621.71 ms /     8 runs   (   77.71 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1831.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"506 809 3354\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    15 runs   (    0.41 ms per token,  2446.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.15 ms /    25 tokens (   10.05 ms per token,    99.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.14 ms /    14 runs   (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1463.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /     7 runs   (    0.23 ms per token,  4347.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     495.49 ms /     6 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     773.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     8 runs   (    0.25 ms per token,  4069.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.39 ms /    24 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =     563.11 ms /     7 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     847.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clay Quitzon\", \"Dr. Emilio Barton\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    17 runs   (    0.48 ms per token,  2102.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.84 ms /   150 tokens (    7.73 ms per token,   129.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1325.48 ms /    16 runs   (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    2605.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"864 877 2102\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    15 runs   (    0.42 ms per token,  2362.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.38 ms /    25 tokens (   10.26 ms per token,    97.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.75 ms /    14 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1482.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     5 runs   (    0.23 ms per token,  4366.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.68 ms /    23 tokens (   11.03 ms per token,    90.67 tokens per second)\n",
      "llama_print_timings:        eval time =     347.47 ms /     4 runs   (   86.87 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     620.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     8 runs   (    0.31 ms per token,  3177.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.77 ms /    24 tokens (   10.66 ms per token,    93.84 tokens per second)\n",
      "llama_print_timings:        eval time =     568.43 ms /     7 runs   (   81.20 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     861.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Lavelle Durgan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    11 runs   (    0.22 ms per token,  4619.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.78 ms /   139 tokens (    8.32 ms per token,   120.16 tokens per second)\n",
      "llama_print_timings:        eval time =     856.97 ms /    10 runs   (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    2054.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     6 runs   (    0.29 ms per token,  3432.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =     412.10 ms /     5 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     692.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.52 ms /    23 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =      86.09 ms /     1 runs   (   86.09 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =     341.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /     8 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.02 ms /    24 tokens (   10.42 ms per token,    95.99 tokens per second)\n",
      "llama_print_timings:        eval time =     556.88 ms /     7 runs   (   79.55 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =     848.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Isaiah Adams\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /     8 runs   (    0.52 ms per token,  1923.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.12 ms /   160 tokens (    7.20 ms per token,   138.87 tokens per second)\n",
      "llama_print_timings:        eval time =     613.21 ms /     7 runs   (   87.60 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    1816.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     6 runs   (    0.20 ms per token,  4942.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.91 ms /    25 tokens (   10.12 ms per token,    98.85 tokens per second)\n",
      "llama_print_timings:        eval time =     602.81 ms /     5 runs   (  120.56 ms per token,     8.29 tokens per second)\n",
      "llama_print_timings:       total time =    1006.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     8 runs   (    0.40 ms per token,  2470.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.82 ms /    23 tokens (   11.38 ms per token,    87.85 tokens per second)\n",
      "llama_print_timings:        eval time =     679.07 ms /     7 runs   (   97.01 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =     993.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.27 ms per token,  3759.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.55 ms /    24 tokens (   10.73 ms per token,    93.19 tokens per second)\n",
      "llama_print_timings:        eval time =     116.32 ms /     1 runs   (  116.32 ms per token,     8.60 tokens per second)\n",
      "llama_print_timings:       total time =     379.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lyn Champlin\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    17 runs   (    0.45 ms per token,  2236.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.59 ms /   180 tokens (    7.83 ms per token,   127.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.24 ms /    16 runs   (   85.14 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    2932.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 894 436 1346\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.64 ms /    19 runs   (    0.61 ms per token,  1631.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1408.05 ms /    18 runs   (   78.23 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1816.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.59 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =      83.71 ms /     1 runs   (   83.71 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     339.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     8 runs   (    0.33 ms per token,  3076.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     586.24 ms /     7 runs   (   83.75 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     879.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosanne Hermiston\", \"Dr. Miguel Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.65 ms /    17 runs   (    0.63 ms per token,  1596.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.58 ms /   155 tokens (    7.47 ms per token,   133.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1269.49 ms /    16 runs   (   79.34 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    2578.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 497 7402\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    15 runs   (    0.54 ms per token,  1856.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.44 ms /    14 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1469.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8230.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.69 ms /    23 tokens (   10.90 ms per token,    91.75 tokens per second)\n",
      "llama_print_timings:        eval time =      86.39 ms /     1 runs   (   86.39 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     341.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4219.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.45 ms /    24 tokens (   10.81 ms per token,    92.50 tokens per second)\n",
      "llama_print_timings:        eval time =      94.60 ms /     1 runs   (   94.60 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     366.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Charise Turner\", \"Shonna Feest\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    12 runs   (    0.49 ms per token,  2033.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.27 ms /   159 tokens (    7.28 ms per token,   137.27 tokens per second)\n",
      "llama_print_timings:        eval time =     849.94 ms /    11 runs   (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    2100.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 874 8506\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.27 ms /    15 runs   (    0.62 ms per token,  1618.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.98 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.57 ms /    14 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1478.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6269.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.34 ms /    23 tokens (   10.84 ms per token,    92.24 tokens per second)\n",
      "llama_print_timings:        eval time =      82.47 ms /     1 runs   (   82.47 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     337.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     7 runs   (    0.25 ms per token,  4039.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.32 ms /    24 tokens (   10.43 ms per token,    95.88 tokens per second)\n",
      "llama_print_timings:        eval time =     487.93 ms /     6 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     768.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Marvis Pollich\", \"Dr.\", \"Jean Koelpin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /    20 runs   (    0.16 ms per token,  6106.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1422.29 ms /   179 tokens (    7.95 ms per token,   125.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1530.47 ms /    19 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    3006.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"724 851 2490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    15 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    25 tokens (   10.12 ms per token,    98.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.11 ms /    14 runs   (   82.44 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1460.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /     9 runs   (    0.21 ms per token,  4729.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.52 ms /    23 tokens (   11.11 ms per token,    90.01 tokens per second)\n",
      "llama_print_timings:        eval time =     646.29 ms /     8 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     931.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.46 ms /    24 tokens (   10.52 ms per token,    95.07 tokens per second)\n",
      "llama_print_timings:        eval time =      98.99 ms /     1 runs   (   98.99 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     355.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Billye Emard\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    19 runs   (    0.25 ms per token,  3979.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.05 ms /   144 tokens (    8.00 ms per token,   125.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1427.40 ms /    18 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    2672.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"356 915 6410\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    15 runs   (    0.32 ms per token,  3109.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    25 tokens (   10.03 ms per token,    99.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.55 ms /    14 runs   (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1487.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2578.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.99 ms /    23 tokens (   10.91 ms per token,    91.64 tokens per second)\n",
      "llama_print_timings:        eval time =     635.01 ms /     8 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     945.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     8 runs   (    0.46 ms per token,  2157.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.71 ms /    24 tokens (   10.53 ms per token,    94.97 tokens per second)\n",
      "llama_print_timings:        eval time =     568.28 ms /     7 runs   (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     874.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Adrienne Lubowitz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /    11 runs   (    0.44 ms per token,  2291.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.00 ms /   176 tokens (    7.89 ms per token,   126.71 tokens per second)\n",
      "llama_print_timings:        eval time =     799.84 ms /    10 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2257.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"112 852 1841\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    15 runs   (    0.48 ms per token,  2104.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.09 ms /    25 tokens (   10.16 ms per token,    98.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.96 ms /    14 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1488.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     7 runs   (    0.25 ms per token,  4002.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    23 tokens (   10.93 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     480.05 ms /     6 runs   (   80.01 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     763.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    13 runs   (    0.40 ms per token,  2472.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.70 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =     968.17 ms /    12 runs   (   80.68 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1307.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Verline Beahan\", \"Marth Mayer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2546.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.25 ms /   149 tokens (    7.77 ms per token,   128.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.76 ms /    16 runs   (   81.80 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    2590.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"600 349 8537\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    15 runs   (    0.48 ms per token,  2080.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    25 tokens (   10.06 ms per token,    99.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.89 ms /    14 runs   (   79.99 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1476.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     9 runs   (    0.30 ms per token,  3325.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    23 tokens (   10.93 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     644.56 ms /     8 runs   (   80.57 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     944.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =      87.78 ms /     1 runs   (   87.78 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     343.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Sherwood Wiegand\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    10 runs   (    0.46 ms per token,  2192.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.77 ms /   154 tokens (    7.54 ms per token,   132.67 tokens per second)\n",
      "llama_print_timings:        eval time =     727.46 ms /     9 runs   (   80.83 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1961.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"628 596 8984\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.60 ms /    15 runs   (    0.44 ms per token,  2272.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.79 ms /    25 tokens (   10.19 ms per token,    98.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.08 ms /    14 runs   (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1472.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     7 runs   (    0.34 ms per token,  2917.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.58 ms /    23 tokens (   11.03 ms per token,    90.70 tokens per second)\n",
      "llama_print_timings:        eval time =     481.05 ms /     6 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     776.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.66 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =      98.71 ms /     1 runs   (   98.71 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =     354.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Zachariah Bradtke\", \"Dr. Leland Bernier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    19 runs   (    0.49 ms per token,  2061.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.20 ms /   163 tokens (    8.47 ms per token,   118.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1430.29 ms /    18 runs   (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2950.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     6 runs   (    0.17 ms per token,  5870.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =     409.56 ms /     5 runs   (   81.91 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     685.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     9 runs   (    0.35 ms per token,  2877.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    23 tokens (   10.89 ms per token,    91.79 tokens per second)\n",
      "llama_print_timings:        eval time =     642.72 ms /     8 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     941.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    11 runs   (    0.39 ms per token,  2556.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =     812.01 ms /    10 runs   (   81.20 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1135.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ike Vandervort\", \"Dr. Felix Rogahn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.11 ms /    18 runs   (    0.62 ms per token,  1619.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.08 ms /   146 tokens (    7.93 ms per token,   126.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1362.81 ms /    17 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2662.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"670 204 0952\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    15 runs   (    0.57 ms per token,  1747.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.69 ms /    25 tokens (   10.11 ms per token,    98.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.51 ms /    14 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1492.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.68 ms /     2 runs   (    0.34 ms per token,  2949.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    23 tokens (   10.93 ms per token,    91.46 tokens per second)\n",
      "llama_print_timings:        eval time =      96.53 ms /     1 runs   (   96.53 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     354.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     8 runs   (    0.38 ms per token,  2658.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.19 ms /    24 tokens (   10.51 ms per token,    95.17 tokens per second)\n",
      "llama_print_timings:        eval time =     563.73 ms /     7 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     857.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Katheryn Cartwright\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    18 runs   (    0.59 ms per token,  1695.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.41 ms /   201 tokens (    8.08 ms per token,   123.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.91 ms /    17 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    3146.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"273 435 3128\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    15 runs   (    0.52 ms per token,  1936.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    25 tokens (   10.20 ms per token,    98.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.23 ms /    14 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1497.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2337.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.58 ms /    23 tokens (   10.98 ms per token,    91.06 tokens per second)\n",
      "llama_print_timings:        eval time =     481.40 ms /     6 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     776.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /     8 runs   (    0.36 ms per token,  2786.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.66 ms /    24 tokens (   10.74 ms per token,    93.15 tokens per second)\n",
      "llama_print_timings:        eval time =     600.90 ms /     7 runs   (   85.84 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     911.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cori Gibson\", \"Dr. Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    16 runs   (    0.36 ms per token,  2797.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.32 ms /   166 tokens (    8.32 ms per token,   120.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.14 ms /    15 runs   (   84.21 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    2731.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"240 282 9218\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    15 runs   (    0.27 ms per token,  3680.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.23 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.75 ms /    14 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1499.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /     9 runs   (    0.30 ms per token,  3338.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.01 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     753.40 ms /     8 runs   (   94.18 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =    1045.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2883.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    24 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =     590.04 ms /     7 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     880.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Glynda Herzog\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    18 runs   (    0.50 ms per token,  1992.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.39 ms /   144 tokens (    8.16 ms per token,   122.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1395.62 ms /    17 runs   (   82.10 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    2709.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"605 634 7934\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    15 runs   (    0.43 ms per token,  2326.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.19 ms /    25 tokens (   10.53 ms per token,    94.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.77 ms /    14 runs   (   83.20 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1523.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"66 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     7 runs   (    0.35 ms per token,  2883.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.86 ms /    23 tokens (   11.30 ms per token,    88.51 tokens per second)\n",
      "llama_print_timings:        eval time =     478.76 ms /     6 runs   (   79.79 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     781.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /     8 runs   (    0.62 ms per token,  1615.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.36 ms /    24 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     572.65 ms /     7 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     886.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lance Murazik\", \"Dr. Santo Schuppe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    18 runs   (    0.24 ms per token,  4229.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.24 ms /   170 tokens (    8.35 ms per token,   119.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1419.37 ms /    17 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    2941.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"800 493 9254\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /    15 runs   (    0.24 ms per token,  4126.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.47 ms /    25 tokens (   10.10 ms per token,    99.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.42 ms /    14 runs   (   78.74 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1415.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     7 runs   (    0.23 ms per token,  4402.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     475.64 ms /     6 runs   (   79.27 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     748.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /    11 runs   (    0.22 ms per token,  4510.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.21 ms /    24 tokens (   10.59 ms per token,    94.41 tokens per second)\n",
      "llama_print_timings:        eval time =     790.33 ms /    10 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1088.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Porfirio Padberg\", \"Araceli Willms\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.07 ms /    18 runs   (    0.28 ms per token,  3550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.46 ms /   164 tokens (    8.37 ms per token,   119.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.66 ms /    17 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    2796.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"610 291 2355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    15 runs   (    0.14 ms per token,  6970.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.35 ms /    14 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1442.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     9 runs   (    0.15 ms per token,  6859.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.43 ms /    23 tokens (   11.15 ms per token,    89.69 tokens per second)\n",
      "llama_print_timings:        eval time =     641.90 ms /     8 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     923.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"limited social contact\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     6 runs   (    0.14 ms per token,  7083.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.72 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =     412.93 ms /     5 runs   (   82.59 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     677.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Maye Braun\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /    16 runs   (    0.18 ms per token,  5521.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.73 ms /   177 tokens (    7.93 ms per token,   126.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.75 ms /    15 runs   (   80.05 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2657.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 789 1414\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    15 runs   (    0.25 ms per token,  4065.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.14 ms /    25 tokens (   10.05 ms per token,    99.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.20 ms /    14 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1429.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4947.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.56 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =     464.69 ms /     6 runs   (   77.45 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =     743.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.11 ms /     8 runs   (    0.14 ms per token,  7181.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.73 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =     560.89 ms /     7 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     834.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ada Boyle\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     7 runs   (    0.17 ms per token,  5804.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.28 ms /   135 tokens (    8.45 ms per token,   118.29 tokens per second)\n",
      "llama_print_timings:        eval time =     470.10 ms /     6 runs   (   78.35 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1634.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 425 3316\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    15 runs   (    0.13 ms per token,  7692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.22 ms /    25 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.05 ms /    14 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1427.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     8 runs   (    0.17 ms per token,  5904.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     557.71 ms /     7 runs   (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     838.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Seasonal Allergic Rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    12 runs   (    0.18 ms per token,  5558.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     886.53 ms /    11 runs   (   80.59 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1183.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Winston Mertz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /    11 runs   (    0.10 ms per token,  9623.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.82 ms /   142 tokens (    8.07 ms per token,   123.93 tokens per second)\n",
      "llama_print_timings:        eval time =     804.24 ms /    10 runs   (   80.42 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1972.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"469 615 8678\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    15 runs   (    0.13 ms per token,  7462.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    25 tokens (   10.02 ms per token,    99.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.22 ms /    14 runs   (   81.73 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1438.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     9 runs   (    0.19 ms per token,  5402.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    23 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =     753.63 ms /     8 runs   (   94.20 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =    1090.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /     8 runs   (    0.30 ms per token,  3381.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =     571.69 ms /     7 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     862.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Morton Huel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     9 runs   (    0.46 ms per token,  2151.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.92 ms /   140 tokens (    8.26 ms per token,   121.12 tokens per second)\n",
      "llama_print_timings:        eval time =     633.60 ms /     8 runs   (   79.20 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1859.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"475 131 0281\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    15 runs   (    0.26 ms per token,  3814.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.53 ms /    14 runs   (   81.04 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1457.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /     7 runs   (    0.18 ms per token,  5542.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.05 ms /    23 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =     493.49 ms /     6 runs   (   82.25 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     771.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3833.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    24 tokens (   10.53 ms per token,    94.94 tokens per second)\n",
      "llama_print_timings:        eval time =     559.78 ms /     7 runs   (   79.97 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     845.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Taylor Larkin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3831.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.83 ms /   164 tokens (    8.43 ms per token,   118.68 tokens per second)\n",
      "llama_print_timings:        eval time =     566.02 ms /     7 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1981.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 838 7356\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    15 runs   (    0.56 ms per token,  1779.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.93 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.02 ms /    14 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1475.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.45 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =      83.41 ms /     1 runs   (   83.41 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     341.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.11 ms /    24 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =      93.14 ms /     1 runs   (   93.14 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =     351.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Olivia Price\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /     7 runs   (    0.42 ms per token,  2376.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.94 ms /   135 tokens (    8.52 ms per token,   117.40 tokens per second)\n",
      "llama_print_timings:        eval time =     480.70 ms /     6 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1672.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 401 6027\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    15 runs   (    0.52 ms per token,  1936.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.98 ms /    25 tokens (   10.16 ms per token,    98.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.71 ms /    14 runs   (   79.34 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1474.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2352.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.62 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     634.55 ms /     8 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     948.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     8 runs   (    0.29 ms per token,  3488.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    24 tokens (   10.48 ms per token,    95.42 tokens per second)\n",
      "llama_print_timings:        eval time =     562.19 ms /     7 runs   (   80.31 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     851.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jesus Skiles\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     8 runs   (    0.14 ms per token,  6914.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2183.58 ms /   258 tokens (    8.46 ms per token,   118.15 tokens per second)\n",
      "llama_print_timings:        eval time =     590.82 ms /     7 runs   (   84.40 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    2795.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 279 9757\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    15 runs   (    0.15 ms per token,  6573.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.37 ms /    25 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.82 ms /    14 runs   (   83.84 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1470.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.21 ms /    23 tokens (   11.05 ms per token,    90.48 tokens per second)\n",
      "llama_print_timings:        eval time =      87.73 ms /     1 runs   (   87.73 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     345.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.10 ms /    24 tokens (   10.59 ms per token,    94.45 tokens per second)\n",
      "llama_print_timings:        eval time =     100.17 ms /     1 runs   (  100.17 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =     358.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Indira Gleason\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    15 runs   (    0.14 ms per token,  6950.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.53 ms /   163 tokens (    8.55 ms per token,   116.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.28 ms /    14 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    2565.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"611 901 5518\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    15 runs   (    0.12 ms per token,  8116.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.63 ms /    25 tokens (   10.15 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.08 ms /    14 runs   (   83.01 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1447.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     7 runs   (    0.13 ms per token,  7726.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.27 ms /    23 tokens (   10.84 ms per token,    92.27 tokens per second)\n",
      "llama_print_timings:        eval time =     504.31 ms /     6 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     767.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     8 runs   (    0.13 ms per token,  7960.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     590.77 ms /     7 runs   (   84.40 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     858.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rhona Dach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /    10 runs   (    0.13 ms per token,  7633.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.49 ms /   136 tokens (    8.42 ms per token,   118.73 tokens per second)\n",
      "llama_print_timings:        eval time =     743.63 ms /     9 runs   (   82.63 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1912.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 774 5914\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /    15 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.09 ms /    25 tokens (   10.04 ms per token,    99.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.42 ms /    14 runs   (   81.17 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1436.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     7 runs   (    0.11 ms per token,  9497.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.12 ms /    23 tokens (   10.92 ms per token,    91.59 tokens per second)\n",
      "llama_print_timings:        eval time =     500.61 ms /     6 runs   (   83.44 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     771.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial Allergic Rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /    12 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.64 ms /    24 tokens (   10.40 ms per token,    96.14 tokens per second)\n",
      "llama_print_timings:        eval time =     898.48 ms /    11 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1174.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Porfirio Baumbach\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    19 runs   (    0.16 ms per token,  6260.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.34 ms /   153 tokens (    7.57 ms per token,   132.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1451.63 ms /    18 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2670.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"475 345 9029\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /    15 runs   (    0.11 ms per token,  8875.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.63 ms /    25 tokens (   10.11 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.01 ms /    14 runs   (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1449.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     7 runs   (    0.10 ms per token,  9915.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.55 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     490.03 ms /     6 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     755.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     8 runs   (    0.13 ms per token,  7692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.08 ms /    24 tokens (   10.54 ms per token,    94.83 tokens per second)\n",
      "llama_print_timings:        eval time =     574.00 ms /     7 runs   (   82.00 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     849.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Nicolas Roob JD\", \"Doctor Lynsey Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    21 runs   (    0.12 ms per token,  8120.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.30 ms /   181 tokens (    7.78 ms per token,   128.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1619.98 ms /    20 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    3080.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"568 257 6677\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    15 runs   (    0.15 ms per token,  6796.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.16 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.99 ms /    14 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1430.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     7 runs   (    0.15 ms per token,  6505.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     490.58 ms /     6 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     762.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9478.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.13 ms /    24 tokens (   10.59 ms per token,    94.44 tokens per second)\n",
      "llama_print_timings:        eval time =      81.57 ms /     1 runs   (   81.57 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     339.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Burton Bartell\", \"Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /    16 runs   (    0.31 ms per token,  3273.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.13 ms /   152 tokens (    7.60 ms per token,   131.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.09 ms /    15 runs   (   77.61 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2406.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 377 329 0956\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    19 runs   (    0.30 ms per token,  3300.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.03 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1396.85 ms /    18 runs   (   77.60 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    1743.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     7 runs   (    0.25 ms per token,  3928.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     466.63 ms /     6 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =     746.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     8 runs   (    0.30 ms per token,  3351.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    24 tokens (   10.46 ms per token,    95.61 tokens per second)\n",
      "llama_print_timings:        eval time =     551.49 ms /     7 runs   (   78.78 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     840.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Elsie Walker\", \"Doctor Nikia Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    17 runs   (    0.28 ms per token,  3598.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.26 ms /   146 tokens (    7.87 ms per token,   127.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.53 ms /    16 runs   (   77.03 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =    2477.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"302 827 9594\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    15 runs   (    0.25 ms per token,  4045.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.53 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.88 ms /    14 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1420.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     9 runs   (    0.24 ms per token,  4141.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.47 ms /    23 tokens (   10.85 ms per token,    92.20 tokens per second)\n",
      "llama_print_timings:        eval time =     617.43 ms /     8 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =     909.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     8 runs   (    0.32 ms per token,  3174.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =     548.13 ms /     7 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     845.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Suzy Buckridge\", \"Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    17 runs   (    0.25 ms per token,  3942.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.82 ms /   188 tokens (    7.41 ms per token,   134.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1236.30 ms /    16 runs   (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    2717.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"929 309 1198\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    15 runs   (    0.27 ms per token,  3720.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.61 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.83 ms /    14 runs   (   78.27 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1421.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     9 runs   (    0.24 ms per token,  4090.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =     619.45 ms /     8 runs   (   77.43 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =     914.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.01 ms /    24 tokens (   10.42 ms per token,    95.99 tokens per second)\n",
      "llama_print_timings:        eval time =      92.39 ms /     1 runs   (   92.39 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =     346.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Brandie McClure\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    11 runs   (    0.32 ms per token,  3148.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.46 ms /   165 tokens (    8.31 ms per token,   120.31 tokens per second)\n",
      "llama_print_timings:        eval time =     770.73 ms /    10 runs   (   77.07 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    2196.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"820 447 5749\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    15 runs   (    0.28 ms per token,  3573.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.03 ms /    14 runs   (   77.57 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    1415.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     7 runs   (    0.28 ms per token,  3530.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.72 ms /    23 tokens (   10.86 ms per token,    92.10 tokens per second)\n",
      "llama_print_timings:        eval time =     466.22 ms /     6 runs   (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =     744.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.27 ms per token,  3649.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =      89.65 ms /     1 runs   (   89.65 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     353.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Karl Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     9 runs   (    0.28 ms per token,  3522.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.05 ms /   159 tokens (    7.28 ms per token,   137.30 tokens per second)\n",
      "llama_print_timings:        eval time =     617.43 ms /     8 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1824.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"577 678 0732\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    15 runs   (    0.26 ms per token,  3824.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.15 ms /    25 tokens (   10.09 ms per token,    99.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.78 ms /    14 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1414.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     9 runs   (    0.22 ms per token,  4522.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.62 ms /    23 tokens (   10.85 ms per token,    92.14 tokens per second)\n",
      "llama_print_timings:        eval time =     635.45 ms /     8 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     928.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     8 runs   (    0.22 ms per token,  4581.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.63 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =     550.59 ms /     7 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     836.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Benton Senger\", \"Dr. Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    17 runs   (    0.30 ms per token,  3312.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.65 ms /   176 tokens (    7.83 ms per token,   127.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.85 ms /    16 runs   (   77.68 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2710.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"135 709 0568\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    15 runs   (    0.31 ms per token,  3176.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.61 ms /    14 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1419.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     9 runs   (    0.34 ms per token,  2940.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    23 tokens (   10.88 ms per token,    91.90 tokens per second)\n",
      "llama_print_timings:        eval time =     618.60 ms /     8 runs   (   77.33 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =     913.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6472.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =      93.56 ms /     1 runs   (   93.56 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =     350.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jules Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /     6 runs   (    0.20 ms per token,  5067.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.81 ms /   161 tokens (    8.50 ms per token,   117.62 tokens per second)\n",
      "llama_print_timings:        eval time =     389.61 ms /     5 runs   (   77.92 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1780.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 905 1902\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    15 runs   (    0.30 ms per token,  3377.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.97 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.58 ms /    14 runs   (   77.76 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1420.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5681.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =      82.80 ms /     1 runs   (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     338.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6756.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.04 ms /    24 tokens (   10.79 ms per token,    92.65 tokens per second)\n",
      "llama_print_timings:        eval time =      88.51 ms /     1 runs   (   88.51 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =     353.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     8 runs   (    0.24 ms per token,  4228.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1636.39 ms /   220 tokens (    7.44 ms per token,   134.44 tokens per second)\n",
      "llama_print_timings:        eval time =     549.06 ms /     7 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    2224.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"328 107 1355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    15 runs   (    0.30 ms per token,  3348.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.25 ms /    25 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.91 ms /    14 runs   (   78.71 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1434.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     7 runs   (    0.22 ms per token,  4519.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.07 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     469.97 ms /     6 runs   (   78.33 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     752.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    24 tokens (   10.49 ms per token,    95.33 tokens per second)\n",
      "llama_print_timings:        eval time =      92.33 ms /     1 runs   (   92.33 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     348.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Darleen McKenzie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    12 runs   (    0.28 ms per token,  3519.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.80 ms /   168 tokens (    8.18 ms per token,   122.20 tokens per second)\n",
      "llama_print_timings:        eval time =     855.41 ms /    11 runs   (   77.76 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2291.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"201 948 3639\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    15 runs   (    0.28 ms per token,  3554.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    25 tokens (   10.07 ms per token,    99.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.71 ms /    14 runs   (   78.62 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1428.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     9 runs   (    0.28 ms per token,  3574.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     632.07 ms /     8 runs   (   79.01 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     925.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /    11 runs   (    0.26 ms per token,  3877.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.77 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =     793.51 ms /    10 runs   (   79.35 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1097.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Jeanie Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /    10 runs   (    0.32 ms per token,  3145.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.20 ms /   155 tokens (    7.46 ms per token,   134.06 tokens per second)\n",
      "llama_print_timings:        eval time =     703.54 ms /     9 runs   (   78.17 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1911.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 786 262 0169\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    19 runs   (    0.33 ms per token,  3053.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.99 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1416.04 ms /    18 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1771.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     9 runs   (    0.28 ms per token,  3567.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     631.64 ms /     8 runs   (   78.96 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     926.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     8 runs   (    0.26 ms per token,  3894.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    24 tokens (   10.49 ms per token,    95.36 tokens per second)\n",
      "llama_print_timings:        eval time =     548.41 ms /     7 runs   (   78.34 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     838.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lorine Koepp\", \"Dr. Shonna Feest\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    19 runs   (    0.32 ms per token,  3147.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.99 ms /   158 tokens (    7.34 ms per token,   136.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1393.46 ms /    18 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    2670.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"583 562 7321\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    15 runs   (    0.28 ms per token,  3551.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.75 ms /    14 runs   (   78.84 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1435.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"106-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    10 runs   (    0.22 ms per token,  4557.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.73 ms /    23 tokens (   10.86 ms per token,    92.10 tokens per second)\n",
      "llama_print_timings:        eval time =     700.54 ms /     9 runs   (   77.84 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     995.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    11 runs   (    0.29 ms per token,  3415.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =     787.77 ms /    10 runs   (   78.78 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1104.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Marcelene Breitenberg\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    19 runs   (    0.32 ms per token,  3077.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.85 ms /   175 tokens (    7.87 ms per token,   127.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1410.70 ms /    18 runs   (   78.37 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    2898.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"463 501 2520\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    15 runs   (    0.30 ms per token,  3357.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.56 ms /    14 runs   (   78.83 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1439.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     5 runs   (    0.18 ms per token,  5537.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     314.41 ms /     4 runs   (   78.60 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =     582.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     9 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =     630.42 ms /     8 runs   (   78.80 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     934.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rene Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     7 runs   (    0.29 ms per token,  3434.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.87 ms /   153 tokens (    7.55 ms per token,   132.37 tokens per second)\n",
      "llama_print_timings:        eval time =     470.30 ms /     6 runs   (   78.38 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1665.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 465 5902\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    15 runs   (    0.35 ms per token,  2867.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.11 ms /    25 tokens (   10.16 ms per token,    98.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.47 ms /    14 runs   (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1449.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     8 runs   (    0.30 ms per token,  3337.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     549.03 ms /     7 runs   (   78.43 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     836.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.29 ms /    24 tokens (   10.47 ms per token,    95.51 tokens per second)\n",
      "llama_print_timings:        eval time =      91.32 ms /     1 runs   (   91.32 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     354.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Orlando McDermott\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    20 runs   (    0.31 ms per token,  3236.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.34 ms /   177 tokens (    7.82 ms per token,   127.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1489.32 ms /    19 runs   (   78.39 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    2983.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"707 964 6957\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    15 runs   (    0.30 ms per token,  3309.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.09 ms /    25 tokens (   10.08 ms per token,    99.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.79 ms /    14 runs   (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1425.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7968.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =      83.16 ms /     1 runs   (   83.16 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     338.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     8 runs   (    0.27 ms per token,  3717.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.33 ms /    24 tokens (   10.43 ms per token,    95.87 tokens per second)\n",
      "llama_print_timings:        eval time =     548.69 ms /     7 runs   (   78.38 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     844.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rich Boehm\", \"Dr. Ramiro Anderson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    16 runs   (    0.33 ms per token,  3018.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.60 ms /   164 tokens (    8.38 ms per token,   119.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.94 ms /    15 runs   (   77.86 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    2627.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"682 912 2064\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    15 runs   (    0.30 ms per token,  3382.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.67 ms /    14 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1426.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     9 runs   (    0.34 ms per token,  2933.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.93 ms /    23 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =     626.53 ms /     8 runs   (   78.32 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =     924.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5797.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.59 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =      84.26 ms /     1 runs   (   84.26 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     340.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jon O'Hara\", \"Dr. Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    19 runs   (    0.31 ms per token,  3184.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2901.81 ms /   383 tokens (    7.58 ms per token,   131.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.56 ms /    18 runs   (   80.03 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    4455.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"352 971 6948\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    15 runs   (    0.27 ms per token,  3742.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.82 ms /    25 tokens (   10.27 ms per token,    97.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.90 ms /    14 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1462.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     9 runs   (    0.24 ms per token,  4122.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.68 ms /    23 tokens (   11.07 ms per token,    90.31 tokens per second)\n",
      "llama_print_timings:        eval time =     638.14 ms /     8 runs   (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     939.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /    11 runs   (    0.25 ms per token,  3981.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.86 ms /    24 tokens (   10.62 ms per token,    94.17 tokens per second)\n",
      "llama_print_timings:        eval time =     807.33 ms /    10 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1120.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Zandra Price\", \"Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    15 runs   (    0.26 ms per token,  3829.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.21 ms /   197 tokens (    8.22 ms per token,   121.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.71 ms /    14 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    2787.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"239 628 8663\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    15 runs   (    0.29 ms per token,  3470.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.22 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.71 ms /    14 runs   (   77.98 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1427.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4701.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     466.91 ms /     6 runs   (   77.82 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     745.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8771.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =      92.97 ms /     1 runs   (   92.97 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     349.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Brett Kertzmann\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    20 runs   (    0.26 ms per token,  3789.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.36 ms /   183 tokens (    7.60 ms per token,   131.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1478.03 ms /    19 runs   (   77.79 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    2977.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"123 543 6862\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    15 runs   (    0.26 ms per token,  3829.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.80 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.35 ms /    14 runs   (   78.03 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1423.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35-year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     8 runs   (    0.22 ms per token,  4542.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     547.49 ms /     7 runs   (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =     833.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     8 runs   (    0.26 ms per token,  3891.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.66 ms /    24 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =     552.93 ms /     7 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     838.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Christopher Beatty\", \"Lynsey Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    14 runs   (    0.30 ms per token,  3346.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.30 ms /   158 tokens (    7.33 ms per token,   136.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.38 ms /    13 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2245.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 816 3286\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    15 runs   (    0.32 ms per token,  3103.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.81 ms /    25 tokens (   10.07 ms per token,    99.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1086.55 ms /    14 runs   (   77.61 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    1415.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7633.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.57 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =      83.60 ms /     1 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     338.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /     8 runs   (    0.37 ms per token,  2735.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =     551.07 ms /     7 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     850.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Josue Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     8 runs   (    0.28 ms per token,  3618.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.64 ms /   167 tokens (    8.23 ms per token,   121.57 tokens per second)\n",
      "llama_print_timings:        eval time =     549.76 ms /     7 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1958.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"827 518 7321\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    15 runs   (    0.32 ms per token,  3132.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.16 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.12 ms /    14 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1427.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6191.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.38 ms /    23 tokens (   10.89 ms per token,    91.86 tokens per second)\n",
      "llama_print_timings:        eval time =      83.85 ms /     1 runs   (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     338.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     8 runs   (    0.33 ms per token,  3001.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    24 tokens (   10.42 ms per token,    95.93 tokens per second)\n",
      "llama_print_timings:        eval time =     551.64 ms /     7 runs   (   78.81 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     844.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Larissa Reilly\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     7 runs   (    0.32 ms per token,  3089.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2446.72 ms /   311 tokens (    7.87 ms per token,   127.11 tokens per second)\n",
      "llama_print_timings:        eval time =     475.48 ms /     6 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2964.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 682 0728\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /    15 runs   (    0.34 ms per token,  2970.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    25 tokens (   10.21 ms per token,    97.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.94 ms /    14 runs   (   79.42 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1453.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"aged 0\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     6 runs   (    0.20 ms per token,  4885.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.92 ms /    23 tokens (   11.00 ms per token,    90.94 tokens per second)\n",
      "llama_print_timings:        eval time =     397.21 ms /     5 runs   (   79.44 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     673.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     8 runs   (    0.17 ms per token,  5835.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.08 ms /    24 tokens (   10.59 ms per token,    94.46 tokens per second)\n",
      "llama_print_timings:        eval time =     567.00 ms /     7 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     849.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jene Hahn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3482.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.68 ms /   168 tokens (    8.18 ms per token,   122.30 tokens per second)\n",
      "llama_print_timings:        eval time =     468.33 ms /     6 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1874.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 459 9284\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    15 runs   (    0.35 ms per token,  2843.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    25 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.38 ms /    14 runs   (   77.67 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1425.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6230.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =      83.17 ms /     1 runs   (   83.17 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     338.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     8 runs   (    0.24 ms per token,  4188.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =     555.47 ms /     7 runs   (   79.35 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     842.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ross Koss\", \"Dr Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    13 runs   (    0.26 ms per token,  3816.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.37 ms /   179 tokens (    7.75 ms per token,   129.11 tokens per second)\n",
      "llama_print_timings:        eval time =     932.13 ms /    12 runs   (   77.68 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2387.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 932 9100\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    15 runs   (    0.31 ms per token,  3235.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.84 ms /    14 runs   (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1429.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     6 runs   (    0.22 ms per token,  4604.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.84 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     392.10 ms /     5 runs   (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     664.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.35 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =      83.92 ms /     1 runs   (   83.92 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     339.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hailey Bechtelar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    12 runs   (    0.28 ms per token,  3618.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2106.62 ms /   268 tokens (    7.86 ms per token,   127.22 tokens per second)\n",
      "llama_print_timings:        eval time =     869.32 ms /    11 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    3042.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"281 408 8768\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /    15 runs   (    0.27 ms per token,  3735.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.52 ms /    25 tokens (   10.18 ms per token,    98.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.55 ms /    14 runs   (   79.68 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1441.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     7 runs   (    0.20 ms per token,  4968.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.52 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     478.65 ms /     6 runs   (   79.77 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =     763.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    24 tokens (   10.54 ms per token,    94.84 tokens per second)\n",
      "llama_print_timings:        eval time =      99.90 ms /     1 runs   (   99.90 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =     358.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Daron Daugherty\", \"Carson Krajcik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    17 runs   (    0.30 ms per token,  3373.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.84 ms /   146 tokens (    7.87 ms per token,   127.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.72 ms /    16 runs   (   77.48 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    2492.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 153 0806\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    15 runs   (    0.29 ms per token,  3433.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    25 tokens (   10.06 ms per token,    99.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.23 ms /    14 runs   (   77.87 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1418.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     6 runs   (    0.23 ms per token,  4264.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     388.14 ms /     5 runs   (   77.63 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =     662.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8032.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.19 ms /    24 tokens (   10.42 ms per token,    95.93 tokens per second)\n",
      "llama_print_timings:        eval time =      93.41 ms /     1 runs   (   93.41 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     348.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Janise Ratke\", \"Dr. Hellen Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    14 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.16 ms /   175 tokens (    7.92 ms per token,   126.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.65 ms /    13 runs   (   86.36 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    2543.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 616 8644\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    15 runs   (    0.49 ms per token,  2022.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.54 ms /    25 tokens (   10.62 ms per token,    94.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.35 ms /    14 runs   (   86.95 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1602.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2883.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.24 ms /    23 tokens (   10.92 ms per token,    91.55 tokens per second)\n",
      "llama_print_timings:        eval time =     669.20 ms /     7 runs   (   95.60 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =     968.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    12 runs   (    0.29 ms per token,  3406.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.29 ms /    24 tokens (   10.68 ms per token,    93.65 tokens per second)\n",
      "llama_print_timings:        eval time =     935.08 ms /    11 runs   (   85.01 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    1251.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Simon Murray\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     6 runs   (    0.34 ms per token,  2964.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.75 ms /   142 tokens (    8.20 ms per token,   122.02 tokens per second)\n",
      "llama_print_timings:        eval time =     439.01 ms /     5 runs   (   87.80 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    1637.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"116 526 3361\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    15 runs   (    0.38 ms per token,  2663.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.96 ms /    25 tokens (   10.32 ms per token,    96.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.40 ms /    14 runs   (   86.60 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    1560.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     7 runs   (    0.31 ms per token,  3224.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.94 ms /    23 tokens (   11.00 ms per token,    90.93 tokens per second)\n",
      "llama_print_timings:        eval time =     501.81 ms /     6 runs   (   83.64 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     784.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     9 runs   (    0.30 ms per token,  3301.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.09 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =     718.01 ms /     8 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =    1015.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shayne Kautzer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    11 runs   (    0.36 ms per token,  2747.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.69 ms /   137 tokens (    8.41 ms per token,   118.96 tokens per second)\n",
      "llama_print_timings:        eval time =     798.64 ms /    10 runs   (   79.86 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2016.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"171 539 8948\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    15 runs   (    0.32 ms per token,  3095.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.96 ms /    14 runs   (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1479.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     7 runs   (    0.46 ms per token,  2186.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.17 ms /    23 tokens (   11.22 ms per token,    89.09 tokens per second)\n",
      "llama_print_timings:        eval time =     506.55 ms /     6 runs   (   84.42 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     800.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8771.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    24 tokens (   10.51 ms per token,    95.17 tokens per second)\n",
      "llama_print_timings:        eval time =      85.20 ms /     1 runs   (   85.20 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     342.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lorina Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     8 runs   (    0.14 ms per token,  7054.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.60 ms /   166 tokens (    8.34 ms per token,   119.89 tokens per second)\n",
      "llama_print_timings:        eval time =     602.63 ms /     7 runs   (   86.09 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    2029.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 928 5491\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    15 runs   (    0.32 ms per token,  3110.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    25 tokens (   10.15 ms per token,    98.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.51 ms /    14 runs   (   77.89 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1426.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6410.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =      83.19 ms /     1 runs   (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     338.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     7 runs   (    0.23 ms per token,  4278.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     467.82 ms /     6 runs   (   77.97 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     746.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Tommie Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    10 runs   (    0.25 ms per token,  4030.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.26 ms /   161 tokens (    8.50 ms per token,   117.58 tokens per second)\n",
      "llama_print_timings:        eval time =     709.90 ms /     9 runs   (   78.88 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    2127.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"586 958 0089\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /    15 runs   (    0.25 ms per token,  3969.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.73 ms /    14 runs   (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1436.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.66 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =      85.73 ms /     1 runs   (   85.73 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     340.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =      87.99 ms /     1 runs   (   87.99 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =     341.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Emilee O'Keefe\", \"Dr.\", \"Rolande Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    24 runs   (    0.25 ms per token,  3933.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.27 ms /   142 tokens (    8.06 ms per token,   124.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1814.72 ms /    23 runs   (   78.90 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    3075.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"900 402 3742\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    15 runs   (    0.32 ms per token,  3110.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.72 ms /    14 runs   (   79.05 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1434.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /     6 runs   (    0.18 ms per token,  5484.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.31 ms /    23 tokens (   10.84 ms per token,    92.25 tokens per second)\n",
      "llama_print_timings:        eval time =     389.22 ms /     5 runs   (   77.84 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     659.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9216.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.48 ms /    24 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =      86.48 ms /     1 runs   (   86.48 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     372.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Twana Cummings\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     8 runs   (    0.16 ms per token,  6206.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.61 ms /   168 tokens (    8.19 ms per token,   122.13 tokens per second)\n",
      "llama_print_timings:        eval time =     581.90 ms /     7 runs   (   83.13 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    1982.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 791 1432\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    15 runs   (    0.29 ms per token,  3444.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.96 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.98 ms /    14 runs   (   86.07 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1541.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /     7 runs   (    0.35 ms per token,  2857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.45 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =     490.11 ms /     6 runs   (   81.69 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     776.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.79 ms /    24 tokens (   10.53 ms per token,    94.94 tokens per second)\n",
      "llama_print_timings:        eval time =     103.41 ms /     1 runs   (  103.41 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     361.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Venita Ondricka\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    12 runs   (    0.46 ms per token,  2197.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1437.66 ms /   184 tokens (    7.81 ms per token,   127.99 tokens per second)\n",
      "llama_print_timings:        eval time =     925.88 ms /    11 runs   (   84.17 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    2450.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"519 417 5455\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    25 tokens (   10.21 ms per token,    97.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.78 ms /    14 runs   (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1507.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9090.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.45 ms /    23 tokens (   11.15 ms per token,    89.69 tokens per second)\n",
      "llama_print_timings:        eval time =      88.70 ms /     1 runs   (   88.70 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     349.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    11 runs   (    0.48 ms per token,  2070.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.17 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =     833.62 ms /    10 runs   (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1158.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Malcolm Cremin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    10 runs   (    0.51 ms per token,  1976.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.60 ms /   149 tokens (    7.84 ms per token,   127.61 tokens per second)\n",
      "llama_print_timings:        eval time =     756.80 ms /     9 runs   (   84.09 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1999.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"671 829 5912\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2280.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.37 ms /    14 runs   (   84.95 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1546.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     7 runs   (    0.24 ms per token,  4161.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     524.94 ms /     6 runs   (   87.49 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     802.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.48 ms /    24 tokens (   10.52 ms per token,    95.06 tokens per second)\n",
      "llama_print_timings:        eval time =     109.78 ms /     1 runs   (  109.78 ms per token,     9.11 tokens per second)\n",
      "llama_print_timings:       total time =     368.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Elizabet Harris\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    11 runs   (    0.37 ms per token,  2730.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3120.98 ms /   399 tokens (    7.82 ms per token,   127.84 tokens per second)\n",
      "llama_print_timings:        eval time =     924.83 ms /    10 runs   (   92.48 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =    4121.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"746 183 7848\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    15 runs   (    0.42 ms per token,  2408.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     280.14 ms /    25 tokens (   11.21 ms per token,    89.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.91 ms /    14 runs   (   93.71 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    1682.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2611.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.23 ms /    23 tokens (   11.79 ms per token,    84.80 tokens per second)\n",
      "llama_print_timings:        eval time =     717.08 ms /     8 runs   (   89.64 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1043.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /     8 runs   (    0.29 ms per token,  3466.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.67 ms /    24 tokens (   11.36 ms per token,    88.02 tokens per second)\n",
      "llama_print_timings:        eval time =     652.10 ms /     7 runs   (   93.16 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =     972.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lance Cummerata\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    18 runs   (    0.35 ms per token,  2887.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1225.86 ms /   147 tokens (    8.34 ms per token,   119.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1520.23 ms /    17 runs   (   89.43 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    2859.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"394 149 7885\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    15 runs   (    0.48 ms per token,  2093.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.15 ms /    25 tokens (   11.09 ms per token,    90.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.49 ms /    14 runs   (   94.75 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =    1706.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /     9 runs   (    0.36 ms per token,  2794.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.51 ms /    23 tokens (   11.89 ms per token,    84.09 tokens per second)\n",
      "llama_print_timings:        eval time =     726.37 ms /     8 runs   (   90.80 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    1054.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     271.45 ms /    24 tokens (   11.31 ms per token,    88.41 tokens per second)\n",
      "llama_print_timings:        eval time =     111.98 ms /     1 runs   (  111.98 ms per token,     8.93 tokens per second)\n",
      "llama_print_timings:       total time =     415.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jennell Gislason\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    19 runs   (    0.41 ms per token,  2416.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.74 ms /   165 tokens (    9.14 ms per token,   109.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1706.01 ms /    18 runs   (   94.78 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =    3350.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"514 449 5507\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    15 runs   (    0.40 ms per token,  2524.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.09 ms /    25 tokens (   11.12 ms per token,    89.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.10 ms /    14 runs   (   94.72 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =    1697.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     7 runs   (    0.35 ms per token,  2824.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     279.67 ms /    23 tokens (   12.16 ms per token,    82.24 tokens per second)\n",
      "llama_print_timings:        eval time =     576.97 ms /     6 runs   (   96.16 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =     900.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    18 runs   (    0.37 ms per token,  2708.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.21 ms /    24 tokens (   11.72 ms per token,    85.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1631.23 ms /    17 runs   (   95.95 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =    2030.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rupert Gottlieb\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    18 runs   (    0.37 ms per token,  2698.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1507.27 ms /   175 tokens (    8.61 ms per token,   116.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1595.84 ms /    17 runs   (   93.87 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =    3232.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 632 0683\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2358.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.85 ms /    25 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1306.56 ms /    14 runs   (   93.33 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =    1703.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3653.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.12 ms /    23 tokens (   11.87 ms per token,    84.21 tokens per second)\n",
      "llama_print_timings:        eval time =     570.98 ms /     6 runs   (   95.16 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =     880.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.82 ms /    24 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     105.37 ms /     1 runs   (  105.37 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =     373.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Trinidad Kuhic\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    20 runs   (    0.35 ms per token,  2829.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.25 ms /   167 tokens (    8.50 ms per token,   117.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1628.75 ms /    19 runs   (   85.72 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    3175.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"294 983 9525\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2687.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.01 ms /    25 tokens (   10.44 ms per token,    95.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1195.22 ms /    14 runs   (   85.37 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =    1550.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     5 runs   (    0.20 ms per token,  4965.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.69 ms /    23 tokens (   11.25 ms per token,    88.91 tokens per second)\n",
      "llama_print_timings:        eval time =     341.07 ms /     4 runs   (   85.27 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     618.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.89 ms /    24 tokens (   10.75 ms per token,    93.06 tokens per second)\n",
      "llama_print_timings:        eval time =     105.80 ms /     1 runs   (  105.80 ms per token,     9.45 tokens per second)\n",
      "llama_print_timings:       total time =     368.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Myles D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     9 runs   (    0.37 ms per token,  2676.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.34 ms /   176 tokens (    8.06 ms per token,   124.00 tokens per second)\n",
      "llama_print_timings:        eval time =     680.40 ms /     8 runs   (   85.05 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    2163.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 614 5654\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2254.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.17 ms /    25 tokens (   10.41 ms per token,    96.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1181.12 ms /    14 runs   (   84.37 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    1533.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     6 runs   (    0.31 ms per token,  3205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.28 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =     418.68 ms /     5 runs   (   83.74 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     704.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9433.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.88 ms /    24 tokens (   10.74 ms per token,    93.07 tokens per second)\n",
      "llama_print_timings:        eval time =     108.65 ms /     1 runs   (  108.65 ms per token,     9.20 tokens per second)\n",
      "llama_print_timings:       total time =     370.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clint Ortiz\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    16 runs   (    0.48 ms per token,  2081.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.05 ms /   153 tokens (    7.77 ms per token,   128.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.50 ms /    15 runs   (   84.23 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    2585.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"521 485 7834\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2105.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.21 ms /    25 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.81 ms /    14 runs   (   85.70 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    1567.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     9 runs   (    0.30 ms per token,  3317.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.41 ms /    23 tokens (   11.28 ms per token,    88.66 tokens per second)\n",
      "llama_print_timings:        eval time =     691.29 ms /     8 runs   (   86.41 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =    1000.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     8 runs   (    0.39 ms per token,  2535.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.47 ms /    24 tokens (   10.77 ms per token,    92.85 tokens per second)\n",
      "llama_print_timings:        eval time =     607.15 ms /     7 runs   (   86.74 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     907.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Louella Hill\", \"Dr. Jarvis Ankunding\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    18 runs   (    0.39 ms per token,  2542.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1700.81 ms /   201 tokens (    8.46 ms per token,   118.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1457.51 ms /    17 runs   (   85.74 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    3286.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"794 972 3849\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    15 runs   (    0.33 ms per token,  3013.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.35 ms /    25 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.75 ms /    14 runs   (   97.77 ms per token,    10.23 tokens per second)\n",
      "llama_print_timings:       total time =    1724.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     293.70 ms /    23 tokens (   12.77 ms per token,    78.31 tokens per second)\n",
      "llama_print_timings:        eval time =     115.66 ms /     1 runs   (  115.66 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =     414.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10471.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     296.16 ms /    24 tokens (   12.34 ms per token,    81.04 tokens per second)\n",
      "llama_print_timings:        eval time =     110.60 ms /     1 runs   (  110.60 ms per token,     9.04 tokens per second)\n",
      "llama_print_timings:       total time =     413.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tiesha Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    11 runs   (    0.40 ms per token,  2492.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1843.51 ms /   212 tokens (    8.70 ms per token,   115.00 tokens per second)\n",
      "llama_print_timings:        eval time =     943.87 ms /    10 runs   (   94.39 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =    2861.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"224 884 5490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    15 runs   (    0.49 ms per token,  2055.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.71 ms /    25 tokens (   11.27 ms per token,    88.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.01 ms /    14 runs   (   93.14 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =    1686.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     7 runs   (    0.29 ms per token,  3451.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     275.72 ms /    23 tokens (   11.99 ms per token,    83.42 tokens per second)\n",
      "llama_print_timings:        eval time =     573.72 ms /     6 runs   (   95.62 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =     887.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     9 runs   (    0.40 ms per token,  2524.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.58 ms /    24 tokens (   11.44 ms per token,    87.41 tokens per second)\n",
      "llama_print_timings:        eval time =     769.37 ms /     8 runs   (   96.17 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =    1097.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ethel Wilkinson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    11 runs   (    0.40 ms per token,  2518.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1245.25 ms /   130 tokens (    9.58 ms per token,   104.40 tokens per second)\n",
      "llama_print_timings:        eval time =     968.00 ms /    10 runs   (   96.80 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =    2305.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"127 618 3053\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    15 runs   (    0.34 ms per token,  2908.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.45 ms /    25 tokens (   11.14 ms per token,    89.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1312.36 ms /    14 runs   (   93.74 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    1699.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     5 runs   (    0.19 ms per token,  5246.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.46 ms /    23 tokens (   11.67 ms per token,    85.67 tokens per second)\n",
      "llama_print_timings:        eval time =     366.54 ms /     4 runs   (   91.64 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     652.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /     8 runs   (    0.34 ms per token,  2980.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.72 ms /    24 tokens (   11.24 ms per token,    88.98 tokens per second)\n",
      "llama_print_timings:        eval time =     654.38 ms /     7 runs   (   93.48 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     967.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rachel Considine\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    19 runs   (    0.38 ms per token,  2665.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1498.53 ms /   171 tokens (    8.76 ms per token,   114.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.76 ms /    18 runs   (   88.99 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    3221.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"654 643 4853\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    15 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.81 ms /    25 tokens (   10.63 ms per token,    94.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1184.69 ms /    14 runs   (   84.62 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =    1542.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     7 runs   (    0.27 ms per token,  3699.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.44 ms /    23 tokens (   11.19 ms per token,    89.34 tokens per second)\n",
      "llama_print_timings:        eval time =     506.94 ms /     6 runs   (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     795.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2679.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.36 ms /    24 tokens (   10.68 ms per token,    93.62 tokens per second)\n",
      "llama_print_timings:        eval time =     842.66 ms /    10 runs   (   84.27 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    1168.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Carmen Frami\", \"Dr. Araceli Willms\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.16 ms /    19 runs   (    0.59 ms per token,  1702.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.41 ms /   204 tokens (    8.07 ms per token,   123.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1426.35 ms /    18 runs   (   79.24 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    3230.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"706 758 8661\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    15 runs   (    0.52 ms per token,  1938.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    25 tokens (   10.14 ms per token,    98.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.42 ms /    14 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1490.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     9 runs   (    0.45 ms per token,  2223.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =     636.80 ms /     8 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     954.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9569.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.75 ms /    24 tokens (   10.57 ms per token,    94.58 tokens per second)\n",
      "llama_print_timings:        eval time =      87.87 ms /     1 runs   (   87.87 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =     347.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lucie Wintheiser\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.60 ms /    19 runs   (    0.51 ms per token,  1980.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.11 ms /   197 tokens (    8.24 ms per token,   121.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1431.31 ms /    18 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    3209.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 796 741 7250\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.23 ms /    19 runs   (    0.54 ms per token,  1856.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.85 ms /    25 tokens (   10.31 ms per token,    96.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1460.02 ms /    18 runs   (   81.11 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1864.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     7 runs   (    0.35 ms per token,  2838.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     477.92 ms /     6 runs   (   79.65 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     770.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     8 runs   (    0.27 ms per token,  3759.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.25 ms /    24 tokens (   10.51 ms per token,    95.14 tokens per second)\n",
      "llama_print_timings:        eval time =     580.97 ms /     7 runs   (   83.00 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     873.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brain Bergnaum\", \"Aja McKenzie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    17 runs   (    0.46 ms per token,  2175.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.76 ms /   190 tokens (    7.40 ms per token,   135.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1310.58 ms /    16 runs   (   81.91 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    2827.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"768 992 2969\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    15 runs   (    0.36 ms per token,  2758.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.36 ms /    25 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.04 ms /    14 runs   (   81.22 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1464.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"25-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /     9 runs   (    0.41 ms per token,  2462.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.31 ms /    23 tokens (   11.14 ms per token,    89.74 tokens per second)\n",
      "llama_print_timings:        eval time =     654.30 ms /     8 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     959.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  4950.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.56 ms /    24 tokens (   10.69 ms per token,    93.55 tokens per second)\n",
      "llama_print_timings:        eval time =     102.25 ms /     1 runs   (  102.25 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     364.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Loan Schaefer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    11 runs   (    0.45 ms per token,  2219.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.42 ms /   168 tokens (    8.28 ms per token,   120.83 tokens per second)\n",
      "llama_print_timings:        eval time =     802.25 ms /    10 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    2267.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"152 405 6650\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    15 runs   (    0.46 ms per token,  2164.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.20 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.09 ms /    14 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1489.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.64 ms /    23 tokens (   10.98 ms per token,    91.04 tokens per second)\n",
      "llama_print_timings:        eval time =      88.20 ms /     1 runs   (   88.20 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =     345.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5714.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.45 ms /    24 tokens (   10.56 ms per token,    94.69 tokens per second)\n",
      "llama_print_timings:        eval time =      91.41 ms /     1 runs   (   91.41 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     349.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Errol McKenzie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    10 runs   (    0.35 ms per token,  2840.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3182.13 ms /   386 tokens (    8.24 ms per token,   121.30 tokens per second)\n",
      "llama_print_timings:        eval time =     745.06 ms /     9 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    3995.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"576 162 0900\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2294.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.04 ms /    25 tokens (   10.36 ms per token,    96.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.61 ms /    14 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1527.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7380.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    23 tokens (   11.13 ms per token,    89.89 tokens per second)\n",
      "llama_print_timings:        eval time =      88.26 ms /     1 runs   (   88.26 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     349.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.96 ms /    24 tokens (   10.67 ms per token,    93.76 tokens per second)\n",
      "llama_print_timings:        eval time =     105.45 ms /     1 runs   (  105.45 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =     366.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Wenona Terry\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    10 runs   (    0.37 ms per token,  2711.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.36 ms /   173 tokens (    8.04 ms per token,   124.34 tokens per second)\n",
      "llama_print_timings:        eval time =     716.00 ms /     9 runs   (   79.56 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2172.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"572 953 6603\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    15 runs   (    0.41 ms per token,  2438.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.46 ms /    25 tokens (   10.22 ms per token,    97.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.26 ms /    14 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1483.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7662.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.83 ms /    23 tokens (   11.04 ms per token,    90.61 tokens per second)\n",
      "llama_print_timings:        eval time =      89.98 ms /     1 runs   (   89.98 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =     348.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /     8 runs   (    0.23 ms per token,  4390.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.61 ms /    24 tokens (   10.65 ms per token,    93.89 tokens per second)\n",
      "llama_print_timings:        eval time =     590.36 ms /     7 runs   (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     881.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Denver Kunde\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     9 runs   (    0.30 ms per token,  3351.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2618.14 ms /   313 tokens (    8.36 ms per token,   119.55 tokens per second)\n",
      "llama_print_timings:        eval time =     818.04 ms /     8 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    3495.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"393 841 1284\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    15 runs   (    0.40 ms per token,  2493.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.07 ms /    25 tokens (   11.28 ms per token,    88.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.71 ms /    14 runs   (   90.27 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1640.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.25 ms /    23 tokens (   11.53 ms per token,    86.71 tokens per second)\n",
      "llama_print_timings:        eval time =      93.71 ms /     1 runs   (   93.71 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     364.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9216.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.14 ms /    24 tokens (   11.17 ms per token,    89.51 tokens per second)\n",
      "llama_print_timings:        eval time =     103.82 ms /     1 runs   (  103.82 ms per token,     9.63 tokens per second)\n",
      "llama_print_timings:       total time =     380.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Charita Kihn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /     7 runs   (    0.25 ms per token,  4074.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1452.62 ms /   180 tokens (    8.07 ms per token,   123.91 tokens per second)\n",
      "llama_print_timings:        eval time =     546.63 ms /     6 runs   (   91.10 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =    2027.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 808 2936\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.27 ms /    15 runs   (    0.35 ms per token,  2847.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.69 ms /    25 tokens (   10.51 ms per token,    95.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1259.95 ms /    14 runs   (   90.00 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    1597.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     9 runs   (    0.28 ms per token,  3557.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.06 ms /    23 tokens (   11.31 ms per token,    88.44 tokens per second)\n",
      "llama_print_timings:        eval time =     649.75 ms /     8 runs   (   81.22 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     958.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10582.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.72 ms /    24 tokens (   10.49 ms per token,    95.34 tokens per second)\n",
      "llama_print_timings:        eval time =      88.94 ms /     1 runs   (   88.94 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =     344.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brigette Prosacco\", \"Doctor Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.56 ms /    19 runs   (    0.50 ms per token,  1986.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.73 ms /   151 tokens (    7.83 ms per token,   127.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.88 ms /    18 runs   (   85.66 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    2869.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"698 642 2180\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    15 runs   (    0.44 ms per token,  2283.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.28 ms /    25 tokens (   10.17 ms per token,    98.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.48 ms /    14 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1488.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.11 ms /     5 runs   (    0.22 ms per token,  4512.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =     328.31 ms /     4 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     602.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     8 runs   (    0.26 ms per token,  3870.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =     571.65 ms /     7 runs   (   81.66 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     871.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms.\", \"Sherill Kerluke\", \"Doctor Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    21 runs   (    0.45 ms per token,  2238.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.06 ms /   152 tokens (    7.71 ms per token,   129.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1646.61 ms /    20 runs   (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2959.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"324 531 8311\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.35 ms /    15 runs   (    0.36 ms per token,  2802.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.77 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.13 ms /    14 runs   (   83.44 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    1520.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /     9 runs   (    0.50 ms per token,  1987.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     647.37 ms /     8 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     951.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.64 ms /    11 runs   (    0.51 ms per token,  1948.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.32 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =     809.64 ms /    10 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1137.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Cassidy Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    12 runs   (    0.41 ms per token,  2464.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.25 ms /   178 tokens (    7.81 ms per token,   128.03 tokens per second)\n",
      "llama_print_timings:        eval time =     871.41 ms /    11 runs   (   79.22 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2341.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"728 373 1589\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    15 runs   (    0.44 ms per token,  2285.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.85 ms /    14 runs   (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1508.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     7 runs   (    0.25 ms per token,  4018.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.27 ms /    23 tokens (   11.06 ms per token,    90.46 tokens per second)\n",
      "llama_print_timings:        eval time =     498.88 ms /     6 runs   (   83.15 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     785.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute Bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     8 runs   (    0.25 ms per token,  4048.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    24 tokens (   10.46 ms per token,    95.59 tokens per second)\n",
      "llama_print_timings:        eval time =     589.13 ms /     7 runs   (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     878.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Sheila Grant\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2511.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.28 ms /   200 tokens (    8.27 ms per token,   120.90 tokens per second)\n",
      "llama_print_timings:        eval time =     650.62 ms /     8 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2358.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"668 492 1524\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    15 runs   (    0.35 ms per token,  2850.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    25 tokens (   10.16 ms per token,    98.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1181.55 ms /    14 runs   (   84.40 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    1514.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /     7 runs   (    0.32 ms per token,  3153.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     491.32 ms /     6 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     783.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     8 runs   (    0.24 ms per token,  4119.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    24 tokens (   10.66 ms per token,    93.79 tokens per second)\n",
      "llama_print_timings:        eval time =     607.01 ms /     7 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     906.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rudolph Ortiz\", \"Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    14 runs   (    0.31 ms per token,  3252.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.80 ms /   166 tokens (    8.35 ms per token,   119.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.90 ms /    13 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    2522.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"161 325 9352\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    15 runs   (    0.35 ms per token,  2833.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.68 ms /    14 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1466.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.76 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =      88.73 ms /     1 runs   (   88.73 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     345.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7518.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.13 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     113.47 ms /     1 runs   (  113.47 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =     368.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Scottie Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /     9 runs   (    0.32 ms per token,  3141.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.94 ms /   185 tokens (    7.62 ms per token,   131.30 tokens per second)\n",
      "llama_print_timings:        eval time =     652.33 ms /     8 runs   (   81.54 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2110.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"236 593 2020\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.03 ms /    15 runs   (    0.34 ms per token,  2982.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.69 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.77 ms /    14 runs   (   82.34 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1489.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.37 ms /     9 runs   (    0.26 ms per token,  3799.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.99 ms /    23 tokens (   11.00 ms per token,    90.91 tokens per second)\n",
      "llama_print_timings:        eval time =     659.06 ms /     8 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     955.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    24 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =      90.21 ms /     1 runs   (   90.21 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     347.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kasandra Stiedemann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    11 runs   (    0.45 ms per token,  2224.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.86 ms /   146 tokens (    7.89 ms per token,   126.75 tokens per second)\n",
      "llama_print_timings:        eval time =     816.05 ms /    10 runs   (   81.60 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    2038.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"431 825 8484\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    15 runs   (    0.53 ms per token,  1876.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.32 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.86 ms /    14 runs   (   80.42 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1493.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /     8 runs   (    0.36 ms per token,  2790.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     559.65 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     852.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     8 runs   (    0.40 ms per token,  2479.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.42 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =     568.75 ms /     7 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     862.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Zackary Wiegand\", \"Dr. Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    18 runs   (    0.41 ms per token,  2433.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.14 ms /   197 tokens (    8.37 ms per token,   119.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1394.17 ms /    17 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    3163.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"156 148 8676\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2358.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.66 ms /    25 tokens (   10.19 ms per token,    98.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.14 ms /    14 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1488.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     9 runs   (    0.40 ms per token,  2469.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.13 ms /    23 tokens (   10.92 ms per token,    91.58 tokens per second)\n",
      "llama_print_timings:        eval time =     648.77 ms /     8 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     956.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"cystitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     6 runs   (    0.29 ms per token,  3409.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =     400.11 ms /     5 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     680.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Barbera McDermott\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    10 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.41 ms /   164 tokens (    8.38 ms per token,   119.32 tokens per second)\n",
      "llama_print_timings:        eval time =     754.66 ms /     9 runs   (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    2165.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 497 9447\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    15 runs   (    0.41 ms per token,  2445.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.98 ms /    25 tokens (   10.28 ms per token,    97.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.32 ms /    14 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1483.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.12 ms /    23 tokens (   10.92 ms per token,    91.59 tokens per second)\n",
      "llama_print_timings:        eval time =      98.43 ms /     1 runs   (   98.43 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =     355.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =      85.25 ms /     1 runs   (   85.25 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     339.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tressa Parisian\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.73 ms /    18 runs   (    0.60 ms per token,  1677.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.90 ms /   165 tokens (    8.34 ms per token,   119.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1342.88 ms /    17 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    2872.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"469 274 5570\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    15 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.68 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.46 ms /    14 runs   (   79.39 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1477.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /     7 runs   (    0.39 ms per token,  2570.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.54 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     473.51 ms /     6 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     758.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6211.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.63 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =     100.31 ms /     1 runs   (  100.31 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     355.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marlin Satterfield\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.93 ms /    16 runs   (    0.37 ms per token,  2696.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.04 ms /   174 tokens (    7.92 ms per token,   126.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.35 ms /    15 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2685.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"192 347 4550\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    15 runs   (    0.34 ms per token,  2977.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.83 ms /    25 tokens (   10.19 ms per token,    98.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.38 ms /    14 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1492.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     7 runs   (    0.30 ms per token,  3341.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.90 ms /    23 tokens (   11.13 ms per token,    89.88 tokens per second)\n",
      "llama_print_timings:        eval time =     482.68 ms /     6 runs   (   80.45 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     773.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     8 runs   (    0.25 ms per token,  3994.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.43 ms /    24 tokens (   10.48 ms per token,    95.45 tokens per second)\n",
      "llama_print_timings:        eval time =     583.14 ms /     7 runs   (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     873.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brice Rosenbaum\", \"Dr. Palmer Kuphal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    17 runs   (    0.39 ms per token,  2533.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.32 ms /   145 tokens (    8.11 ms per token,   123.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1301.82 ms /    16 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2587.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"364 789 1298\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    15 runs   (    0.35 ms per token,  2826.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.79 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.70 ms /    14 runs   (   83.12 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    1502.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"65-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     9 runs   (    0.24 ms per token,  4087.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    23 tokens (   11.09 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =     668.88 ms /     8 runs   (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     964.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /    24 tokens (   10.66 ms per token,    93.83 tokens per second)\n",
      "llama_print_timings:        eval time =      88.02 ms /     1 runs   (   88.02 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =     348.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Leonel Goldner\", \"Dr.\", \"Orville Will\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2505.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.75 ms /   172 tokens (    8.15 ms per token,   122.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1439.24 ms /    17 runs   (   84.66 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    2952.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"433 901 0403\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.56 ms /    15 runs   (    0.37 ms per token,  2696.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.83 ms /    25 tokens (   10.27 ms per token,    97.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.32 ms /    14 runs   (   83.24 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1510.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     7 runs   (    0.30 ms per token,  3309.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.10 ms /    23 tokens (   11.09 ms per token,    90.16 tokens per second)\n",
      "llama_print_timings:        eval time =     513.35 ms /     6 runs   (   85.56 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =     804.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\", \"obesity\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    17 runs   (    0.32 ms per token,  3105.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    24 tokens (   10.49 ms per token,    95.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1347.78 ms /    16 runs   (   84.24 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    1694.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosemary Bahringer\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    21 runs   (    0.41 ms per token,  2411.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.77 ms /   171 tokens (    8.19 ms per token,   122.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1624.91 ms /    20 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    3166.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"819 569 6933\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    15 runs   (    0.54 ms per token,  1838.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.82 ms /    25 tokens (   10.35 ms per token,    96.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.46 ms /    14 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1503.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    23 tokens (   11.13 ms per token,    89.81 tokens per second)\n",
      "llama_print_timings:        eval time =      93.66 ms /     1 runs   (   93.66 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =     355.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.27 ms /     8 runs   (    0.28 ms per token,  3524.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.72 ms /    24 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =     581.16 ms /     7 runs   (   83.02 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     883.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Effie Bogan\", \"Doctor Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2512.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.54 ms /   186 tokens (    7.59 ms per token,   131.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.26 ms /    14 runs   (   81.09 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2632.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 788 5835\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    15 runs   (    0.47 ms per token,  2113.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.34 ms /    25 tokens (   10.29 ms per token,    97.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.54 ms /    14 runs   (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1500.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     8 runs   (    0.36 ms per token,  2759.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.93 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     577.38 ms /     7 runs   (   82.48 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     869.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.88 ms /    24 tokens (   10.74 ms per token,    93.07 tokens per second)\n",
      "llama_print_timings:        eval time =     100.92 ms /     1 runs   (  100.92 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =     364.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Monty Farrell\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     7 runs   (    0.59 ms per token,  1697.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2654.25 ms /   351 tokens (    7.56 ms per token,   132.24 tokens per second)\n",
      "llama_print_timings:        eval time =     487.96 ms /     6 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    3199.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 415 9902\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    15 runs   (    0.54 ms per token,  1864.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.58 ms /    25 tokens (   10.26 ms per token,    97.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.81 ms /    14 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1509.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5952.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.55 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =      95.33 ms /     1 runs   (   95.33 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     355.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     6 runs   (    0.26 ms per token,  3888.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.25 ms /    24 tokens (   10.59 ms per token,    94.40 tokens per second)\n",
      "llama_print_timings:        eval time =     427.54 ms /     5 runs   (   85.51 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =     709.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Arnoldo Heidenreich\", \"Dr. Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    18 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1647.27 ms /   195 tokens (    8.45 ms per token,   118.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.78 ms /    17 runs   (   85.87 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    3212.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 647 555 0634\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    19 runs   (    0.41 ms per token,  2442.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.77 ms /    25 tokens (   10.43 ms per token,    95.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1544.54 ms /    18 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    1918.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     7 runs   (    0.20 ms per token,  5120.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.26 ms /    23 tokens (   11.27 ms per token,    88.71 tokens per second)\n",
      "llama_print_timings:        eval time =     715.89 ms /     6 runs   (  119.32 ms per token,     8.38 tokens per second)\n",
      "llama_print_timings:       total time =    1048.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     8 runs   (    0.24 ms per token,  4230.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.08 ms /    24 tokens (   10.67 ms per token,    93.72 tokens per second)\n",
      "llama_print_timings:        eval time =     691.47 ms /     7 runs   (   98.78 ms per token,    10.12 tokens per second)\n",
      "llama_print_timings:       total time =     991.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Garret Huel\", \"Dr. Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    18 runs   (    0.44 ms per token,  2258.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.45 ms /   135 tokens (    8.58 ms per token,   116.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1422.00 ms /    17 runs   (   83.65 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    2710.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"623 579 4257\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2365.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    25 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1181.01 ms /    14 runs   (   84.36 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    1518.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     7 runs   (    0.24 ms per token,  4227.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.59 ms /    23 tokens (   10.85 ms per token,    92.15 tokens per second)\n",
      "llama_print_timings:        eval time =     618.90 ms /     6 runs   (  103.15 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =     902.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    24 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =      98.67 ms /     1 runs   (   98.67 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =     357.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Werner Kuphal\", \"Dr Harland Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    14 runs   (    0.32 ms per token,  3111.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.00 ms /   138 tokens (    8.28 ms per token,   120.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.12 ms /    13 runs   (   86.78 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    2347.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"431 498 7835\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.12 ms /    15 runs   (    0.41 ms per token,  2452.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.14 ms /    14 runs   (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1537.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     7 runs   (    0.30 ms per token,  3298.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.64 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =     490.01 ms /     6 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     775.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     6 runs   (    0.20 ms per token,  4882.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =     424.86 ms /     5 runs   (   84.97 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     697.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Erica Schamberger\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    17 runs   (    0.44 ms per token,  2292.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.83 ms /   179 tokens (    7.81 ms per token,   127.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1270.90 ms /    16 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    2793.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"830 481 3310\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    15 runs   (    0.42 ms per token,  2405.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.09 ms /    25 tokens (   10.16 ms per token,    98.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.95 ms /    14 runs   (   82.64 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1507.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7968.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.36 ms /    23 tokens (   10.89 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =      90.70 ms /     1 runs   (   90.70 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =     346.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     8 runs   (    0.26 ms per token,  3866.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    24 tokens (   10.42 ms per token,    95.99 tokens per second)\n",
      "llama_print_timings:        eval time =     585.42 ms /     7 runs   (   83.63 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     874.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosanne Labadie\", \"Doctor Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    20 runs   (    0.38 ms per token,  2656.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.48 ms /   163 tokens (    8.45 ms per token,   118.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1544.86 ms /    19 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    3049.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"206 425 4604\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2601.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.95 ms /    14 runs   (   86.28 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1544.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     7 runs   (    0.27 ms per token,  3739.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.43 ms /    23 tokens (   11.06 ms per token,    90.40 tokens per second)\n",
      "llama_print_timings:        eval time =     500.29 ms /     6 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     785.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5649.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =      88.33 ms /     1 runs   (   88.33 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     349.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Verla Schroeder\", \"Dr Brendan Abshire\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    19 runs   (    0.46 ms per token,  2170.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.97 ms /   152 tokens (    7.76 ms per token,   128.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1530.43 ms /    18 runs   (   85.02 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    2825.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"631 809 2537\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    15 runs   (    0.45 ms per token,  2247.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.43 ms /    25 tokens (   10.34 ms per token,    96.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.70 ms /    14 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1483.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     9 runs   (    0.33 ms per token,  3026.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.41 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =     647.54 ms /     8 runs   (   80.94 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     943.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9216.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.87 ms /    24 tokens (   10.66 ms per token,    93.80 tokens per second)\n",
      "llama_print_timings:        eval time =      91.95 ms /     1 runs   (   91.95 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     352.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ela Kohler\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    12 runs   (    0.28 ms per token,  3540.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.29 ms /   169 tokens (    8.15 ms per token,   122.70 tokens per second)\n",
      "llama_print_timings:        eval time =     947.12 ms /    11 runs   (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    2386.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"616 281 5128\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    15 runs   (    0.32 ms per token,  3147.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.64 ms /    25 tokens (   11.39 ms per token,    87.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.52 ms /    14 runs   (   87.68 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    1592.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.28 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =      96.65 ms /     1 runs   (   96.65 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     358.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7662.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.44 ms /    24 tokens (   10.60 ms per token,    94.33 tokens per second)\n",
      "llama_print_timings:        eval time =     100.48 ms /     1 runs   (  100.48 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =     359.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"patient\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /     5 runs   (    0.25 ms per token,  4003.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.35 ms /   141 tokens (    8.24 ms per token,   121.31 tokens per second)\n",
      "llama_print_timings:        eval time =     339.78 ms /     4 runs   (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1523.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 985 7282\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    15 runs   (    0.62 ms per token,  1601.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.32 ms /    14 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1472.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     6 runs   (    0.39 ms per token,  2552.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.75 ms /    23 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     394.93 ms /     5 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     674.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     4 runs   (    0.18 ms per token,  5540.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.13 ms /    24 tokens (   10.51 ms per token,    95.19 tokens per second)\n",
      "llama_print_timings:        eval time =     242.55 ms /     3 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     510.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tamar Auer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /     7 runs   (    0.33 ms per token,  2990.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.06 ms /   166 tokens (    8.27 ms per token,   120.99 tokens per second)\n",
      "llama_print_timings:        eval time =     466.60 ms /     6 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1878.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 893 4226\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    15 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.49 ms /    14 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1465.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.17 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =      90.18 ms /     1 runs   (   90.18 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     346.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7462.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =      96.60 ms /     1 runs   (   96.60 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     351.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Iona Wisozk\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     8 runs   (    0.39 ms per token,  2596.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.60 ms /   136 tokens (    8.38 ms per token,   119.34 tokens per second)\n",
      "llama_print_timings:        eval time =     547.00 ms /     7 runs   (   78.14 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1737.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 237 5148\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    15 runs   (    0.61 ms per token,  1648.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    25 tokens (   10.06 ms per token,    99.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.55 ms /    14 runs   (   78.11 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1468.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     7 runs   (    0.30 ms per token,  3383.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.54 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =     479.23 ms /     6 runs   (   79.87 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     765.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     8 runs   (    0.40 ms per token,  2471.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =     542.63 ms /     7 runs   (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =     845.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Leonel Smith\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     6 runs   (    0.22 ms per token,  4524.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.49 ms /   180 tokens (    7.70 ms per token,   129.82 tokens per second)\n",
      "llama_print_timings:        eval time =     399.24 ms /     5 runs   (   79.85 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1809.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 683 5318\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    15 runs   (    0.54 ms per token,  1841.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.65 ms /    14 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1463.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3484.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     484.35 ms /     6 runs   (   80.72 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     774.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    11 runs   (    0.53 ms per token,  1882.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.73 ms /    24 tokens (   10.41 ms per token,    96.10 tokens per second)\n",
      "llama_print_timings:        eval time =     781.57 ms /    10 runs   (   78.16 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1107.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Rigoberto Jast\", \"Dr.\", \"Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.35 ms /    21 runs   (    0.54 ms per token,  1850.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.89 ms /   161 tokens (    8.50 ms per token,   117.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1556.31 ms /    20 runs   (   77.82 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    3101.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"412 378 6674\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    15 runs   (    0.58 ms per token,  1738.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.57 ms /    25 tokens (   10.10 ms per token,    98.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.37 ms /    14 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1474.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     9 runs   (    0.40 ms per token,  2476.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.49 ms /    23 tokens (   10.85 ms per token,    92.19 tokens per second)\n",
      "llama_print_timings:        eval time =     628.43 ms /     8 runs   (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     937.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9950.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    24 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =      81.87 ms /     1 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     337.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Carroll DuBuque\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.14 ms /    19 runs   (    0.53 ms per token,  1874.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.75 ms /   200 tokens (    8.12 ms per token,   123.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1404.74 ms /    18 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    3194.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"247 989 7858\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.24 ms /    15 runs   (    0.55 ms per token,  1820.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.58 ms /    14 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1479.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     7 runs   (    0.24 ms per token,  4206.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.34 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     485.84 ms /     6 runs   (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     767.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6389.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =      86.67 ms /     1 runs   (   86.67 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     342.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Janetta Ratke\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.28 ms /    17 runs   (    0.55 ms per token,  1832.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.34 ms /   200 tokens (    8.12 ms per token,   123.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.13 ms /    16 runs   (   78.07 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    3016.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"956 187 6062\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    15 runs   (    0.52 ms per token,  1907.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.90 ms /    25 tokens (   10.12 ms per token,    98.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.88 ms /    14 runs   (   78.49 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1468.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     9 runs   (    0.35 ms per token,  2819.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     630.07 ms /     8 runs   (   78.76 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     934.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.93 ms /    24 tokens (   10.50 ms per token,    95.26 tokens per second)\n",
      "llama_print_timings:        eval time =      83.59 ms /     1 runs   (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     339.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Wilburn Jerde\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     7 runs   (    0.34 ms per token,  2979.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.19 ms /   173 tokens (    7.95 ms per token,   125.71 tokens per second)\n",
      "llama_print_timings:        eval time =     466.34 ms /     6 runs   (   77.72 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1878.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 487 7749\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    15 runs   (    0.56 ms per token,  1793.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    25 tokens (   10.06 ms per token,    99.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.80 ms /    14 runs   (   78.63 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1467.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6349.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.94 ms /    23 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =      90.86 ms /     1 runs   (   90.86 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =     345.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6309.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.70 ms /    24 tokens (   10.40 ms per token,    96.12 tokens per second)\n",
      "llama_print_timings:        eval time =      85.11 ms /     1 runs   (   85.11 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =     339.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ria Will\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     6 runs   (    0.33 ms per token,  3000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.48 ms /   143 tokens (    8.01 ms per token,   124.84 tokens per second)\n",
      "llama_print_timings:        eval time =     392.19 ms /     5 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1570.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"255 263 4369\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    15 runs   (    0.53 ms per token,  1874.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    25 tokens (   10.05 ms per token,    99.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.43 ms /    14 runs   (   78.82 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1465.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.33 ms /    23 tokens (   10.84 ms per token,    92.25 tokens per second)\n",
      "llama_print_timings:        eval time =      88.79 ms /     1 runs   (   88.79 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     342.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.73 ms /    24 tokens (   10.41 ms per token,    96.10 tokens per second)\n",
      "llama_print_timings:        eval time =      92.79 ms /     1 runs   (   92.79 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =     348.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Gita Kuhn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.63 ms /    10 runs   (    0.66 ms per token,  1508.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.41 ms /   149 tokens (    7.73 ms per token,   129.41 tokens per second)\n",
      "llama_print_timings:        eval time =     713.03 ms /     9 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1946.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"145 862 4321\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.37 ms /    15 runs   (    0.49 ms per token,  2035.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.96 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.61 ms /    14 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1473.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     5 runs   (    0.25 ms per token,  4058.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.38 ms /    23 tokens (   10.89 ms per token,    91.86 tokens per second)\n",
      "llama_print_timings:        eval time =     317.00 ms /     4 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     584.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5899.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =      88.34 ms /     1 runs   (   88.34 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     344.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Debroah Emmerich\", \"Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.18 ms /    19 runs   (    0.54 ms per token,  1866.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.51 ms /   184 tokens (    7.58 ms per token,   131.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1407.95 ms /    18 runs   (   78.22 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2956.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"681 263 3855\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    15 runs   (    0.63 ms per token,  1590.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.68 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.05 ms /    14 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    1476.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2491.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.95 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     624.19 ms /     8 runs   (   78.02 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =     929.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     8 runs   (    0.39 ms per token,  2555.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.01 ms /    24 tokens (   10.50 ms per token,    95.24 tokens per second)\n",
      "llama_print_timings:        eval time =     549.10 ms /     7 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     850.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nana Konopelski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     9 runs   (    0.46 ms per token,  2175.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2398.88 ms /   319 tokens (    7.52 ms per token,   132.98 tokens per second)\n",
      "llama_print_timings:        eval time =     642.61 ms /     8 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    3100.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 552 1317\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.19 ms /    15 runs   (    0.61 ms per token,  1632.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.58 ms /    25 tokens (   10.22 ms per token,    97.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.90 ms /    14 runs   (   79.99 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1497.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     7 runs   (    0.21 ms per token,  4691.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.83 ms /    23 tokens (   11.04 ms per token,    90.61 tokens per second)\n",
      "llama_print_timings:        eval time =     488.78 ms /     6 runs   (   81.46 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     771.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.70 ms /    11 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.72 ms /    24 tokens (   10.57 ms per token,    94.59 tokens per second)\n",
      "llama_print_timings:        eval time =     794.83 ms /    10 runs   (   79.48 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1127.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marybelle Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     8 runs   (    0.38 ms per token,  2621.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.19 ms /   156 tokens (    7.42 ms per token,   134.69 tokens per second)\n",
      "llama_print_timings:        eval time =     549.13 ms /     7 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1755.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 237 6647\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.52 ms /    15 runs   (    0.57 ms per token,  1761.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    25 tokens (   10.05 ms per token,    99.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.23 ms /    14 runs   (   78.09 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1463.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     6 runs   (    0.26 ms per token,  3861.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     395.95 ms /     5 runs   (   79.19 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     673.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6688.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.93 ms /    24 tokens (   10.46 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      92.27 ms /     1 runs   (   92.27 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =     348.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Maryln Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /     9 runs   (    0.42 ms per token,  2399.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.98 ms /   141 tokens (    8.11 ms per token,   123.36 tokens per second)\n",
      "llama_print_timings:        eval time =     622.15 ms /     8 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1825.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"782 964 0950\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    15 runs   (    0.50 ms per token,  2000.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.68 ms /    14 runs   (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1461.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     9 runs   (    0.29 ms per token,  3436.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     635.64 ms /     8 runs   (   79.46 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     928.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    24 tokens (   10.42 ms per token,    95.99 tokens per second)\n",
      "llama_print_timings:        eval time =     544.38 ms /     7 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =     845.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Lily Armstrong\", \"Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    16 runs   (    0.49 ms per token,  2021.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.72 ms /   163 tokens (    8.42 ms per token,   118.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1196.07 ms /    15 runs   (   79.74 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    2694.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"607 134 1479\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    15 runs   (    0.50 ms per token,  2011.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.14 ms /    14 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1454.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6872.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.04 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =      90.54 ms /     1 runs   (   90.54 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     345.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    11 runs   (    0.41 ms per token,  2454.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.50 ms /    24 tokens (   10.40 ms per token,    96.19 tokens per second)\n",
      "llama_print_timings:        eval time =     787.16 ms /    10 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1113.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alvaro Stehr\", \"Leoma Jaskolski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    16 runs   (    0.51 ms per token,  1946.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.50 ms /   214 tokens (    7.68 ms per token,   130.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.22 ms /    15 runs   (   78.08 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    2945.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"393 593 0382\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    15 runs   (    0.53 ms per token,  1903.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.34 ms /    25 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.91 ms /    14 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1466.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     7 runs   (    0.35 ms per token,  2849.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.42 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     474.73 ms /     6 runs   (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     763.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5571.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =      98.05 ms /     1 runs   (   98.05 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =     354.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cesar Rice\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    14 runs   (    0.53 ms per token,  1870.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1624.53 ms /   199 tokens (    8.16 ms per token,   122.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1014.02 ms /    13 runs   (   78.00 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2757.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"365 451 0342\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1949.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    25 tokens (   10.07 ms per token,    99.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.48 ms /    14 runs   (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1476.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6711.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    23 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =      87.73 ms /     1 runs   (   87.73 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     344.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2686.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.82 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     559.64 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     857.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rodolfo Shanahan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.13 ms /    12 runs   (    0.59 ms per token,  1683.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.61 ms /   215 tokens (    7.67 ms per token,   130.41 tokens per second)\n",
      "llama_print_timings:        eval time =     860.35 ms /    11 runs   (   78.21 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2611.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"191 481 2147\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    15 runs   (    0.54 ms per token,  1838.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.92 ms /    25 tokens (   10.12 ms per token,    98.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.96 ms /    14 runs   (   79.07 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1475.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5420.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =      92.31 ms /     1 runs   (   92.31 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     348.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6006.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    24 tokens (   10.46 ms per token,    95.59 tokens per second)\n",
      "llama_print_timings:        eval time =      96.40 ms /     1 runs   (   96.40 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =     351.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cecil Shanahan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    11 runs   (    0.27 ms per token,  3658.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.54 ms /   166 tokens (    8.26 ms per token,   121.03 tokens per second)\n",
      "llama_print_timings:        eval time =     794.63 ms /    10 runs   (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2223.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"265 185 4566\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2620.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.04 ms /    14 runs   (   82.43 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1493.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     7 runs   (    0.24 ms per token,  4149.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.89 ms /    23 tokens (   11.21 ms per token,    89.19 tokens per second)\n",
      "llama_print_timings:        eval time =     541.58 ms /     6 runs   (   90.26 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     829.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     8 runs   (    0.22 ms per token,  4509.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =     631.31 ms /     7 runs   (   90.19 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     914.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jorge Watsica\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     9 runs   (    0.25 ms per token,  4010.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.24 ms /   167 tokens (    8.50 ms per token,   117.67 tokens per second)\n",
      "llama_print_timings:        eval time =     699.47 ms /     8 runs   (   87.43 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2159.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"713 732 8162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    15 runs   (    0.41 ms per token,  2412.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.09 ms /    25 tokens (   10.12 ms per token,    98.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.52 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1491.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2703.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.44 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     681.88 ms /     8 runs   (   85.23 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     991.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7434.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.44 ms /    24 tokens (   10.56 ms per token,    94.70 tokens per second)\n",
      "llama_print_timings:        eval time =      94.20 ms /     1 runs   (   94.20 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =     353.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Khalilah Harber\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2591.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.12 ms /   133 tokens (    8.68 ms per token,   115.24 tokens per second)\n",
      "llama_print_timings:        eval time =     655.10 ms /     8 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1865.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 134 3203\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.50 ms /    15 runs   (    0.37 ms per token,  2727.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    25 tokens (   10.20 ms per token,    98.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.19 ms /    14 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1495.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     9 runs   (    0.20 ms per token,  5099.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.43 ms /    23 tokens (   11.06 ms per token,    90.40 tokens per second)\n",
      "llama_print_timings:        eval time =     667.08 ms /     8 runs   (   83.39 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     955.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary complaint\", \"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.15 ms /    13 runs   (    0.40 ms per token,  2523.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.55 ms /    24 tokens (   10.77 ms per token,    92.83 tokens per second)\n",
      "llama_print_timings:        eval time =     976.96 ms /    12 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1314.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Lyn Fadel\", \"Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.07 ms /    18 runs   (    0.50 ms per token,  1984.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.00 ms /   142 tokens (    8.30 ms per token,   120.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1355.33 ms /    17 runs   (   79.73 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    2685.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"877 269 0145\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    15 runs   (    0.45 ms per token,  2225.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.69 ms /    25 tokens (   10.23 ms per token,    97.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.68 ms /    14 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1504.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     7 runs   (    0.41 ms per token,  2430.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    23 tokens (   10.97 ms per token,    91.12 tokens per second)\n",
      "llama_print_timings:        eval time =     490.57 ms /     6 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     785.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     8 runs   (    0.51 ms per token,  1968.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    24 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =     575.05 ms /     7 runs   (   82.15 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     882.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lurline Beahan\", \"family members\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    16 runs   (    0.56 ms per token,  1800.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2969.09 ms /   360 tokens (    8.25 ms per token,   121.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.77 ms /    15 runs   (   83.78 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    4362.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"636 667 5562\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    15 runs   (    0.55 ms per token,  1825.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.20 ms /    25 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.38 ms /    14 runs   (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    1556.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.19 ms /    23 tokens (   11.23 ms per token,    89.08 tokens per second)\n",
      "llama_print_timings:        eval time =      93.48 ms /     1 runs   (   93.48 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     358.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    11 runs   (    0.38 ms per token,  2614.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.49 ms /    24 tokens (   10.77 ms per token,    92.85 tokens per second)\n",
      "llama_print_timings:        eval time =     835.65 ms /    10 runs   (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1168.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clair Cremin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /     9 runs   (    0.58 ms per token,  1710.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.51 ms /   206 tokens (    7.97 ms per token,   125.42 tokens per second)\n",
      "llama_print_timings:        eval time =     647.68 ms /     8 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2364.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 718 1469\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    15 runs   (    0.48 ms per token,  2077.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.85 ms /    25 tokens (   10.23 ms per token,    97.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1190.53 ms /    14 runs   (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    1604.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.70 ms /     9 runs   (    0.30 ms per token,  3328.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.08 ms /    23 tokens (   11.09 ms per token,    90.17 tokens per second)\n",
      "llama_print_timings:        eval time =     661.10 ms /     8 runs   (   82.64 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     963.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     8 runs   (    0.33 ms per token,  3004.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.70 ms /    24 tokens (   10.57 ms per token,    94.60 tokens per second)\n",
      "llama_print_timings:        eval time =     608.28 ms /     7 runs   (   86.90 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     908.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Maria Ernser\", \"Doctor Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    17 runs   (    0.48 ms per token,  2094.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.67 ms /   164 tokens (    8.50 ms per token,   117.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.90 ms /    16 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2824.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"536 531 7666\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    15 runs   (    0.49 ms per token,  2022.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.54 ms /    25 tokens (   10.22 ms per token,    97.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.23 ms /    14 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1499.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     9 runs   (    0.35 ms per token,  2883.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    23 tokens (   11.04 ms per token,    90.60 tokens per second)\n",
      "llama_print_timings:        eval time =     656.69 ms /     8 runs   (   82.09 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     968.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10101.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.70 ms /    24 tokens (   10.70 ms per token,    93.50 tokens per second)\n",
      "llama_print_timings:        eval time =      85.91 ms /     1 runs   (   85.91 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     346.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Gilma Swaniawski\", \"Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.43 ms /    17 runs   (    0.55 ms per token,  1803.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.84 ms /   197 tokens (    8.35 ms per token,   119.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1291.63 ms /    16 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    3078.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"683 811 8801\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.62 ms /    15 runs   (    0.57 ms per token,  1740.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    25 tokens (   10.25 ms per token,    97.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.38 ms /    14 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1509.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     9 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.50 ms /    23 tokens (   11.11 ms per token,    90.02 tokens per second)\n",
      "llama_print_timings:        eval time =     658.02 ms /     8 runs   (   82.25 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     951.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7326.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.41 ms /    24 tokens (   10.60 ms per token,    94.33 tokens per second)\n",
      "llama_print_timings:        eval time =      90.42 ms /     1 runs   (   90.42 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =     350.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mariel Medhurst\", \"Doctor Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.31 ms /    16 runs   (    0.58 ms per token,  1719.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2149.06 ms /   271 tokens (    7.93 ms per token,   126.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.71 ms /    15 runs   (   81.38 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    3510.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 125 1747\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    15 runs   (    0.57 ms per token,  1769.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.01 ms /    25 tokens (   10.32 ms per token,    96.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.70 ms /    14 runs   (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1530.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5882.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.32 ms /    23 tokens (   11.23 ms per token,    89.04 tokens per second)\n",
      "llama_print_timings:        eval time =      98.19 ms /     1 runs   (   98.19 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =     362.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     8 runs   (    0.26 ms per token,  3822.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    24 tokens (   10.64 ms per token,    94.01 tokens per second)\n",
      "llama_print_timings:        eval time =     577.65 ms /     7 runs   (   82.52 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     866.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Miguel Kulas\", \"Dr Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    16 runs   (    0.48 ms per token,  2088.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.49 ms /   176 tokens (    7.96 ms per token,   125.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.01 ms /    15 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2732.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 589 6712\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.81 ms /    15 runs   (    0.59 ms per token,  1702.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.27 ms /    25 tokens (   10.17 ms per token,    98.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.58 ms /    14 runs   (   81.61 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1516.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     8 runs   (    0.24 ms per token,  4184.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.13 ms /    23 tokens (   11.09 ms per token,    90.15 tokens per second)\n",
      "llama_print_timings:        eval time =     571.87 ms /     7 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     868.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     8 runs   (    0.39 ms per token,  2573.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.26 ms /    24 tokens (   10.55 ms per token,    94.76 tokens per second)\n",
      "llama_print_timings:        eval time =     568.55 ms /     7 runs   (   81.22 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     872.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Dalila Leuschke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    11 runs   (    0.53 ms per token,  1888.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.22 ms /   161 tokens (    8.65 ms per token,   115.64 tokens per second)\n",
      "llama_print_timings:        eval time =     801.77 ms /    10 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2269.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"586 824 7144\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    15 runs   (    0.52 ms per token,  1914.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    25 tokens (   10.24 ms per token,    97.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.43 ms /    14 runs   (   80.60 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1490.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     9 runs   (    0.27 ms per token,  3637.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.12 ms /    23 tokens (   11.05 ms per token,    90.51 tokens per second)\n",
      "llama_print_timings:        eval time =     654.30 ms /     8 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     950.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     8 runs   (    0.38 ms per token,  2658.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.42 ms /    24 tokens (   10.64 ms per token,    93.96 tokens per second)\n",
      "llama_print_timings:        eval time =     561.58 ms /     7 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     863.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Piedad Schaefer\", \"Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    15 runs   (    0.49 ms per token,  2054.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.20 ms /   185 tokens (    7.63 ms per token,   131.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.58 ms /    14 runs   (   81.04 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2664.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 333 6337\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2160.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.39 ms /    25 tokens (   10.26 ms per token,    97.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.62 ms /    14 runs   (   80.76 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1497.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     7 runs   (    0.30 ms per token,  3289.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.77 ms /    23 tokens (   11.08 ms per token,    90.28 tokens per second)\n",
      "llama_print_timings:        eval time =     489.57 ms /     6 runs   (   81.60 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     780.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6756.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.48 ms /    24 tokens (   10.65 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =      98.00 ms /     1 runs   (   98.00 ms per token,    10.20 tokens per second)\n",
      "llama_print_timings:       total time =     360.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Karl Rau\", \"Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    13 runs   (    0.46 ms per token,  2161.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.37 ms /   166 tokens (    8.39 ms per token,   119.14 tokens per second)\n",
      "llama_print_timings:        eval time =     963.92 ms /    12 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2450.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 231 2788\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    15 runs   (    0.56 ms per token,  1784.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /    25 tokens (   10.23 ms per token,    97.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.52 ms /    14 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1497.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /     6 runs   (    0.21 ms per token,  4765.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    23 tokens (   11.10 ms per token,    90.08 tokens per second)\n",
      "llama_print_timings:        eval time =     416.43 ms /     5 runs   (   83.29 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     695.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Black\", \"Caribbean\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /     9 runs   (    0.35 ms per token,  2889.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     649.00 ms /     8 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     955.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nga McKenzie\", \"Dr. Jerrell Rippin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    17 runs   (    0.53 ms per token,  1885.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2955.01 ms /   354 tokens (    8.35 ms per token,   119.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1322.88 ms /    16 runs   (   82.68 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    4418.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS Number\", \"999 481 9437\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.61 ms /    20 runs   (    0.63 ms per token,  1585.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.62 ms /    25 tokens (   10.38 ms per token,    96.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1577.76 ms /    19 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1999.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    23 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =      94.67 ms /     1 runs   (   94.67 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     358.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     6 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.51 ms /    24 tokens (   10.77 ms per token,    92.84 tokens per second)\n",
      "llama_print_timings:        eval time =     410.50 ms /     5 runs   (   82.10 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     697.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Celina Mayert\", \"Doctor Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    19 runs   (    0.53 ms per token,  1878.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.53 ms /   149 tokens (    7.86 ms per token,   127.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1448.50 ms /    18 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    2782.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"751 135 0572\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    15 runs   (    0.52 ms per token,  1928.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.54 ms /    25 tokens (   10.14 ms per token,    98.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.78 ms /    14 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1507.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /     9 runs   (    0.26 ms per token,  3839.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.21 ms /    23 tokens (   10.92 ms per token,    91.56 tokens per second)\n",
      "llama_print_timings:        eval time =     656.91 ms /     8 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     951.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.02 ms /    24 tokens (   10.54 ms per token,    94.85 tokens per second)\n",
      "llama_print_timings:        eval time =      89.92 ms /     1 runs   (   89.92 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     347.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tai Emmerich\", \"Doctor Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.97 ms /    18 runs   (    0.55 ms per token,  1805.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.55 ms /   138 tokens (    8.41 ms per token,   118.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1372.72 ms /    17 runs   (   80.75 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    2694.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"232 727 9417\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    15 runs   (    0.51 ms per token,  1969.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.02 ms /    25 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.87 ms /    14 runs   (   80.71 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1494.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     7 runs   (    0.32 ms per token,  3126.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.65 ms /    23 tokens (   11.03 ms per token,    90.68 tokens per second)\n",
      "llama_print_timings:        eval time =     488.70 ms /     6 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     780.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     8 runs   (    0.35 ms per token,  2866.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.53 ms /    24 tokens (   10.61 ms per token,    94.29 tokens per second)\n",
      "llama_print_timings:        eval time =     559.85 ms /     7 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     858.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Neely Dach\", \"Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    16 runs   (    0.49 ms per token,  2057.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1899.31 ms /   228 tokens (    8.33 ms per token,   120.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.66 ms /    15 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    3239.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"196 302 1090\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    15 runs   (    0.46 ms per token,  2193.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.91 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.31 ms /    14 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1496.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /     7 runs   (    0.33 ms per token,  2994.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    23 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =     493.90 ms /     6 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     791.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8298.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.44 ms /    24 tokens (   10.68 ms per token,    93.59 tokens per second)\n",
      "llama_print_timings:        eval time =      94.06 ms /     1 runs   (   94.06 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =     356.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Patrick Ferry\", \"Dr.\", \"Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.10 ms /    20 runs   (    0.66 ms per token,  1526.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.15 ms /   187 tokens (    7.56 ms per token,   132.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1522.15 ms /    19 runs   (   80.11 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    3106.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"371 995 6440\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.01 ms /    15 runs   (    0.60 ms per token,  1665.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    25 tokens (   10.27 ms per token,    97.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.20 ms /    14 runs   (   81.80 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1523.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     7 runs   (    0.38 ms per token,  2636.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.81 ms /    23 tokens (   11.08 ms per token,    90.26 tokens per second)\n",
      "llama_print_timings:        eval time =     502.00 ms /     6 runs   (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     795.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6250.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.71 ms /    24 tokens (   10.65 ms per token,    93.86 tokens per second)\n",
      "llama_print_timings:        eval time =      86.02 ms /     1 runs   (   86.02 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     346.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dona Farrell\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     7 runs   (    0.42 ms per token,  2356.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.20 ms /   141 tokens (    8.23 ms per token,   121.53 tokens per second)\n",
      "llama_print_timings:        eval time =     487.54 ms /     6 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1688.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"830 437 8609\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.49 ms /    15 runs   (    0.57 ms per token,  1766.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.09 ms /    25 tokens (   10.20 ms per token,    98.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.32 ms /    14 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1505.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6557.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =      92.83 ms /     1 runs   (   92.83 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =     351.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.28 ms /     8 runs   (    0.41 ms per token,  2439.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.90 ms /    24 tokens (   10.58 ms per token,    94.53 tokens per second)\n",
      "llama_print_timings:        eval time =     571.28 ms /     7 runs   (   81.61 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     874.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lucien Homenick\", \"Dr. Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    18 runs   (    0.45 ms per token,  2209.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.27 ms /   141 tokens (    8.23 ms per token,   121.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.66 ms /    17 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2673.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"440 824 4915\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    15 runs   (    0.51 ms per token,  1954.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    25 tokens (   10.20 ms per token,    98.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.11 ms /    14 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1495.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     6 runs   (    0.26 ms per token,  3848.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.22 ms /    23 tokens (   11.01 ms per token,    90.83 tokens per second)\n",
      "llama_print_timings:        eval time =     406.65 ms /     5 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     687.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     8 runs   (    0.32 ms per token,  3118.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.24 ms /    24 tokens (   10.59 ms per token,    94.40 tokens per second)\n",
      "llama_print_timings:        eval time =     594.58 ms /     7 runs   (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     883.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Brinda Thiel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     7 runs   (    0.39 ms per token,  2545.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.60 ms /   140 tokens (    8.30 ms per token,   120.52 tokens per second)\n",
      "llama_print_timings:        eval time =     491.61 ms /     6 runs   (   81.93 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1696.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 696 9906\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    15 runs   (    0.53 ms per token,  1896.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.81 ms /    25 tokens (   10.15 ms per token,    98.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.32 ms /    14 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1505.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /     7 runs   (    0.38 ms per token,  2665.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.66 ms /    23 tokens (   11.03 ms per token,    90.67 tokens per second)\n",
      "llama_print_timings:        eval time =     487.29 ms /     6 runs   (   81.21 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     783.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /     8 runs   (    0.41 ms per token,  2410.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.25 ms /    24 tokens (   10.68 ms per token,    93.66 tokens per second)\n",
      "llama_print_timings:        eval time =     558.73 ms /     7 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     863.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Benny Dibbert\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    17 runs   (    0.64 ms per token,  1551.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.76 ms /   167 tokens (    8.38 ms per token,   119.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1295.95 ms /    16 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2836.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 583 848 7520\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.06 ms /    19 runs   (    0.58 ms per token,  1718.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.62 ms /    25 tokens (   10.19 ms per token,    98.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.15 ms /    18 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1853.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     7 runs   (    0.37 ms per token,  2696.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     500.19 ms /     6 runs   (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     788.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    11 runs   (    0.48 ms per token,  2103.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.40 ms /    24 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =     812.68 ms /    10 runs   (   81.27 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1138.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brittney Stehr\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.14 ms /    11 runs   (    0.47 ms per token,  2139.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.79 ms /   155 tokens (    7.61 ms per token,   131.49 tokens per second)\n",
      "llama_print_timings:        eval time =     801.08 ms /    10 runs   (   80.11 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    2064.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"161 425 1133\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.50 ms /    15 runs   (    0.57 ms per token,  1765.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.08 ms /    25 tokens (   10.20 ms per token,    98.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.16 ms /    14 runs   (   81.58 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1512.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  7017.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.64 ms /    23 tokens (   11.03 ms per token,    90.68 tokens per second)\n",
      "llama_print_timings:        eval time =      96.90 ms /     1 runs   (   96.90 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =     356.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7722.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.87 ms /    24 tokens (   10.54 ms per token,    94.91 tokens per second)\n",
      "llama_print_timings:        eval time =      85.98 ms /     1 runs   (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     343.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Janina Cruickshank\", \"Dr. Tracey Hamill\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.50 ms /    20 runs   (    0.53 ms per token,  1904.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.11 ms /   160 tokens (    7.29 ms per token,   137.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1532.74 ms /    19 runs   (   80.67 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2856.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 597 6921\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    15 runs   (    0.57 ms per token,  1752.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    25 tokens (   10.18 ms per token,    98.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.55 ms /    14 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1495.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    23 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =      87.36 ms /     1 runs   (   87.36 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     346.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.40 ms /     8 runs   (    0.55 ms per token,  1816.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.68 ms /    24 tokens (   10.57 ms per token,    94.61 tokens per second)\n",
      "llama_print_timings:        eval time =     574.46 ms /     7 runs   (   82.07 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     879.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Frida Kassulke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    12 runs   (    0.63 ms per token,  1595.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.47 ms /   139 tokens (    8.35 ms per token,   119.78 tokens per second)\n",
      "llama_print_timings:        eval time =     879.70 ms /    11 runs   (   79.97 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2142.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"644 602 8806\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    15 runs   (    0.56 ms per token,  1769.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.76 ms /    25 tokens (   10.23 ms per token,    97.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.55 ms /    14 runs   (   79.47 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1481.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2653.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =     578.70 ms /     7 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     878.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    24 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =      86.31 ms /     1 runs   (   86.31 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     345.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Marybeth Kozey\", \"Dr. Jude Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.28 ms /    20 runs   (    0.61 ms per token,  1628.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.53 ms /   155 tokens (    7.58 ms per token,   131.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1525.59 ms /    19 runs   (   80.29 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2859.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"278 661 5395\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    15 runs   (    0.42 ms per token,  2353.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.87 ms /    25 tokens (   10.23 ms per token,    97.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.40 ms /    14 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1490.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     7 runs   (    0.24 ms per token,  4184.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.59 ms /    23 tokens (   11.07 ms per token,    90.34 tokens per second)\n",
      "llama_print_timings:        eval time =     499.82 ms /     6 runs   (   83.30 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     783.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     8 runs   (    0.39 ms per token,  2572.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    24 tokens (   10.56 ms per token,    94.69 tokens per second)\n",
      "llama_print_timings:        eval time =     565.39 ms /     7 runs   (   80.77 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     860.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Adelia McDermott\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    12 runs   (    0.49 ms per token,  2029.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.81 ms /   154 tokens (    7.64 ms per token,   130.97 tokens per second)\n",
      "llama_print_timings:        eval time =     887.56 ms /    11 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2154.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"461 477 9235\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2043.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.26 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.00 ms /    14 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1497.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     9 runs   (    0.25 ms per token,  4074.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.80 ms /    23 tokens (   11.08 ms per token,    90.27 tokens per second)\n",
      "llama_print_timings:        eval time =     655.01 ms /     8 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     955.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7936.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.82 ms /    24 tokens (   10.49 ms per token,    95.31 tokens per second)\n",
      "llama_print_timings:        eval time =      90.18 ms /     1 runs   (   90.18 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     347.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Geoffrey Treutel\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.13 ms /    17 runs   (    0.54 ms per token,  1861.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2455.20 ms /   307 tokens (    8.00 ms per token,   125.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1309.62 ms /    16 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    3914.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 741 5669\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1992.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.39 ms /    25 tokens (   10.34 ms per token,    96.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.97 ms /    14 runs   (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1534.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7722.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    23 tokens (   11.17 ms per token,    89.54 tokens per second)\n",
      "llama_print_timings:        eval time =      97.59 ms /     1 runs   (   97.59 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     362.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    11 runs   (    0.57 ms per token,  1742.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.34 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =     846.99 ms /    10 runs   (   84.70 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1183.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tory Luettgen\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.07 ms /    16 runs   (    0.38 ms per token,  2638.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.63 ms /   169 tokens (    8.25 ms per token,   121.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1219.89 ms /    15 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2715.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 621 0407\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    15 runs   (    0.49 ms per token,  2020.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.61 ms /    25 tokens (   10.22 ms per token,    97.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.52 ms /    14 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1493.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.73 ms /    23 tokens (   11.03 ms per token,    90.65 tokens per second)\n",
      "llama_print_timings:        eval time =      93.57 ms /     1 runs   (   93.57 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =     353.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     7 runs   (    0.30 ms per token,  3281.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.15 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =     495.18 ms /     6 runs   (   82.53 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     783.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Edyth Larson\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    18 runs   (    0.51 ms per token,  1955.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.29 ms /   182 tokens (    7.75 ms per token,   128.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1363.07 ms /    17 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2928.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"854 407 7183\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1953.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    25 tokens (   10.18 ms per token,    98.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.01 ms /    14 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1507.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6779.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.99 ms /    23 tokens (   11.04 ms per token,    90.56 tokens per second)\n",
      "llama_print_timings:        eval time =      94.52 ms /     1 runs   (   94.52 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =     354.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.71 ms /    24 tokens (   10.53 ms per token,    94.97 tokens per second)\n",
      "llama_print_timings:        eval time =      98.23 ms /     1 runs   (   98.23 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =     354.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Elroy Little\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     8 runs   (    0.50 ms per token,  2015.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.47 ms /   139 tokens (    8.34 ms per token,   119.88 tokens per second)\n",
      "llama_print_timings:        eval time =     559.87 ms /     7 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1776.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 361 242 8662\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.07 ms /    19 runs   (    0.53 ms per token,  1886.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.84 ms /    25 tokens (   10.23 ms per token,    97.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1450.93 ms /    18 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1851.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     7 runs   (    0.31 ms per token,  3251.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.77 ms /    23 tokens (   11.16 ms per token,    89.57 tokens per second)\n",
      "llama_print_timings:        eval time =     496.32 ms /     6 runs   (   82.72 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     787.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.40 ms /     8 runs   (    0.43 ms per token,  2350.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.25 ms /    24 tokens (   10.59 ms per token,    94.40 tokens per second)\n",
      "llama_print_timings:        eval time =     564.61 ms /     7 runs   (   80.66 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     869.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Alberta Stiedemann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    11 runs   (    0.49 ms per token,  2034.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.64 ms /   167 tokens (    8.38 ms per token,   119.40 tokens per second)\n",
      "llama_print_timings:        eval time =     810.18 ms /    10 runs   (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2281.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"732 104 1716\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.97 ms /    15 runs   (    0.46 ms per token,  2153.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.48 ms /    25 tokens (   10.22 ms per token,    97.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.87 ms /    14 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1480.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     7 runs   (    0.41 ms per token,  2426.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.95 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =     491.83 ms /     6 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     784.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    11 runs   (    0.44 ms per token,  2276.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.17 ms /    24 tokens (   10.63 ms per token,    94.06 tokens per second)\n",
      "llama_print_timings:        eval time =     816.06 ms /    10 runs   (   81.61 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1149.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Rosina Lehner\", \"Dr.\", \"Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.23 ms /    22 runs   (    0.51 ms per token,  1958.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.83 ms /   166 tokens (    8.42 ms per token,   118.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1675.44 ms /    21 runs   (   79.78 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    3241.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"164 716 3210\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    15 runs   (    0.55 ms per token,  1831.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    25 tokens (   10.26 ms per token,    97.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.23 ms /    14 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1515.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     9 runs   (    0.31 ms per token,  3180.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.25 ms /    23 tokens (   11.05 ms per token,    90.46 tokens per second)\n",
      "llama_print_timings:        eval time =     651.39 ms /     8 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     947.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     8 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.29 ms /    24 tokens (   10.60 ms per token,    94.38 tokens per second)\n",
      "llama_print_timings:        eval time =     566.60 ms /     7 runs   (   80.94 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     868.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Albert Ryan\", \"Dr Jude Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    13 runs   (    0.51 ms per token,  1974.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.61 ms /   152 tokens (    7.71 ms per token,   129.63 tokens per second)\n",
      "llama_print_timings:        eval time =     971.98 ms /    12 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2250.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 884 2739\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    15 runs   (    0.51 ms per token,  1971.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.01 ms /    25 tokens (   10.20 ms per token,    98.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.94 ms /    14 runs   (   81.57 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1501.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     7 runs   (    0.28 ms per token,  3514.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.57 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     482.42 ms /     6 runs   (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     770.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2631.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    24 tokens (   10.62 ms per token,    94.15 tokens per second)\n",
      "llama_print_timings:        eval time =     804.90 ms /    10 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1133.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lucas Dickinson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2685.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.92 ms /   159 tokens (    7.41 ms per token,   134.87 tokens per second)\n",
      "llama_print_timings:        eval time =     565.63 ms /     7 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1798.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"252 254 5515\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.06 ms /    15 runs   (    0.47 ms per token,  2124.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.43 ms /    25 tokens (   10.22 ms per token,    97.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.14 ms /    14 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1490.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.28 ms /    23 tokens (   11.01 ms per token,    90.81 tokens per second)\n",
      "llama_print_timings:        eval time =      90.91 ms /     1 runs   (   90.91 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =     349.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8032.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.37 ms /    24 tokens (   10.56 ms per token,    94.72 tokens per second)\n",
      "llama_print_timings:        eval time =     102.92 ms /     1 runs   (  102.92 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =     361.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tyra Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     9 runs   (    0.46 ms per token,  2154.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.82 ms /   163 tokens (    8.53 ms per token,   117.28 tokens per second)\n",
      "llama_print_timings:        eval time =     644.09 ms /     8 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2090.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     6 runs   (    0.18 ms per token,  5660.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.11 ms /    25 tokens (   10.20 ms per token,    98.00 tokens per second)\n",
      "llama_print_timings:        eval time =     411.86 ms /     5 runs   (   82.37 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     683.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /     9 runs   (    0.47 ms per token,  2105.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.20 ms /    23 tokens (   11.05 ms per token,    90.48 tokens per second)\n",
      "llama_print_timings:        eval time =     644.41 ms /     8 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     954.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5730.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    24 tokens (   10.52 ms per token,    95.08 tokens per second)\n",
      "llama_print_timings:        eval time =     102.58 ms /     1 runs   (  102.58 ms per token,     9.75 tokens per second)\n",
      "llama_print_timings:       total time =     360.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Elenore Zieme\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    16 runs   (    0.51 ms per token,  1964.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.42 ms /   145 tokens (    8.04 ms per token,   124.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.06 ms /    15 runs   (   80.00 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2497.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 467 3075\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.77 ms /    15 runs   (    0.52 ms per token,  1931.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.68 ms /    25 tokens (   10.23 ms per token,    97.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.79 ms /    14 runs   (   81.20 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1505.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     8 runs   (    0.23 ms per token,  4296.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.46 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =     574.47 ms /     7 runs   (   82.07 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     862.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.96 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =      93.69 ms /     1 runs   (   93.69 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     353.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Dorene Miller\", \"Dr. Xochitl Haley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.13 ms /    20 runs   (    0.56 ms per token,  1797.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1637.16 ms /   201 tokens (    8.15 ms per token,   122.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1532.33 ms /    19 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    3342.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"302 989 2836\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.10 ms /    15 runs   (    0.47 ms per token,  2111.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.65 ms /    25 tokens (   10.23 ms per token,    97.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.66 ms /    14 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1499.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"66-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     9 runs   (    0.32 ms per token,  3084.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.54 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     657.95 ms /     8 runs   (   82.24 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     972.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /     8 runs   (    0.37 ms per token,  2680.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.62 ms /    24 tokens (   10.61 ms per token,    94.26 tokens per second)\n",
      "llama_print_timings:        eval time =     566.03 ms /     7 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     870.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Loreta Romaguera\", \"Doctor Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.51 ms /    19 runs   (    0.61 ms per token,  1651.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.53 ms /   157 tokens (    7.51 ms per token,   133.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1441.76 ms /    18 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    2783.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"642 271 3927\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    15 runs   (    0.48 ms per token,  2071.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.66 ms /    25 tokens (   10.23 ms per token,    97.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.67 ms /    14 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1499.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4239.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.63 ms /    23 tokens (   10.98 ms per token,    91.04 tokens per second)\n",
      "llama_print_timings:        eval time =     493.66 ms /     6 runs   (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     769.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5813.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =      95.09 ms /     1 runs   (   95.09 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =     354.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jorge Gutmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     7 runs   (    0.36 ms per token,  2753.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.06 ms /   137 tokens (    8.45 ms per token,   118.40 tokens per second)\n",
      "llama_print_timings:        eval time =     482.05 ms /     6 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1682.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 377 7497\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    15 runs   (    0.50 ms per token,  2008.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.08 ms /    25 tokens (   10.20 ms per token,    98.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.14 ms /    14 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1487.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     8 runs   (    0.28 ms per token,  3539.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     575.92 ms /     7 runs   (   82.27 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     861.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     8 runs   (    0.34 ms per token,  2948.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.40 ms /    24 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =     559.70 ms /     7 runs   (   79.96 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     862.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kurtis Gleichner PhD\", \"Dr. Santo Schuppe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    20 runs   (    0.46 ms per token,  2170.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.88 ms /   169 tokens (    8.27 ms per token,   120.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1518.77 ms /    19 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    3078.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"106 607 1103\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1883.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.04 ms /    25 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.36 ms /    14 runs   (   81.03 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1503.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     7 runs   (    0.21 ms per token,  4804.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.28 ms /    23 tokens (   11.06 ms per token,    90.45 tokens per second)\n",
      "llama_print_timings:        eval time =     498.79 ms /     6 runs   (   83.13 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     783.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     8 runs   (    0.38 ms per token,  2659.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    24 tokens (   10.61 ms per token,    94.28 tokens per second)\n",
      "llama_print_timings:        eval time =     559.67 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     863.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sena Bradtke\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2313.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.43 ms /   177 tokens (    7.95 ms per token,   125.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1120.49 ms /    14 runs   (   80.03 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2640.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 157 1612\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    15 runs   (    0.57 ms per token,  1759.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    25 tokens (   10.21 ms per token,    97.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.43 ms /    14 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1507.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     8 runs   (    0.31 ms per token,  3256.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.16 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     572.65 ms /     7 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     863.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6211.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.79 ms /    24 tokens (   10.57 ms per token,    94.57 tokens per second)\n",
      "llama_print_timings:        eval time =      94.22 ms /     1 runs   (   94.22 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     353.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tim Durgan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     7 runs   (    0.53 ms per token,  1888.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.02 ms /   140 tokens (    8.29 ms per token,   120.69 tokens per second)\n",
      "llama_print_timings:        eval time =     483.06 ms /     6 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1690.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"793 698 3062\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.58 ms /    15 runs   (    0.57 ms per token,  1748.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.36 ms /    25 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.54 ms /    14 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1512.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     5 runs   (    0.16 ms per token,  6105.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.30 ms /    23 tokens (   11.06 ms per token,    90.45 tokens per second)\n",
      "llama_print_timings:        eval time =     338.58 ms /     4 runs   (   84.65 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     606.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\", \"Chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.71 ms /    18 runs   (    0.48 ms per token,  2067.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.08 ms /    24 tokens (   10.59 ms per token,    94.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1365.81 ms /    17 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1742.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Hertha Jacobson\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    19 runs   (    0.59 ms per token,  1685.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.57 ms /   161 tokens (    8.63 ms per token,   115.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.76 ms /    18 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2982.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"136 245 2486\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.38 ms /    15 runs   (    0.56 ms per token,  1789.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.69 ms /    25 tokens (   10.23 ms per token,    97.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.79 ms /    14 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1498.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4410.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.80 ms /    23 tokens (   11.08 ms per token,    90.27 tokens per second)\n",
      "llama_print_timings:        eval time =     575.24 ms /     7 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     862.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.88 ms /    24 tokens (   10.54 ms per token,    94.91 tokens per second)\n",
      "llama_print_timings:        eval time =      92.05 ms /     1 runs   (   92.05 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =     350.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mary Senger\", \"Dr. Latoria Eichmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    18 runs   (    0.59 ms per token,  1687.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.82 ms /   160 tokens (    7.27 ms per token,   137.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1361.50 ms /    17 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2676.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"868 544 1615\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    15 runs   (    0.54 ms per token,  1868.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.44 ms /    25 tokens (   10.22 ms per token,    97.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.56 ms /    14 runs   (   81.61 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1513.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     9 runs   (    0.29 ms per token,  3460.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.10 ms /    23 tokens (   11.05 ms per token,    90.52 tokens per second)\n",
      "llama_print_timings:        eval time =     653.66 ms /     8 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     947.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5917.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.86 ms /    24 tokens (   10.62 ms per token,    94.17 tokens per second)\n",
      "llama_print_timings:        eval time =      93.34 ms /     1 runs   (   93.34 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     353.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ethyl Herzog\", \"Dr. Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    16 runs   (    0.51 ms per token,  1960.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.73 ms /   150 tokens (    7.80 ms per token,   128.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.36 ms /    15 runs   (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2524.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"487 321 3764\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2069.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.74 ms /    25 tokens (   10.23 ms per token,    97.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.15 ms /    14 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1504.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3640.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.04 ms /    23 tokens (   11.00 ms per token,    90.89 tokens per second)\n",
      "llama_print_timings:        eval time =     497.41 ms /     6 runs   (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     794.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\", \"stress\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    15 runs   (    0.43 ms per token,  2345.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    24 tokens (   10.58 ms per token,    94.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.74 ms /    14 runs   (   80.48 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1476.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Monty Leannon\", \"Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.11 ms /    12 runs   (    0.43 ms per token,  2347.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.69 ms /   175 tokens (    8.00 ms per token,   124.94 tokens per second)\n",
      "llama_print_timings:        eval time =     876.49 ms /    11 runs   (   79.68 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    2368.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 796 3867\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.93 ms /    15 runs   (    0.53 ms per token,  1890.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.92 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.78 ms /    14 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1501.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.92 ms /    23 tokens (   11.04 ms per token,    90.58 tokens per second)\n",
      "llama_print_timings:        eval time =      87.27 ms /     1 runs   (   87.27 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =     346.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    24 tokens (   10.59 ms per token,    94.47 tokens per second)\n",
      "llama_print_timings:        eval time =     103.69 ms /     1 runs   (  103.69 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     365.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brittany Moen\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.34 ms /    18 runs   (    0.52 ms per token,  1928.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.86 ms /   161 tokens (    8.65 ms per token,   115.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1360.31 ms /    17 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2893.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 564 449 7772\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.57 ms /    19 runs   (    0.66 ms per token,  1511.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.35 ms /    25 tokens (   10.17 ms per token,    98.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1449.70 ms /    18 runs   (   80.54 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1867.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    23 tokens (   11.00 ms per token,    90.92 tokens per second)\n",
      "llama_print_timings:        eval time =      95.74 ms /     1 runs   (   95.74 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     354.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7462.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.68 ms /    24 tokens (   10.57 ms per token,    94.61 tokens per second)\n",
      "llama_print_timings:        eval time =      94.81 ms /     1 runs   (   94.81 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     352.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Tama Champlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    11 runs   (    0.51 ms per token,  1960.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.51 ms /   163 tokens (    8.54 ms per token,   117.14 tokens per second)\n",
      "llama_print_timings:        eval time =     803.72 ms /    10 runs   (   80.37 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2269.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"897 226 8140\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2255.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.24 ms /    25 tokens (   10.21 ms per token,    97.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.40 ms /    14 runs   (   80.46 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1499.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     7 runs   (    0.21 ms per token,  4729.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.39 ms /    23 tokens (   10.97 ms per token,    91.13 tokens per second)\n",
      "llama_print_timings:        eval time =     496.04 ms /     6 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     777.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7751.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.15 ms /    24 tokens (   10.59 ms per token,    94.43 tokens per second)\n",
      "llama_print_timings:        eval time =      93.71 ms /     1 runs   (   93.71 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     352.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Paulene Hoeger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    11 runs   (    0.45 ms per token,  2242.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.26 ms /   215 tokens (    7.77 ms per token,   128.72 tokens per second)\n",
      "llama_print_timings:        eval time =     824.78 ms /    10 runs   (   82.48 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    2581.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"896 188 8819\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.62 ms /    15 runs   (    0.44 ms per token,  2264.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.80 ms /    25 tokens (   10.27 ms per token,    97.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1164.74 ms /    14 runs   (   83.20 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1520.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     7 runs   (    0.26 ms per token,  3910.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    23 tokens (   10.99 ms per token,    90.99 tokens per second)\n",
      "llama_print_timings:        eval time =     511.08 ms /     6 runs   (   85.18 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     796.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2712.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.70 ms /    24 tokens (   10.57 ms per token,    94.60 tokens per second)\n",
      "llama_print_timings:        eval time =     572.54 ms /     7 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     875.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brenton Mertz\", \"Doctor Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.26 ms /    20 runs   (    0.51 ms per token,  1949.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.23 ms /   152 tokens (    7.72 ms per token,   129.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1527.17 ms /    19 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2871.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"865 557 8000\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1881.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.49 ms /    25 tokens (   10.22 ms per token,    97.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.71 ms /    14 runs   (   80.98 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1506.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     8 runs   (    0.31 ms per token,  3253.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    23 tokens (   10.94 ms per token,    91.38 tokens per second)\n",
      "llama_print_timings:        eval time =     579.14 ms /     7 runs   (   82.73 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     865.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.16 ms /     2 runs   (    0.08 ms per token, 12269.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.49 ms /    24 tokens (   10.60 ms per token,    94.31 tokens per second)\n",
      "llama_print_timings:        eval time =      90.84 ms /     1 runs   (   90.84 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =     348.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Andrea Jenkins\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     6 runs   (    0.30 ms per token,  3384.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1424.66 ms /   190 tokens (    7.50 ms per token,   133.36 tokens per second)\n",
      "llama_print_timings:        eval time =     403.67 ms /     5 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1857.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 402 7852\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2016.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.99 ms /    25 tokens (   10.24 ms per token,    97.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.86 ms /    14 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1499.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.67 ms /    23 tokens (   11.07 ms per token,    90.31 tokens per second)\n",
      "llama_print_timings:        eval time =      91.66 ms /     1 runs   (   91.66 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     352.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Childhood asthma\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     8 runs   (    0.39 ms per token,  2578.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.64 ms /    24 tokens (   10.61 ms per token,    94.25 tokens per second)\n",
      "llama_print_timings:        eval time =     581.57 ms /     7 runs   (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     882.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Danette Gulgowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    11 runs   (    0.52 ms per token,  1908.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.81 ms /   163 tokens (    8.53 ms per token,   117.20 tokens per second)\n",
      "llama_print_timings:        eval time =     802.21 ms /    10 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2270.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"683 608 2093\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    15 runs   (    0.60 ms per token,  1671.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.76 ms /    25 tokens (   10.23 ms per token,    97.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.69 ms /    14 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1506.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     9 runs   (    0.28 ms per token,  3574.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.70 ms /    23 tokens (   11.07 ms per token,    90.30 tokens per second)\n",
      "llama_print_timings:        eval time =     650.97 ms /     8 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     952.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    11 runs   (    0.38 ms per token,  2600.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    24 tokens (   10.60 ms per token,    94.35 tokens per second)\n",
      "llama_print_timings:        eval time =     814.42 ms /    10 runs   (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1139.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mohammad McClure\", \"Dr. Rueben Friesen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.24 ms /    20 runs   (    0.51 ms per token,  1952.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.57 ms /   184 tokens (    7.69 ms per token,   129.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1526.75 ms /    19 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    3107.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 819 1962\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    15 runs   (    0.60 ms per token,  1656.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.26 ms /    25 tokens (   10.25 ms per token,    97.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.50 ms /    14 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1522.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     8 runs   (    0.39 ms per token,  2546.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    23 tokens (   11.09 ms per token,    90.17 tokens per second)\n",
      "llama_print_timings:        eval time =     576.12 ms /     7 runs   (   82.30 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     873.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6349.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =      92.62 ms /     1 runs   (   92.62 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     352.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Darnell Kertzmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    13 runs   (    0.45 ms per token,  2229.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.53 ms /   188 tokens (    7.53 ms per token,   132.81 tokens per second)\n",
      "llama_print_timings:        eval time =     968.71 ms /    12 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2468.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"447 858 0249\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.59 ms /    15 runs   (    0.57 ms per token,  1745.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    25 tokens (   10.26 ms per token,    97.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.29 ms /    14 runs   (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1502.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /     9 runs   (    0.48 ms per token,  2091.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    23 tokens (   11.09 ms per token,    90.18 tokens per second)\n",
      "llama_print_timings:        eval time =     663.10 ms /     8 runs   (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     979.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.03 ms /    24 tokens (   10.63 ms per token,    94.11 tokens per second)\n",
      "llama_print_timings:        eval time =      89.89 ms /     1 runs   (   89.89 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     351.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Eric Halvorson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    10 runs   (    0.41 ms per token,  2439.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2894.28 ms /   366 tokens (    7.91 ms per token,   126.46 tokens per second)\n",
      "llama_print_timings:        eval time =     748.54 ms /     9 runs   (   83.17 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    3715.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"130 269 4578\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.31 ms /    15 runs   (    0.42 ms per token,  2377.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.29 ms /    25 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.98 ms /    14 runs   (   83.57 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1532.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     9 runs   (    0.27 ms per token,  3728.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.20 ms /    23 tokens (   11.18 ms per token,    89.43 tokens per second)\n",
      "llama_print_timings:        eval time =     674.36 ms /     8 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     978.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.52 ms /    24 tokens (   10.77 ms per token,    92.84 tokens per second)\n",
      "llama_print_timings:        eval time =      91.84 ms /     1 runs   (   91.84 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     356.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Elli Lind\", \"Dr.\", \"Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    21 runs   (    0.54 ms per token,  1863.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.87 ms /   157 tokens (    7.51 ms per token,   133.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1603.88 ms /    20 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2963.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"261 103 2152\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.54 ms /    15 runs   (    0.90 ms per token,  1107.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.90 ms /    25 tokens (   10.24 ms per token,    97.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.48 ms /    14 runs   (   83.11 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    1550.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /     9 runs   (    0.29 ms per token,  3472.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.16 ms /    23 tokens (   11.05 ms per token,    90.50 tokens per second)\n",
      "llama_print_timings:        eval time =     679.20 ms /     8 runs   (   84.90 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     980.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    24 tokens (   10.60 ms per token,    94.36 tokens per second)\n",
      "llama_print_timings:        eval time =      91.85 ms /     1 runs   (   91.85 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     352.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Enrique Konopelski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     9 runs   (    0.39 ms per token,  2594.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.19 ms /   161 tokens (    8.65 ms per token,   115.56 tokens per second)\n",
      "llama_print_timings:        eval time =     660.31 ms /     8 runs   (   82.54 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    2108.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 652 4409\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    15 runs   (    0.49 ms per token,  2054.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.15 ms /    25 tokens (   10.25 ms per token,    97.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.29 ms /    14 runs   (   82.45 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1513.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /     6 runs   (    0.25 ms per token,  3973.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.12 ms /    23 tokens (   11.05 ms per token,    90.51 tokens per second)\n",
      "llama_print_timings:        eval time =     416.62 ms /     5 runs   (   83.32 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     696.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     9 runs   (    0.23 ms per token,  4339.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.65 ms /    24 tokens (   10.61 ms per token,    94.25 tokens per second)\n",
      "llama_print_timings:        eval time =     685.44 ms /     8 runs   (   85.68 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     988.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Daryl Hermiston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /    12 runs   (    0.45 ms per token,  2240.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.47 ms /   148 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
      "llama_print_timings:        eval time =     890.54 ms /    11 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2142.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 266 496 6700\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.42 ms /    19 runs   (    0.50 ms per token,  2017.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.82 ms /    25 tokens (   10.23 ms per token,    97.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.06 ms /    18 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1862.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"62-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.98 ms /    23 tokens (   11.04 ms per token,    90.56 tokens per second)\n",
      "llama_print_timings:        eval time =     660.76 ms /     8 runs   (   82.60 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     966.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /     8 runs   (    0.46 ms per token,  2154.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    24 tokens (   10.53 ms per token,    95.01 tokens per second)\n",
      "llama_print_timings:        eval time =     567.62 ms /     7 runs   (   81.09 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     867.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jody Friesen\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    15 runs   (    0.51 ms per token,  1972.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.52 ms /   135 tokens (    8.60 ms per token,   116.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.92 ms /    14 runs   (   79.92 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2402.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 957 8426\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    15 runs   (    0.54 ms per token,  1862.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.19 ms /    25 tokens (   10.21 ms per token,    97.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.70 ms /    14 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1501.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7462.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    23 tokens (   11.02 ms per token,    90.75 tokens per second)\n",
      "llama_print_timings:        eval time =      90.00 ms /     1 runs   (   90.00 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =     348.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     8 runs   (    0.47 ms per token,  2136.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.61 ms /    24 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =     578.72 ms /     7 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     884.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Merna Okuneva\", \"Bernie Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.91 ms /    18 runs   (    0.66 ms per token,  1511.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1655.28 ms /   224 tokens (    7.39 ms per token,   135.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1381.68 ms /    17 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    3208.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"175 873 3746\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    15 runs   (    0.55 ms per token,  1828.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.22 ms /    25 tokens (   10.29 ms per token,    97.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.17 ms /    14 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1520.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.13 ms /    23 tokens (   11.09 ms per token,    90.15 tokens per second)\n",
      "llama_print_timings:        eval time =      93.47 ms /     1 runs   (   93.47 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     354.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10928.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.23 ms /    24 tokens (   10.63 ms per token,    94.03 tokens per second)\n",
      "llama_print_timings:        eval time =      84.13 ms /     1 runs   (   84.13 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     342.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wilmer Lesch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /     9 runs   (    0.46 ms per token,  2170.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.08 ms /   151 tokens (    7.75 ms per token,   129.05 tokens per second)\n",
      "llama_print_timings:        eval time =     648.80 ms /     8 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1880.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"673 186 1531\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    15 runs   (    0.53 ms per token,  1903.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.89 ms /    25 tokens (   10.20 ms per token,    98.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.45 ms /    14 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1495.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.51 ms /    23 tokens (   11.02 ms per token,    90.73 tokens per second)\n",
      "llama_print_timings:        eval time =      96.11 ms /     1 runs   (   96.11 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =     355.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    17 runs   (    0.49 ms per token,  2024.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    24 tokens (   10.51 ms per token,    95.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1295.25 ms /    16 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1689.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Steven Christiansen\", \"Dr.\", \"Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.08 ms /    22 runs   (    0.59 ms per token,  1681.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.12 ms /   150 tokens (    7.81 ms per token,   127.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1690.68 ms /    21 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    3056.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"173 238 7291\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    15 runs   (    0.50 ms per token,  1985.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.91 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.96 ms /    14 runs   (   81.07 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1512.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     9 runs   (    0.25 ms per token,  3978.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.29 ms /    23 tokens (   11.01 ms per token,    90.81 tokens per second)\n",
      "llama_print_timings:        eval time =     652.17 ms /     8 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     943.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     8 runs   (    0.48 ms per token,  2086.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.28 ms /    24 tokens (   10.59 ms per token,    94.39 tokens per second)\n",
      "llama_print_timings:        eval time =     571.75 ms /     7 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     876.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Shelba Pfannerstill\", \"Dr. Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.70 ms /    21 runs   (    0.51 ms per token,  1962.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.48 ms /   168 tokens (    8.35 ms per token,   119.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.78 ms /    20 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    3185.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"299 289 6686\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.88 ms /    15 runs   (    0.59 ms per token,  1688.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.91 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.19 ms /    14 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1508.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     7 runs   (    0.27 ms per token,  3761.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.66 ms /    23 tokens (   10.99 ms per token,    91.03 tokens per second)\n",
      "llama_print_timings:        eval time =     498.94 ms /     6 runs   (   83.16 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     779.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    11 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.49 ms /    24 tokens (   10.56 ms per token,    94.68 tokens per second)\n",
      "llama_print_timings:        eval time =     809.19 ms /    10 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1137.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Arlinda Bosco\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.69 ms /    16 runs   (    0.54 ms per token,  1840.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.68 ms /   161 tokens (    8.64 ms per token,   115.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1202.80 ms /    15 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2722.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"416 671 2230\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.67 ms /    15 runs   (    0.51 ms per token,  1954.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    25 tokens (   10.24 ms per token,    97.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.02 ms /    14 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1493.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.89 ms /     9 runs   (    0.54 ms per token,  1841.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    23 tokens (   11.06 ms per token,    90.43 tokens per second)\n",
      "llama_print_timings:        eval time =     654.18 ms /     8 runs   (   81.77 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     973.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5747.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.35 ms /    24 tokens (   10.60 ms per token,    94.36 tokens per second)\n",
      "llama_print_timings:        eval time =      96.21 ms /     1 runs   (   96.21 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =     356.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rodolfo Murphy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /    10 runs   (    0.57 ms per token,  1761.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.55 ms /   140 tokens (    8.30 ms per token,   120.43 tokens per second)\n",
      "llama_print_timings:        eval time =     719.73 ms /     9 runs   (   79.97 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1955.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"380 817 0611\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    15 runs   (    0.54 ms per token,  1852.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    25 tokens (   10.20 ms per token,    98.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.65 ms /    14 runs   (   80.55 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1488.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2330.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.43 ms /    23 tokens (   11.02 ms per token,    90.75 tokens per second)\n",
      "llama_print_timings:        eval time =     654.42 ms /     8 runs   (   81.80 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     963.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.60 ms /     8 runs   (    0.45 ms per token,  2222.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.60 ms /    24 tokens (   10.61 ms per token,    94.27 tokens per second)\n",
      "llama_print_timings:        eval time =     568.28 ms /     7 runs   (   81.18 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     873.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hal Spinka\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.16 ms /     9 runs   (    0.46 ms per token,  2163.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.46 ms /   141 tokens (    8.24 ms per token,   121.29 tokens per second)\n",
      "llama_print_timings:        eval time =     642.67 ms /     8 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1873.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"870 248 7671\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    15 runs   (    0.53 ms per token,  1900.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.19 ms /    25 tokens (   10.25 ms per token,    97.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.50 ms /    14 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1512.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     9 runs   (    0.40 ms per token,  2511.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.14 ms /    23 tokens (   11.01 ms per token,    90.86 tokens per second)\n",
      "llama_print_timings:        eval time =     653.57 ms /     8 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     967.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7633.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =      93.54 ms /     1 runs   (   93.54 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =     351.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Deon Stoltenberg\", \"Doctor Rhett Padberg\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.46 ms /    19 runs   (    0.55 ms per token,  1816.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.05 ms /   165 tokens (    8.45 ms per token,   118.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.14 ms /    18 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    3001.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"502 876 1381\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    15 runs   (    0.44 ms per token,  2274.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.73 ms /    25 tokens (   10.27 ms per token,    97.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.68 ms /    14 runs   (   81.62 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1501.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     9 runs   (    0.30 ms per token,  3291.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.05 ms /    23 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =     655.28 ms /     8 runs   (   81.91 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     949.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.74 ms /     8 runs   (    0.47 ms per token,  2138.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    24 tokens (   10.60 ms per token,    94.30 tokens per second)\n",
      "llama_print_timings:        eval time =     571.75 ms /     7 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     875.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Lashon Rau\", \"Dr. Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    19 runs   (    0.52 ms per token,  1927.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.46 ms /   151 tokens (    7.78 ms per token,   128.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1448.97 ms /    18 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2782.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"648 361 1744\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    15 runs   (    0.49 ms per token,  2041.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.19 ms /    25 tokens (   10.25 ms per token,    97.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.25 ms /    14 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1517.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     9 runs   (    0.40 ms per token,  2484.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.07 ms /    23 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =     659.64 ms /     8 runs   (   82.45 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     971.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2611.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.89 ms /    24 tokens (   10.62 ms per token,    94.16 tokens per second)\n",
      "llama_print_timings:        eval time =     569.14 ms /     7 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     866.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lemuel Mosciski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    10 runs   (    0.41 ms per token,  2453.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.58 ms /   186 tokens (    7.63 ms per token,   131.03 tokens per second)\n",
      "llama_print_timings:        eval time =     730.12 ms /     9 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2215.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"754 862 8839\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    15 runs   (    0.52 ms per token,  1925.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.43 ms /    25 tokens (   10.26 ms per token,    97.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.83 ms /    14 runs   (   81.35 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1521.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     6 runs   (    0.17 ms per token,  5946.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.10 ms /    23 tokens (   11.09 ms per token,    90.16 tokens per second)\n",
      "llama_print_timings:        eval time =     418.35 ms /     5 runs   (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     692.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5602.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    24 tokens (   10.63 ms per token,    94.05 tokens per second)\n",
      "llama_print_timings:        eval time =      93.35 ms /     1 runs   (   93.35 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     353.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rosena Kohler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    10 runs   (    0.62 ms per token,  1610.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.94 ms /   156 tokens (    7.54 ms per token,   132.66 tokens per second)\n",
      "llama_print_timings:        eval time =     725.75 ms /     9 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1981.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"589 202 1256\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1810.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.91 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.15 ms /    14 runs   (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1497.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.57 ms /     7 runs   (    0.22 ms per token,  4452.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.18 ms /    23 tokens (   11.05 ms per token,    90.49 tokens per second)\n",
      "llama_print_timings:        eval time =     493.09 ms /     6 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     776.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /     9 runs   (    0.40 ms per token,  2505.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    24 tokens (   10.61 ms per token,    94.28 tokens per second)\n",
      "llama_print_timings:        eval time =     656.27 ms /     8 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     968.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Reuben Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /     9 runs   (    0.50 ms per token,  2005.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1648.24 ms /   197 tokens (    8.37 ms per token,   119.52 tokens per second)\n",
      "llama_print_timings:        eval time =     654.76 ms /     8 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    2367.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"847 432 4656\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    15 runs   (    0.48 ms per token,  2097.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    25 tokens (   10.25 ms per token,    97.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.50 ms /    14 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1500.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /     9 runs   (    0.32 ms per token,  3089.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.23 ms /    23 tokens (   11.05 ms per token,    90.47 tokens per second)\n",
      "llama_print_timings:        eval time =     661.01 ms /     8 runs   (   82.63 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     956.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    24 tokens (   10.55 ms per token,    94.77 tokens per second)\n",
      "llama_print_timings:        eval time =      89.27 ms /     1 runs   (   89.27 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =     348.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Jene Schowalter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    11 runs   (    0.40 ms per token,  2476.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.66 ms /   166 tokens (    8.41 ms per token,   118.86 tokens per second)\n",
      "llama_print_timings:        eval time =     814.08 ms /    10 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    2286.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 181 6134\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    15 runs   (    0.56 ms per token,  1796.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.75 ms /    25 tokens (   10.23 ms per token,    97.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.60 ms /    14 runs   (   80.83 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1498.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =      89.48 ms /     1 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     346.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.74 ms /    24 tokens (   10.57 ms per token,    94.58 tokens per second)\n",
      "llama_print_timings:        eval time =     104.57 ms /     1 runs   (  104.57 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =     362.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wes Streich\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    15 runs   (    0.47 ms per token,  2139.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     946.41 ms /   120 tokens (    7.89 ms per token,   126.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.51 ms /    14 runs   (   80.68 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2198.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"418 265 6567\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    15 runs   (    0.40 ms per token,  2525.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.59 ms /    25 tokens (   10.18 ms per token,    98.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.80 ms /    14 runs   (   81.34 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1494.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.11 ms /     7 runs   (    0.30 ms per token,  3312.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    23 tokens (   11.04 ms per token,    90.56 tokens per second)\n",
      "llama_print_timings:        eval time =     482.35 ms /     6 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     772.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /     8 runs   (    0.38 ms per token,  2603.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.93 ms /    24 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =     566.52 ms /     7 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     867.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hien Kunde\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    10 runs   (    0.42 ms per token,  2368.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.97 ms /   153 tokens (    7.68 ms per token,   130.22 tokens per second)\n",
      "llama_print_timings:        eval time =     725.69 ms /     9 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1971.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"344 901 3727\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    15 runs   (    0.49 ms per token,  2052.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.07 ms /    25 tokens (   10.24 ms per token,    97.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.03 ms /    14 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1500.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.44 ms /     7 runs   (    0.35 ms per token,  2865.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.77 ms /    23 tokens (   11.03 ms per token,    90.63 tokens per second)\n",
      "llama_print_timings:        eval time =     486.92 ms /     6 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     780.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =      93.78 ms /     1 runs   (   93.78 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =     353.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raymon Klein\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    17 runs   (    0.48 ms per token,  2098.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1418.84 ms /   188 tokens (    7.55 ms per token,   132.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1320.60 ms /    16 runs   (   82.54 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    2865.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"213 428 3849\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.21 ms /    15 runs   (    0.41 ms per token,  2415.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    25 tokens (   10.24 ms per token,    97.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.27 ms /    14 runs   (   81.66 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1505.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /     9 runs   (    0.36 ms per token,  2764.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    23 tokens (   11.06 ms per token,    90.39 tokens per second)\n",
      "llama_print_timings:        eval time =     658.14 ms /     8 runs   (   82.27 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     969.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.51 ms /    24 tokens (   10.65 ms per token,    93.93 tokens per second)\n",
      "llama_print_timings:        eval time =      92.16 ms /     1 runs   (   92.16 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     353.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jimmie Kreiger\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    15 runs   (    0.54 ms per token,  1857.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.27 ms /   147 tokens (    7.93 ms per token,   126.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.10 ms /    14 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2417.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 111 3260\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    15 runs   (    0.59 ms per token,  1695.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    25 tokens (   10.21 ms per token,    97.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.72 ms /    14 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1508.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.65 ms /     9 runs   (    0.41 ms per token,  2464.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.75 ms /    23 tokens (   11.03 ms per token,    90.64 tokens per second)\n",
      "llama_print_timings:        eval time =     656.16 ms /     8 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     961.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.71 ms /    24 tokens (   10.57 ms per token,    94.60 tokens per second)\n",
      "llama_print_timings:        eval time =      92.04 ms /     1 runs   (   92.04 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     350.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Elise Lakin\", \"Emilio Barton\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.80 ms /    16 runs   (    0.49 ms per token,  2051.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.72 ms /   172 tokens (    8.12 ms per token,   123.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1211.61 ms /    15 runs   (   80.77 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    2734.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"573 687 4170\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    15 runs   (    0.53 ms per token,  1895.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.55 ms /    25 tokens (   10.26 ms per token,    97.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.16 ms /    14 runs   (   81.80 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1526.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     7 runs   (    0.22 ms per token,  4566.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.13 ms /    23 tokens (   11.05 ms per token,    90.50 tokens per second)\n",
      "llama_print_timings:        eval time =     495.50 ms /     6 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     777.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     8 runs   (    0.39 ms per token,  2574.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.67 ms /    24 tokens (   10.61 ms per token,    94.24 tokens per second)\n",
      "llama_print_timings:        eval time =     568.99 ms /     7 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     873.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Willian Pollich\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /     9 runs   (    0.56 ms per token,  1795.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.45 ms /   147 tokens (    7.97 ms per token,   125.49 tokens per second)\n",
      "llama_print_timings:        eval time =     642.55 ms /     8 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1880.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"493 211 8555\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    15 runs   (    0.54 ms per token,  1836.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.55 ms /    25 tokens (   10.14 ms per token,    98.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.29 ms /    14 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1511.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     7 runs   (    0.18 ms per token,  5455.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.84 ms /    23 tokens (   10.99 ms per token,    90.97 tokens per second)\n",
      "llama_print_timings:        eval time =     495.08 ms /     6 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     769.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.67 ms /    11 runs   (    0.42 ms per token,  2353.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.87 ms /    24 tokens (   10.58 ms per token,    94.54 tokens per second)\n",
      "llama_print_timings:        eval time =     809.31 ms /    10 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1137.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.87 ms /   177 tokens (    7.93 ms per token,   126.08 tokens per second)\n",
      "llama_print_timings:        eval time =      96.93 ms /     1 runs   (   96.93 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =    1504.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"534 443 4572\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    15 runs   (    0.52 ms per token,  1939.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.96 ms /    25 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.73 ms /    14 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1496.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"62\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     5 runs   (    0.21 ms per token,  4734.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    23 tokens (   11.15 ms per token,    89.72 tokens per second)\n",
      "llama_print_timings:        eval time =     325.20 ms /     4 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     598.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /     8 runs   (    0.35 ms per token,  2877.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.20 ms /    24 tokens (   10.59 ms per token,    94.41 tokens per second)\n",
      "llama_print_timings:        eval time =     574.57 ms /     7 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     877.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Barney Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2491.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.23 ms /   164 tokens (    8.53 ms per token,   117.29 tokens per second)\n",
      "llama_print_timings:        eval time =     659.01 ms /     8 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    2114.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 192 683 1428\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.25 ms /    19 runs   (    0.54 ms per token,  1853.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.11 ms /    25 tokens (   10.20 ms per token,    98.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1476.86 ms /    18 runs   (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1887.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     7 runs   (    0.28 ms per token,  3562.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.73 ms /    23 tokens (   11.08 ms per token,    90.29 tokens per second)\n",
      "llama_print_timings:        eval time =     503.14 ms /     6 runs   (   83.86 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     797.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =      90.53 ms /     1 runs   (   90.53 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =     349.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jutta Ruecker\", \"Shannon Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.97 ms /    19 runs   (    0.58 ms per token,  1732.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.93 ms /   171 tokens (    8.16 ms per token,   122.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.16 ms /    18 runs   (   80.01 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2995.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"424 961 1294\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    15 runs   (    0.55 ms per token,  1822.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    25 tokens (   10.23 ms per token,    97.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.32 ms /    14 runs   (   80.74 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1504.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2301.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.93 ms /    23 tokens (   11.04 ms per token,    90.58 tokens per second)\n",
      "llama_print_timings:        eval time =     656.63 ms /     8 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     961.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6134.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    24 tokens (   10.58 ms per token,    94.54 tokens per second)\n",
      "llama_print_timings:        eval time =      90.58 ms /     1 runs   (   90.58 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     349.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Deandre Renner\", \"Dr. Ramiro Anderson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    17 runs   (    0.53 ms per token,  1879.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.97 ms /   167 tokens (    8.37 ms per token,   119.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1286.28 ms /    16 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2820.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"310 848 4411\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    15 runs   (    0.57 ms per token,  1757.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /    25 tokens (   10.23 ms per token,    97.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.68 ms /    14 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1509.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.37 ms per token,  2732.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.33 ms /    23 tokens (   11.06 ms per token,    90.43 tokens per second)\n",
      "llama_print_timings:        eval time =     663.86 ms /     8 runs   (   82.98 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     971.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6369.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    24 tokens (   10.53 ms per token,    94.96 tokens per second)\n",
      "llama_print_timings:        eval time =      91.48 ms /     1 runs   (   91.48 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     349.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Wilma Yundt\", \"Eldon Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.45 ms /    19 runs   (    0.55 ms per token,  1818.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.28 ms /   156 tokens (    7.53 ms per token,   132.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1439.25 ms /    18 runs   (   79.96 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2782.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"812 499 6629\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    15 runs   (    0.49 ms per token,  2057.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.71 ms /    25 tokens (   10.15 ms per token,    98.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.49 ms /    14 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1514.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2562.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    23 tokens (   11.04 ms per token,    90.56 tokens per second)\n",
      "llama_print_timings:        eval time =     656.18 ms /     8 runs   (   82.02 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     972.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8032.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.43 ms /    24 tokens (   10.60 ms per token,    94.33 tokens per second)\n",
      "llama_print_timings:        eval time =      95.36 ms /     1 runs   (   95.36 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     354.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Donna Fay\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.44 ms /    19 runs   (    0.55 ms per token,  1819.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.68 ms /   205 tokens (    8.01 ms per token,   124.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1446.57 ms /    18 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    3257.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"448 827 4563\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    15 runs   (    0.52 ms per token,  1905.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.98 ms /    25 tokens (   10.20 ms per token,    98.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.41 ms /    14 runs   (   81.60 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1513.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.89 ms /     9 runs   (    0.32 ms per token,  3117.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.52 ms /    23 tokens (   11.07 ms per token,    90.37 tokens per second)\n",
      "llama_print_timings:        eval time =     664.41 ms /     8 runs   (   83.05 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     979.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2650.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    24 tokens (   10.60 ms per token,    94.36 tokens per second)\n",
      "llama_print_timings:        eval time =     570.03 ms /     7 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     874.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Evelynn O'Kon\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.23 ms /    13 runs   (    0.63 ms per token,  1579.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.23 ms /   148 tokens (    7.90 ms per token,   126.58 tokens per second)\n",
      "llama_print_timings:        eval time =     964.36 ms /    12 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2240.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 507 743 6102\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.20 ms /    19 runs   (    0.64 ms per token,  1557.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.99 ms /    25 tokens (   10.24 ms per token,    97.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1476.74 ms /    18 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1892.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /     9 runs   (    0.49 ms per token,  2024.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    23 tokens (   10.95 ms per token,    91.35 tokens per second)\n",
      "llama_print_timings:        eval time =     660.43 ms /     8 runs   (   82.55 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     972.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5730.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.88 ms /    24 tokens (   10.58 ms per token,    94.53 tokens per second)\n",
      "llama_print_timings:        eval time =      96.02 ms /     1 runs   (   96.02 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =     355.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Gavin Abernathy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    10 runs   (    0.58 ms per token,  1712.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.66 ms /   133 tokens (    8.68 ms per token,   115.19 tokens per second)\n",
      "llama_print_timings:        eval time =     722.24 ms /     9 runs   (   80.25 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1959.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 127 9916\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    15 runs   (    0.53 ms per token,  1896.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.84 ms /    25 tokens (   10.23 ms per token,    97.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.25 ms /    14 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1500.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     7 runs   (    0.19 ms per token,  5267.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.59 ms /    23 tokens (   11.03 ms per token,    90.70 tokens per second)\n",
      "llama_print_timings:        eval time =     496.69 ms /     6 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     777.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  4975.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.64 ms /    24 tokens (   10.57 ms per token,    94.62 tokens per second)\n",
      "llama_print_timings:        eval time =      91.75 ms /     1 runs   (   91.75 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =     351.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Sybil Bauch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    12 runs   (    0.40 ms per token,  2517.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.78 ms /   149 tokens (    7.86 ms per token,   127.16 tokens per second)\n",
      "llama_print_timings:        eval time =     884.35 ms /    11 runs   (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2138.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"413 842 9756\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2364.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.98 ms /    25 tokens (   10.24 ms per token,    97.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.36 ms /    14 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1504.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"65-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /     9 runs   (    0.42 ms per token,  2391.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.27 ms /    23 tokens (   10.97 ms per token,    91.17 tokens per second)\n",
      "llama_print_timings:        eval time =     662.25 ms /     8 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     973.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2330.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =     576.15 ms /     7 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     875.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Arlette Watsica\", \"Doctor Riley Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.81 ms /    20 runs   (    0.54 ms per token,  1850.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.87 ms /   165 tokens (    8.45 ms per token,   118.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1526.55 ms /    19 runs   (   80.34 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    3084.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"749 692 6446\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.89 ms /    15 runs   (    0.53 ms per token,  1901.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.90 ms /    25 tokens (   10.16 ms per token,    98.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.21 ms /    14 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1510.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     9 runs   (    0.46 ms per token,  2172.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.73 ms /    23 tokens (   11.03 ms per token,    90.65 tokens per second)\n",
      "llama_print_timings:        eval time =     657.54 ms /     8 runs   (   82.19 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     961.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /     8 runs   (    0.36 ms per token,  2805.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.68 ms /    24 tokens (   10.61 ms per token,    94.24 tokens per second)\n",
      "llama_print_timings:        eval time =     589.91 ms /     7 runs   (   84.27 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     880.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ezra Feest\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    16 runs   (    0.39 ms per token,  2559.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.56 ms /   151 tokens (    7.76 ms per token,   128.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.98 ms /    15 runs   (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    2515.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"856 467 7944\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /    15 runs   (    0.18 ms per token,  5664.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.65 ms /    14 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1480.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     7 runs   (    0.11 ms per token,  9055.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.44 ms /    23 tokens (   10.85 ms per token,    92.21 tokens per second)\n",
      "llama_print_timings:        eval time =     521.92 ms /     6 runs   (   86.99 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     787.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     8 runs   (    0.13 ms per token,  7540.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.09 ms /    24 tokens (   10.50 ms per token,    95.21 tokens per second)\n",
      "llama_print_timings:        eval time =     575.21 ms /     7 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     845.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Archie Bergnaum\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /    10 runs   (    0.10 ms per token,  9596.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.91 ms /   171 tokens (    8.14 ms per token,   122.85 tokens per second)\n",
      "llama_print_timings:        eval time =     731.48 ms /     9 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2144.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"359 808 7480\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /    15 runs   (    0.11 ms per token,  9179.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.63 ms /    25 tokens (   10.15 ms per token,    98.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.81 ms /    14 runs   (   82.49 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1442.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     7 runs   (    0.10 ms per token, 10447.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.65 ms /    23 tokens (   10.94 ms per token,    91.40 tokens per second)\n",
      "llama_print_timings:        eval time =     509.31 ms /     6 runs   (   84.89 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     775.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     8 runs   (    0.11 ms per token,  9378.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    24 tokens (   10.55 ms per token,    94.81 tokens per second)\n",
      "llama_print_timings:        eval time =     579.25 ms /     7 runs   (   82.75 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     850.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lloyd Howell\", \"Cira Jakubowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /    15 runs   (    0.14 ms per token,  7235.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.78 ms /   147 tokens (    7.90 ms per token,   126.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.94 ms /    14 runs   (   82.35 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    2349.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"867 173 0931\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    15 runs   (    0.15 ms per token,  6535.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.94 ms /    14 runs   (   84.07 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1468.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     8 runs   (    0.13 ms per token,  7469.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.43 ms /    23 tokens (   10.84 ms per token,    92.21 tokens per second)\n",
      "llama_print_timings:        eval time =     575.41 ms /     7 runs   (   82.20 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     845.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    11 runs   (    0.21 ms per token,  4657.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =     786.36 ms /    10 runs   (   78.64 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1077.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Georgette Rogahn\", \"Dr. Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    17 runs   (    0.16 ms per token,  6393.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.86 ms /   189 tokens (    7.39 ms per token,   135.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1284.73 ms /    16 runs   (   80.30 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2735.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 921 6721\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.95 ms /    15 runs   (    0.13 ms per token,  7700.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.80 ms /    25 tokens (   10.19 ms per token,    98.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.65 ms /    14 runs   (   81.40 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1429.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     8 runs   (    0.11 ms per token,  9142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     587.55 ms /     7 runs   (   83.94 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     857.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /     8 runs   (    0.14 ms per token,  7332.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    24 tokens (   10.66 ms per token,    93.79 tokens per second)\n",
      "llama_print_timings:        eval time =     588.32 ms /     7 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     865.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stephane Parisian\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    10 runs   (    0.59 ms per token,  1709.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3445.46 ms /   406 tokens (    8.49 ms per token,   117.84 tokens per second)\n",
      "llama_print_timings:        eval time =     772.69 ms /     9 runs   (   85.85 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    4302.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"214 155 7643\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    15 runs   (    0.52 ms per token,  1907.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.80 ms /    25 tokens (   10.63 ms per token,    94.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.98 ms /    14 runs   (   85.71 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    1566.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5509.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.91 ms /    23 tokens (   11.21 ms per token,    89.18 tokens per second)\n",
      "llama_print_timings:        eval time =     101.83 ms /     1 runs   (  101.83 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =     365.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.60 ms /    24 tokens (   10.78 ms per token,    92.81 tokens per second)\n",
      "llama_print_timings:        eval time =      94.23 ms /     1 runs   (   94.23 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     356.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jackeline Corkery\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2612.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2685.52 ms /   335 tokens (    8.02 ms per token,   124.74 tokens per second)\n",
      "llama_print_timings:        eval time =     597.06 ms /     7 runs   (   85.29 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    3323.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 884 0448\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    15 runs   (    0.49 ms per token,  2038.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    25 tokens (   10.21 ms per token,    97.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.37 ms /    14 runs   (   86.17 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1560.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     5 runs   (    0.13 ms per token,  7716.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.92 ms /    23 tokens (   11.34 ms per token,    88.15 tokens per second)\n",
      "llama_print_timings:        eval time =     376.81 ms /     4 runs   (   94.20 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =     650.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6006.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.36 ms /    24 tokens (   10.81 ms per token,    92.54 tokens per second)\n",
      "llama_print_timings:        eval time =      97.54 ms /     1 runs   (   97.54 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     362.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lien Green\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     9 runs   (    0.23 ms per token,  4426.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.23 ms /   142 tokens (    8.40 ms per token,   119.01 tokens per second)\n",
      "llama_print_timings:        eval time =     660.62 ms /     8 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1890.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"435 117 5537\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    15 runs   (    0.44 ms per token,  2258.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.67 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.35 ms /    14 runs   (   81.38 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1485.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     8 runs   (    0.41 ms per token,  2467.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.38 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =     576.09 ms /     7 runs   (   82.30 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     877.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.07 ms /    11 runs   (    0.28 ms per token,  3584.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    24 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =     806.09 ms /    10 runs   (   80.61 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1111.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Arlinda Hegmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    12 runs   (    0.25 ms per token,  4000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1637.13 ms /   195 tokens (    8.40 ms per token,   119.11 tokens per second)\n",
      "llama_print_timings:        eval time =     886.33 ms /    11 runs   (   80.58 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2577.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"391 737 3128\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    15 runs   (    0.25 ms per token,  3991.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.56 ms /    25 tokens (   10.10 ms per token,    98.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.60 ms /    14 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1470.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.52 ms /    23 tokens (   10.98 ms per token,    91.08 tokens per second)\n",
      "llama_print_timings:        eval time =     100.68 ms /     1 runs   (  100.68 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =     359.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /    11 runs   (    0.15 ms per token,  6823.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.31 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =     808.11 ms /    10 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1092.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Stephenie Kling\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     8 runs   (    0.11 ms per token,  8705.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.81 ms /   151 tokens (    7.67 ms per token,   130.31 tokens per second)\n",
      "llama_print_timings:        eval time =     563.61 ms /     7 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1740.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 693 6991\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    19 runs   (    0.12 ms per token,  8210.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.73 ms /    25 tokens (   10.35 ms per token,    96.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1476.13 ms /    18 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1788.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.64 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =      96.00 ms /     1 runs   (   96.00 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =     350.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /    11 runs   (    0.14 ms per token,  7227.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.27 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     797.31 ms /    10 runs   (   79.73 ms per token,    12.54 tokens per second)\n",
      "llama_print_timings:       total time =    1079.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cletus Paucek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.19 ms /    10 runs   (    0.12 ms per token,  8410.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1166.52 ms /   146 tokens (    7.99 ms per token,   125.16 tokens per second)\n",
      "llama_print_timings:        eval time =     732.71 ms /     9 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1921.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"164 198 2714\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /    15 runs   (    0.11 ms per token,  9113.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.64 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.07 ms /    14 runs   (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1453.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"75 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     6 runs   (    0.10 ms per token,  9852.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     432.74 ms /     5 runs   (   86.55 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     696.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 11976.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.58 ms /    24 tokens (   10.52 ms per token,    95.02 tokens per second)\n",
      "llama_print_timings:        eval time =     112.29 ms /     1 runs   (  112.29 ms per token,     8.91 tokens per second)\n",
      "llama_print_timings:       total time =     369.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Bo Jast\", \"Dr. Marcus Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    14 runs   (    0.18 ms per token,  5663.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.42 ms /   172 tokens (    8.02 ms per token,   124.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1028.26 ms /    13 runs   (   79.10 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2456.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 165 9299\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /    15 runs   (    0.12 ms per token,  8441.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1192.07 ms /    14 runs   (   85.15 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =    1480.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     6 runs   (    0.10 ms per token,  9868.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.33 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     419.24 ms /     5 runs   (   83.85 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     682.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     7 runs   (    0.14 ms per token,  7391.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    24 tokens (   10.48 ms per token,    95.42 tokens per second)\n",
      "llama_print_timings:        eval time =     511.13 ms /     6 runs   (   85.19 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =     780.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Stormy Bernier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /    10 runs   (    0.16 ms per token,  6321.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.78 ms /   143 tokens (    8.03 ms per token,   124.48 tokens per second)\n",
      "llama_print_timings:        eval time =     742.39 ms /     9 runs   (   82.49 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1924.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"358 368 4923\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    15 runs   (    0.20 ms per token,  4958.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.96 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.17 ms /    14 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1415.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     9 runs   (    0.13 ms per token,  7839.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     656.51 ms /     8 runs   (   82.06 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     929.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8130.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.56 ms /    24 tokens (   10.40 ms per token,    96.17 tokens per second)\n",
      "llama_print_timings:        eval time =      88.81 ms /     1 runs   (   88.81 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     341.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Hue Purdy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     7 runs   (    0.15 ms per token,  6487.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2152.28 ms /   288 tokens (    7.47 ms per token,   133.81 tokens per second)\n",
      "llama_print_timings:        eval time =     515.22 ms /     6 runs   (   85.87 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    2689.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 231 3889\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.26 ms /    15 runs   (    0.22 ms per token,  4601.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.63 ms /    25 tokens (   10.23 ms per token,    97.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.88 ms /    14 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1449.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     7 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.91 ms /    23 tokens (   11.00 ms per token,    90.94 tokens per second)\n",
      "llama_print_timings:        eval time =     512.49 ms /     6 runs   (   85.42 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     782.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /    12 runs   (    0.11 ms per token,  8875.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.44 ms /    24 tokens (   10.64 ms per token,    93.96 tokens per second)\n",
      "llama_print_timings:        eval time =     921.38 ms /    11 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1205.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ruthe Beer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     8 runs   (    0.27 ms per token,  3750.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2452.94 ms /   291 tokens (    8.43 ms per token,   118.63 tokens per second)\n",
      "llama_print_timings:        eval time =     590.68 ms /     7 runs   (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    3079.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 868 3351\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    15 runs   (    0.21 ms per token,  4740.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.90 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1298.20 ms /    14 runs   (   92.73 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    1612.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7575.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.36 ms /    23 tokens (   11.15 ms per token,    89.72 tokens per second)\n",
      "llama_print_timings:        eval time =     106.04 ms /     1 runs   (  106.04 ms per token,     9.43 tokens per second)\n",
      "llama_print_timings:       total time =     368.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.23 ms /    24 tokens (   10.68 ms per token,    93.67 tokens per second)\n",
      "llama_print_timings:        eval time =      98.93 ms /     1 runs   (   98.93 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =     361.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gale Cummings\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /    10 runs   (    0.32 ms per token,  3125.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.97 ms /   137 tokens (    8.38 ms per token,   119.34 tokens per second)\n",
      "llama_print_timings:        eval time =     728.97 ms /     9 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1928.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"488 843 4764\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    15 runs   (    0.12 ms per token,  8370.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.92 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1180.73 ms /    14 runs   (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =    1479.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     7 runs   (    0.11 ms per token,  9222.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.32 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     493.06 ms /     6 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     760.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9615.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.30 ms /    24 tokens (   10.39 ms per token,    96.27 tokens per second)\n",
      "llama_print_timings:        eval time =      84.98 ms /     1 runs   (   84.98 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     338.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lucio Rempel\", \"Doctor Rueben Friesen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /    20 runs   (    0.12 ms per token,  8035.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.77 ms /   168 tokens (    8.22 ms per token,   121.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1522.32 ms /    19 runs   (   80.12 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    2955.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"549 927 1612\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /    15 runs   (    0.14 ms per token,  6922.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.45 ms /    14 runs   (   81.96 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1440.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     9 runs   (    0.18 ms per token,  5681.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    23 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     657.27 ms /     8 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     944.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     8 runs   (    0.18 ms per token,  5685.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =     559.62 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     838.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Sam Koepp\", \"Dr. Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /    17 runs   (    0.19 ms per token,  5396.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.22 ms /   157 tokens (    7.38 ms per token,   135.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1290.14 ms /    16 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2512.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"536 534 4995\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    15 runs   (    0.18 ms per token,  5703.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.85 ms /    14 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1443.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     7 runs   (    0.10 ms per token,  9929.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.68 ms /    23 tokens (   10.90 ms per token,    91.75 tokens per second)\n",
      "llama_print_timings:        eval time =     512.30 ms /     6 runs   (   85.38 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     776.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /    11 runs   (    0.10 ms per token, 10367.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    24 tokens (   10.55 ms per token,    94.77 tokens per second)\n",
      "llama_print_timings:        eval time =     934.28 ms /    10 runs   (   93.43 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =    1221.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Marcela Hahn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /    10 runs   (    0.20 ms per token,  5015.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.08 ms /   146 tokens (    7.88 ms per token,   126.95 tokens per second)\n",
      "llama_print_timings:        eval time =     726.70 ms /     9 runs   (   80.74 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1908.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"495 979 5257\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /    15 runs   (    0.17 ms per token,  5978.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.71 ms /    25 tokens (   10.11 ms per token,    98.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1188.71 ms /    14 runs   (   84.91 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =    1489.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     9 runs   (    0.19 ms per token,  5217.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.28 ms /    23 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     647.82 ms /     8 runs   (   80.98 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     930.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     6 runs   (    0.19 ms per token,  5309.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.04 ms /    24 tokens (   10.42 ms per token,    95.99 tokens per second)\n",
      "llama_print_timings:        eval time =     408.21 ms /     5 runs   (   81.64 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     677.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mike Gottlieb\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.09 ms /     9 runs   (    0.12 ms per token,  8287.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.77 ms /   145 tokens (    7.98 ms per token,   125.35 tokens per second)\n",
      "llama_print_timings:        eval time =     702.69 ms /     8 runs   (   87.84 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1878.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"671 864 7119\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /    15 runs   (    0.15 ms per token,  6482.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.07 ms /    14 runs   (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1435.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"41-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     9 runs   (    0.17 ms per token,  5795.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.48 ms /    23 tokens (   10.85 ms per token,    92.19 tokens per second)\n",
      "llama_print_timings:        eval time =     656.37 ms /     8 runs   (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     930.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =      96.36 ms /     1 runs   (   96.36 ms per token,    10.38 tokens per second)\n",
      "llama_print_timings:       total time =     356.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Nichol Carter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     9 runs   (    0.23 ms per token,  4297.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.28 ms /   146 tokens (    7.88 ms per token,   126.93 tokens per second)\n",
      "llama_print_timings:        eval time =     623.60 ms /     8 runs   (   77.95 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1815.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"329 108 3328\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /    15 runs   (    0.13 ms per token,  7780.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    25 tokens (   10.04 ms per token,    99.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1186.96 ms /    14 runs   (   84.78 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    1477.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    23 tokens (   11.13 ms per token,    89.81 tokens per second)\n",
      "llama_print_timings:        eval time =     119.41 ms /     1 runs   (  119.41 ms per token,     8.37 tokens per second)\n",
      "llama_print_timings:       total time =     384.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /    16 runs   (    0.16 ms per token,  6199.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.66 ms /    24 tokens (   10.99 ms per token,    91.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1361.20 ms /    15 runs   (   90.75 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =    1684.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Oretha Terry\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /    10 runs   (    0.40 ms per token,  2503.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2498.75 ms /   313 tokens (    7.98 ms per token,   125.26 tokens per second)\n",
      "llama_print_timings:        eval time =     737.89 ms /     9 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    3305.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"236 304 5656\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /    15 runs   (    0.28 ms per token,  3543.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.63 ms /    25 tokens (   10.31 ms per token,    97.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.71 ms /    14 runs   (   83.41 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1497.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    23 tokens (   11.06 ms per token,    90.38 tokens per second)\n",
      "llama_print_timings:        eval time =      89.75 ms /     1 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     348.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8810.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.04 ms /    24 tokens (   10.58 ms per token,    94.47 tokens per second)\n",
      "llama_print_timings:        eval time =     106.17 ms /     1 runs   (  106.17 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =     364.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Domitila Quitzon\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     9 runs   (    0.14 ms per token,  6912.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.16 ms /   151 tokens (    7.64 ms per token,   130.83 tokens per second)\n",
      "llama_print_timings:        eval time =     661.17 ms /     8 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1840.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 259 1826\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    15 runs   (    0.35 ms per token,  2826.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.35 ms /    25 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.98 ms /    14 runs   (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1497.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     8 runs   (    0.26 ms per token,  3800.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    23 tokens (   10.89 ms per token,    91.79 tokens per second)\n",
      "llama_print_timings:        eval time =     582.71 ms /     7 runs   (   83.24 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     874.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /    11 runs   (    0.20 ms per token,  5104.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.21 ms /    24 tokens (   10.51 ms per token,    95.16 tokens per second)\n",
      "llama_print_timings:        eval time =     850.98 ms /    10 runs   (   85.10 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    1161.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rey Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     8 runs   (    0.10 ms per token,  9987.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.80 ms /   153 tokens (    7.57 ms per token,   132.03 tokens per second)\n",
      "llama_print_timings:        eval time =     602.18 ms /     7 runs   (   86.03 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1783.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"615 589 6806\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /    15 runs   (    0.13 ms per token,  7828.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.83 ms /    25 tokens (   10.15 ms per token,    98.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.73 ms /    14 runs   (   81.77 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1434.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     9 runs   (    0.13 ms per token,  7922.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     681.92 ms /     8 runs   (   85.24 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     961.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    24 tokens (   10.48 ms per token,    95.46 tokens per second)\n",
      "llama_print_timings:        eval time =      99.23 ms /     1 runs   (   99.23 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =     357.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Felica Maggio\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    18 runs   (    0.19 ms per token,  5162.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1888.51 ms /   237 tokens (    7.97 ms per token,   125.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1352.54 ms /    17 runs   (   79.56 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    3310.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"554 825 5546\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /    15 runs   (    0.12 ms per token,  8165.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    25 tokens (   10.16 ms per token,    98.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.04 ms /    14 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1443.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    23 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =      97.64 ms /     1 runs   (   97.64 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     352.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11235.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    24 tokens (   10.53 ms per token,    95.01 tokens per second)\n",
      "llama_print_timings:        eval time =      95.49 ms /     1 runs   (   95.49 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     351.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ron Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     7 runs   (    0.13 ms per token,  7454.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.56 ms /   156 tokens (    7.45 ms per token,   134.30 tokens per second)\n",
      "llama_print_timings:        eval time =     487.50 ms /     6 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1667.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 822 6576\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    19 runs   (    0.19 ms per token,  5178.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.23 ms /    25 tokens (   10.05 ms per token,    99.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1440.37 ms /    18 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1756.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =      87.06 ms /     1 runs   (   87.06 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     341.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 11976.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.23 ms /    24 tokens (   10.47 ms per token,    95.53 tokens per second)\n",
      "llama_print_timings:        eval time =      94.65 ms /     1 runs   (   94.65 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     349.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Max Gutkowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     7 runs   (    0.11 ms per token,  9446.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.04 ms /   163 tokens (    8.50 ms per token,   117.69 tokens per second)\n",
      "llama_print_timings:        eval time =     488.41 ms /     6 runs   (   81.40 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1888.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 243 6735\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    15 runs   (    0.13 ms per token,  7915.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.52 ms /    14 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1427.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.21 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =      99.90 ms /     1 runs   (   99.90 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =     353.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     7 runs   (    0.15 ms per token,  6769.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.77 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =     477.61 ms /     6 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     748.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mandi Legros\", \"Jude Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /    16 runs   (    0.16 ms per token,  6216.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.45 ms /   166 tokens (    8.29 ms per token,   120.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1178.74 ms /    15 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2606.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     6 runs   (    0.11 ms per token,  8746.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.65 ms /    25 tokens (   10.23 ms per token,    97.79 tokens per second)\n",
      "llama_print_timings:        eval time =     408.60 ms /     5 runs   (   81.72 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     681.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     4 runs   (    0.10 ms per token,  9756.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.93 ms /    23 tokens (   10.91 ms per token,    91.66 tokens per second)\n",
      "llama_print_timings:        eval time =     256.54 ms /     3 runs   (   85.51 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =     518.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.91 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      89.36 ms /     1 runs   (   89.36 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =     344.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Eliseo Tremblay\", \"Palmer Kuphal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /    16 runs   (    0.12 ms per token,  8407.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.10 ms /   135 tokens (    8.46 ms per token,   118.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1231.74 ms /    15 runs   (   82.12 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    2415.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 519 1403\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    15 runs   (    0.14 ms per token,  7139.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    25 tokens (   10.02 ms per token,    99.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.21 ms /    14 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1413.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10752.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    23 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =      99.22 ms /     1 runs   (   99.22 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =     373.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     8 runs   (    0.12 ms per token,  8205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.83 ms /    24 tokens (   10.49 ms per token,    95.30 tokens per second)\n",
      "llama_print_timings:        eval time =     580.42 ms /     7 runs   (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     850.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Erich Heaney\", \"Dr Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    17 runs   (    0.29 ms per token,  3500.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.38 ms /   173 tokens (    7.97 ms per token,   125.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1235.72 ms /    16 runs   (   77.23 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =    2705.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"658 345 6932\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    15 runs   (    0.31 ms per token,  3201.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.64 ms /    14 runs   (   79.47 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1442.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6622.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =      95.36 ms /     1 runs   (   95.36 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =     349.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    24 tokens (   10.44 ms per token,    95.79 tokens per second)\n",
      "llama_print_timings:        eval time =      90.88 ms /     1 runs   (   90.88 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =     346.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Enid Pacocha\", \"Dr Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    16 runs   (    0.24 ms per token,  4081.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.24 ms /   184 tokens (    7.59 ms per token,   131.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.17 ms /    15 runs   (   77.88 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    2646.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 454 9177\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    15 runs   (    0.29 ms per token,  3453.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.61 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.60 ms /    14 runs   (   78.97 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1427.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     6 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.66 ms /    23 tokens (   10.86 ms per token,    92.12 tokens per second)\n",
      "llama_print_timings:        eval time =     399.50 ms /     5 runs   (   79.90 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     670.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    24 tokens (   10.48 ms per token,    95.43 tokens per second)\n",
      "llama_print_timings:        eval time =      97.22 ms /     1 runs   (   97.22 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =     352.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Fanny Botsford\", \"doctor\", \"Marcus Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    23 runs   (    0.28 ms per token,  3554.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.81 ms /   200 tokens (    8.12 ms per token,   123.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1708.23 ms /    22 runs   (   77.65 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    3451.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"408 141 8803\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    15 runs   (    0.26 ms per token,  3872.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.35 ms /    25 tokens (   10.09 ms per token,    99.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.02 ms /    14 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1426.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     5 runs   (    0.17 ms per token,  5889.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.75 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =     316.61 ms /     4 runs   (   79.15 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     583.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10101.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    24 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =      88.52 ms /     1 runs   (   88.52 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =     345.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Magali Bailey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     7 runs   (    0.22 ms per token,  4611.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1138.95 ms /   135 tokens (    8.44 ms per token,   118.53 tokens per second)\n",
      "llama_print_timings:        eval time =     469.31 ms /     6 runs   (   78.22 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1638.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 793 8035\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    15 runs   (    0.30 ms per token,  3284.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.13 ms /    25 tokens (   10.05 ms per token,    99.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.55 ms /    14 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1418.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"aged 7\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     6 runs   (    0.18 ms per token,  5529.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.85 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     394.11 ms /     5 runs   (   78.82 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     664.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.95 ms /    24 tokens (   10.41 ms per token,    96.02 tokens per second)\n",
      "llama_print_timings:        eval time =      90.08 ms /     1 runs   (   90.08 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =     346.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kelli Gorczany\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /    11 runs   (    0.22 ms per token,  4573.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.36 ms /   176 tokens (    7.83 ms per token,   127.78 tokens per second)\n",
      "llama_print_timings:        eval time =     788.96 ms /    10 runs   (   78.90 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    2216.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"734 327 5431\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    15 runs   (    0.26 ms per token,  3857.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    25 tokens (   10.02 ms per token,    99.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.48 ms /    14 runs   (   78.32 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1417.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     9 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    23 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     635.50 ms /     8 runs   (   79.44 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     915.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     8 runs   (    0.16 ms per token,  6284.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.44 ms /    24 tokens (   10.44 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =     554.19 ms /     7 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     830.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Chadwick Green\", \"Doctor Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    19 runs   (    0.24 ms per token,  4198.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.82 ms /   210 tokens (    7.81 ms per token,   127.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1409.29 ms /    18 runs   (   78.29 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    3145.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"704 783 6592\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    15 runs   (    0.22 ms per token,  4462.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    25 tokens (   10.11 ms per token,    98.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.80 ms /    14 runs   (   78.70 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1419.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9132.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =      91.48 ms /     1 runs   (   91.48 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     346.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /    11 runs   (    0.26 ms per token,  3910.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =     790.33 ms /    10 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1093.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Tom Schroeder\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    18 runs   (    0.31 ms per token,  3202.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1902.74 ms /   241 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1330.35 ms /    17 runs   (   78.26 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    3332.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"235 979 2369\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.71 ms /    15 runs   (    0.25 ms per token,  4040.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.02 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.30 ms /    14 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1430.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.17 ms per token,  6024.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.75 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =      90.19 ms /     1 runs   (   90.19 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     345.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10471.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =      88.91 ms /     1 runs   (   88.91 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     342.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alberto Hammes\", \"Kim Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.48 ms /    13 runs   (    0.27 ms per token,  3741.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1626.25 ms /   224 tokens (    7.26 ms per token,   137.74 tokens per second)\n",
      "llama_print_timings:        eval time =     936.97 ms /    12 runs   (   78.08 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    2634.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"681 942 3122\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    15 runs   (    0.24 ms per token,  4189.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1103.94 ms /    14 runs   (   78.85 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1427.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8810.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.81 ms /    23 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     101.94 ms /     1 runs   (  101.94 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =     357.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"childhood asthma\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     8 runs   (    0.23 ms per token,  4381.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    24 tokens (   10.44 ms per token,    95.81 tokens per second)\n",
      "llama_print_timings:        eval time =     551.48 ms /     7 runs   (   78.78 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     836.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Sandi Trantow\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    11 runs   (    0.23 ms per token,  4290.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.96 ms /   175 tokens (    7.87 ms per token,   127.09 tokens per second)\n",
      "llama_print_timings:        eval time =     777.74 ms /    10 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2204.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"232 188 5211\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    15 runs   (    0.27 ms per token,  3672.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.08 ms /    14 runs   (   78.15 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1419.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =      96.72 ms /     1 runs   (   96.72 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =     352.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     8 runs   (    0.20 ms per token,  4910.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.70 ms /    24 tokens (   10.40 ms per token,    96.12 tokens per second)\n",
      "llama_print_timings:        eval time =     549.17 ms /     7 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     832.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Michell Stiedemann\", \"Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    19 runs   (    0.26 ms per token,  3890.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2990.81 ms /   376 tokens (    7.95 ms per token,   125.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1431.09 ms /    18 runs   (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    4525.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 808 5664\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /    15 runs   (    0.30 ms per token,  3285.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.45 ms /    25 tokens (   10.26 ms per token,    97.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.75 ms /    14 runs   (   80.55 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1461.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6711.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.44 ms /    23 tokens (   11.15 ms per token,    89.69 tokens per second)\n",
      "llama_print_timings:        eval time =      92.49 ms /     1 runs   (   92.49 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =     354.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     8 runs   (    0.21 ms per token,  4686.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.37 ms /    24 tokens (   10.60 ms per token,    94.35 tokens per second)\n",
      "llama_print_timings:        eval time =     565.77 ms /     7 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     853.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Sylvie Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /    10 runs   (    0.21 ms per token,  4655.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.08 ms /   188 tokens (    7.41 ms per token,   134.95 tokens per second)\n",
      "llama_print_timings:        eval time =     707.99 ms /     9 runs   (   78.67 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    2144.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"703 623 5109\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    15 runs   (    0.28 ms per token,  3574.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.59 ms /    14 runs   (   79.40 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1440.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     9 runs   (    0.18 ms per token,  5699.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    23 tokens (   10.92 ms per token,    91.60 tokens per second)\n",
      "llama_print_timings:        eval time =     637.10 ms /     8 runs   (   79.64 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     918.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8196.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =      86.23 ms /     1 runs   (   86.23 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     341.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Fairy Corkery\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    16 runs   (    0.23 ms per token,  4287.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.70 ms /   171 tokens (    8.03 ms per token,   124.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.96 ms /    15 runs   (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    2618.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"283 985 9046\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    15 runs   (    0.25 ms per token,  3998.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.75 ms /    14 runs   (   77.98 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1413.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5189.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.19 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     530.70 ms /     6 runs   (   88.45 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     804.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     8 runs   (    0.17 ms per token,  5925.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.31 ms /    24 tokens (   10.43 ms per token,    95.88 tokens per second)\n",
      "llama_print_timings:        eval time =     561.27 ms /     7 runs   (   80.18 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     843.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kina Medhurst\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     8 runs   (    0.16 ms per token,  6211.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.31 ms /   131 tokens (    8.67 ms per token,   115.29 tokens per second)\n",
      "llama_print_timings:        eval time =     555.68 ms /     7 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1716.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 989 0823\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /    15 runs   (    0.14 ms per token,  6996.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.57 ms /    25 tokens (   10.30 ms per token,    97.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.12 ms /    14 runs   (   80.94 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1439.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     6 runs   (    0.19 ms per token,  5263.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.85 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     407.92 ms /     5 runs   (   81.58 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =     680.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     8 runs   (    0.13 ms per token,  7866.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.39 ms /    24 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =     569.52 ms /     7 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     841.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Gustavo Brakus\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     9 runs   (    0.11 ms per token,  9503.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1635.78 ms /   220 tokens (    7.44 ms per token,   134.49 tokens per second)\n",
      "llama_print_timings:        eval time =     646.70 ms /     8 runs   (   80.84 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2301.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS Number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     6 runs   (    0.14 ms per token,  7075.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =     416.84 ms /     5 runs   (   83.37 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     686.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11173.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    23 tokens (   11.01 ms per token,    90.86 tokens per second)\n",
      "llama_print_timings:        eval time =      91.49 ms /     1 runs   (   91.49 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     348.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     8 runs   (    0.11 ms per token,  9049.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.51 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =     591.20 ms /     7 runs   (   84.46 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     863.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Janet Mertz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /    11 runs   (    0.14 ms per token,  7124.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.08 ms /   188 tokens (    7.45 ms per token,   134.18 tokens per second)\n",
      "llama_print_timings:        eval time =     800.37 ms /    10 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2231.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"181 633 0293\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /    15 runs   (    0.13 ms per token,  7466.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.15 ms /    25 tokens (   10.29 ms per token,    97.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.13 ms /    14 runs   (   81.94 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1442.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10204.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    23 tokens (   10.93 ms per token,    91.49 tokens per second)\n",
      "llama_print_timings:        eval time =      91.38 ms /     1 runs   (   91.38 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     347.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     6 runs   (    0.12 ms per token,  8522.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    24 tokens (   10.48 ms per token,    95.38 tokens per second)\n",
      "llama_print_timings:        eval time =     399.30 ms /     5 runs   (   79.86 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     665.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Colton Boehm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /    10 runs   (    0.13 ms per token,  7880.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.90 ms /   162 tokens (    8.57 ms per token,   116.64 tokens per second)\n",
      "llama_print_timings:        eval time =     786.71 ms /     9 runs   (   87.41 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2203.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"827 535 9130\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /    15 runs   (    0.12 ms per token,  8004.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.24 ms /    25 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1192.81 ms /    14 runs   (   85.20 ms per token,    11.74 tokens per second)\n",
      "llama_print_timings:       total time =    1479.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     7 runs   (    0.12 ms per token,  8244.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     499.26 ms /     6 runs   (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     763.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\", \"stress\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /    12 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =     887.98 ms /    11 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1166.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Candice Hermann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.74 ms /     7 runs   (    0.11 ms per token,  9446.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.21 ms /   133 tokens (    8.68 ms per token,   115.23 tokens per second)\n",
      "llama_print_timings:        eval time =     490.43 ms /     6 runs   (   81.74 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1659.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 723 5237\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /    15 runs   (    0.15 ms per token,  6535.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.39 ms /    14 runs   (   80.31 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1420.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     8 runs   (    0.16 ms per token,  6324.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.53 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =     584.43 ms /     7 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     860.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9389.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.47 ms /    24 tokens (   10.52 ms per token,    95.06 tokens per second)\n",
      "llama_print_timings:        eval time =      91.62 ms /     1 runs   (   91.62 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     347.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marshall Morar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     8 runs   (    0.13 ms per token,  7448.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.60 ms /   185 tokens (    7.62 ms per token,   131.24 tokens per second)\n",
      "llama_print_timings:        eval time =     575.00 ms /     7 runs   (   82.14 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    2000.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"130 986 1025\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /    15 runs   (    0.12 ms per token,  8375.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.78 ms /    25 tokens (   10.15 ms per token,    98.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.79 ms /    14 runs   (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1454.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     7 runs   (    0.20 ms per token,  5105.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.02 ms /    23 tokens (   11.09 ms per token,    90.19 tokens per second)\n",
      "llama_print_timings:        eval time =     487.57 ms /     6 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     768.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     8 runs   (    0.20 ms per token,  5018.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.33 ms /    24 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =     562.23 ms /     7 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     840.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Martin Tillman\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    16 runs   (    0.26 ms per token,  3866.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.86 ms /   185 tokens (    7.51 ms per token,   133.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.29 ms /    15 runs   (   77.69 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2644.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"635 781 4011\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    15 runs   (    0.28 ms per token,  3633.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.83 ms /    25 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.94 ms /    14 runs   (   79.00 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1442.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =      87.80 ms /     1 runs   (   87.80 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     343.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     7 runs   (    0.19 ms per token,  5208.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    24 tokens (   10.41 ms per token,    96.03 tokens per second)\n",
      "llama_print_timings:        eval time =     482.91 ms /     6 runs   (   80.48 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     760.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cyrus Rath\", \"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    16 runs   (    0.26 ms per token,  3866.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.88 ms /   191 tokens (    7.31 ms per token,   136.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.52 ms /    15 runs   (   78.23 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2649.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"439 806 1195\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    15 runs   (    0.18 ms per token,  5645.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.88 ms /    25 tokens (   10.08 ms per token,    99.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.33 ms /    14 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1438.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"22 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     7 runs   (    0.10 ms per token,  9957.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     499.24 ms /     6 runs   (   83.21 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     767.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"intimate partner abuse\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     8 runs   (    0.25 ms per token,  4034.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    24 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =     549.79 ms /     7 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     833.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lyndon Borer\", \"Dr. Jacques Quigley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    18 runs   (    0.23 ms per token,  4390.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.57 ms /   143 tokens (    8.01 ms per token,   124.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1330.49 ms /    17 runs   (   78.26 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2564.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"409 925 5517\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    15 runs   (    0.25 ms per token,  4060.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    25 tokens (   10.04 ms per token,    99.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.70 ms /    14 runs   (   78.62 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1419.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     8 runs   (    0.16 ms per token,  6289.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =     554.74 ms /     7 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     829.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8510.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.68 ms /    24 tokens (   10.40 ms per token,    96.12 tokens per second)\n",
      "llama_print_timings:        eval time =      91.33 ms /     1 runs   (   91.33 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     344.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Desmond Carter\", \"Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /    14 runs   (    0.32 ms per token,  3165.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.29 ms /   141 tokens (    8.11 ms per token,   123.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.48 ms /    13 runs   (   77.19 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =    2225.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"480 662 1782\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /    15 runs   (    0.23 ms per token,  4427.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.78 ms /    14 runs   (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1479.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"65 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     7 runs   (    0.28 ms per token,  3606.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.41 ms /    23 tokens (   10.84 ms per token,    92.22 tokens per second)\n",
      "llama_print_timings:        eval time =     484.66 ms /     6 runs   (   80.78 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     764.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6849.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.75 ms /    24 tokens (   10.41 ms per token,    96.10 tokens per second)\n",
      "llama_print_timings:        eval time =      92.19 ms /     1 runs   (   92.19 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     346.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Margarita Jacobi\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.97 ms /     9 runs   (    0.22 ms per token,  4561.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3174.55 ms /   386 tokens (    8.22 ms per token,   121.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.82 ms /     8 runs   (   81.60 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    3866.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 791 119 7580\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    19 runs   (    0.30 ms per token,  3287.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.56 ms /    25 tokens (   10.26 ms per token,    97.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1441.44 ms /    18 runs   (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1801.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"77-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     9 runs   (    0.22 ms per token,  4527.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.79 ms /    23 tokens (   11.08 ms per token,    90.27 tokens per second)\n",
      "llama_print_timings:        eval time =     651.57 ms /     8 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     947.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     8 runs   (    0.18 ms per token,  5494.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    24 tokens (   10.63 ms per token,    94.05 tokens per second)\n",
      "llama_print_timings:        eval time =     578.19 ms /     7 runs   (   82.60 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     863.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shon Hayes\", \"Doctor Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /    17 runs   (    0.25 ms per token,  3933.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2585.13 ms /   331 tokens (    7.81 ms per token,   128.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1261.99 ms /    16 runs   (   78.87 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    3935.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"284 217 3404\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    15 runs   (    0.26 ms per token,  3812.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    25 tokens (   10.21 ms per token,    97.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.00 ms /    14 runs   (   80.14 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1450.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     8 runs   (    0.19 ms per token,  5270.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.72 ms /    23 tokens (   11.03 ms per token,    90.65 tokens per second)\n",
      "llama_print_timings:        eval time =     569.08 ms /     7 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     858.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     8 runs   (    0.18 ms per token,  5681.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.96 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =     570.42 ms /     7 runs   (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     853.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shelton Wolff\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    17 runs   (    0.23 ms per token,  4318.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.66 ms /   142 tokens (    8.05 ms per token,   124.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1241.47 ms /    16 runs   (   77.59 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2464.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"172 927 1215\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.59 ms /    15 runs   (    0.24 ms per token,  4181.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    25 tokens (   10.05 ms per token,    99.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.55 ms /    14 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1407.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     9 runs   (    0.23 ms per token,  4407.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.43 ms /    23 tokens (   10.84 ms per token,    92.21 tokens per second)\n",
      "llama_print_timings:        eval time =     633.83 ms /     8 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     923.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.88 ms /    24 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =      91.03 ms /     1 runs   (   91.03 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =     345.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tu Mueller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.20 ms /     9 runs   (    0.24 ms per token,  4089.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.87 ms /   147 tokens (    7.83 ms per token,   127.73 tokens per second)\n",
      "llama_print_timings:        eval time =     618.65 ms /     8 runs   (   77.33 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    1813.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"239 702 8390\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    15 runs   (    0.27 ms per token,  3690.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.44 ms /    25 tokens (   10.06 ms per token,    99.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.13 ms /    14 runs   (   78.29 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1422.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     7 runs   (    0.16 ms per token,  6092.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.24 ms /    23 tokens (   10.84 ms per token,    92.28 tokens per second)\n",
      "llama_print_timings:        eval time =     478.95 ms /     6 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     749.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     8 runs   (    0.19 ms per token,  5379.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.33 ms /    24 tokens (   10.39 ms per token,    96.26 tokens per second)\n",
      "llama_print_timings:        eval time =     549.16 ms /     7 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =     828.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Joesph Murray\", \"Dr. Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.85 ms /    15 runs   (    0.32 ms per token,  3092.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.21 ms /   164 tokens (    8.37 ms per token,   119.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.65 ms /    14 runs   (   77.55 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    2535.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 525 2098\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    15 runs   (    0.33 ms per token,  3022.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.03 ms /    25 tokens (   10.08 ms per token,    99.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.30 ms /    14 runs   (   77.95 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1420.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     8 runs   (    0.23 ms per token,  4336.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.99 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     559.67 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     846.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     7 runs   (    0.11 ms per token,  8883.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.08 ms /    24 tokens (   10.42 ms per token,    95.97 tokens per second)\n",
      "llama_print_timings:        eval time =     503.42 ms /     6 runs   (   83.90 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     768.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Chester Schneider\", \"Dr. Ciara Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    17 runs   (    0.26 ms per token,  3873.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.39 ms /   150 tokens (    7.69 ms per token,   130.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.93 ms /    16 runs   (   78.18 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2486.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"147 574 2474\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    15 runs   (    0.27 ms per token,  3657.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.94 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.17 ms /    14 runs   (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1423.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     8 runs   (    0.21 ms per token,  4714.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.20 ms /    23 tokens (   10.83 ms per token,    92.30 tokens per second)\n",
      "llama_print_timings:        eval time =     556.00 ms /     7 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     842.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    13 runs   (    0.26 ms per token,  3841.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    24 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =     940.90 ms /    12 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1245.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mohammed Gottlieb\", \"Dr. Hellen Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    17 runs   (    0.31 ms per token,  3217.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.37 ms /   175 tokens (    7.86 ms per token,   127.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1237.52 ms /    16 runs   (   77.35 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    2702.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"890 523 7463\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    15 runs   (    0.25 ms per token,  3987.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.43 ms /    25 tokens (   10.06 ms per token,    99.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.48 ms /    14 runs   (   78.18 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1417.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6153.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.17 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =      93.24 ms /     1 runs   (   93.24 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     348.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.33 ms /    24 tokens (   10.43 ms per token,    95.87 tokens per second)\n",
      "llama_print_timings:        eval time =      90.03 ms /     1 runs   (   90.03 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =     343.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Maryanna Jerde\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    10 runs   (    0.25 ms per token,  4042.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.92 ms /   148 tokens (    7.77 ms per token,   128.70 tokens per second)\n",
      "llama_print_timings:        eval time =     695.33 ms /     9 runs   (   77.26 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    1894.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"594 234 0076\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /    15 runs   (    0.27 ms per token,  3734.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.10 ms /    25 tokens (   10.04 ms per token,    99.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.19 ms /    14 runs   (   77.94 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1418.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     5 runs   (    0.15 ms per token,  6501.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.93 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     326.05 ms /     4 runs   (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     594.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /    11 runs   (    0.25 ms per token,  3946.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.60 ms /    24 tokens (   10.40 ms per token,    96.16 tokens per second)\n",
      "llama_print_timings:        eval time =     780.61 ms /    10 runs   (   78.06 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1078.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cornelius Will\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     9 runs   (    0.20 ms per token,  4980.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.86 ms /   148 tokens (    7.78 ms per token,   128.49 tokens per second)\n",
      "llama_print_timings:        eval time =     645.02 ms /     8 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1835.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"879 217 7520\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    15 runs   (    0.25 ms per token,  4005.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    25 tokens (   10.02 ms per token,    99.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.60 ms /    14 runs   (   78.04 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1413.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     7 runs   (    0.21 ms per token,  4666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.10 ms /    23 tokens (   10.83 ms per token,    92.33 tokens per second)\n",
      "llama_print_timings:        eval time =     472.65 ms /     6 runs   (   78.77 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     751.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     8 runs   (    0.22 ms per token,  4553.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    24 tokens (   10.42 ms per token,    95.97 tokens per second)\n",
      "llama_print_timings:        eval time =     548.56 ms /     7 runs   (   78.37 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =     831.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Emory Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    10 runs   (    0.23 ms per token,  4317.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3203.38 ms /   391 tokens (    8.19 ms per token,   122.06 tokens per second)\n",
      "llama_print_timings:        eval time =     721.69 ms /     9 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    3972.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"321 267 2810\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    15 runs   (    0.28 ms per token,  3534.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.71 ms /    25 tokens (   10.27 ms per token,    97.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.46 ms /    14 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1464.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"22 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4926.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.73 ms /    23 tokens (   11.08 ms per token,    90.29 tokens per second)\n",
      "llama_print_timings:        eval time =     498.11 ms /     6 runs   (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =     776.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     8 runs   (    0.22 ms per token,  4471.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.76 ms /    24 tokens (   10.62 ms per token,    94.20 tokens per second)\n",
      "llama_print_timings:        eval time =     567.01 ms /     7 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     857.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Harold Ward\", \"Dr. Jerrell Rippin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /    15 runs   (    0.24 ms per token,  4185.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.66 ms /   185 tokens (    7.51 ms per token,   133.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.28 ms /    14 runs   (   77.31 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    2543.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 352 6867\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    15 runs   (    0.28 ms per token,  3528.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.53 ms /    25 tokens (   10.10 ms per token,    99.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.84 ms /    14 runs   (   78.63 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1433.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8771.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =      87.53 ms /     1 runs   (   87.53 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     343.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8771.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =      99.67 ms /     1 runs   (   99.67 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =     354.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Laverne Murazik\", \"Dr. Hellen Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    16 runs   (    0.26 ms per token,  3875.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1619.90 ms /   206 tokens (    7.86 ms per token,   127.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.87 ms /    15 runs   (   77.92 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    2876.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 221 4006\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    15 runs   (    0.28 ms per token,  3611.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.25 ms /    14 runs   (   78.37 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1423.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =      89.75 ms /     1 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     344.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.70 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =      99.40 ms /     1 runs   (   99.40 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =     353.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marva Johnston\", \"Dr. Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    15 runs   (    0.29 ms per token,  3491.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.64 ms /   176 tokens (    7.82 ms per token,   127.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.58 ms /    14 runs   (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    2543.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 954 3107\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    15 runs   (    0.30 ms per token,  3357.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.55 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.63 ms /    14 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1434.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.93 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =      87.77 ms /     1 runs   (   87.77 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     342.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /     6 runs   (    0.23 ms per token,  4408.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =     393.74 ms /     5 runs   (   78.75 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     664.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Arden Grant\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     8 runs   (    0.23 ms per token,  4350.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.22 ms /   173 tokens (    7.96 ms per token,   125.71 tokens per second)\n",
      "llama_print_timings:        eval time =     541.69 ms /     7 runs   (   77.38 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    1951.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"435 591 5463\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    15 runs   (    0.26 ms per token,  3787.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.83 ms /    14 runs   (   78.27 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1424.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     9 runs   (    0.19 ms per token,  5360.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    23 tokens (   10.88 ms per token,    91.95 tokens per second)\n",
      "llama_print_timings:        eval time =     632.75 ms /     8 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     916.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =      91.39 ms /     1 runs   (   91.39 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     346.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jerrold Dare\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    17 runs   (    0.27 ms per token,  3751.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.11 ms /   178 tokens (    7.78 ms per token,   128.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1237.13 ms /    16 runs   (   77.32 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    2710.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 846 6874\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /    15 runs   (    0.29 ms per token,  3483.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.40 ms /    14 runs   (   78.39 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1422.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     8 runs   (    0.16 ms per token,  6092.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    23 tokens (   10.87 ms per token,    91.96 tokens per second)\n",
      "llama_print_timings:        eval time =     555.21 ms /     7 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     831.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     7 runs   (    0.21 ms per token,  4723.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.35 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     472.53 ms /     6 runs   (   78.76 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =     750.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Maire Cummings\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    11 runs   (    0.34 ms per token,  2900.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.31 ms /   146 tokens (    7.87 ms per token,   127.03 tokens per second)\n",
      "llama_print_timings:        eval time =     775.18 ms /    10 runs   (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    1986.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"258 157 9332\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    15 runs   (    0.28 ms per token,  3596.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.03 ms /    25 tokens (   10.04 ms per token,    99.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.53 ms /    14 runs   (   78.40 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1422.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     5 runs   (    0.17 ms per token,  5820.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.82 ms /    23 tokens (   10.86 ms per token,    92.07 tokens per second)\n",
      "llama_print_timings:        eval time =     325.70 ms /     4 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =     590.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     8 runs   (    0.21 ms per token,  4825.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.92 ms /    24 tokens (   10.41 ms per token,    96.03 tokens per second)\n",
      "llama_print_timings:        eval time =     544.68 ms /     7 runs   (   77.81 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     826.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jeffery Swift\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.93 ms /    18 runs   (    0.27 ms per token,  3648.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.07 ms /   137 tokens (    8.33 ms per token,   120.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.42 ms /    17 runs   (   76.97 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =    2552.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"898 486 4173\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    15 runs   (    0.27 ms per token,  3763.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    25 tokens (   10.06 ms per token,    99.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1089.97 ms /    14 runs   (   77.85 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1412.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     7 runs   (    0.17 ms per token,  6060.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    23 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     482.72 ms /     6 runs   (   80.45 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     755.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.70 ms /    24 tokens (   10.40 ms per token,    96.12 tokens per second)\n",
      "llama_print_timings:        eval time =      87.53 ms /     1 runs   (   87.53 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     341.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Theressa Weissnat\", \"Dr. Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    18 runs   (    0.24 ms per token,  4213.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.20 ms /   186 tokens (    7.50 ms per token,   133.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1315.73 ms /    17 runs   (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    2801.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"869 937 4729\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.93 ms /    15 runs   (    0.26 ms per token,  3818.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.24 ms /    25 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.86 ms /    14 runs   (   78.20 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1428.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.67 ms /     9 runs   (    0.18 ms per token,  5405.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.30 ms /    23 tokens (   10.88 ms per token,    91.89 tokens per second)\n",
      "llama_print_timings:        eval time =     641.81 ms /     8 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     924.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     104.62 ms /     1 runs   (  104.62 ms per token,     9.56 tokens per second)\n",
      "llama_print_timings:       total time =     362.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bertram Lakin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    10 runs   (    0.25 ms per token,  4045.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.13 ms /   149 tokens (    7.72 ms per token,   129.55 tokens per second)\n",
      "llama_print_timings:        eval time =     695.20 ms /     9 runs   (   77.24 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =    1893.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"284 181 7355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    15 runs   (    0.27 ms per token,  3719.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.42 ms /    25 tokens (   10.06 ms per token,    99.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.82 ms /    14 runs   (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1419.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /     8 runs   (    0.19 ms per token,  5312.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.46 ms /    23 tokens (   10.85 ms per token,    92.20 tokens per second)\n",
      "llama_print_timings:        eval time =     555.05 ms /     7 runs   (   79.29 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     830.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /    11 runs   (    0.19 ms per token,  5339.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    24 tokens (   10.42 ms per token,    95.93 tokens per second)\n",
      "llama_print_timings:        eval time =     790.33 ms /    10 runs   (   79.03 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1083.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Alexia Koss\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.31 ms /    19 runs   (    0.28 ms per token,  3580.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.73 ms /   184 tokens (    7.58 ms per token,   131.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1393.99 ms /    18 runs   (   77.44 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    2887.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 545 8694\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    15 runs   (    0.30 ms per token,  3305.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.53 ms /    25 tokens (   10.10 ms per token,    99.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.19 ms /    14 runs   (   78.59 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1427.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     7 runs   (    0.16 ms per token,  6386.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.19 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     480.37 ms /     6 runs   (   80.06 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     751.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.36 ms /     7 runs   (    0.20 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =     474.60 ms /     6 runs   (   79.10 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     751.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Fanny Hartmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     7 runs   (    0.20 ms per token,  5043.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.61 ms /   123 tokens (    7.59 ms per token,   131.75 tokens per second)\n",
      "llama_print_timings:        eval time =     465.09 ms /     6 runs   (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    1426.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 326 5414\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    15 runs   (    0.25 ms per token,  3977.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.40 ms /    14 runs   (   77.67 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    1405.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     6 runs   (    0.14 ms per token,  7290.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.32 ms /    23 tokens (   10.84 ms per token,    92.25 tokens per second)\n",
      "llama_print_timings:        eval time =     418.89 ms /     5 runs   (   83.78 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     685.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    24 tokens (   10.41 ms per token,    96.09 tokens per second)\n",
      "llama_print_timings:        eval time =      91.42 ms /     1 runs   (   91.42 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     345.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Coy Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     7 runs   (    0.22 ms per token,  4487.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.95 ms /   163 tokens (    8.40 ms per token,   119.07 tokens per second)\n",
      "llama_print_timings:        eval time =     468.80 ms /     6 runs   (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1865.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 217 6102\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /    15 runs   (    0.29 ms per token,  3505.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.75 ms /    25 tokens (   10.07 ms per token,    99.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1091.58 ms /    14 runs   (   77.97 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1413.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6968.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =      95.44 ms /     1 runs   (   95.44 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =     350.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     7 runs   (    0.23 ms per token,  4424.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.31 ms /    24 tokens (   10.39 ms per token,    96.26 tokens per second)\n",
      "llama_print_timings:        eval time =     473.69 ms /     6 runs   (   78.95 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     751.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Myrta Heidenreich\", \"Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.06 ms /    19 runs   (    0.27 ms per token,  3757.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1615.03 ms /   193 tokens (    8.37 ms per token,   119.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1396.88 ms /    18 runs   (   77.60 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    3112.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"175 139 9644\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    15 runs   (    0.31 ms per token,  3232.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.50 ms /    25 tokens (   10.10 ms per token,    99.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.59 ms /    14 runs   (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1438.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     9 runs   (    0.20 ms per token,  4888.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     643.87 ms /     8 runs   (   80.48 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     930.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /     8 runs   (    0.23 ms per token,  4402.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =     551.76 ms /     7 runs   (   78.82 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =     838.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Julieta Pouros MD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    14 runs   (    0.26 ms per token,  3797.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1371.38 ms /   163 tokens (    8.41 ms per token,   118.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.35 ms /    13 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2453.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"220 336 5858\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    15 runs   (    0.27 ms per token,  3671.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.98 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.20 ms /    14 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1434.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     7 runs   (    0.16 ms per token,  6086.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    23 tokens (   10.89 ms per token,    91.86 tokens per second)\n",
      "llama_print_timings:        eval time =     481.25 ms /     6 runs   (   80.21 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     754.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.98 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =      88.08 ms /     1 runs   (   88.08 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     343.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kayleen Hirthe\", \"Riley Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.26 ms /    18 runs   (    0.29 ms per token,  3422.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.40 ms /   152 tokens (    7.59 ms per token,   131.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.60 ms /    17 runs   (   77.15 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2570.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"605 898 3585\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    15 runs   (    0.27 ms per token,  3650.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.77 ms /    14 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1422.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     9 runs   (    0.14 ms per token,  7281.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     658.97 ms /     8 runs   (   82.37 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     947.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.21 ms /    24 tokens (   10.38 ms per token,    96.31 tokens per second)\n",
      "llama_print_timings:        eval time =      98.13 ms /     1 runs   (   98.13 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     352.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ollie Auer\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    17 runs   (    0.14 ms per token,  7404.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.24 ms /   159 tokens (    7.32 ms per token,   136.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1295.11 ms /    16 runs   (   80.94 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2505.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"864 119 4145\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /    15 runs   (    0.12 ms per token,  8337.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.21 ms /    25 tokens (   10.13 ms per token,    98.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.64 ms /    14 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1436.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     9 runs   (    0.10 ms per token,  9890.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.54 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     671.20 ms /     8 runs   (   83.90 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     941.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =      88.55 ms /     1 runs   (   88.55 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     344.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Lidia Leuschke\", \"Dr. Clayton Jast\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.59 ms /    19 runs   (    0.14 ms per token,  7333.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.41 ms /   165 tokens (    8.43 ms per token,   118.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.19 ms /    18 runs   (   81.07 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2894.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"435 427 7312\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /    15 runs   (    0.12 ms per token,  8112.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    25 tokens (   10.18 ms per token,    98.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.12 ms /    14 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1441.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.80 ms /    23 tokens (   10.95 ms per token,    91.34 tokens per second)\n",
      "llama_print_timings:        eval time =      88.34 ms /     1 runs   (   88.34 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     343.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     8 runs   (    0.14 ms per token,  6999.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.31 ms /    24 tokens (   10.55 ms per token,    94.74 tokens per second)\n",
      "llama_print_timings:        eval time =     582.14 ms /     7 runs   (   83.16 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     854.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santiago Jones\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     7 runs   (    0.13 ms per token,  7454.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.69 ms /   155 tokens (    7.55 ms per token,   132.51 tokens per second)\n",
      "llama_print_timings:        eval time =     505.75 ms /     6 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =    1690.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"158 691 2648\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /    15 runs   (    0.14 ms per token,  7385.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    25 tokens (   10.16 ms per token,    98.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.62 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1438.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  8928.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    23 tokens (   10.93 ms per token,    91.50 tokens per second)\n",
      "llama_print_timings:        eval time =     102.64 ms /     1 runs   (  102.64 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =     358.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8230.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    24 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =      90.27 ms /     1 runs   (   90.27 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     344.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Tyrell Willms JD\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.12 ms /    18 runs   (    0.17 ms per token,  5761.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.26 ms /   184 tokens (    7.70 ms per token,   129.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1369.68 ms /    17 runs   (   80.57 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2848.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"644 132 1256\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /    15 runs   (    0.22 ms per token,  4508.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.23 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.30 ms /    14 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1437.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /     9 runs   (    0.18 ms per token,  5603.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =     699.57 ms /     8 runs   (   87.45 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     984.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     8 runs   (    0.30 ms per token,  3289.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.19 ms /    24 tokens (   10.67 ms per token,    93.68 tokens per second)\n",
      "llama_print_timings:        eval time =     622.15 ms /     7 runs   (   88.88 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     978.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Norma Moen\", \"Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.65 ms /    19 runs   (    0.46 ms per token,  2196.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.10 ms /   166 tokens (    8.33 ms per token,   120.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1534.01 ms /    18 runs   (   85.22 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =    3043.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"869 754 2853\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    15 runs   (    0.34 ms per token,  2906.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.67 ms /    25 tokens (   10.31 ms per token,    97.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1171.42 ms /    14 runs   (   83.67 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    1509.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.09 ms per token, 11764.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    23 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =     126.38 ms /     1 runs   (  126.38 ms per token,     7.91 tokens per second)\n",
      "llama_print_timings:       total time =     390.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    11 runs   (    0.35 ms per token,  2834.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.60 ms /    24 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     853.77 ms /    10 runs   (   85.38 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =    1178.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Lakisha Kessler\", \"Dr. Rhett Padberg\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    20 runs   (    0.53 ms per token,  1892.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.08 ms /   171 tokens (    8.16 ms per token,   122.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1545.36 ms /    19 runs   (   81.33 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    3094.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"260 935 8499\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    15 runs   (    0.48 ms per token,  2092.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.44 ms /    25 tokens (   10.14 ms per token,    98.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.70 ms /    14 runs   (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1515.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"75 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     7 runs   (    0.20 ms per token,  4888.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     503.59 ms /     6 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     783.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    11 runs   (    0.28 ms per token,  3598.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.93 ms /    24 tokens (   10.58 ms per token,    94.51 tokens per second)\n",
      "llama_print_timings:        eval time =     834.18 ms /    10 runs   (   83.42 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    1147.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Clarine Kerluke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    11 runs   (    0.36 ms per token,  2816.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2936.01 ms /   380 tokens (    7.73 ms per token,   129.43 tokens per second)\n",
      "llama_print_timings:        eval time =     867.18 ms /    10 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    3878.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"336 562 8078\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    15 runs   (    0.29 ms per token,  3404.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.57 ms /    25 tokens (   10.46 ms per token,    95.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1338.73 ms /    14 runs   (   95.62 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    1695.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     9 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.04 ms /    23 tokens (   11.18 ms per token,    89.48 tokens per second)\n",
      "llama_print_timings:        eval time =     691.92 ms /     8 runs   (   86.49 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     990.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7936.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =      99.83 ms /     1 runs   (   99.83 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =     363.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ida Stamm\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    16 runs   (    0.40 ms per token,  2492.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.29 ms /   180 tokens (    7.77 ms per token,   128.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1258.72 ms /    15 runs   (   83.91 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    2767.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 464 0070\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    15 runs   (    0.46 ms per token,  2166.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.45 ms /    25 tokens (   10.34 ms per token,    96.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.18 ms /    14 runs   (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    1535.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5633.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =      96.57 ms /     1 runs   (   96.57 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     353.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.64 ms /     7 runs   (    0.38 ms per token,  2647.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.33 ms /    24 tokens (   10.76 ms per token,    92.91 tokens per second)\n",
      "llama_print_timings:        eval time =     518.57 ms /     6 runs   (   86.43 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     823.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Adelia Rowe\", \"Dr. Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    14 runs   (    0.28 ms per token,  3584.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.55 ms /   175 tokens (    8.09 ms per token,   123.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.33 ms /    13 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    2622.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 734 4147\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2291.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.49 ms /    25 tokens (   10.30 ms per token,    97.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.12 ms /    14 runs   (   83.22 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    1532.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     7 runs   (    0.24 ms per token,  4129.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.08 ms /    23 tokens (   10.96 ms per token,    91.24 tokens per second)\n",
      "llama_print_timings:        eval time =     504.28 ms /     6 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     790.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.21 ms /    24 tokens (   10.59 ms per token,    94.41 tokens per second)\n",
      "llama_print_timings:        eval time =      97.57 ms /     1 runs   (   97.57 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     356.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Salena Reichert\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    16 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.64 ms /   168 tokens (    8.38 ms per token,   119.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.85 ms /    15 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2731.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"454 778 2885\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    15 runs   (    0.58 ms per token,  1737.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.65 ms /    25 tokens (   10.15 ms per token,    98.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.35 ms /    14 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1494.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /     9 runs   (    0.38 ms per token,  2663.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.18 ms /    23 tokens (   10.92 ms per token,    91.57 tokens per second)\n",
      "llama_print_timings:        eval time =     648.79 ms /     8 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     959.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     8 runs   (    0.43 ms per token,  2341.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.06 ms /    24 tokens (   10.54 ms per token,    94.84 tokens per second)\n",
      "llama_print_timings:        eval time =     592.03 ms /     7 runs   (   84.58 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     882.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Della Koepp\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    18 runs   (    0.47 ms per token,  2135.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.64 ms /   157 tokens (    7.41 ms per token,   134.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1368.53 ms /    17 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2660.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"410 616 2405\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.11 ms /    15 runs   (    0.61 ms per token,  1646.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    25 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.96 ms /    14 runs   (   80.28 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1503.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     5 runs   (    0.19 ms per token,  5235.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.45 ms /    23 tokens (   10.93 ms per token,    91.47 tokens per second)\n",
      "llama_print_timings:        eval time =     337.25 ms /     4 runs   (   84.31 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     613.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     7 runs   (    0.17 ms per token,  5823.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.28 ms /    24 tokens (   10.47 ms per token,    95.51 tokens per second)\n",
      "llama_print_timings:        eval time =     495.64 ms /     6 runs   (   82.61 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     772.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hal Kemmer\", \"Doctor Ollie Dooley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    19 runs   (    0.51 ms per token,  1953.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.48 ms /   156 tokens (    7.50 ms per token,   133.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1447.42 ms /    18 runs   (   80.41 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2760.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"833 676 3284\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    15 runs   (    0.52 ms per token,  1937.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.28 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.78 ms /    14 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1494.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     7 runs   (    0.24 ms per token,  4176.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    23 tokens (   11.08 ms per token,    90.23 tokens per second)\n",
      "llama_print_timings:        eval time =     526.59 ms /     6 runs   (   87.77 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     805.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     8 runs   (    0.34 ms per token,  2912.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.47 ms /    24 tokens (   10.64 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =     568.50 ms /     7 runs   (   81.21 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     870.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Mica Cormier\", \"Dr. Palmer Kuphal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.74 ms /    19 runs   (    0.57 ms per token,  1769.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.70 ms /   168 tokens (    8.38 ms per token,   119.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1428.00 ms /    18 runs   (   79.33 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    2986.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"779 455 0335\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.21 ms /    15 runs   (    0.61 ms per token,  1629.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.25 ms /    25 tokens (   10.13 ms per token,    98.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.44 ms /    14 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1506.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =     106.55 ms /     1 runs   (  106.55 ms per token,     9.39 tokens per second)\n",
      "llama_print_timings:       total time =     370.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    11 runs   (    0.27 ms per token,  3678.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.81 ms /    24 tokens (   10.83 ms per token,    92.37 tokens per second)\n",
      "llama_print_timings:        eval time =     820.01 ms /    10 runs   (   82.00 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1133.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Sebrina Hackett\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    14 runs   (    0.42 ms per token,  2366.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.91 ms /   177 tokens (    7.90 ms per token,   126.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.26 ms /    13 runs   (   82.64 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    2573.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"576 493 4702\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.00 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.78 ms /    14 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1522.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.06 ms /    23 tokens (   10.96 ms per token,    91.25 tokens per second)\n",
      "llama_print_timings:        eval time =      92.70 ms /     1 runs   (   92.70 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =     350.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    11 runs   (    0.41 ms per token,  2419.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.40 ms /    24 tokens (   10.39 ms per token,    96.23 tokens per second)\n",
      "llama_print_timings:        eval time =     812.49 ms /    10 runs   (   81.25 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1142.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Teddy Oberbrunner\", \"Doctor Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    21 runs   (    0.43 ms per token,  2325.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.48 ms /   165 tokens (    8.35 ms per token,   119.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1626.95 ms /    20 runs   (   81.35 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    3161.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"144 901 9871\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    15 runs   (    0.54 ms per token,  1863.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    25 tokens (   10.20 ms per token,    98.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.33 ms /    14 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1492.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     7 runs   (    0.19 ms per token,  5384.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.60 ms /    23 tokens (   10.98 ms per token,    91.05 tokens per second)\n",
      "llama_print_timings:        eval time =     518.00 ms /     6 runs   (   86.33 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     795.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.62 ms /    24 tokens (   10.65 ms per token,    93.89 tokens per second)\n",
      "llama_print_timings:        eval time =      95.42 ms /     1 runs   (   95.42 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =     356.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Anastasia Nicolas\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     7 runs   (    0.29 ms per token,  3489.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.36 ms /   177 tokens (    7.96 ms per token,   125.68 tokens per second)\n",
      "llama_print_timings:        eval time =     495.09 ms /     6 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1936.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 949 2775\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    15 runs   (    0.58 ms per token,  1723.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.67 ms /    25 tokens (   10.15 ms per token,    98.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.14 ms /    14 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1501.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.88 ms /     6 runs   (    0.15 ms per token,  6787.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    23 tokens (   10.93 ms per token,    91.50 tokens per second)\n",
      "llama_print_timings:        eval time =     410.81 ms /     5 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     680.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6079.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.75 ms /    24 tokens (   10.61 ms per token,    94.21 tokens per second)\n",
      "llama_print_timings:        eval time =      97.99 ms /     1 runs   (   97.99 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =     358.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Porter Champlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.20 ms /    10 runs   (    0.52 ms per token,  1923.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.50 ms /   180 tokens (    7.92 ms per token,   126.18 tokens per second)\n",
      "llama_print_timings:        eval time =     725.88 ms /     9 runs   (   80.65 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    2217.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"252 685 3634\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1882.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.60 ms /    25 tokens (   10.14 ms per token,    98.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.62 ms /    14 runs   (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1495.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     2 runs   (    0.28 ms per token,  3590.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    23 tokens (   11.07 ms per token,    90.37 tokens per second)\n",
      "llama_print_timings:        eval time =      96.39 ms /     1 runs   (   96.39 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =     357.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8368.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.16 ms /    24 tokens (   10.76 ms per token,    92.97 tokens per second)\n",
      "llama_print_timings:        eval time =      92.30 ms /     1 runs   (   92.30 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     353.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Benita Bahringer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    11 runs   (    0.53 ms per token,  1878.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.15 ms /   151 tokens (    7.80 ms per token,   128.17 tokens per second)\n",
      "llama_print_timings:        eval time =     793.08 ms /    10 runs   (   79.31 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    2059.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"213 396 8684\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    15 runs   (    0.32 ms per token,  3151.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.52 ms /    25 tokens (   10.34 ms per token,    96.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1174.57 ms /    14 runs   (   83.90 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =    1517.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     9 runs   (    0.24 ms per token,  4221.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.63 ms /    23 tokens (   11.11 ms per token,    89.97 tokens per second)\n",
      "llama_print_timings:        eval time =     670.85 ms /     8 runs   (   83.86 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     975.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     8 runs   (    0.27 ms per token,  3720.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.23 ms /    24 tokens (   10.55 ms per token,    94.78 tokens per second)\n",
      "llama_print_timings:        eval time =     610.29 ms /     7 runs   (   87.18 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =     899.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Maida Kassulke\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.12 ms /    21 runs   (    0.48 ms per token,  2075.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.79 ms /   165 tokens (    8.59 ms per token,   116.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1626.49 ms /    20 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    3199.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"648 641 6373\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    15 runs   (    0.42 ms per token,  2383.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.95 ms /    25 tokens (   10.16 ms per token,    98.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.01 ms /    14 runs   (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1506.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     9 runs   (    0.23 ms per token,  4385.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    23 tokens (   11.02 ms per token,    90.73 tokens per second)\n",
      "llama_print_timings:        eval time =     688.02 ms /     8 runs   (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     974.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10869.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.44 ms /    24 tokens (   11.02 ms per token,    90.76 tokens per second)\n",
      "llama_print_timings:        eval time =      99.07 ms /     1 runs   (   99.07 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =     368.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Junior O'Hara\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    10 runs   (    0.44 ms per token,  2268.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2971.80 ms /   362 tokens (    8.21 ms per token,   121.81 tokens per second)\n",
      "llama_print_timings:        eval time =     782.38 ms /     9 runs   (   86.93 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    3826.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"107 852 7107\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.72 ms /    15 runs   (    0.45 ms per token,  2231.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    25 tokens (   10.24 ms per token,    97.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.96 ms /    14 runs   (   89.21 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =    1607.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     5 runs   (    0.27 ms per token,  3742.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.15 ms /    23 tokens (   11.14 ms per token,    89.79 tokens per second)\n",
      "llama_print_timings:        eval time =     351.99 ms /     4 runs   (   88.00 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =     628.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"domestic abuse\", \"depression screening\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    13 runs   (    0.30 ms per token,  3297.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.67 ms /    24 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1027.33 ms /    12 runs   (   85.61 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1360.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gonzalo Weimann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    10 runs   (    0.30 ms per token,  3332.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2950.50 ms /   378 tokens (    7.81 ms per token,   128.11 tokens per second)\n",
      "llama_print_timings:        eval time =     772.26 ms /     9 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    3782.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"755 116 7006\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    15 runs   (    0.45 ms per token,  2239.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.81 ms /    25 tokens (   10.35 ms per token,    96.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1253.64 ms /    14 runs   (   89.55 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    1610.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6153.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.26 ms /    23 tokens (   11.27 ms per token,    88.71 tokens per second)\n",
      "llama_print_timings:        eval time =     110.95 ms /     1 runs   (  110.95 ms per token,     9.01 tokens per second)\n",
      "llama_print_timings:       total time =     376.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     8 runs   (    0.23 ms per token,  4259.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.20 ms /    24 tokens (   10.72 ms per token,    93.31 tokens per second)\n",
      "llama_print_timings:        eval time =     614.17 ms /     7 runs   (   87.74 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     909.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Quentin Lueilwitz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    10 runs   (    0.59 ms per token,  1707.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2807.25 ms /   324 tokens (    8.66 ms per token,   115.42 tokens per second)\n",
      "llama_print_timings:        eval time =     790.76 ms /     9 runs   (   87.86 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    3673.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"916 463 6675\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2637.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.72 ms /    25 tokens (   10.83 ms per token,    92.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1261.51 ms /    14 runs   (   90.11 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    1623.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.23 ms /    23 tokens (   11.84 ms per token,    84.49 tokens per second)\n",
      "llama_print_timings:        eval time =      98.66 ms /     1 runs   (   98.66 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =     381.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.16 ms per token,  6430.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.61 ms /    24 tokens (   10.65 ms per token,    93.89 tokens per second)\n",
      "llama_print_timings:        eval time =     113.42 ms /     1 runs   (  113.42 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =     373.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Lorean Lakin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    12 runs   (    0.38 ms per token,  2640.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1469.32 ms /   166 tokens (    8.85 ms per token,   112.98 tokens per second)\n",
      "llama_print_timings:        eval time =     941.57 ms /    11 runs   (   85.60 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    2487.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"167 584 1706\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    15 runs   (    0.45 ms per token,  2207.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.23 ms /    25 tokens (   10.41 ms per token,    96.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1202.51 ms /    14 runs   (   85.89 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1560.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     5 runs   (    0.16 ms per token,  6385.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.31 ms /    23 tokens (   11.06 ms per token,    90.44 tokens per second)\n",
      "llama_print_timings:        eval time =     390.70 ms /     4 runs   (   97.67 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     659.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"obesity\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /    13 runs   (    0.32 ms per token,  3172.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     282.85 ms /    24 tokens (   11.79 ms per token,    84.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1058.50 ms /    12 runs   (   88.21 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1417.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lenard Barton\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    17 runs   (    0.37 ms per token,  2690.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1495.71 ms /   185 tokens (    8.08 ms per token,   123.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1410.31 ms /    16 runs   (   88.14 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    3019.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"733 139 9278\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    15 runs   (    0.48 ms per token,  2077.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.78 ms /    25 tokens (   10.35 ms per token,    96.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.56 ms /    14 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1508.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     9 runs   (    0.35 ms per token,  2827.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    23 tokens (   10.93 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     658.15 ms /     8 runs   (   82.27 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     962.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     8 runs   (    0.28 ms per token,  3538.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.63 ms /    24 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     614.46 ms /     7 runs   (   87.78 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     913.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Samira Mante\", \"Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    17 runs   (    0.40 ms per token,  2477.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1509.32 ms /   187 tokens (    8.07 ms per token,   123.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1340.40 ms /    16 runs   (   83.78 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    2973.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 768 861 2022\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.15 ms /    19 runs   (    0.53 ms per token,  1872.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.54 ms /    25 tokens (   10.94 ms per token,    91.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1449.44 ms /    18 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1877.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     5 runs   (    0.18 ms per token,  5446.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.48 ms /    23 tokens (   10.93 ms per token,    91.46 tokens per second)\n",
      "llama_print_timings:        eval time =     330.31 ms /     4 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     598.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    11 runs   (    0.45 ms per token,  2210.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.83 ms /    24 tokens (   10.49 ms per token,    95.30 tokens per second)\n",
      "llama_print_timings:        eval time =     804.97 ms /    10 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1126.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Tammi Dooley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /    11 runs   (    0.27 ms per token,  3649.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.35 ms /   148 tokens (    7.85 ms per token,   127.44 tokens per second)\n",
      "llama_print_timings:        eval time =     830.75 ms /    10 runs   (   83.08 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    2043.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"370 444 3802\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.89 ms /    15 runs   (    0.39 ms per token,  2547.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    25 tokens (   10.12 ms per token,    98.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1273.47 ms /    14 runs   (   90.96 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    1625.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /     7 runs   (    0.33 ms per token,  2988.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.38 ms /    23 tokens (   11.02 ms per token,    90.77 tokens per second)\n",
      "llama_print_timings:        eval time =     536.90 ms /     6 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     833.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     8 runs   (    0.26 ms per token,  3911.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     276.73 ms /    24 tokens (   11.53 ms per token,    86.73 tokens per second)\n",
      "llama_print_timings:        eval time =     604.58 ms /     7 runs   (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     912.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Melita Parisian\", \"Dr. Iva O'Keefe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.34 ms /    20 runs   (    0.67 ms per token,  1499.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1657.72 ms /   213 tokens (    7.78 ms per token,   128.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1500.09 ms /    19 runs   (   78.95 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    3341.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 164 3948\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.83 ms /    15 runs   (    0.39 ms per token,  2572.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.71 ms /    25 tokens (   10.15 ms per token,    98.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.13 ms /    14 runs   (   81.72 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1486.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"52\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     5 runs   (    0.16 ms per token,  6090.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    23 tokens (   10.92 ms per token,    91.54 tokens per second)\n",
      "llama_print_timings:        eval time =     381.63 ms /     4 runs   (   95.41 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =     649.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7722.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     277.68 ms /    24 tokens (   11.57 ms per token,    86.43 tokens per second)\n",
      "llama_print_timings:        eval time =     103.48 ms /     1 runs   (  103.48 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =     385.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rayna Weissnat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     9 runs   (    0.46 ms per token,  2192.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.83 ms /   181 tokens (    7.93 ms per token,   126.15 tokens per second)\n",
      "llama_print_timings:        eval time =     663.46 ms /     8 runs   (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    2154.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 952 2055\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    15 runs   (    0.51 ms per token,  1963.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.50 ms /    25 tokens (   10.50 ms per token,    95.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.15 ms /    14 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1579.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.31 ms /     2 runs   (    0.15 ms per token,  6451.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.55 ms /    23 tokens (   11.46 ms per token,    87.27 tokens per second)\n",
      "llama_print_timings:        eval time =      98.70 ms /     1 runs   (   98.70 ms per token,    10.13 tokens per second)\n",
      "llama_print_timings:       total time =     367.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.38 ms /     9 runs   (    0.49 ms per token,  2052.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.34 ms /    24 tokens (   10.64 ms per token,    93.99 tokens per second)\n",
      "llama_print_timings:        eval time =     651.88 ms /     8 runs   (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     969.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Fonda Friesen\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    19 runs   (    0.41 ms per token,  2449.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1235.85 ms /   151 tokens (    8.18 ms per token,   122.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1541.21 ms /    18 runs   (   85.62 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    2897.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"191 474 0933\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2350.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.24 ms /    25 tokens (   10.29 ms per token,    97.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1243.05 ms /    14 runs   (   88.79 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =    1595.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     9 runs   (    0.27 ms per token,  3646.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.21 ms /    23 tokens (   11.75 ms per token,    85.12 tokens per second)\n",
      "llama_print_timings:        eval time =     716.56 ms /     8 runs   (   89.57 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1023.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7326.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     272.03 ms /    24 tokens (   11.33 ms per token,    88.22 tokens per second)\n",
      "llama_print_timings:        eval time =     102.16 ms /     1 runs   (  102.16 ms per token,     9.79 tokens per second)\n",
      "llama_print_timings:       total time =     378.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ivette Dickens\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    19 runs   (    0.34 ms per token,  2956.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1257.58 ms /   157 tokens (    8.01 ms per token,   124.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1584.75 ms /    18 runs   (   88.04 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    2973.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"518 751 3519\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    15 runs   (    0.37 ms per token,  2711.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.85 ms /    25 tokens (   10.71 ms per token,    93.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.18 ms /    14 runs   (   86.23 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    1570.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     8 runs   (    0.18 ms per token,  5502.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.74 ms /    23 tokens (   11.95 ms per token,    83.72 tokens per second)\n",
      "llama_print_timings:        eval time =     608.23 ms /     7 runs   (   86.89 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     912.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     8 runs   (    0.19 ms per token,  5369.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.23 ms /    24 tokens (   11.18 ms per token,    89.47 tokens per second)\n",
      "llama_print_timings:        eval time =     616.53 ms /     7 runs   (   88.08 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     919.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Douglas Conroy\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    16 runs   (    0.37 ms per token,  2676.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.73 ms /   136 tokens (    8.75 ms per token,   114.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.37 ms /    15 runs   (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    2523.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"156 884 9453\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.45 ms /    15 runs   (    0.36 ms per token,  2751.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.85 ms /    25 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.42 ms /    14 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    1522.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /     9 runs   (    0.32 ms per token,  3145.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.73 ms /    23 tokens (   11.25 ms per token,    88.90 tokens per second)\n",
      "llama_print_timings:        eval time =     675.54 ms /     8 runs   (   84.44 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     990.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     8 runs   (    0.38 ms per token,  2628.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.97 ms /    24 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     588.34 ms /     7 runs   (   84.05 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     898.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ollie Dooley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /     9 runs   (    0.44 ms per token,  2276.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.11 ms /   156 tokens (    7.80 ms per token,   128.17 tokens per second)\n",
      "llama_print_timings:        eval time =     675.60 ms /     8 runs   (   84.45 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1948.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"835 796 0085\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    15 runs   (    0.46 ms per token,  2163.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     280.73 ms /    25 tokens (   11.23 ms per token,    89.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.33 ms /    14 runs   (   86.09 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1584.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     7 runs   (    0.30 ms per token,  3362.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     280.62 ms /    23 tokens (   12.20 ms per token,    81.96 tokens per second)\n",
      "llama_print_timings:        eval time =     534.77 ms /     6 runs   (   89.13 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =     847.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /    11 runs   (    0.27 ms per token,  3641.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.27 ms /    24 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =     916.28 ms /    10 runs   (   91.63 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =    1225.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Margeret Rolfson\", \"Doctor Chance Aufderhar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.87 ms /    22 runs   (    0.40 ms per token,  2479.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1731.22 ms /   215 tokens (    8.05 ms per token,   124.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1854.81 ms /    21 runs   (   88.32 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    3736.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"892 812 0775\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    15 runs   (    0.51 ms per token,  1957.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.01 ms /    25 tokens (   10.72 ms per token,    93.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.19 ms /    14 runs   (   83.30 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1550.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     5 runs   (    0.20 ms per token,  5060.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     276.19 ms /    23 tokens (   12.01 ms per token,    83.28 tokens per second)\n",
      "llama_print_timings:        eval time =     401.78 ms /     4 runs   (  100.44 ms per token,     9.96 tokens per second)\n",
      "llama_print_timings:       total time =     696.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9523.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.42 ms /    24 tokens (   10.89 ms per token,    91.81 tokens per second)\n",
      "llama_print_timings:        eval time =      89.11 ms /     1 runs   (   89.11 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =     354.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ewa Schiller\", \"Dr. Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    17 runs   (    0.42 ms per token,  2355.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.07 ms /   148 tokens (    7.91 ms per token,   126.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1295.54 ms /    16 runs   (   80.97 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2591.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"526 195 0417\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.92 ms /    15 runs   (    0.33 ms per token,  3048.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.68 ms /    25 tokens (   10.15 ms per token,    98.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.88 ms /    14 runs   (   80.71 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1468.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     5 runs   (    0.16 ms per token,  6402.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.89 ms /    23 tokens (   10.91 ms per token,    91.67 tokens per second)\n",
      "llama_print_timings:        eval time =     334.48 ms /     4 runs   (   83.62 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     603.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     8 runs   (    0.27 ms per token,  3712.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.70 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =     574.58 ms /     7 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     858.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Christi Hilpert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    10 runs   (    0.30 ms per token,  3299.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.90 ms /   154 tokens (    7.70 ms per token,   129.86 tokens per second)\n",
      "llama_print_timings:        eval time =     765.34 ms /     9 runs   (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    2004.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"806 868 0352\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2254.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.30 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.04 ms /    14 runs   (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1509.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     7 runs   (    0.26 ms per token,  3875.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.07 ms /    23 tokens (   10.96 ms per token,    91.24 tokens per second)\n",
      "llama_print_timings:        eval time =     497.11 ms /     6 runs   (   82.85 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     781.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /    11 runs   (    0.28 ms per token,  3541.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.58 ms /    24 tokens (   10.48 ms per token,    95.40 tokens per second)\n",
      "llama_print_timings:        eval time =     813.30 ms /    10 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1121.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alex Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2618.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3124.53 ms /   398 tokens (    7.85 ms per token,   127.38 tokens per second)\n",
      "llama_print_timings:        eval time =     573.78 ms /     7 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    3753.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"632 187 5371\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    15 runs   (    0.52 ms per token,  1905.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.39 ms /    25 tokens (   10.34 ms per token,    96.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.44 ms /    14 runs   (   82.96 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1537.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /     9 runs   (    0.26 ms per token,  3869.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.38 ms /    23 tokens (   11.15 ms per token,    89.71 tokens per second)\n",
      "llama_print_timings:        eval time =     664.77 ms /     8 runs   (   83.10 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     964.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7662.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.64 ms /    24 tokens (   10.69 ms per token,    93.52 tokens per second)\n",
      "llama_print_timings:        eval time =      99.20 ms /     1 runs   (   99.20 ms per token,    10.08 tokens per second)\n",
      "llama_print_timings:       total time =     361.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. August Daugherty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /    10 runs   (    0.34 ms per token,  2915.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2968.80 ms /   366 tokens (    8.11 ms per token,   123.28 tokens per second)\n",
      "llama_print_timings:        eval time =     768.59 ms /     9 runs   (   85.40 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =    3809.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"851 334 6658\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    15 runs   (    0.54 ms per token,  1849.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.79 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.39 ms /    14 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    1542.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"41-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.78 ms /     9 runs   (    0.31 ms per token,  3239.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.58 ms /    23 tokens (   11.11 ms per token,    89.99 tokens per second)\n",
      "llama_print_timings:        eval time =     676.32 ms /     8 runs   (   84.54 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     984.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10810.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.12 ms /    24 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =      98.62 ms /     1 runs   (   98.62 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =     367.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ted Strosin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     8 runs   (    0.17 ms per token,  5738.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     695.32 ms /    96 tokens (    7.24 ms per token,   138.07 tokens per second)\n",
      "llama_print_timings:        eval time =     593.40 ms /     7 runs   (   84.77 ms per token,    11.80 tokens per second)\n",
      "llama_print_timings:       total time =    1315.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 305 1597\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    15 runs   (    0.32 ms per token,  3080.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.59 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.69 ms /    14 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1478.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     6 runs   (    0.22 ms per token,  4542.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.69 ms /    23 tokens (   10.86 ms per token,    92.11 tokens per second)\n",
      "llama_print_timings:        eval time =     409.69 ms /     5 runs   (   81.94 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     682.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     8 runs   (    0.30 ms per token,  3318.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.47 ms /    24 tokens (   10.39 ms per token,    96.20 tokens per second)\n",
      "llama_print_timings:        eval time =     575.07 ms /     7 runs   (   82.15 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     861.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Julene Wuckert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    11 runs   (    0.39 ms per token,  2586.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.22 ms /   145 tokens (    8.02 ms per token,   124.76 tokens per second)\n",
      "llama_print_timings:        eval time =     812.10 ms /    10 runs   (   81.21 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    2042.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 185 6336\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    15 runs   (    0.37 ms per token,  2693.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.54 ms /    25 tokens (   10.10 ms per token,    98.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.62 ms /    14 runs   (   82.33 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1493.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.53 ms /    23 tokens (   10.94 ms per token,    91.44 tokens per second)\n",
      "llama_print_timings:        eval time =      94.67 ms /     1 runs   (   94.67 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     352.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10928.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    24 tokens (   10.50 ms per token,    95.26 tokens per second)\n",
      "llama_print_timings:        eval time =      88.66 ms /     1 runs   (   88.66 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     343.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Deana Klein\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    18 runs   (    0.63 ms per token,  1598.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1676.05 ms /   210 tokens (    7.98 ms per token,   125.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1431.65 ms /    17 runs   (   84.21 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    3242.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"853 921 5277\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.10 ms /    15 runs   (    0.34 ms per token,  2943.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.87 ms /    25 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.85 ms /    14 runs   (   85.85 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    1545.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6968.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =      95.89 ms /     1 runs   (   95.89 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     353.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"cystitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     6 runs   (    0.24 ms per token,  4187.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    24 tokens (   10.54 ms per token,    94.87 tokens per second)\n",
      "llama_print_timings:        eval time =     424.43 ms /     5 runs   (   84.89 ms per token,    11.78 tokens per second)\n",
      "llama_print_timings:       total time =     701.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.56 ms /     2 runs   (    0.28 ms per token,  3584.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.91 ms /   199 tokens (    8.40 ms per token,   119.10 tokens per second)\n",
      "llama_print_timings:        eval time =      97.46 ms /     1 runs   (   97.46 ms per token,    10.26 tokens per second)\n",
      "llama_print_timings:       total time =    1776.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"277 181 7031\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    15 runs   (    0.37 ms per token,  2695.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.19 ms /    25 tokens (   10.77 ms per token,    92.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.41 ms /    14 runs   (   86.74 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1571.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     7 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    23 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     512.26 ms /     6 runs   (   85.38 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     785.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    11 runs   (    0.42 ms per token,  2394.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.10 ms /    24 tokens (   10.50 ms per token,    95.20 tokens per second)\n",
      "llama_print_timings:        eval time =     833.25 ms /    10 runs   (   83.32 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1142.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alissa Gutkowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.78 ms /     8 runs   (    0.22 ms per token,  4499.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.12 ms /   169 tokens (    8.18 ms per token,   122.28 tokens per second)\n",
      "llama_print_timings:        eval time =     588.15 ms /     7 runs   (   84.02 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1999.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 746 8442\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.04 ms /    15 runs   (    0.40 ms per token,  2481.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.18 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.64 ms /    14 runs   (   83.55 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1522.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     7 runs   (    0.14 ms per token,  7021.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.21 ms /    23 tokens (   10.92 ms per token,    91.56 tokens per second)\n",
      "llama_print_timings:        eval time =     538.53 ms /     6 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     824.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9523.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.22 ms /    24 tokens (   10.51 ms per token,    95.16 tokens per second)\n",
      "llama_print_timings:        eval time =     102.87 ms /     1 runs   (  102.87 ms per token,     9.72 tokens per second)\n",
      "llama_print_timings:       total time =     359.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Shaniqua Dicki\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     8 runs   (    0.21 ms per token,  4744.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     938.70 ms /   121 tokens (    7.76 ms per token,   128.90 tokens per second)\n",
      "llama_print_timings:        eval time =     586.33 ms /     7 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1558.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 162 2695\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    19 runs   (    0.42 ms per token,  2398.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1467.59 ms /    18 runs   (   81.53 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1841.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.42 ms /     7 runs   (    0.20 ms per token,  4943.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.95 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =     510.26 ms /     6 runs   (   85.04 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     789.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    14 runs   (    0.28 ms per token,  3534.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    24 tokens (   10.56 ms per token,    94.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.29 ms /    13 runs   (   86.95 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1450.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jon Bechtelar\", \"Dr. Ramiro Anderson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /    18 runs   (    0.38 ms per token,  2633.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.20 ms /   151 tokens (    7.74 ms per token,   129.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1488.21 ms /    17 runs   (   87.54 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    2780.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"176 647 9362\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.23 ms /    15 runs   (    0.35 ms per token,  2870.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.63 ms /    25 tokens (   10.27 ms per token,    97.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1324.51 ms /    14 runs   (   94.61 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =    1666.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.23 ms /    23 tokens (   11.05 ms per token,    90.47 tokens per second)\n",
      "llama_print_timings:        eval time =     103.58 ms /     1 runs   (  103.58 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     365.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    24 tokens (   10.68 ms per token,    93.62 tokens per second)\n",
      "llama_print_timings:        eval time =     102.33 ms /     1 runs   (  102.33 ms per token,     9.77 tokens per second)\n",
      "llama_print_timings:       total time =     363.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bernard Koch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     7 runs   (    0.30 ms per token,  3370.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.66 ms /   137 tokens (    8.38 ms per token,   119.27 tokens per second)\n",
      "llama_print_timings:        eval time =     496.52 ms /     6 runs   (   82.75 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1681.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"517 238 5600\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.12 ms /    15 runs   (    0.34 ms per token,  2926.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.12 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.19 ms /    14 runs   (   82.66 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1495.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"55-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     9 runs   (    0.30 ms per token,  3297.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.31 ms /    23 tokens (   10.88 ms per token,    91.88 tokens per second)\n",
      "llama_print_timings:        eval time =     654.09 ms /     8 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     945.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.94 ms /    24 tokens (   10.41 ms per token,    96.02 tokens per second)\n",
      "llama_print_timings:        eval time =      95.24 ms /     1 runs   (   95.24 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =     351.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alvaro Beer\", \"Doctor Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    19 runs   (    0.40 ms per token,  2500.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.28 ms /   192 tokens (    7.26 ms per token,   137.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.52 ms /    18 runs   (   85.31 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    3070.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 975 1076\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    15 runs   (    0.51 ms per token,  1948.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.54 ms /    14 runs   (   80.82 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1489.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5068.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    23 tokens (   10.95 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =     509.79 ms /     6 runs   (   84.97 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     792.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6920.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =      95.81 ms /     1 runs   (   95.81 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     351.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Elida Boyle\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    18 runs   (    0.45 ms per token,  2239.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.71 ms /   172 tokens (    8.05 ms per token,   124.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.80 ms /    17 runs   (   79.87 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2875.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"761 566 4778\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    15 runs   (    0.48 ms per token,  2097.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.86 ms /    25 tokens (   10.15 ms per token,    98.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.87 ms /    14 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1501.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.24 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =      92.75 ms /     1 runs   (   92.75 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =     349.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     9 runs   (    0.31 ms per token,  3265.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.61 ms /    24 tokens (   10.44 ms per token,    95.77 tokens per second)\n",
      "llama_print_timings:        eval time =     660.11 ms /     8 runs   (   82.51 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     961.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Willie Wolff\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.32 ms /    16 runs   (    0.39 ms per token,  2533.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.26 ms /   137 tokens (    8.34 ms per token,   119.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.83 ms /    15 runs   (   80.59 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2453.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"199 644 7393\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2648.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.81 ms /    14 runs   (   81.42 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1479.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     9 runs   (    0.23 ms per token,  4343.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.99 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     691.79 ms /     8 runs   (   86.47 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     986.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.19 ms /    24 tokens (   10.47 ms per token,    95.55 tokens per second)\n",
      "llama_print_timings:        eval time =      98.92 ms /     1 runs   (   98.92 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =     356.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Sherman Ebert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     9 runs   (    0.46 ms per token,  2173.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.77 ms /   164 tokens (    8.38 ms per token,   119.29 tokens per second)\n",
      "llama_print_timings:        eval time =     642.78 ms /     8 runs   (   80.35 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2068.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"157 934 4173\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.63 ms /    15 runs   (    0.51 ms per token,  1964.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.48 ms /    14 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1488.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2276.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.88 ms /    23 tokens (   10.91 ms per token,    91.68 tokens per second)\n",
      "llama_print_timings:        eval time =     593.97 ms /     7 runs   (   84.85 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =     896.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  7017.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.02 ms /    24 tokens (   10.50 ms per token,    95.23 tokens per second)\n",
      "llama_print_timings:        eval time =      98.11 ms /     1 runs   (   98.11 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     357.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ignacio Littel\", \"Dr. Ciara Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    18 runs   (    0.43 ms per token,  2340.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.30 ms /   180 tokens (    7.73 ms per token,   129.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1366.23 ms /    17 runs   (   80.37 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2891.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 905 1158\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    15 runs   (    0.44 ms per token,  2289.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.76 ms /    25 tokens (   10.15 ms per token,    98.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.96 ms /    14 runs   (   81.07 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1493.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7968.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.59 ms /    23 tokens (   11.03 ms per token,    90.70 tokens per second)\n",
      "llama_print_timings:        eval time =      91.36 ms /     1 runs   (   91.36 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     350.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     6 runs   (    0.18 ms per token,  5676.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.05 ms /    24 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =     415.13 ms /     5 runs   (   83.03 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     686.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ramon Johns\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     9 runs   (    0.37 ms per token,  2698.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3216.57 ms /   391 tokens (    8.23 ms per token,   121.56 tokens per second)\n",
      "llama_print_timings:        eval time =     658.47 ms /     8 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    3926.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 338 558 8523\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    19 runs   (    0.44 ms per token,  2250.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.90 ms /    25 tokens (   10.28 ms per token,    97.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1503.67 ms /    18 runs   (   83.54 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1897.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     7 runs   (    0.35 ms per token,  2894.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    23 tokens (   11.14 ms per token,    89.73 tokens per second)\n",
      "llama_print_timings:        eval time =     515.20 ms /     6 runs   (   85.87 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     812.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    11 runs   (    0.40 ms per token,  2527.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    24 tokens (   10.67 ms per token,    93.73 tokens per second)\n",
      "llama_print_timings:        eval time =     846.74 ms /    10 runs   (   84.67 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1181.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Antonia Jaskolski\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.29 ms /    17 runs   (    0.43 ms per token,  2331.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.53 ms /   137 tokens (    8.36 ms per token,   119.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1301.69 ms /    16 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2576.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"439 737 0921\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    15 runs   (    0.53 ms per token,  1870.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.65 ms /    14 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1500.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.59 ms /     6 runs   (    0.26 ms per token,  3775.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    23 tokens (   10.93 ms per token,    91.52 tokens per second)\n",
      "llama_print_timings:        eval time =     422.26 ms /     5 runs   (   84.45 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     700.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     8 runs   (    0.27 ms per token,  3710.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.87 ms /    24 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =     573.91 ms /     7 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     860.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ai Labadie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.51 ms /     8 runs   (    0.31 ms per token,  3188.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.94 ms /   175 tokens (    7.90 ms per token,   126.63 tokens per second)\n",
      "llama_print_timings:        eval time =     556.79 ms /     7 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1982.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 518 1120\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    15 runs   (    0.47 ms per token,  2135.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.20 ms /    14 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1490.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.42 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =      92.33 ms /     1 runs   (   92.33 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     349.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    11 runs   (    0.41 ms per token,  2416.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.46 ms /    24 tokens (   10.44 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =     821.75 ms /    10 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1131.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mercy Kuvalis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    11 runs   (    0.28 ms per token,  3595.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.06 ms /   130 tokens (    8.76 ms per token,   114.13 tokens per second)\n",
      "llama_print_timings:        eval time =     805.45 ms /    10 runs   (   80.55 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    2001.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"565 774 6900\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    15 runs   (    0.43 ms per token,  2332.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.63 ms /    14 runs   (   79.47 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1462.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     9 runs   (    0.23 ms per token,  4371.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.67 ms /    23 tokens (   10.86 ms per token,    92.12 tokens per second)\n",
      "llama_print_timings:        eval time =     650.18 ms /     8 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     940.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     8 runs   (    0.25 ms per token,  4030.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.98 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =     576.99 ms /     7 runs   (   82.43 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     858.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Thad D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.76 ms /    11 runs   (    0.34 ms per token,  2925.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.88 ms /   160 tokens (    7.19 ms per token,   139.02 tokens per second)\n",
      "llama_print_timings:        eval time =     814.11 ms /    10 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    2027.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"499 985 4755\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    15 runs   (    0.35 ms per token,  2833.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.57 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1198.15 ms /    14 runs   (   85.58 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1527.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     9 runs   (    0.30 ms per token,  3365.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    23 tokens (   10.96 ms per token,    91.25 tokens per second)\n",
      "llama_print_timings:        eval time =     696.25 ms /     8 runs   (   87.03 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     996.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     8 runs   (    0.20 ms per token,  4987.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.90 ms /    24 tokens (   10.50 ms per token,    95.28 tokens per second)\n",
      "llama_print_timings:        eval time =     632.46 ms /     7 runs   (   90.35 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =     915.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raymond Reilly\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /     8 runs   (    0.29 ms per token,  3442.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1384.22 ms /   166 tokens (    8.34 ms per token,   119.92 tokens per second)\n",
      "llama_print_timings:        eval time =     592.77 ms /     7 runs   (   84.68 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    2020.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"462 103 1836\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    15 runs   (    0.46 ms per token,  2183.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.03 ms /    25 tokens (   10.12 ms per token,    98.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.98 ms /    14 runs   (   81.43 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1496.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     9 runs   (    0.23 ms per token,  4308.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.66 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =     652.25 ms /     8 runs   (   81.53 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     943.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  7017.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =     105.41 ms /     1 runs   (  105.41 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =     362.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Ta Bailey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /    11 runs   (    0.35 ms per token,  2887.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.61 ms /   162 tokens (    8.54 ms per token,   117.09 tokens per second)\n",
      "llama_print_timings:        eval time =     791.15 ms /    10 runs   (   79.11 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2237.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"449 946 0442\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    15 runs   (    0.48 ms per token,  2063.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.44 ms /    14 runs   (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1471.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"85-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     9 runs   (    0.34 ms per token,  2918.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.03 ms /    23 tokens (   10.91 ms per token,    91.62 tokens per second)\n",
      "llama_print_timings:        eval time =     653.85 ms /     8 runs   (   81.73 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     963.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /    11 runs   (    0.37 ms per token,  2728.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    24 tokens (   10.50 ms per token,    95.27 tokens per second)\n",
      "llama_print_timings:        eval time =     814.74 ms /    10 runs   (   81.47 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1137.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lenny Windler\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    17 runs   (    0.52 ms per token,  1930.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1881.54 ms /   228 tokens (    8.25 ms per token,   121.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.11 ms /    16 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    3301.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"412 466 7952\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    15 runs   (    0.41 ms per token,  2424.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.84 ms /    25 tokens (   10.15 ms per token,    98.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.89 ms /    14 runs   (   81.14 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1491.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8695.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    23 tokens (   10.95 ms per token,    91.33 tokens per second)\n",
      "llama_print_timings:        eval time =      96.84 ms /     1 runs   (   96.84 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     353.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9090.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.03 ms /    24 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =      94.83 ms /     1 runs   (   94.83 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     354.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Elias MacGyver\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.87 ms /    19 runs   (    0.36 ms per token,  2767.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1146.74 ms /   143 tokens (    8.02 ms per token,   124.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1504.15 ms /    18 runs   (   83.56 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    2766.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"313 123 4492\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /    15 runs   (    0.38 ms per token,  2635.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.95 ms /    25 tokens (   10.08 ms per token,    99.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.39 ms /    14 runs   (   87.38 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1558.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     7 runs   (    0.13 ms per token,  7900.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.88 ms /    23 tokens (   11.04 ms per token,    90.59 tokens per second)\n",
      "llama_print_timings:        eval time =     609.17 ms /     6 runs   (  101.53 ms per token,     9.85 tokens per second)\n",
      "llama_print_timings:       total time =     882.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /     8 runs   (    0.19 ms per token,  5312.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.64 ms /    24 tokens (   10.65 ms per token,    93.88 tokens per second)\n",
      "llama_print_timings:        eval time =     622.29 ms /     7 runs   (   88.90 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     904.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2182.75 ms /   261 tokens (    8.36 ms per token,   119.57 tokens per second)\n",
      "llama_print_timings:        eval time =     113.44 ms /     1 runs   (  113.44 ms per token,     8.82 tokens per second)\n",
      "llama_print_timings:       total time =    2299.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"841 431 7383\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2579.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.98 ms /    25 tokens (   10.24 ms per token,    97.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1183.88 ms /    14 runs   (   84.56 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    1528.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     7 runs   (    0.12 ms per token,  8264.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.24 ms /    23 tokens (   11.18 ms per token,    89.41 tokens per second)\n",
      "llama_print_timings:        eval time =     525.00 ms /     6 runs   (   87.50 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     801.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11173.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    24 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =     111.60 ms /     1 runs   (  111.60 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =     370.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Judi Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    10 runs   (    0.45 ms per token,  2225.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.51 ms /   136 tokens (    8.48 ms per token,   117.90 tokens per second)\n",
      "llama_print_timings:        eval time =     710.64 ms /     9 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1930.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"655 925 8053\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2365.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.72 ms /    14 runs   (   79.62 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1469.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     8 runs   (    0.20 ms per token,  4984.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =     640.34 ms /     7 runs   (   91.48 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     918.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.75 ms /    24 tokens (   10.61 ms per token,    94.21 tokens per second)\n",
      "llama_print_timings:        eval time =      96.97 ms /     1 runs   (   96.97 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =     356.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo Wyman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     8 runs   (    0.27 ms per token,  3664.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.40 ms /   172 tokens (    8.17 ms per token,   122.39 tokens per second)\n",
      "llama_print_timings:        eval time =     583.33 ms /     7 runs   (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    2025.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"859 108 0548\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    15 runs   (    0.49 ms per token,  2050.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.26 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.29 ms /    14 runs   (   83.73 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1536.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     7 runs   (    0.21 ms per token,  4745.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.09 ms /    23 tokens (   10.96 ms per token,    91.24 tokens per second)\n",
      "llama_print_timings:        eval time =     491.56 ms /     6 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     771.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.00 ms /    24 tokens (   10.46 ms per token,    95.62 tokens per second)\n",
      "llama_print_timings:        eval time =      90.57 ms /     1 runs   (   90.57 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     346.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Gaynell Hudson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /     9 runs   (    0.50 ms per token,  1995.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.20 ms /   145 tokens (    7.95 ms per token,   125.85 tokens per second)\n",
      "llama_print_timings:        eval time =     631.30 ms /     8 runs   (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1854.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"690 716 5639\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    15 runs   (    0.49 ms per token,  2030.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.04 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.92 ms /    14 runs   (   79.85 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1482.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     9 runs   (    0.35 ms per token,  2871.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.40 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     642.66 ms /     8 runs   (   80.33 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     953.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =      92.44 ms /     1 runs   (   92.44 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =     348.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Aleshia Effertz\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    16 runs   (    0.45 ms per token,  2216.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.80 ms /   186 tokens (    7.52 ms per token,   133.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1181.89 ms /    15 runs   (   78.79 ms per token,    12.69 tokens per second)\n",
      "llama_print_timings:       total time =    2695.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 571 7226\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.30 ms /    15 runs   (    0.49 ms per token,  2053.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.17 ms /    25 tokens (   10.17 ms per token,    98.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.35 ms /    14 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    1487.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     8 runs   (    0.21 ms per token,  4813.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.14 ms /    23 tokens (   10.92 ms per token,    91.58 tokens per second)\n",
      "llama_print_timings:        eval time =     572.61 ms /     7 runs   (   81.80 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     858.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7042.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    24 tokens (   10.49 ms per token,    95.30 tokens per second)\n",
      "llama_print_timings:        eval time =      91.88 ms /     1 runs   (   91.88 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     352.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Timmy Kilback\", \"Doctor Riley Prohaska\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    18 runs   (    0.50 ms per token,  2017.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.66 ms /   181 tokens (    7.69 ms per token,   129.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1335.17 ms /    17 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2872.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"901 584 8849\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    15 runs   (    0.51 ms per token,  1960.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.79 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.76 ms /    14 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1501.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3651.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.63 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =     506.69 ms /     6 runs   (   84.45 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     801.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /     8 runs   (    0.20 ms per token,  4941.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.31 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =     575.13 ms /     7 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     857.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ron Armstrong\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /     8 runs   (    0.24 ms per token,  4140.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2978.62 ms /   384 tokens (    7.76 ms per token,   128.92 tokens per second)\n",
      "llama_print_timings:        eval time =     660.61 ms /     7 runs   (   94.37 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =    3678.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"520 987 1276\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    15 runs   (    0.48 ms per token,  2095.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.99 ms /    25 tokens (   10.32 ms per token,    96.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1182.40 ms /    14 runs   (   84.46 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =    1556.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     9 runs   (    0.22 ms per token,  4534.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.73 ms /    23 tokens (   11.16 ms per token,    89.59 tokens per second)\n",
      "llama_print_timings:        eval time =     674.20 ms /     8 runs   (   84.27 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     976.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.39 ms /    24 tokens (   10.64 ms per token,    93.97 tokens per second)\n",
      "llama_print_timings:        eval time =      94.91 ms /     1 runs   (   94.91 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =     355.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Leda Lebsack\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     8 runs   (    0.34 ms per token,  2978.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.48 ms /   137 tokens (    8.36 ms per token,   119.60 tokens per second)\n",
      "llama_print_timings:        eval time =     559.68 ms /     7 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1750.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 593 9975\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2015.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.37 ms /    25 tokens (   10.09 ms per token,    99.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.36 ms /    14 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1484.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     7 runs   (    0.16 ms per token,  6118.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     486.44 ms /     6 runs   (   81.07 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     767.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6920.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.64 ms /    24 tokens (   10.40 ms per token,    96.14 tokens per second)\n",
      "llama_print_timings:        eval time =      93.23 ms /     1 runs   (   93.23 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =     349.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kyle Greenfelder\", \"Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.00 ms /    13 runs   (    0.38 ms per token,  2601.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1621.03 ms /   201 tokens (    8.06 ms per token,   124.00 tokens per second)\n",
      "llama_print_timings:        eval time =     958.49 ms /    12 runs   (   79.87 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2668.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"117 435 2400\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.88 ms /    15 runs   (    0.46 ms per token,  2179.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.13 ms /    25 tokens (   10.13 ms per token,    98.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.58 ms /    14 runs   (   80.83 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1496.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6968.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    23 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =      90.20 ms /     1 runs   (   90.20 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     347.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.14 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     101.13 ms /     1 runs   (  101.13 ms per token,     9.89 tokens per second)\n",
      "llama_print_timings:       total time =     355.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Booker O'Conner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     9 runs   (    0.32 ms per token,  3101.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.29 ms /   177 tokens (    7.83 ms per token,   127.77 tokens per second)\n",
      "llama_print_timings:        eval time =     633.33 ms /     8 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2068.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 352 9555\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    15 runs   (    0.54 ms per token,  1858.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.91 ms /    25 tokens (   10.12 ms per token,    98.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1129.95 ms /    14 runs   (   80.71 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1494.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    23 tokens (   10.87 ms per token,    91.96 tokens per second)\n",
      "llama_print_timings:        eval time =      88.67 ms /     1 runs   (   88.67 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     344.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     7 runs   (    0.18 ms per token,  5668.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.36 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     496.84 ms /     6 runs   (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     771.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lien Kub\", \"Doctor Hellen Roberts\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    16 runs   (    0.46 ms per token,  2177.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.00 ms /   165 tokens (    8.36 ms per token,   119.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.77 ms /    15 runs   (   79.05 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2691.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 422 4701\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2257.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.02 ms /    14 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1462.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     6 runs   (    0.21 ms per token,  4842.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.43 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     413.46 ms /     5 runs   (   82.69 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     686.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2564.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.17 ms /    15 runs   (   79.01 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1561.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stacee Friesen\", \"Doctor Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.48 ms /    21 runs   (    0.45 ms per token,  2214.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.76 ms /   173 tokens (    8.01 ms per token,   124.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1578.76 ms /    20 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    3132.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"703 271 0272\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.23 ms /    15 runs   (    0.42 ms per token,  2406.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.13 ms /    25 tokens (   10.09 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.38 ms /    14 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1488.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     9 runs   (    0.29 ms per token,  3456.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.43 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     660.65 ms /     8 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     955.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     8 runs   (    0.31 ms per token,  3228.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    24 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =     592.38 ms /     7 runs   (   84.63 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     881.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Anneliese Gutkowski\", \"Dr. Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.28 ms /    18 runs   (    0.35 ms per token,  2866.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.63 ms /   187 tokens (    7.50 ms per token,   133.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1418.25 ms /    17 runs   (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =    2930.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 394 9884\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2186.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.14 ms /    25 tokens (   10.17 ms per token,    98.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1194.86 ms /    14 runs   (   85.35 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    1543.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.07 ms /    23 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =     107.68 ms /     1 runs   (  107.68 ms per token,     9.29 tokens per second)\n",
      "llama_print_timings:       total time =     366.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.33 ms /     9 runs   (    0.26 ms per token,  3870.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.60 ms /    24 tokens (   10.53 ms per token,    95.01 tokens per second)\n",
      "llama_print_timings:        eval time =     691.62 ms /     8 runs   (   86.45 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     983.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Dovie Hackett\", \"Dr. Jude Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.99 ms /    19 runs   (    0.42 ms per token,  2378.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.87 ms /   159 tokens (    7.42 ms per token,   134.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1506.53 ms /    18 runs   (   83.70 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    2817.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"875 803 5683\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2682.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.89 ms /    25 tokens (   10.12 ms per token,    98.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1184.83 ms /    14 runs   (   84.63 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =    1521.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     9 runs   (    0.30 ms per token,  3386.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.90 ms /    23 tokens (   10.95 ms per token,    91.31 tokens per second)\n",
      "llama_print_timings:        eval time =     692.08 ms /     8 runs   (   86.51 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     991.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\", \"Chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    18 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.97 ms /    24 tokens (   10.50 ms per token,    95.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1439.04 ms /    17 runs   (   84.65 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1789.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Kelsi Koch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     9 runs   (    0.33 ms per token,  3035.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1160.93 ms /   142 tokens (    8.18 ms per token,   122.32 tokens per second)\n",
      "llama_print_timings:        eval time =     661.65 ms /     8 runs   (   82.71 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1872.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"775 635 7538\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    15 runs   (    0.37 ms per token,  2736.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.70 ms /    25 tokens (   10.15 ms per token,    98.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.42 ms /    14 runs   (   82.46 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1488.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     9 runs   (    0.31 ms per token,  3228.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     657.36 ms /     8 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     955.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     8 runs   (    0.32 ms per token,  3082.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.54 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =     582.73 ms /     7 runs   (   83.25 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     879.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Marian Larson\", \"Dr. Alejandro Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    18 runs   (    0.46 ms per token,  2153.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1894.15 ms /   226 tokens (    8.38 ms per token,   119.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1397.12 ms /    17 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    3425.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"341 407 9468\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.84 ms /    15 runs   (    0.39 ms per token,  2570.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    25 tokens (   10.23 ms per token,    97.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.13 ms /    14 runs   (   83.51 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =    1520.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     7 runs   (    0.28 ms per token,  3571.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.50 ms /    23 tokens (   11.07 ms per token,    90.37 tokens per second)\n",
      "llama_print_timings:        eval time =     558.25 ms /     6 runs   (   93.04 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =     842.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"complaint\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     6 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.93 ms /    24 tokens (   10.96 ms per token,    91.28 tokens per second)\n",
      "llama_print_timings:        eval time =     427.06 ms /     5 runs   (   85.41 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     705.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kraig Greenholt\", \"Dr. Rolande Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    17 runs   (    0.45 ms per token,  2243.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.06 ms /   143 tokens (    8.08 ms per token,   123.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1281.27 ms /    16 runs   (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2571.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 264 4213\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    15 runs   (    0.50 ms per token,  2001.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.95 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.79 ms /    14 runs   (   80.20 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1498.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     8 runs   (    0.30 ms per token,  3364.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.42 ms /    23 tokens (   10.97 ms per token,    91.12 tokens per second)\n",
      "llama_print_timings:        eval time =     572.52 ms /     7 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     861.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /     8 runs   (    0.47 ms per token,  2111.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.20 ms /    24 tokens (   10.51 ms per token,    95.16 tokens per second)\n",
      "llama_print_timings:        eval time =     575.46 ms /     7 runs   (   82.21 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     874.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Burt Johnston\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.96 ms /    17 runs   (    0.47 ms per token,  2134.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1385.41 ms /   169 tokens (    8.20 ms per token,   121.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1273.13 ms /    16 runs   (   79.57 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2801.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"463 924 9100\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    15 runs   (    0.58 ms per token,  1712.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.13 ms /    25 tokens (   10.13 ms per token,    98.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.68 ms /    14 runs   (   80.48 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1501.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.53 ms /    23 tokens (   11.02 ms per token,    90.72 tokens per second)\n",
      "llama_print_timings:        eval time =      92.34 ms /     1 runs   (   92.34 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     350.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     8 runs   (    0.31 ms per token,  3211.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.00 ms /    24 tokens (   10.50 ms per token,    95.24 tokens per second)\n",
      "llama_print_timings:        eval time =     573.95 ms /     7 runs   (   81.99 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     867.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lois Thompson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     9 runs   (    0.40 ms per token,  2475.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1652.98 ms /   194 tokens (    8.52 ms per token,   117.36 tokens per second)\n",
      "llama_print_timings:        eval time =     663.61 ms /     8 runs   (   82.95 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    2370.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"108 589 4964\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.25 ms /    15 runs   (    0.42 ms per token,  2399.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.19 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.15 ms /    14 runs   (   89.15 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    1596.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     6 runs   (    0.16 ms per token,  6185.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.69 ms /    23 tokens (   11.25 ms per token,    88.91 tokens per second)\n",
      "llama_print_timings:        eval time =     431.27 ms /     5 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     713.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7547.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.17 ms /    24 tokens (   10.72 ms per token,    93.32 tokens per second)\n",
      "llama_print_timings:        eval time =     102.83 ms /     1 runs   (  102.83 ms per token,     9.73 tokens per second)\n",
      "llama_print_timings:       total time =     366.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Teodora Kris\", \"Dr. Bennie Abbott\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.58 ms /    20 runs   (    0.58 ms per token,  1727.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.03 ms /   156 tokens (    7.65 ms per token,   130.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1544.39 ms /    19 runs   (   81.28 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2905.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 837 7075\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    15 runs   (    0.57 ms per token,  1762.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.29 ms /    25 tokens (   10.37 ms per token,    96.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.90 ms /    14 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1511.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2495.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.37 ms /    23 tokens (   10.97 ms per token,    91.14 tokens per second)\n",
      "llama_print_timings:        eval time =     653.91 ms /     8 runs   (   81.74 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     954.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.69 ms /     8 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     575.45 ms /     7 runs   (   82.21 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     859.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Amada Ernser\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.07 ms /    17 runs   (    0.47 ms per token,  2105.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.89 ms /   184 tokens (    7.66 ms per token,   130.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.76 ms /    16 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2829.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"563 566 2158\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.19 ms /    15 runs   (    0.48 ms per token,  2086.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.99 ms /    25 tokens (   10.16 ms per token,    98.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1158.97 ms /    14 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1516.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     9 runs   (    0.28 ms per token,  3614.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.94 ms /    23 tokens (   11.17 ms per token,    89.52 tokens per second)\n",
      "llama_print_timings:        eval time =     694.58 ms /     8 runs   (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =     998.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.93 ms /     8 runs   (    0.24 ms per token,  4153.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.29 ms /    24 tokens (   10.51 ms per token,    95.13 tokens per second)\n",
      "llama_print_timings:        eval time =     602.95 ms /     7 runs   (   86.14 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     887.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Paula Kuvalis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    11 runs   (    0.61 ms per token,  1638.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.52 ms /   157 tokens (    7.50 ms per token,   133.33 tokens per second)\n",
      "llama_print_timings:        eval time =     834.54 ms /    10 runs   (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    2104.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"618 116 3318\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /    15 runs   (    0.26 ms per token,  3788.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.02 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1194.68 ms /    14 runs   (   85.33 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =    1520.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     7 runs   (    0.15 ms per token,  6717.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =     603.28 ms /     6 runs   (  100.55 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =     872.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    11 runs   (    0.36 ms per token,  2806.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.38 ms /    24 tokens (   10.81 ms per token,    92.53 tokens per second)\n",
      "llama_print_timings:        eval time =     851.28 ms /    10 runs   (   85.13 ms per token,    11.75 tokens per second)\n",
      "llama_print_timings:       total time =    1170.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Shana Johns\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.70 ms /    18 runs   (    0.37 ms per token,  2685.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.74 ms /   141 tokens (    8.35 ms per token,   119.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1454.78 ms /    17 runs   (   85.58 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =    2768.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"382 976 1004\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.03 ms /    15 runs   (    0.40 ms per token,  2485.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.38 ms /    25 tokens (   10.14 ms per token,    98.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.42 ms /    14 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1482.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"68\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     5 runs   (    0.20 ms per token,  5128.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     341.88 ms /     4 runs   (   85.47 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     613.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6097.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.23 ms /    24 tokens (   10.47 ms per token,    95.53 tokens per second)\n",
      "llama_print_timings:        eval time =     108.13 ms /     1 runs   (  108.13 ms per token,     9.25 tokens per second)\n",
      "llama_print_timings:       total time =     363.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lincoln Cruickshank\", \"Doctor Antonette Tromp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    18 runs   (    0.40 ms per token,  2508.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1654.52 ms /   220 tokens (    7.52 ms per token,   132.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1436.51 ms /    17 runs   (   84.50 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =    3208.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 558 3490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    15 runs   (    0.32 ms per token,  3087.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.47 ms /    25 tokens (   10.46 ms per token,    95.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.85 ms /    14 runs   (   90.06 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    1598.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"1 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     5 runs   (    0.11 ms per token,  9057.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.12 ms /    23 tokens (   11.22 ms per token,    89.11 tokens per second)\n",
      "llama_print_timings:        eval time =     362.85 ms /     4 runs   (   90.71 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =     634.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     8 runs   (    0.17 ms per token,  5743.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.94 ms /    24 tokens (   10.54 ms per token,    94.88 tokens per second)\n",
      "llama_print_timings:        eval time =     617.96 ms /     7 runs   (   88.28 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     896.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Iona Reichert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     7 runs   (    0.24 ms per token,  4100.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.50 ms /   137 tokens (    8.49 ms per token,   117.85 tokens per second)\n",
      "llama_print_timings:        eval time =     513.56 ms /     6 runs   (   85.59 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1710.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 221 4866\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    15 runs   (    0.52 ms per token,  1918.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.67 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.84 ms /    14 runs   (   82.06 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1512.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.91 ms /     8 runs   (    0.36 ms per token,  2746.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    23 tokens (   10.96 ms per token,    91.21 tokens per second)\n",
      "llama_print_timings:        eval time =     574.03 ms /     7 runs   (   82.00 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     870.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     6 runs   (    0.26 ms per token,  3865.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     418.39 ms /     5 runs   (   83.68 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     700.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo Nolan\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    15 runs   (    0.48 ms per token,  2088.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.59 ms /   190 tokens (    7.41 ms per token,   134.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.29 ms /    14 runs   (   79.59 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2638.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"675 526 0122\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    15 runs   (    0.47 ms per token,  2140.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.39 ms /    25 tokens (   10.18 ms per token,    98.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.43 ms /    14 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1504.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /     9 runs   (    0.26 ms per token,  3897.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.21 ms /    23 tokens (   11.40 ms per token,    87.71 tokens per second)\n",
      "llama_print_timings:        eval time =     679.91 ms /     8 runs   (   84.99 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     985.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.49 ms /    11 runs   (    0.50 ms per token,  2003.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.44 ms /    24 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     809.94 ms /    10 runs   (   80.99 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1145.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Eugene Reichert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.67 ms /   140 tokens (    8.24 ms per token,   121.35 tokens per second)\n",
      "llama_print_timings:        eval time =     723.26 ms /     9 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1941.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"536 247 5671\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    15 runs   (    0.45 ms per token,  2220.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.79 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.40 ms /    14 runs   (   81.96 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1505.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2491.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.34 ms /    23 tokens (   11.15 ms per token,    89.72 tokens per second)\n",
      "llama_print_timings:        eval time =     652.06 ms /     8 runs   (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     960.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     8 runs   (    0.35 ms per token,  2898.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.57 ms /    24 tokens (   10.77 ms per token,    92.82 tokens per second)\n",
      "llama_print_timings:        eval time =     595.13 ms /     7 runs   (   85.02 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     899.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clyde Streich\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.21 ms /    18 runs   (    0.57 ms per token,  1762.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.92 ms /   175 tokens (    8.03 ms per token,   124.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1376.00 ms /    17 runs   (   80.94 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2934.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"367 955 8828\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    15 runs   (    0.44 ms per token,  2251.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.30 ms /    25 tokens (   10.21 ms per token,    97.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.53 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1513.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /     8 runs   (    0.18 ms per token,  5567.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.27 ms /    23 tokens (   11.01 ms per token,    90.81 tokens per second)\n",
      "llama_print_timings:        eval time =     573.21 ms /     7 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     854.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7490.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.28 ms /    24 tokens (   10.64 ms per token,    94.01 tokens per second)\n",
      "llama_print_timings:        eval time =     104.83 ms /     1 runs   (  104.83 ms per token,     9.54 tokens per second)\n",
      "llama_print_timings:       total time =     366.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Vaughn Vandervort\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.65 ms /    12 runs   (    0.47 ms per token,  2125.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1388.78 ms /   170 tokens (    8.17 ms per token,   122.41 tokens per second)\n",
      "llama_print_timings:        eval time =     920.70 ms /    11 runs   (   83.70 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    2387.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"887 808 6269\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.94 ms /    15 runs   (    0.53 ms per token,  1889.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.85 ms /    25 tokens (   10.11 ms per token,    98.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.16 ms /    14 runs   (   80.23 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1486.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     7 runs   (    0.21 ms per token,  4723.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.30 ms /    23 tokens (   11.01 ms per token,    90.80 tokens per second)\n",
      "llama_print_timings:        eval time =     494.01 ms /     6 runs   (   82.34 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     772.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    17 runs   (    0.34 ms per token,  2904.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    24 tokens (   10.53 ms per token,    94.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.85 ms /    16 runs   (   83.30 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1681.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mickey Grant\", \"Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    13 runs   (    0.36 ms per token,  2810.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.37 ms /   137 tokens (    8.48 ms per token,   117.86 tokens per second)\n",
      "llama_print_timings:        eval time =     973.77 ms /    12 runs   (   81.15 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    2229.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"225 848 4479\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.55 ms /    15 runs   (    0.17 ms per token,  5875.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    25 tokens (   10.06 ms per token,    99.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.68 ms /    14 runs   (   93.19 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =    1619.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.52 ms /     7 runs   (    0.22 ms per token,  4608.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.68 ms /    23 tokens (   11.07 ms per token,    90.31 tokens per second)\n",
      "llama_print_timings:        eval time =     468.70 ms /     6 runs   (   78.12 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =     756.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     6 runs   (    0.22 ms per token,  4548.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.66 ms /    24 tokens (   10.40 ms per token,    96.13 tokens per second)\n",
      "llama_print_timings:        eval time =     395.56 ms /     5 runs   (   79.11 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =     671.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Claude Marks\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /     9 runs   (    0.35 ms per token,  2837.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     929.14 ms /   128 tokens (    7.26 ms per token,   137.76 tokens per second)\n",
      "llama_print_timings:        eval time =     617.30 ms /     8 runs   (   77.16 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1602.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"625 258 8859\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.28 ms /    15 runs   (    0.35 ms per token,  2843.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.79 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.00 ms /    14 runs   (   81.29 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1488.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     5 runs   (    0.21 ms per token,  4816.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.03 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     323.85 ms /     4 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     592.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6896.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.24 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =      87.68 ms /     1 runs   (   87.68 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     343.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Aleen Kreiger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    10 runs   (    0.37 ms per token,  2718.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.91 ms /   135 tokens (    8.69 ms per token,   115.10 tokens per second)\n",
      "llama_print_timings:        eval time =     742.38 ms /     9 runs   (   82.49 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1973.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"793 343 3940\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    15 runs   (    0.31 ms per token,  3178.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1087.16 ms /    14 runs   (   77.65 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    1426.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     7 runs   (    0.26 ms per token,  3861.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    23 tokens (   10.87 ms per token,    91.96 tokens per second)\n",
      "llama_print_timings:        eval time =     506.52 ms /     6 runs   (   84.42 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     784.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.75 ms /     8 runs   (    0.34 ms per token,  2908.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     584.69 ms /     7 runs   (   83.53 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     876.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Eduardo Adams\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.79 ms /    15 runs   (    0.32 ms per token,  3134.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.22 ms /   149 tokens (    7.81 ms per token,   127.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.18 ms /    14 runs   (   77.37 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    2351.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"522 733 6043\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.19 ms /    15 runs   (    0.35 ms per token,  2892.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.20 ms /    25 tokens (   10.05 ms per token,    99.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.88 ms /    14 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1438.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.79 ms /     9 runs   (    0.31 ms per token,  3223.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.05 ms /    23 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =     628.21 ms /     8 runs   (   78.53 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     923.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     8 runs   (    0.27 ms per token,  3691.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.90 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =     559.17 ms /     7 runs   (   79.88 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     844.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Quintin Pouros\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    10 runs   (    0.28 ms per token,  3607.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2155.22 ms /   288 tokens (    7.48 ms per token,   133.63 tokens per second)\n",
      "llama_print_timings:        eval time =     739.17 ms /     9 runs   (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    2953.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"157 444 9803\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    15 runs   (    0.31 ms per token,  3176.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.40 ms /    25 tokens (   10.74 ms per token,    93.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.43 ms /    14 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1517.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.90 ms /     9 runs   (    0.21 ms per token,  4749.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.55 ms /    23 tokens (   11.02 ms per token,    90.71 tokens per second)\n",
      "llama_print_timings:        eval time =     648.61 ms /     8 runs   (   81.08 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     953.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Generalized Anxiety Disorder\", \"anxiety\", \"depression screening\", \"substance use\", \"drug abuse\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    32 runs   (    0.27 ms per token,  3702.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    24 tokens (   10.58 ms per token,    94.56 tokens per second)\n",
      "llama_print_timings:        eval time =    2470.69 ms /    31 runs   (   79.70 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    2894.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Stacia Cummerata\", \"Winston McCullough\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.66 ms /    20 runs   (    0.48 ms per token,  2070.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.49 ms /   194 tokens (    8.34 ms per token,   119.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1506.76 ms /    19 runs   (   79.30 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    3279.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"670 969 7309\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    15 runs   (    0.50 ms per token,  1994.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    25 tokens (   10.10 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.24 ms /    14 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1488.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.46 ms /     9 runs   (    0.38 ms per token,  2599.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.72 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =     650.92 ms /     8 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     963.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    24 tokens (   10.47 ms per token,    95.50 tokens per second)\n",
      "llama_print_timings:        eval time =      93.09 ms /     1 runs   (   93.09 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =     350.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cecelia Greenfelder\", \"Dr. Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.16 ms /    17 runs   (    0.48 ms per token,  2083.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.83 ms /   167 tokens (    8.23 ms per token,   121.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.56 ms /    16 runs   (   78.53 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2762.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 111 4383\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    15 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    25 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.67 ms /    14 runs   (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1455.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.48 ms /     6 runs   (    0.25 ms per token,  4051.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =     400.66 ms /     5 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     676.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.89 ms /    24 tokens (   10.58 ms per token,    94.53 tokens per second)\n",
      "llama_print_timings:        eval time =      93.56 ms /     1 runs   (   93.56 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =     360.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cody Haley\", \"Dr. Rochell Stehr\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.03 ms /    17 runs   (    0.47 ms per token,  2117.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.48 ms /   145 tokens (    7.93 ms per token,   126.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.28 ms /    16 runs   (   78.02 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2528.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 879 4736\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.29 ms /    15 runs   (    0.42 ms per token,  2385.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.99 ms /    25 tokens (   10.04 ms per token,    99.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1159.00 ms /    14 runs   (   82.79 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1500.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     6 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.17 ms /    23 tokens (   11.14 ms per token,    89.78 tokens per second)\n",
      "llama_print_timings:        eval time =     424.16 ms /     5 runs   (   84.83 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =     703.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7547.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.76 ms /    24 tokens (   10.74 ms per token,    93.11 tokens per second)\n",
      "llama_print_timings:        eval time =     111.61 ms /     1 runs   (  111.61 ms per token,     8.96 tokens per second)\n",
      "llama_print_timings:       total time =     382.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Gina Hegmann\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.32 ms /    20 runs   (    0.57 ms per token,  1766.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.29 ms /   140 tokens (    8.29 ms per token,   120.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1539.14 ms /    19 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2874.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"359 343 3661\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    15 runs   (    0.48 ms per token,  2098.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.17 ms /    25 tokens (   10.21 ms per token,    97.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.21 ms /    14 runs   (   81.66 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1496.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /     9 runs   (    0.36 ms per token,  2795.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     657.06 ms /     8 runs   (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     956.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     8 runs   (    0.42 ms per token,  2390.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.89 ms /    24 tokens (   10.50 ms per token,    95.28 tokens per second)\n",
      "llama_print_timings:        eval time =     597.18 ms /     7 runs   (   85.31 ms per token,    11.72 tokens per second)\n",
      "llama_print_timings:       total time =     891.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Carroll Murray\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /     8 runs   (    0.36 ms per token,  2778.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1888.36 ms /   233 tokens (    8.10 ms per token,   123.39 tokens per second)\n",
      "llama_print_timings:        eval time =     559.21 ms /     7 runs   (   79.89 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2490.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"136 239 3196\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    15 runs   (    0.51 ms per token,  1973.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.24 ms /    25 tokens (   10.09 ms per token,    99.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.01 ms /    14 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1480.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /     8 runs   (    0.32 ms per token,  3128.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.24 ms /    23 tokens (   10.92 ms per token,    91.55 tokens per second)\n",
      "llama_print_timings:        eval time =     573.21 ms /     7 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     857.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7326.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    24 tokens (   10.49 ms per token,    95.32 tokens per second)\n",
      "llama_print_timings:        eval time =      98.94 ms /     1 runs   (   98.94 ms per token,    10.11 tokens per second)\n",
      "llama_print_timings:       total time =     355.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Eufemia Carroll\", \"Doctor Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    18 runs   (    0.39 ms per token,  2569.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1147.08 ms /   160 tokens (    7.17 ms per token,   139.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1399.49 ms /    17 runs   (   82.32 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    2661.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"644 586 8918\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.55 ms /    15 runs   (    0.50 ms per token,  1985.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.25 ms /    14 runs   (   78.23 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1462.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"73-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     9 runs   (    0.30 ms per token,  3290.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.36 ms /    23 tokens (   10.89 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =     631.40 ms /     8 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =     928.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =      91.42 ms /     1 runs   (   91.42 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     347.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Arthur Lind\", \"Doctor Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    14 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.41 ms /   146 tokens (    8.06 ms per token,   124.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1023.38 ms /    13 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    2316.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"452 251 7755\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.86 ms /    15 runs   (    0.66 ms per token,  1520.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.44 ms /    25 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.06 ms /    14 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1490.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.31 ms /     9 runs   (    0.48 ms per token,  2089.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    23 tokens (   10.87 ms per token,    92.01 tokens per second)\n",
      "llama_print_timings:        eval time =     647.61 ms /     8 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     959.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     8 runs   (    0.27 ms per token,  3729.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.13 ms /    24 tokens (   10.42 ms per token,    95.95 tokens per second)\n",
      "llama_print_timings:        eval time =     557.57 ms /     7 runs   (   79.65 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =     841.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Monet Konopelski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /     9 runs   (    0.44 ms per token,  2254.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.16 ms /   153 tokens (    7.54 ms per token,   132.68 tokens per second)\n",
      "llama_print_timings:        eval time =     620.37 ms /     8 runs   (   77.55 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    1837.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 771 5053\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.50 ms /    15 runs   (    0.63 ms per token,  1579.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.23 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.98 ms /    14 runs   (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    1483.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     7 runs   (    0.45 ms per token,  2199.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.07 ms /    23 tokens (   10.96 ms per token,    91.25 tokens per second)\n",
      "llama_print_timings:        eval time =     479.33 ms /     6 runs   (   79.89 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =     789.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.43 ms /    11 runs   (    0.49 ms per token,  2027.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.75 ms /    24 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =     787.16 ms /    10 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1130.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Danial Rohan\", \"Dr. Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.30 ms /    17 runs   (    0.49 ms per token,  2046.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1369.15 ms /   162 tokens (    8.45 ms per token,   118.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1240.73 ms /    16 runs   (   77.55 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    2754.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"837 915 3497\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.50 ms /    15 runs   (    0.43 ms per token,  2307.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.01 ms /    25 tokens (   10.08 ms per token,    99.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.42 ms /    14 runs   (   78.03 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1451.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2625.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.24 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     634.31 ms /     8 runs   (   79.29 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =     940.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     8 runs   (    0.32 ms per token,  3157.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =     560.88 ms /     7 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     856.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Major Kautzer\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.81 ms /    16 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.49 ms /   144 tokens (    7.95 ms per token,   125.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.73 ms /    15 runs   (   77.58 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2434.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 627 659 8322\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.45 ms /    19 runs   (    0.39 ms per token,  2552.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.29 ms /    25 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1477.40 ms /    18 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1865.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     7 runs   (    0.35 ms per token,  2818.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.18 ms /    23 tokens (   11.36 ms per token,    88.06 tokens per second)\n",
      "llama_print_timings:        eval time =     492.19 ms /     6 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     799.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     8 runs   (    0.24 ms per token,  4166.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    24 tokens (   10.44 ms per token,    95.79 tokens per second)\n",
      "llama_print_timings:        eval time =     579.59 ms /     7 runs   (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     866.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Edmundo Collins\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     9 runs   (    0.36 ms per token,  2814.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.70 ms /   167 tokens (    8.47 ms per token,   118.13 tokens per second)\n",
      "llama_print_timings:        eval time =     642.11 ms /     8 runs   (   80.26 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    2109.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"152 381 1402\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    15 runs   (    0.41 ms per token,  2457.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.15 ms /    25 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1133.37 ms /    14 runs   (   80.95 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    1492.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     9 runs   (    0.35 ms per token,  2818.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    23 tokens (   10.98 ms per token,    91.07 tokens per second)\n",
      "llama_print_timings:        eval time =     641.63 ms /     8 runs   (   80.20 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     952.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /    11 runs   (    0.37 ms per token,  2705.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    24 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =     836.88 ms /    10 runs   (   83.69 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    1152.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Guy Mills\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /     8 runs   (    0.29 ms per token,  3392.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.52 ms /   170 tokens (    8.13 ms per token,   122.96 tokens per second)\n",
      "llama_print_timings:        eval time =     575.17 ms /     7 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    2005.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"174 204 4971\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.42 ms /    15 runs   (    0.43 ms per token,  2337.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.25 ms /    25 tokens (   10.05 ms per token,    99.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.79 ms /    14 runs   (   79.48 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1460.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"75 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.84 ms /     7 runs   (    0.26 ms per token,  3796.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.88 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     486.23 ms /     6 runs   (   81.04 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =     769.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7326.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.27 ms /    24 tokens (   10.39 ms per token,    96.28 tokens per second)\n",
      "llama_print_timings:        eval time =      91.72 ms /     1 runs   (   91.72 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =     346.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jared Wyman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     7 runs   (    0.12 ms per token,  8363.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2220.59 ms /   275 tokens (    8.07 ms per token,   123.84 tokens per second)\n",
      "llama_print_timings:        eval time =     510.11 ms /     6 runs   (   85.02 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =    2748.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 259 8387\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    15 runs   (    0.31 ms per token,  3201.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.69 ms /    25 tokens (   10.19 ms per token,    98.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.17 ms /    14 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1449.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8298.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.36 ms /    23 tokens (   10.97 ms per token,    91.14 tokens per second)\n",
      "llama_print_timings:        eval time =     103.63 ms /     1 runs   (  103.63 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     361.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.10 ms per token,  9756.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.83 ms /    24 tokens (   10.49 ms per token,    95.30 tokens per second)\n",
      "llama_print_timings:        eval time =      90.31 ms /     1 runs   (   90.31 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =     346.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Johnsie Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    11 runs   (    0.24 ms per token,  4116.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.02 ms /   140 tokens (    8.16 ms per token,   122.48 tokens per second)\n",
      "llama_print_timings:        eval time =     783.60 ms /    10 runs   (   78.36 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1978.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"565 275 1162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.59 ms /    15 runs   (    0.31 ms per token,  3269.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.65 ms /    25 tokens (   10.07 ms per token,    99.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.54 ms /    14 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1431.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     9 runs   (    0.16 ms per token,  6392.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.45 ms /    23 tokens (   10.85 ms per token,    92.20 tokens per second)\n",
      "llama_print_timings:        eval time =     644.38 ms /     8 runs   (   80.55 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     918.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     8 runs   (    0.13 ms per token,  7707.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.81 ms /    24 tokens (   10.41 ms per token,    96.07 tokens per second)\n",
      "llama_print_timings:        eval time =     599.31 ms /     7 runs   (   85.62 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =     866.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Trudie Jones\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    17 runs   (    0.14 ms per token,  6913.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.26 ms /   151 tokens (    7.66 ms per token,   130.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1314.63 ms /    16 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    2520.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"684 377 3682\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /    15 runs   (    0.23 ms per token,  4363.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.20 ms /    25 tokens (   10.13 ms per token,    98.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.45 ms /    14 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1463.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     9 runs   (    0.24 ms per token,  4237.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    23 tokens (   10.88 ms per token,    91.92 tokens per second)\n",
      "llama_print_timings:        eval time =     639.46 ms /     8 runs   (   79.93 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     925.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     8 runs   (    0.24 ms per token,  4241.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.16 ms /    24 tokens (   10.46 ms per token,    95.56 tokens per second)\n",
      "llama_print_timings:        eval time =     570.43 ms /     7 runs   (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =     855.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Miguelina Ledner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    10 runs   (    0.25 ms per token,  4035.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.93 ms /   185 tokens (    7.52 ms per token,   133.00 tokens per second)\n",
      "llama_print_timings:        eval time =     713.28 ms /     9 runs   (   79.25 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2155.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"757 221 7518\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /    15 runs   (    0.31 ms per token,  3244.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.59 ms /    25 tokens (   10.10 ms per token,    98.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.98 ms /    14 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1458.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     7 runs   (    0.15 ms per token,  6481.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     487.21 ms /     6 runs   (   81.20 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     758.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /    11 runs   (    0.21 ms per token,  4739.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    24 tokens (   10.44 ms per token,    95.78 tokens per second)\n",
      "llama_print_timings:        eval time =     799.47 ms /    10 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1099.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Clyde Gleichner\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.39 ms /    20 runs   (    0.27 ms per token,  3712.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.84 ms /   141 tokens (    8.11 ms per token,   123.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1494.25 ms /    19 runs   (   78.64 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    2756.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"322 755 2501\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    15 runs   (    0.25 ms per token,  4002.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1110.72 ms /    14 runs   (   79.34 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1433.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /     7 runs   (    0.17 ms per token,  5942.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.79 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     485.48 ms /     6 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     757.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.14 ms /     8 runs   (    0.14 ms per token,  7005.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.75 ms /    24 tokens (   10.41 ms per token,    96.10 tokens per second)\n",
      "llama_print_timings:        eval time =     575.29 ms /     7 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     844.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Waylon Waelchi\", \"Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    18 runs   (    0.30 ms per token,  3310.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.03 ms /   153 tokens (    7.70 ms per token,   129.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1486.60 ms /    17 runs   (   87.45 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2777.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"511 168 4472\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.59 ms /    15 runs   (    0.37 ms per token,  2681.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.46 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1170.27 ms /    14 runs   (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    1520.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     9 runs   (    0.18 ms per token,  5632.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.95 ms /    23 tokens (   11.04 ms per token,    90.57 tokens per second)\n",
      "llama_print_timings:        eval time =     824.11 ms /     8 runs   (  103.01 ms per token,     9.71 tokens per second)\n",
      "llama_print_timings:       total time =    1154.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2710.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.29 ms /    24 tokens (   10.47 ms per token,    95.51 tokens per second)\n",
      "llama_print_timings:        eval time =     598.05 ms /     7 runs   (   85.44 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     894.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Oren Rowe\", \"Tracey Hamill\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    15 runs   (    0.43 ms per token,  2312.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.79 ms /   140 tokens (    8.23 ms per token,   121.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1216.12 ms /    14 runs   (   86.87 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    2476.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"616 405 3935\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    15 runs   (    0.46 ms per token,  2167.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.01 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.89 ms /    14 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1488.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.11 ms /     9 runs   (    0.35 ms per token,  2893.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     644.96 ms /     8 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     951.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.64 ms /     8 runs   (    0.46 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =     572.14 ms /     7 runs   (   81.73 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     878.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cyrus Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     9 runs   (    0.39 ms per token,  2548.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1139.16 ms /   131 tokens (    8.70 ms per token,   115.00 tokens per second)\n",
      "llama_print_timings:        eval time =     640.84 ms /     8 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1834.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"725 663 1952\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.10 ms /    15 runs   (    0.54 ms per token,  1852.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    25 tokens (   10.06 ms per token,    99.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.00 ms /    14 runs   (   79.43 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1475.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /     9 runs   (    0.46 ms per token,  2168.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.53 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =     650.60 ms /     8 runs   (   81.33 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     956.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    11 runs   (    0.34 ms per token,  2982.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =     809.30 ms /    10 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1121.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Osvaldo Wunsch\", \"Dr. Lynsey Lemke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    19 runs   (    0.57 ms per token,  1754.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.06 ms /   165 tokens (    8.33 ms per token,   120.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1438.90 ms /    18 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2979.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"899 453 6822\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    15 runs   (    0.53 ms per token,  1896.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.24 ms /    25 tokens (   10.17 ms per token,    98.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.77 ms /    14 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1519.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.94 ms /     7 runs   (    0.42 ms per token,  2376.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    23 tokens (   11.01 ms per token,    90.82 tokens per second)\n",
      "llama_print_timings:        eval time =     489.61 ms /     6 runs   (   81.60 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     784.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5479.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.16 ms /    24 tokens (   10.55 ms per token,    94.80 tokens per second)\n",
      "llama_print_timings:        eval time =      99.50 ms /     1 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     358.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wilford Zieme\", \"Dr. Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.53 ms /    18 runs   (    0.47 ms per token,  2109.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.14 ms /   146 tokens (    7.94 ms per token,   125.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1351.38 ms /    17 runs   (   79.49 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2654.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"705 115 6431\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.98 ms /    15 runs   (    0.40 ms per token,  2510.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.83 ms /    25 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.96 ms /    14 runs   (   80.21 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1476.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     9 runs   (    0.28 ms per token,  3620.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =     660.51 ms /     8 runs   (   82.56 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     962.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     8 runs   (    0.28 ms per token,  3573.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.12 ms /    24 tokens (   10.46 ms per token,    95.57 tokens per second)\n",
      "llama_print_timings:        eval time =     574.25 ms /     7 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     864.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Frank Feest\", \"Dr.\", \"Latoria Eichmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      12.58 ms /    22 runs   (    0.57 ms per token,  1748.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.93 ms /   192 tokens (    7.27 ms per token,   137.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1670.56 ms /    21 runs   (   79.55 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    3258.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"526 458 9422\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2106.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.71 ms /    25 tokens (   10.23 ms per token,    97.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.75 ms /    14 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1506.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8695.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.30 ms /    23 tokens (   11.01 ms per token,    90.80 tokens per second)\n",
      "llama_print_timings:        eval time =      92.37 ms /     1 runs   (   92.37 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     350.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.32 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =      91.19 ms /     1 runs   (   91.19 ms per token,    10.97 tokens per second)\n",
      "llama_print_timings:       total time =     346.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rachel Thompson\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    16 runs   (    0.56 ms per token,  1770.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.50 ms /   173 tokens (    8.04 ms per token,   124.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1193.29 ms /    15 runs   (   79.55 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2711.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"587 784 1377\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    15 runs   (    0.45 ms per token,  2214.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.68 ms /    25 tokens (   10.19 ms per token,    98.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.67 ms /    14 runs   (   80.26 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1488.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     8 runs   (    0.22 ms per token,  4629.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.56 ms /    23 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_print_timings:        eval time =     567.71 ms /     7 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     851.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     8 runs   (    0.40 ms per token,  2488.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.55 ms /    24 tokens (   10.52 ms per token,    95.03 tokens per second)\n",
      "llama_print_timings:        eval time =     572.90 ms /     7 runs   (   81.84 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     879.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Bill Schneider\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     7 runs   (    0.34 ms per token,  2982.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.76 ms /   146 tokens (    7.94 ms per token,   125.89 tokens per second)\n",
      "llama_print_timings:        eval time =     489.56 ms /     6 runs   (   81.59 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1690.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 343 4744\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    15 runs   (    0.54 ms per token,  1841.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.01 ms /    14 runs   (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1529.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     6 runs   (    0.19 ms per token,  5295.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    23 tokens (   10.89 ms per token,    91.86 tokens per second)\n",
      "llama_print_timings:        eval time =     417.24 ms /     5 runs   (   83.45 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     693.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /    11 runs   (    0.39 ms per token,  2575.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.28 ms /    24 tokens (   10.51 ms per token,    95.13 tokens per second)\n",
      "llama_print_timings:        eval time =     813.56 ms /    10 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1146.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stephany Torp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /    10 runs   (    0.37 ms per token,  2704.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.38 ms /   184 tokens (    7.65 ms per token,   130.74 tokens per second)\n",
      "llama_print_timings:        eval time =     714.34 ms /     9 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    2186.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 343 355 4694\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    19 runs   (    0.49 ms per token,  2026.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.39 ms /    25 tokens (   10.18 ms per token,    98.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1455.72 ms /    18 runs   (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1846.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  4989.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    23 tokens (   10.95 ms per token,    91.33 tokens per second)\n",
      "llama_print_timings:        eval time =     495.11 ms /     6 runs   (   82.52 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     773.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    11 runs   (    0.34 ms per token,  2985.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.31 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =     816.04 ms /    10 runs   (   81.60 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1140.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Jenice Hansen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    10 runs   (    0.45 ms per token,  2230.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1406.13 ms /   187 tokens (    7.52 ms per token,   132.99 tokens per second)\n",
      "llama_print_timings:        eval time =     718.21 ms /     9 runs   (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    2187.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"861 545 5826\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1809.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.29 ms /    25 tokens (   10.13 ms per token,    98.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.61 ms /    14 runs   (   80.26 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1493.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"22 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     7 runs   (    0.43 ms per token,  2343.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    23 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =     495.99 ms /     6 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     786.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.05 ms /     8 runs   (    0.38 ms per token,  2619.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     575.51 ms /     7 runs   (   82.22 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     882.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Myles Grady\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /     9 runs   (    0.35 ms per token,  2846.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1386.40 ms /   170 tokens (    8.16 ms per token,   122.62 tokens per second)\n",
      "llama_print_timings:        eval time =     631.36 ms /     8 runs   (   78.92 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    2076.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"538 162 8991\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.44 ms /    15 runs   (    0.43 ms per token,  2330.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.35 ms /    25 tokens (   10.13 ms per token,    98.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.40 ms /    14 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1487.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.47 ms /    23 tokens (   10.98 ms per token,    91.10 tokens per second)\n",
      "llama_print_timings:        eval time =      93.70 ms /     1 runs   (   93.70 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =     351.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.85 ms /    24 tokens (   10.54 ms per token,    94.92 tokens per second)\n",
      "llama_print_timings:        eval time =      95.86 ms /     1 runs   (   95.86 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     355.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lonnie Stracke\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    17 runs   (    0.42 ms per token,  2370.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.58 ms /   141 tokens (    8.19 ms per token,   122.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1272.07 ms /    16 runs   (   79.50 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2548.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"498 427 7585\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    15 runs   (    0.45 ms per token,  2201.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.40 ms /    25 tokens (   10.14 ms per token,    98.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.42 ms /    14 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1485.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     7 runs   (    0.30 ms per token,  3341.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.01 ms /    23 tokens (   10.96 ms per token,    91.26 tokens per second)\n",
      "llama_print_timings:        eval time =     495.69 ms /     6 runs   (   82.61 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     783.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8583.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    24 tokens (   10.51 ms per token,    95.12 tokens per second)\n",
      "llama_print_timings:        eval time =      90.35 ms /     1 runs   (   90.35 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =     347.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Floria Kovacek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /     9 runs   (    0.45 ms per token,  2227.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1886.37 ms /   236 tokens (    7.99 ms per token,   125.11 tokens per second)\n",
      "llama_print_timings:        eval time =     636.17 ms /     8 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2587.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 154 9658\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    15 runs   (    0.59 ms per token,  1703.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.27 ms /    25 tokens (   10.21 ms per token,    97.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.08 ms /    14 runs   (   81.36 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1509.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     7 runs   (    0.28 ms per token,  3613.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =     497.61 ms /     6 runs   (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     785.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /     8 runs   (    0.33 ms per token,  3004.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    24 tokens (   10.58 ms per token,    94.55 tokens per second)\n",
      "llama_print_timings:        eval time =     573.99 ms /     7 runs   (   82.00 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     875.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Dan Oberbrunner\", \"Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    18 runs   (    0.45 ms per token,  2218.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.20 ms /   184 tokens (    7.65 ms per token,   130.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1352.59 ms /    17 runs   (   79.56 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    2898.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 484 2366\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    15 runs   (    0.51 ms per token,  1973.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    25 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.10 ms /    14 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1494.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     5 runs   (    0.20 ms per token,  5096.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.24 ms /    23 tokens (   10.92 ms per token,    91.55 tokens per second)\n",
      "llama_print_timings:        eval time =     345.80 ms /     4 runs   (   86.45 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     613.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     7 runs   (    0.27 ms per token,  3753.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    24 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =     494.32 ms /     6 runs   (   82.39 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     789.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Edie Kunze\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    17 runs   (    0.49 ms per token,  2054.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.98 ms /   186 tokens (    7.54 ms per token,   132.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1267.45 ms /    16 runs   (   79.22 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    2806.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"255 338 1935\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    15 runs   (    0.50 ms per token,  2005.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.28 ms /    25 tokens (   10.21 ms per token,    97.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1127.06 ms /    14 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1498.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     5 runs   (    0.19 ms per token,  5370.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    23 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =     347.56 ms /     4 runs   (   86.89 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     622.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5405.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.51 ms /    24 tokens (   10.56 ms per token,    94.67 tokens per second)\n",
      "llama_print_timings:        eval time =      91.92 ms /     1 runs   (   91.92 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     350.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Denise Waters\", \"Tracie Lesch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.51 ms /    18 runs   (    0.53 ms per token,  1892.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1403.71 ms /   185 tokens (    7.59 ms per token,   131.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1353.12 ms /    17 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2903.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"203 473 4006\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    15 runs   (    0.52 ms per token,  1929.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.47 ms /    25 tokens (   10.22 ms per token,    97.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.11 ms /    14 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1494.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.98 ms /     9 runs   (    0.22 ms per token,  4556.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.81 ms /    23 tokens (   11.04 ms per token,    90.62 tokens per second)\n",
      "llama_print_timings:        eval time =     656.31 ms /     8 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     949.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     8 runs   (    0.20 ms per token,  5111.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    24 tokens (   10.57 ms per token,    94.56 tokens per second)\n",
      "llama_print_timings:        eval time =     577.43 ms /     7 runs   (   82.49 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =     861.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Martha Senger\", \"Dr. Jackelyn Pacocha\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.57 ms /    20 runs   (    0.58 ms per token,  1728.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1382.30 ms /   163 tokens (    8.48 ms per token,   117.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1501.68 ms /    19 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    3044.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"564 205 3883\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    15 runs   (    0.49 ms per token,  2041.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.63 ms /    25 tokens (   10.11 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.91 ms /    14 runs   (   80.49 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1494.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     7 runs   (    0.32 ms per token,  3093.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.94 ms /    23 tokens (   11.00 ms per token,    90.93 tokens per second)\n",
      "llama_print_timings:        eval time =     484.38 ms /     6 runs   (   80.73 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     777.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.83 ms /     8 runs   (    0.23 ms per token,  4381.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.14 ms /    24 tokens (   10.55 ms per token,    94.81 tokens per second)\n",
      "llama_print_timings:        eval time =     574.07 ms /     7 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =     854.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sammy Mosciski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.45 ms /     8 runs   (    0.31 ms per token,  3265.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.84 ms /   142 tokens (    8.13 ms per token,   123.07 tokens per second)\n",
      "llama_print_timings:        eval time =     568.31 ms /     7 runs   (   81.19 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1764.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 643 4435\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.18 ms /    15 runs   (    0.41 ms per token,  2427.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.45 ms /    25 tokens (   10.18 ms per token,    98.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.81 ms /    14 runs   (   79.56 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1471.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 years\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     5 runs   (    0.16 ms per token,  6329.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    23 tokens (   10.95 ms per token,    91.33 tokens per second)\n",
      "llama_print_timings:        eval time =     338.69 ms /     4 runs   (   84.67 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     608.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Seasonal allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /    12 runs   (    0.47 ms per token,  2133.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.95 ms /    24 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =     885.13 ms /    11 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    1219.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Shantae Ankunding\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    12 runs   (    0.53 ms per token,  1873.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2999.42 ms /   374 tokens (    8.02 ms per token,   124.69 tokens per second)\n",
      "llama_print_timings:        eval time =     895.08 ms /    11 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    3988.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"399 717 3878\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.92 ms /    15 runs   (    0.59 ms per token,  1681.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.89 ms /    25 tokens (   10.32 ms per token,    96.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1159.39 ms /    14 runs   (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1533.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /     9 runs   (    0.49 ms per token,  2059.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.53 ms /    23 tokens (   11.15 ms per token,    89.66 tokens per second)\n",
      "llama_print_timings:        eval time =     671.24 ms /     8 runs   (   83.90 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     984.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    11 runs   (    0.42 ms per token,  2370.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.18 ms /    24 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =     834.88 ms /    10 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    1177.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ethan Feeney\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.43 ms /     8 runs   (    0.30 ms per token,  3289.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.53 ms /   163 tokens (    8.49 ms per token,   117.81 tokens per second)\n",
      "llama_print_timings:        eval time =     558.53 ms /     7 runs   (   79.79 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1985.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"218 568 6815\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    15 runs   (    0.47 ms per token,  2116.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.72 ms /    25 tokens (   10.15 ms per token,    98.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.36 ms /    14 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1503.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7220.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.65 ms /    23 tokens (   10.98 ms per token,    91.04 tokens per second)\n",
      "llama_print_timings:        eval time =      92.59 ms /     1 runs   (   92.59 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =     351.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     8 runs   (    0.28 ms per token,  3619.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    24 tokens (   10.54 ms per token,    94.87 tokens per second)\n",
      "llama_print_timings:        eval time =     569.35 ms /     7 runs   (   81.34 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     862.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Walker Brown\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     7 runs   (    0.25 ms per token,  3950.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1153.14 ms /   140 tokens (    8.24 ms per token,   121.41 tokens per second)\n",
      "llama_print_timings:        eval time =     488.63 ms /     6 runs   (   81.44 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1673.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"196 517 9277\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    15 runs   (    0.51 ms per token,  1949.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.05 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1118.80 ms /    14 runs   (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    1490.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     8 runs   (    0.31 ms per token,  3225.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.96 ms /    23 tokens (   10.95 ms per token,    91.28 tokens per second)\n",
      "llama_print_timings:        eval time =     572.69 ms /     7 runs   (   81.81 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =     873.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary complaint\", \"pre-existing condition\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /    13 runs   (    0.41 ms per token,  2452.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.87 ms /    24 tokens (   10.45 ms per token,    95.67 tokens per second)\n",
      "llama_print_timings:        eval time =     972.56 ms /    12 runs   (   81.05 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1313.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Raven Kulas\", \"Dr. Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.91 ms /    18 runs   (    0.50 ms per token,  2019.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.62 ms /   157 tokens (    7.44 ms per token,   134.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1390.61 ms /    17 runs   (   81.80 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    2713.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"223 512 4530\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    15 runs   (    0.42 ms per token,  2380.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.78 ms /    25 tokens (   10.15 ms per token,    98.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.13 ms /    14 runs   (   81.08 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1495.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     9 runs   (    0.35 ms per token,  2876.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.02 ms /    23 tokens (   10.96 ms per token,    91.26 tokens per second)\n",
      "llama_print_timings:        eval time =     661.35 ms /     8 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     964.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.01 ms /     8 runs   (    0.38 ms per token,  2658.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.48 ms /    24 tokens (   10.56 ms per token,    94.68 tokens per second)\n",
      "llama_print_timings:        eval time =     575.24 ms /     7 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     876.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kurtis Schowalter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     9 runs   (    0.46 ms per token,  2186.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1167.41 ms /   156 tokens (    7.48 ms per token,   133.63 tokens per second)\n",
      "llama_print_timings:        eval time =     644.23 ms /     8 runs   (   80.53 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1885.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"168 947 5400\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    15 runs   (    0.40 ms per token,  2499.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.60 ms /    25 tokens (   10.18 ms per token,    98.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.36 ms /    14 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1477.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     5 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.57 ms /    23 tokens (   10.98 ms per token,    91.06 tokens per second)\n",
      "llama_print_timings:        eval time =     340.94 ms /     4 runs   (   85.24 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     606.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7874.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.19 ms /    24 tokens (   10.47 ms per token,    95.54 tokens per second)\n",
      "llama_print_timings:        eval time =      97.64 ms /     1 runs   (   97.64 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =     356.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Shirlee Kerluke\", \"Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    15 runs   (    0.51 ms per token,  1947.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2859.12 ms /   363 tokens (    7.88 ms per token,   126.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.48 ms /    14 runs   (   81.46 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    4128.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 624 2351\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.32 ms /    15 runs   (    0.62 ms per token,  1609.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.44 ms /    25 tokens (   10.34 ms per token,    96.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.48 ms /    14 runs   (   82.53 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1539.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7751.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.76 ms /    23 tokens (   11.16 ms per token,    89.58 tokens per second)\n",
      "llama_print_timings:        eval time =      93.35 ms /     1 runs   (   93.35 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     355.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4250.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.99 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =     507.43 ms /     6 runs   (   84.57 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     790.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Renae Haag\", \"Doctor Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    17 runs   (    0.25 ms per token,  4025.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.74 ms /   183 tokens (    7.68 ms per token,   130.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1384.80 ms /    16 runs   (   86.55 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    2862.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"486 491 1162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    15 runs   (    0.29 ms per token,  3430.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1113.30 ms /    14 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1447.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6779.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.01 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =      89.82 ms /     1 runs   (   89.82 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =     344.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =      89.55 ms /     1 runs   (   89.55 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =     343.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jodi Mueller\", \"Dr. Marcus Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.63 ms /    18 runs   (    0.31 ms per token,  3197.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1638.28 ms /   220 tokens (    7.45 ms per token,   134.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1322.91 ms /    17 runs   (   77.82 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =    3065.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"247 894 4863\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    15 runs   (    0.29 ms per token,  3445.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.58 ms /    25 tokens (   10.14 ms per token,    98.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.60 ms /    14 runs   (   78.47 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1433.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.72 ms /    23 tokens (   10.94 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =      94.96 ms /     1 runs   (   94.96 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =     352.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli urinary tract infection\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    14 runs   (    0.30 ms per token,  3291.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.30 ms /    24 tokens (   10.55 ms per token,    94.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1030.03 ms /    13 runs   (   79.23 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1359.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ambrose Sporer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     8 runs   (    0.23 ms per token,  4305.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1618.56 ms /   195 tokens (    8.30 ms per token,   120.48 tokens per second)\n",
      "llama_print_timings:        eval time =     546.66 ms /     7 runs   (   78.09 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    2203.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 604 7922\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.77 ms /    15 runs   (    0.32 ms per token,  3142.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.35 ms /    25 tokens (   10.09 ms per token,    99.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.86 ms /    14 runs   (   79.06 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1449.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9174.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    23 tokens (   10.91 ms per token,    91.62 tokens per second)\n",
      "llama_print_timings:        eval time =      93.98 ms /     1 runs   (   93.98 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =     349.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    12 runs   (    0.21 ms per token,  4868.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.94 ms /    24 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =     868.04 ms /    11 runs   (   78.91 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1173.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Vi Yundt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    10 runs   (    0.24 ms per token,  4210.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.91 ms /   138 tokens (    8.27 ms per token,   120.85 tokens per second)\n",
      "llama_print_timings:        eval time =     707.08 ms /     9 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1900.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"360 475 8066\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    15 runs   (    0.28 ms per token,  3557.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.70 ms /    25 tokens (   10.07 ms per token,    99.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.14 ms /    14 runs   (   78.51 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1437.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     7 runs   (    0.22 ms per token,  4554.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.62 ms /    23 tokens (   10.85 ms per token,    92.14 tokens per second)\n",
      "llama_print_timings:        eval time =     484.70 ms /     6 runs   (   80.78 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     768.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     8 runs   (    0.17 ms per token,  5830.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    24 tokens (   10.43 ms per token,    95.91 tokens per second)\n",
      "llama_print_timings:        eval time =     557.16 ms /     7 runs   (   79.59 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     833.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Deshawn Bernhard\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /    17 runs   (    0.28 ms per token,  3523.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.43 ms /   167 tokens (    8.24 ms per token,   121.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1234.88 ms /    16 runs   (   77.18 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    2700.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"102 676 5510\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    15 runs   (    0.29 ms per token,  3418.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.33 ms /    25 tokens (   10.05 ms per token,    99.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.23 ms /    14 runs   (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1434.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.18 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =      92.18 ms /     1 runs   (   92.18 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     349.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9950.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.40 ms /    24 tokens (   10.47 ms per token,    95.47 tokens per second)\n",
      "llama_print_timings:        eval time =      87.85 ms /     1 runs   (   87.85 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =     343.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms.\", \"Opal O'Hara\", \"Dr.\", \"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    23 runs   (    0.32 ms per token,  3080.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1652.72 ms /   216 tokens (    7.65 ms per token,   130.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1714.02 ms /    22 runs   (   77.91 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    3501.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"663 768 3635\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    15 runs   (    0.32 ms per token,  3112.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.61 ms /    25 tokens (   10.14 ms per token,    98.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.96 ms /    14 runs   (   79.21 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =    1453.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    23 tokens (   10.94 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =      94.47 ms /     1 runs   (   94.47 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =     351.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4419.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.36 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     568.90 ms /     7 runs   (   81.27 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     854.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Lorrie Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    13 runs   (    0.27 ms per token,  3652.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.99 ms /   141 tokens (    8.11 ms per token,   123.25 tokens per second)\n",
      "llama_print_timings:        eval time =     928.10 ms /    12 runs   (   77.34 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    2143.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"752 604 6342\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.19 ms /    15 runs   (    0.28 ms per token,  3578.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.49 ms /    25 tokens (   10.06 ms per token,    99.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.51 ms /    14 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1433.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     9 runs   (    0.22 ms per token,  4591.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    23 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =     635.82 ms /     8 runs   (   79.48 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =     919.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.75 ms /    24 tokens (   10.41 ms per token,    96.09 tokens per second)\n",
      "llama_print_timings:        eval time =      88.89 ms /     1 runs   (   88.89 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     343.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rita Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.86 ms /    10 runs   (    0.29 ms per token,  3496.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.77 ms /   154 tokens (    7.50 ms per token,   133.24 tokens per second)\n",
      "llama_print_timings:        eval time =     698.03 ms /     9 runs   (   77.56 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    1902.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 693 4878\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    15 runs   (    0.30 ms per token,  3370.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.84 ms /    25 tokens (   10.07 ms per token,    99.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.59 ms /    14 runs   (   78.54 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1444.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     9 runs   (    0.22 ms per token,  4473.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.04 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     640.12 ms /     8 runs   (   80.01 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     929.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /    11 runs   (    0.23 ms per token,  4281.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     800.15 ms /    10 runs   (   80.02 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    1104.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Norberto Kling\", \"Dr. Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.67 ms /    17 runs   (    0.33 ms per token,  2998.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.98 ms /   153 tokens (    7.55 ms per token,   132.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.79 ms /    16 runs   (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2499.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"288 553 3952\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /    15 runs   (    0.32 ms per token,  3140.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.16 ms /    14 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1435.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     9 runs   (    0.23 ms per token,  4293.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     640.69 ms /     8 runs   (   80.09 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     924.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6825.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.56 ms /    24 tokens (   10.44 ms per token,    95.79 tokens per second)\n",
      "llama_print_timings:        eval time =      88.74 ms /     1 runs   (   88.74 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     345.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Bryanna Schaefer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /    13 runs   (    0.27 ms per token,  3669.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1613.92 ms /   202 tokens (    7.99 ms per token,   125.16 tokens per second)\n",
      "llama_print_timings:        eval time =     932.26 ms /    12 runs   (   77.69 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2618.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"149 627 8042\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    15 runs   (    0.27 ms per token,  3679.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.80 ms /    25 tokens (   10.11 ms per token,    98.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.83 ms /    14 runs   (   79.13 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1439.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =      91.79 ms /     1 runs   (   91.79 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     346.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     8 runs   (    0.20 ms per token,  5115.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =     562.26 ms /     7 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =     845.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Charley Hermann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.96 ms /     8 runs   (    0.25 ms per token,  4077.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1141.32 ms /   136 tokens (    8.39 ms per token,   119.16 tokens per second)\n",
      "llama_print_timings:        eval time =     551.09 ms /     7 runs   (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1726.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"893 351 8193\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.79 ms /    15 runs   (    0.25 ms per token,  3963.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.95 ms /    25 tokens (   10.04 ms per token,    99.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.21 ms /    14 runs   (   78.01 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1419.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5061.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.38 ms /    23 tokens (   10.84 ms per token,    92.23 tokens per second)\n",
      "llama_print_timings:        eval time =     481.59 ms /     6 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     756.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /    11 runs   (    0.31 ms per token,  3217.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.44 ms /    24 tokens (   10.39 ms per token,    96.22 tokens per second)\n",
      "llama_print_timings:        eval time =     789.59 ms /    10 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1094.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dave Dickens\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.73 ms /     7 runs   (    0.25 ms per token,  4050.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1135.14 ms /   129 tokens (    8.80 ms per token,   113.64 tokens per second)\n",
      "llama_print_timings:        eval time =     483.35 ms /     6 runs   (   80.56 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1656.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 443 6568\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.30 ms /    15 runs   (    0.29 ms per token,  3485.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.57 ms /    25 tokens (   10.06 ms per token,    99.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.24 ms /    14 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1423.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /     8 runs   (    0.23 ms per token,  4383.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.36 ms /    23 tokens (   10.84 ms per token,    92.24 tokens per second)\n",
      "llama_print_timings:        eval time =     559.40 ms /     7 runs   (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     839.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6944.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.40 ms /    24 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =      90.40 ms /     1 runs   (   90.40 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =     345.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6289.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1864.54 ms /   235 tokens (    7.93 ms per token,   126.04 tokens per second)\n",
      "llama_print_timings:        eval time =      86.62 ms /     1 runs   (   86.62 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    1958.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"177 542 0620\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    15 runs   (    0.26 ms per token,  3832.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.17 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.20 ms /    14 runs   (   79.44 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1444.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.17 ms /     7 runs   (    0.17 ms per token,  5982.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    23 tokens (   10.94 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     484.85 ms /     6 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     757.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /     8 runs   (    0.20 ms per token,  5012.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     566.98 ms /     7 runs   (   81.00 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     853.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Brigid Carter\", \"Dr Tracey Hamill\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /    14 runs   (    0.27 ms per token,  3645.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.78 ms /   167 tokens (    8.23 ms per token,   121.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1008.57 ms /    13 runs   (   77.58 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2455.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 485 7803\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    15 runs   (    0.36 ms per token,  2770.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.77 ms /    14 runs   (   78.63 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1437.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     8 runs   (    0.28 ms per token,  3615.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    23 tokens (   10.88 ms per token,    91.90 tokens per second)\n",
      "llama_print_timings:        eval time =     566.39 ms /     7 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     855.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =      89.70 ms /     1 runs   (   89.70 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     345.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Renay Kshlerin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    12 runs   (    0.24 ms per token,  4116.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.85 ms /   187 tokens (    7.45 ms per token,   134.26 tokens per second)\n",
      "llama_print_timings:        eval time =     851.84 ms /    11 runs   (   77.44 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =    2304.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"228 984 4635\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    15 runs   (    0.33 ms per token,  3024.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.82 ms /    25 tokens (   10.11 ms per token,    98.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.81 ms /    14 runs   (   78.63 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1436.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     7 runs   (    0.18 ms per token,  5409.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     480.87 ms /     6 runs   (   80.15 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     757.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.92 ms /    24 tokens (   10.46 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =      91.50 ms /     1 runs   (   91.50 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     347.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Roxy Bode\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    19 runs   (    0.36 ms per token,  2746.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1145.63 ms /   144 tokens (    7.96 ms per token,   125.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1395.35 ms /    18 runs   (   77.52 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    2668.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"858 716 9693\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    15 runs   (    0.24 ms per token,  4083.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.32 ms /    25 tokens (   10.05 ms per token,    99.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1095.48 ms /    14 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    1415.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.89 ms /     7 runs   (    0.13 ms per token,  7900.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.96 ms /    23 tokens (   10.87 ms per token,    92.01 tokens per second)\n",
      "llama_print_timings:        eval time =     485.06 ms /     6 runs   (   80.84 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     753.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     8 runs   (    0.25 ms per token,  3980.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.25 ms /    24 tokens (   10.39 ms per token,    96.29 tokens per second)\n",
      "llama_print_timings:        eval time =     563.65 ms /     7 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     846.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     2 runs   (    0.25 ms per token,  4032.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1653.08 ms /   216 tokens (    7.65 ms per token,   130.67 tokens per second)\n",
      "llama_print_timings:        eval time =      86.01 ms /     1 runs   (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1746.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"600 754 9512\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /    15 runs   (    0.30 ms per token,  3362.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.28 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.92 ms /    14 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1445.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     9 runs   (    0.23 ms per token,  4306.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =     641.52 ms /     8 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =     939.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     9 runs   (    0.27 ms per token,  3735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.20 ms /    24 tokens (   10.51 ms per token,    95.16 tokens per second)\n",
      "llama_print_timings:        eval time =     646.19 ms /     8 runs   (   80.77 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     942.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Fae Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    11 runs   (    0.24 ms per token,  4188.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.06 ms /   165 tokens (    8.32 ms per token,   120.26 tokens per second)\n",
      "llama_print_timings:        eval time =     782.53 ms /    10 runs   (   78.25 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2206.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"948 326 9626\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /    15 runs   (    0.27 ms per token,  3637.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.20 ms /    25 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1083.56 ms /    14 runs   (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    1420.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     7 runs   (    0.15 ms per token,  6523.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.66 ms /    23 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =     481.44 ms /     6 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     755.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute Viral Pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /    11 runs   (    0.24 ms per token,  4093.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.69 ms /    24 tokens (   10.45 ms per token,    95.73 tokens per second)\n",
      "llama_print_timings:        eval time =     793.78 ms /    10 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1092.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Irvin Barton\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     9 runs   (    0.18 ms per token,  5524.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1379.32 ms /   174 tokens (    7.93 ms per token,   126.15 tokens per second)\n",
      "llama_print_timings:        eval time =     639.85 ms /     8 runs   (   79.98 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =    2055.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"101 891 0182\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /    15 runs   (    0.25 ms per token,  4051.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.39 ms /    25 tokens (   10.06 ms per token,    99.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.78 ms /    14 runs   (   78.77 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1427.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     6 runs   (    0.13 ms per token,  7792.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.35 ms /    23 tokens (   10.88 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =     406.85 ms /     5 runs   (   81.37 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =     680.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7604.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =      88.91 ms /     1 runs   (   88.91 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     343.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cherie McLaughlin\", \"Dr. Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    18 runs   (    0.27 ms per token,  3702.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1653.15 ms /   216 tokens (    7.65 ms per token,   130.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1326.87 ms /    17 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    3085.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 568 6596\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    15 runs   (    0.32 ms per token,  3082.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.40 ms /    25 tokens (   10.14 ms per token,    98.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1114.84 ms /    14 runs   (   79.63 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1453.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    23 tokens (   10.94 ms per token,    91.41 tokens per second)\n",
      "llama_print_timings:        eval time =      94.43 ms /     1 runs   (   94.43 ms per token,    10.59 tokens per second)\n",
      "llama_print_timings:       total time =     351.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.73 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =      99.89 ms /     1 runs   (   99.89 ms per token,    10.01 tokens per second)\n",
      "llama_print_timings:       total time =     354.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Barrett Boyer\", \"Tracie Lesch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    16 runs   (    0.28 ms per token,  3510.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1614.52 ms /   193 tokens (    8.37 ms per token,   119.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1163.29 ms /    15 runs   (   77.55 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2867.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 889 5848\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    15 runs   (    0.30 ms per token,  3345.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.68 ms /    25 tokens (   10.11 ms per token,    98.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.38 ms /    14 runs   (   78.96 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1440.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     9 runs   (    0.19 ms per token,  5175.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.04 ms /    23 tokens (   10.91 ms per token,    91.62 tokens per second)\n",
      "llama_print_timings:        eval time =     645.07 ms /     8 runs   (   80.63 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     931.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     8 runs   (    0.16 ms per token,  6130.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.05 ms /    24 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =     566.71 ms /     7 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     844.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Aide Larkin\", \"Doctor Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.06 ms /    21 runs   (    0.29 ms per token,  3466.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.37 ms /   169 tokens (    8.14 ms per token,   122.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1552.80 ms /    20 runs   (   77.64 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    3055.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"322 673 1275\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    15 runs   (    0.30 ms per token,  3298.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.39 ms /    14 runs   (   78.74 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1444.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.39 ms /     7 runs   (    0.20 ms per token,  5054.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =     485.53 ms /     6 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     760.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.55 ms /     8 runs   (    0.19 ms per token,  5144.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     561.70 ms /     7 runs   (   80.24 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     838.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Corrine Baumbach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    12 runs   (    0.34 ms per token,  2957.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2165.53 ms /   273 tokens (    7.93 ms per token,   126.07 tokens per second)\n",
      "llama_print_timings:        eval time =     864.68 ms /    11 runs   (   78.61 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    3099.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"236 588 2696\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    15 runs   (    0.29 ms per token,  3447.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    25 tokens (   10.18 ms per token,    98.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1115.33 ms /    14 runs   (   79.67 ms per token,    12.55 tokens per second)\n",
      "llama_print_timings:       total time =    1453.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     7 runs   (    0.22 ms per token,  4487.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.45 ms /    23 tokens (   10.98 ms per token,    91.11 tokens per second)\n",
      "llama_print_timings:        eval time =     493.76 ms /     6 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     780.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7547.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.85 ms /    24 tokens (   10.54 ms per token,    94.92 tokens per second)\n",
      "llama_print_timings:        eval time =      91.34 ms /     1 runs   (   91.34 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     349.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Gracie Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.77 ms /     7 runs   (    0.25 ms per token,  3961.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.41 ms /   137 tokens (    8.32 ms per token,   120.13 tokens per second)\n",
      "llama_print_timings:        eval time =     474.56 ms /     6 runs   (   79.09 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1645.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 207 9206\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /    15 runs   (    0.26 ms per token,  3845.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.05 ms /    25 tokens (   10.04 ms per token,    99.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.65 ms /    14 runs   (   78.19 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1421.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     7 runs   (    0.22 ms per token,  4495.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.90 ms /    23 tokens (   10.87 ms per token,    92.04 tokens per second)\n",
      "llama_print_timings:        eval time =     482.33 ms /     6 runs   (   80.39 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     768.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.71 ms /     8 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =     558.59 ms /     7 runs   (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =     836.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Larissa Aufderhar\", \"Dr. Randy Bergstrom\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.25 ms /    17 runs   (    0.25 ms per token,  3997.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1374.60 ms /   170 tokens (    8.09 ms per token,   123.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1241.20 ms /    16 runs   (   77.58 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2701.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 678 1006\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    15 runs   (    0.32 ms per token,  3165.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.83 ms /    25 tokens (   10.07 ms per token,    99.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.80 ms /    14 runs   (   78.49 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1434.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.80 ms /     6 runs   (    0.13 ms per token,  7537.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     408.27 ms /     5 runs   (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =     678.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8368.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.05 ms /    24 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =      89.13 ms /     1 runs   (   89.13 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =     343.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Erick Leannon\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.04 ms /     9 runs   (    0.23 ms per token,  4420.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.99 ms /   154 tokens (    7.50 ms per token,   133.33 tokens per second)\n",
      "llama_print_timings:        eval time =     628.81 ms /     8 runs   (   78.60 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1821.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"807 928 3488\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    15 runs   (    0.27 ms per token,  3700.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    25 tokens (   10.09 ms per token,    99.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.46 ms /    14 runs   (   78.39 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1421.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     7 runs   (    0.19 ms per token,  5376.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     483.43 ms /     6 runs   (   80.57 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =     755.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8849.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.40 ms /    24 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =      94.06 ms /     1 runs   (   94.06 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =     350.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Toccara Glover\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /    15 runs   (    0.24 ms per token,  4082.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.46 ms /   165 tokens (    8.32 ms per token,   120.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.38 ms /    14 runs   (   77.53 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    2534.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 934 6211\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.01 ms /    15 runs   (    0.33 ms per token,  2992.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.16 ms /    25 tokens (   10.09 ms per token,    99.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.76 ms /    14 runs   (   78.63 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1438.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.54 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =      89.95 ms /     1 runs   (   89.95 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     345.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    11 runs   (    0.19 ms per token,  5260.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    24 tokens (   10.41 ms per token,    96.04 tokens per second)\n",
      "llama_print_timings:        eval time =     788.59 ms /    10 runs   (   78.86 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1083.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Roderick Kihn\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    16 runs   (    0.25 ms per token,  3947.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.59 ms /   159 tokens (    7.29 ms per token,   137.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1169.85 ms /    15 runs   (   77.99 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2414.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"729 644 5018\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    15 runs   (    0.26 ms per token,  3863.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.97 ms /    14 runs   (   78.50 ms per token,    12.74 tokens per second)\n",
      "llama_print_timings:       total time =    1424.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /     9 runs   (    0.27 ms per token,  3664.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.36 ms /    23 tokens (   10.89 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =     639.76 ms /     8 runs   (   79.97 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     935.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /    11 runs   (    0.22 ms per token,  4448.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    24 tokens (   10.45 ms per token,    95.72 tokens per second)\n",
      "llama_print_timings:        eval time =     793.85 ms /    10 runs   (   79.38 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    1092.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Zachary Ankunding\", \"Dr. Cletus Paucek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    21 runs   (    0.28 ms per token,  3586.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.58 ms /   184 tokens (    7.58 ms per token,   131.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1545.27 ms /    20 runs   (   77.26 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    3055.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"831 238 6191\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /    15 runs   (    0.28 ms per token,  3594.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.73 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.15 ms /    14 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1418.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.74 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =      93.96 ms /     1 runs   (   93.96 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =     348.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =      90.57 ms /     1 runs   (   90.57 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     345.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rodney Champlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /    10 runs   (    0.21 ms per token,  4875.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.98 ms /   170 tokens (    8.08 ms per token,   123.73 tokens per second)\n",
      "llama_print_timings:        eval time =     703.43 ms /     9 runs   (   78.16 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2121.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 878 4827\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /    15 runs   (    0.30 ms per token,  3382.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.22 ms /    25 tokens (   10.09 ms per token,    99.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.55 ms /    14 runs   (   78.68 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1434.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     7 runs   (    0.20 ms per token,  4961.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =     483.29 ms /     6 runs   (   80.55 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     763.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     8 runs   (    0.16 ms per token,  6163.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =     561.73 ms /     7 runs   (   80.25 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =     844.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Loida Wuckert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    11 runs   (    0.27 ms per token,  3683.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.45 ms /   179 tokens (    7.75 ms per token,   129.01 tokens per second)\n",
      "llama_print_timings:        eval time =     777.51 ms /    10 runs   (   77.75 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2219.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"838 661 5933\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    15 runs   (    0.31 ms per token,  3199.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.59 ms /    14 runs   (   77.76 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1414.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     9 runs   (    0.26 ms per token,  3828.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     643.02 ms /     8 runs   (   80.38 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =     931.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6872.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.34 ms /    24 tokens (   10.43 ms per token,    95.87 tokens per second)\n",
      "llama_print_timings:        eval time =      93.30 ms /     1 runs   (   93.30 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     348.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Alexis Krajcik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    13 runs   (    0.25 ms per token,  3933.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.08 ms /   163 tokens (    8.42 ms per token,   118.80 tokens per second)\n",
      "llama_print_timings:        eval time =     931.90 ms /    12 runs   (   77.66 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    2370.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"569 741 9308\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    15 runs   (    0.27 ms per token,  3735.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.22 ms /    25 tokens (   10.05 ms per token,    99.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1094.52 ms /    14 runs   (   78.18 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    1432.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     7 runs   (    0.15 ms per token,  6572.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.75 ms /    23 tokens (   10.90 ms per token,    91.73 tokens per second)\n",
      "llama_print_timings:        eval time =     493.33 ms /     6 runs   (   82.22 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     766.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    11 runs   (    0.22 ms per token,  4473.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.80 ms /    24 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =     789.90 ms /    10 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1085.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Modesta Corwin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /    10 runs   (    0.28 ms per token,  3537.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3087.78 ms /   395 tokens (    7.82 ms per token,   127.92 tokens per second)\n",
      "llama_print_timings:        eval time =     721.90 ms /     9 runs   (   80.21 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    3860.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"668 657 8926\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    15 runs   (    0.29 ms per token,  3455.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    25 tokens (   10.27 ms per token,    97.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1134.81 ms /    14 runs   (   81.06 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    1473.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"41-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     9 runs   (    0.23 ms per token,  4339.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.70 ms /    23 tokens (   11.07 ms per token,    90.30 tokens per second)\n",
      "llama_print_timings:        eval time =     656.58 ms /     8 runs   (   82.07 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     957.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.30 ms per token,  3300.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.66 ms /    24 tokens (   10.61 ms per token,    94.24 tokens per second)\n",
      "llama_print_timings:        eval time =     101.29 ms /     1 runs   (  101.29 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =     364.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Caroll Zulauf\", \"Dr. Sang Blanda\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.30 ms /    18 runs   (    0.35 ms per token,  2855.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.11 ms /   147 tokens (    7.82 ms per token,   127.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1322.01 ms /    17 runs   (   77.77 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2573.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"436 752 7426\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /    15 runs   (    0.24 ms per token,  4212.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.18 ms /    25 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.36 ms /    14 runs   (   78.60 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1430.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.66 ms /     7 runs   (    0.24 ms per token,  4224.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.56 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =     485.77 ms /     6 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     762.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     8 runs   (    0.20 ms per token,  5050.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.28 ms /    24 tokens (   10.43 ms per token,    95.89 tokens per second)\n",
      "llama_print_timings:        eval time =     563.57 ms /     7 runs   (   80.51 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     842.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Delilah Runolfsson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /    12 runs   (    0.27 ms per token,  3687.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.91 ms /   139 tokens (    8.22 ms per token,   121.62 tokens per second)\n",
      "llama_print_timings:        eval time =     858.51 ms /    11 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    2059.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 674 4499\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.68 ms /    15 runs   (    0.31 ms per token,  3205.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.46 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.92 ms /    14 runs   (   78.35 ms per token,    12.76 tokens per second)\n",
      "llama_print_timings:       total time =    1427.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     9 runs   (    0.25 ms per token,  4039.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.55 ms /    23 tokens (   10.85 ms per token,    92.17 tokens per second)\n",
      "llama_print_timings:        eval time =     640.02 ms /     8 runs   (   80.00 ms per token,    12.50 tokens per second)\n",
      "llama_print_timings:       total time =     931.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.47 ms /     2 runs   (    0.24 ms per token,  4255.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =      91.61 ms /     1 runs   (   91.61 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =     351.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Chantel Kunze\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    11 runs   (    0.21 ms per token,  4662.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.19 ms /   154 tokens (    7.51 ms per token,   133.08 tokens per second)\n",
      "llama_print_timings:        eval time =     784.13 ms /    10 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1988.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"460 253 5816\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /    15 runs   (    0.23 ms per token,  4295.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.69 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1099.41 ms /    14 runs   (   78.53 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1420.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.41 ms /     8 runs   (    0.18 ms per token,  5681.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.43 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     560.73 ms /     7 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =     839.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     6 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     409.34 ms /     5 runs   (   81.87 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     676.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Benny Nikolaus\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.88 ms /     9 runs   (    0.21 ms per token,  4797.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.74 ms /   144 tokens (    7.95 ms per token,   125.79 tokens per second)\n",
      "llama_print_timings:        eval time =     629.44 ms /     8 runs   (   78.68 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1807.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"837 674 4786\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    15 runs   (    0.28 ms per token,  3611.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.01 ms /    25 tokens (   10.04 ms per token,    99.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.82 ms /    14 runs   (   79.20 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1443.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     7 runs   (    0.16 ms per token,  6357.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.80 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     487.20 ms /     6 runs   (   81.20 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =     757.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7326.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    24 tokens (   10.40 ms per token,    96.13 tokens per second)\n",
      "llama_print_timings:        eval time =      91.67 ms /     1 runs   (   91.67 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     346.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Hipolito Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /     8 runs   (    0.22 ms per token,  4451.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1375.48 ms /   166 tokens (    8.29 ms per token,   120.69 tokens per second)\n",
      "llama_print_timings:        eval time =     556.26 ms /     7 runs   (   79.47 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1967.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 379 5432\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /    15 runs   (    0.30 ms per token,  3327.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    25 tokens (   10.07 ms per token,    99.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.30 ms /    14 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1435.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     5 runs   (    0.15 ms per token,  6631.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.78 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     348.30 ms /     4 runs   (   87.07 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     611.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     8 runs   (    0.20 ms per token,  5111.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.43 ms /    24 tokens (   10.39 ms per token,    96.22 tokens per second)\n",
      "llama_print_timings:        eval time =     563.03 ms /     7 runs   (   80.43 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     840.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Irving Frami\", \"Dr Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.16 ms /    17 runs   (    0.30 ms per token,  3292.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.78 ms /   161 tokens (    8.51 ms per token,   117.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.87 ms /    16 runs   (   77.87 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    2708.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"111 703 1406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    15 runs   (    0.33 ms per token,  3073.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.85 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.87 ms /    14 runs   (   78.42 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1438.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"35 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     7 runs   (    0.18 ms per token,  5447.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.17 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =     484.31 ms /     6 runs   (   80.72 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =     758.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    11 runs   (    0.23 ms per token,  4439.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.21 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =     795.99 ms /    10 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1093.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Latoya Hoeger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /    12 runs   (    0.27 ms per token,  3692.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.42 ms /   132 tokens (    8.62 ms per token,   116.05 tokens per second)\n",
      "llama_print_timings:        eval time =     860.96 ms /    11 runs   (   78.27 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    2056.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"363 531 4107\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.35 ms /    15 runs   (    0.29 ms per token,  3449.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.23 ms /    14 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1425.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     9 runs   (    0.25 ms per token,  3984.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.08 ms /    23 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =     635.08 ms /     8 runs   (   79.39 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     926.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8510.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.86 ms /    24 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =      93.20 ms /     1 runs   (   93.20 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =     347.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Isreal MacGyver\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.50 ms /    16 runs   (    0.28 ms per token,  3554.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1393.87 ms /   182 tokens (    7.66 ms per token,   130.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.71 ms /    15 runs   (   77.78 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2650.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"611 865 6801\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.84 ms /    15 runs   (    0.32 ms per token,  3097.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.22 ms /    25 tokens (   10.13 ms per token,    98.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1112.50 ms /    14 runs   (   79.46 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    1448.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     6 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    23 tokens (   10.89 ms per token,    91.83 tokens per second)\n",
      "llama_print_timings:        eval time =     415.94 ms /     5 runs   (   83.19 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     687.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     6 runs   (    0.18 ms per token,  5581.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.64 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =     410.44 ms /     5 runs   (   82.09 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     685.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Kristina Senger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.93 ms /    12 runs   (    0.24 ms per token,  4094.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2456.75 ms /   312 tokens (    7.87 ms per token,   127.00 tokens per second)\n",
      "llama_print_timings:        eval time =     872.51 ms /    11 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    3392.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"600 516 4467\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    15 runs   (    0.27 ms per token,  3679.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.56 ms /    25 tokens (   10.22 ms per token,    97.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.39 ms /    14 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1475.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7246.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.59 ms /    23 tokens (   11.03 ms per token,    90.70 tokens per second)\n",
      "llama_print_timings:        eval time =      94.66 ms /     1 runs   (   94.66 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     353.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.29 ms /     8 runs   (    0.16 ms per token,  6220.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    24 tokens (   10.58 ms per token,    94.54 tokens per second)\n",
      "llama_print_timings:        eval time =     572.33 ms /     7 runs   (   81.76 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =     853.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marietta Wuckert\", \"Doctor Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    18 runs   (    0.26 ms per token,  3837.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.96 ms /   157 tokens (    7.38 ms per token,   135.58 tokens per second)\n",
      "llama_print_timings:        eval time =    1328.18 ms /    17 runs   (   78.13 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    2598.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"748 523 1477\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.56 ms /    15 runs   (    0.30 ms per token,  3288.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.47 ms /    25 tokens (   10.06 ms per token,    99.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.34 ms /    14 runs   (   78.45 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1432.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     7 runs   (    0.17 ms per token,  5847.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =     487.87 ms /     6 runs   (   81.31 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     763.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     8 runs   (    0.20 ms per token,  5053.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.65 ms /    24 tokens (   10.40 ms per token,    96.14 tokens per second)\n",
      "llama_print_timings:        eval time =     568.85 ms /     7 runs   (   81.26 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =     852.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Janyce Gusikowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.92 ms /    13 runs   (    0.30 ms per token,  3316.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1150.80 ms /   149 tokens (    7.72 ms per token,   129.47 tokens per second)\n",
      "llama_print_timings:        eval time =     942.62 ms /    12 runs   (   78.55 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2169.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"692 364 2672\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    15 runs   (    0.27 ms per token,  3744.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.75 ms /    25 tokens (   10.07 ms per token,    99.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.92 ms /    14 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1432.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6896.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.04 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =      90.28 ms /     1 runs   (   90.28 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     345.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary diagnosis\", \"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    13 runs   (    0.32 ms per token,  3130.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.12 ms /    24 tokens (   10.38 ms per token,    96.34 tokens per second)\n",
      "llama_print_timings:        eval time =     951.92 ms /    12 runs   (   79.33 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1271.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Daniele Hoeger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     9 runs   (    0.23 ms per token,  4285.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1137.64 ms /   131 tokens (    8.68 ms per token,   115.15 tokens per second)\n",
      "llama_print_timings:        eval time =     628.66 ms /     8 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1806.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"451 666 4332\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /    15 runs   (    0.27 ms per token,  3665.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.28 ms /    25 tokens (   10.05 ms per token,    99.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.16 ms /    14 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    1423.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"25 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     7 runs   (    0.17 ms per token,  6029.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.88 ms /    23 tokens (   10.86 ms per token,    92.04 tokens per second)\n",
      "llama_print_timings:        eval time =     491.48 ms /     6 runs   (   81.91 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =     766.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6153.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =      92.10 ms /     1 runs   (   92.10 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =     346.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alden Barton\", \"Dr. Almeda Okuneva\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    19 runs   (    0.28 ms per token,  3510.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.55 ms /   154 tokens (    7.51 ms per token,   133.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1406.88 ms /    18 runs   (   78.16 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2678.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 494 6863\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.73 ms /    15 runs   (    0.32 ms per token,  3170.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.08 ms /    14 runs   (   78.65 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1436.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     4 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.78 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =     267.19 ms /     3 runs   (   89.06 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =     528.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8510.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.79 ms /    24 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =      93.30 ms /     1 runs   (   93.30 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     349.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kyong Oberbrunner\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    20 runs   (    0.30 ms per token,  3347.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.51 ms /   190 tokens (    7.36 ms per token,   135.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1473.95 ms /    19 runs   (   77.58 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2995.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"413 559 7685\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.29 ms /    15 runs   (    0.29 ms per token,  3495.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.92 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1109.91 ms /    14 runs   (   79.28 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    1444.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     9 runs   (    0.25 ms per token,  3937.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.99 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     644.38 ms /     8 runs   (   80.55 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =     947.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7490.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =      91.52 ms /     1 runs   (   91.52 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     352.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Roderick Senger\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    15 runs   (    0.29 ms per token,  3452.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.52 ms /   191 tokens (    7.34 ms per token,   136.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.87 ms /    14 runs   (   77.56 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    2570.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 794 4796\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.98 ms /    15 runs   (    0.33 ms per token,  3010.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1106.78 ms /    14 runs   (   79.06 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1446.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /     8 runs   (    0.24 ms per token,  4117.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    23 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     575.73 ms /     7 runs   (   82.25 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     860.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    24 tokens (   10.48 ms per token,    95.42 tokens per second)\n",
      "llama_print_timings:        eval time =      91.80 ms /     1 runs   (   91.80 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     348.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Inocencia Kassulke\", \"Dr. Azucena Crona\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.13 ms /    20 runs   (    0.26 ms per token,  3896.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.11 ms /   139 tokens (    8.22 ms per token,   121.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1476.18 ms /    19 runs   (   77.69 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2741.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 896 2283\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /    15 runs   (    0.30 ms per token,  3304.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.30 ms /    25 tokens (   10.05 ms per token,    99.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.05 ms /    14 runs   (   78.43 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1432.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     4 runs   (    0.13 ms per token,  7984.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.91 ms /    23 tokens (   10.87 ms per token,    92.03 tokens per second)\n",
      "llama_print_timings:        eval time =     260.29 ms /     3 runs   (   86.76 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     520.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     8 runs   (    0.22 ms per token,  4602.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.79 ms /    24 tokens (   10.41 ms per token,    96.08 tokens per second)\n",
      "llama_print_timings:        eval time =     565.88 ms /     7 runs   (   80.84 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     847.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jenae Feeney\", \"Dr Ariane Pagac\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /    17 runs   (    0.27 ms per token,  3660.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.54 ms /   172 tokens (    8.00 ms per token,   124.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.83 ms /    16 runs   (   78.18 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2725.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 363 6710\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    15 runs   (    0.31 ms per token,  3240.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.88 ms /    25 tokens (   10.08 ms per token,    99.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1100.27 ms /    14 runs   (   78.59 ms per token,    12.72 tokens per second)\n",
      "llama_print_timings:       total time =    1433.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8583.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    23 tokens (   10.89 ms per token,    91.87 tokens per second)\n",
      "llama_print_timings:        eval time =      90.98 ms /     1 runs   (   90.98 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =     346.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.31 ms /     7 runs   (    0.19 ms per token,  5347.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.22 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =     482.64 ms /     6 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =     759.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ligia Von\", \"Randy Bergstrom\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    14 runs   (    0.23 ms per token,  4353.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.44 ms /   191 tokens (    7.31 ms per token,   136.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1010.71 ms /    13 runs   (   77.75 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    2478.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 758 7644\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    15 runs   (    0.29 ms per token,  3442.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.59 ms /    25 tokens (   10.10 ms per token,    98.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1108.30 ms /    14 runs   (   79.16 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    1434.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.54 ms /     7 runs   (    0.22 ms per token,  4542.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     486.79 ms /     6 runs   (   81.13 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =     774.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     7 runs   (    0.14 ms per token,  6930.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.08 ms /    24 tokens (   10.46 ms per token,    95.59 tokens per second)\n",
      "llama_print_timings:        eval time =     487.81 ms /     6 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     760.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jutta Trantow\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    20 runs   (    0.28 ms per token,  3564.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.81 ms /   159 tokens (    7.29 ms per token,   137.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1475.69 ms /    19 runs   (   77.67 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    2749.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"777 781 7674\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    15 runs   (    0.26 ms per token,  3804.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.91 ms /    25 tokens (   10.08 ms per token,    99.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1105.16 ms /    14 runs   (   78.94 ms per token,    12.67 tokens per second)\n",
      "llama_print_timings:       total time =    1431.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     7 runs   (    0.21 ms per token,  4827.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.10 ms /    23 tokens (   10.87 ms per token,    91.96 tokens per second)\n",
      "llama_print_timings:        eval time =     484.64 ms /     6 runs   (   80.77 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =     762.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8810.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =      98.59 ms /     1 runs   (   98.59 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =     354.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Carole Corkery\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /    11 runs   (    0.30 ms per token,  3345.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.83 ms /   153 tokens (    7.57 ms per token,   132.14 tokens per second)\n",
      "llama_print_timings:        eval time =     791.68 ms /    10 runs   (   79.17 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =    2018.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"208 144 0309\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /    15 runs   (    0.29 ms per token,  3399.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.52 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1097.69 ms /    14 runs   (   78.41 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    1426.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6825.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.41 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =      91.96 ms /     1 runs   (   91.96 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     347.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.01 ms /    24 tokens (   10.42 ms per token,    96.00 tokens per second)\n",
      "llama_print_timings:        eval time =      95.86 ms /     1 runs   (   95.86 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     350.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Judi McCullough\", \"Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    18 runs   (    0.30 ms per token,  3375.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1620.07 ms /   207 tokens (    7.83 ms per token,   127.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1329.77 ms /    17 runs   (   78.22 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =    3047.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"173 732 5874\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /    15 runs   (    0.26 ms per token,  3777.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.74 ms /    25 tokens (   10.11 ms per token,    98.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1104.19 ms /    14 runs   (   78.87 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1433.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     7 runs   (    0.23 ms per token,  4305.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.77 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =     492.67 ms /     6 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     769.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli urinary tract infection\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.17 ms /    14 runs   (    0.23 ms per token,  4412.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1026.74 ms /    13 runs   (   78.98 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1343.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Julene Kihn\", \"Dr. Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    18 runs   (    0.24 ms per token,  4115.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.37 ms /   151 tokens (    7.63 ms per token,   131.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1335.63 ms /    17 runs   (   78.57 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2579.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"414 219 4085\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    15 runs   (    0.26 ms per token,  3870.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    25 tokens (   10.05 ms per token,    99.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.82 ms /    14 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1447.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     5 runs   (    0.14 ms per token,  7183.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.83 ms /    23 tokens (   10.86 ms per token,    92.06 tokens per second)\n",
      "llama_print_timings:        eval time =     345.65 ms /     4 runs   (   86.41 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     608.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     8 runs   (    0.27 ms per token,  3722.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.09 ms /    24 tokens (   10.42 ms per token,    95.96 tokens per second)\n",
      "llama_print_timings:        eval time =     564.64 ms /     7 runs   (   80.66 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =     851.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otha Lockman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  5010.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2336.63 ms /   297 tokens (    7.87 ms per token,   127.11 tokens per second)\n",
      "llama_print_timings:        eval time =     477.58 ms /     6 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2845.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 865 8027\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    15 runs   (    0.29 ms per token,  3453.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.39 ms /    25 tokens (   10.18 ms per token,    98.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.91 ms /    14 runs   (   79.42 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1440.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.77 ms /     6 runs   (    0.13 ms per token,  7792.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.47 ms /    23 tokens (   11.02 ms per token,    90.74 tokens per second)\n",
      "llama_print_timings:        eval time =     416.72 ms /     5 runs   (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     686.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8771.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.40 ms /    24 tokens (   10.56 ms per token,    94.71 tokens per second)\n",
      "llama_print_timings:        eval time =     100.91 ms /     1 runs   (  100.91 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =     359.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Denita Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     6 runs   (    0.18 ms per token,  5576.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     933.70 ms /   122 tokens (    7.65 ms per token,   130.66 tokens per second)\n",
      "llama_print_timings:        eval time =     403.09 ms /     5 runs   (   80.62 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1356.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 948 8825\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.40 ms /    19 runs   (    0.28 ms per token,  3521.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.19 ms /    25 tokens (   10.05 ms per token,    99.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1405.06 ms /    18 runs   (   78.06 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =    1753.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"two year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.05 ms /     6 runs   (    0.18 ms per token,  5692.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.56 ms /    23 tokens (   10.85 ms per token,    92.16 tokens per second)\n",
      "llama_print_timings:        eval time =     409.87 ms /     5 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     682.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7352.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =      94.22 ms /     1 runs   (   94.22 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     348.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Gertie Bradtke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /    12 runs   (    0.25 ms per token,  4070.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.12 ms /   151 tokens (    7.64 ms per token,   130.84 tokens per second)\n",
      "llama_print_timings:        eval time =     854.71 ms /    11 runs   (   77.70 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2072.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"490 191 5835\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    15 runs   (    0.29 ms per token,  3413.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.36 ms /    25 tokens (   10.09 ms per token,    99.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.98 ms /    14 runs   (   79.14 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1443.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.39 ms /    23 tokens (   10.84 ms per token,    92.22 tokens per second)\n",
      "llama_print_timings:        eval time =      91.92 ms /     1 runs   (   91.92 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     346.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     8 runs   (    0.20 ms per token,  5066.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.55 ms /    24 tokens (   10.40 ms per token,    96.17 tokens per second)\n",
      "llama_print_timings:        eval time =     585.20 ms /     7 runs   (   83.60 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     868.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Willodean Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    12 runs   (    0.17 ms per token,  5727.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.48 ms /   184 tokens (    7.61 ms per token,   131.48 tokens per second)\n",
      "llama_print_timings:        eval time =     954.96 ms /    11 runs   (   86.81 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    2396.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"284 389 0464\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    15 runs   (    0.31 ms per token,  3236.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.90 ms /    25 tokens (   10.16 ms per token,    98.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1270.00 ms /    14 runs   (   90.71 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =    1606.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.43 ms /     8 runs   (    0.18 ms per token,  5578.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.06 ms /    23 tokens (   10.92 ms per token,    91.61 tokens per second)\n",
      "llama_print_timings:        eval time =     583.65 ms /     7 runs   (   83.38 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     867.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     8 runs   (    0.19 ms per token,  5329.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.10 ms /    24 tokens (   10.96 ms per token,    91.22 tokens per second)\n",
      "llama_print_timings:        eval time =     615.94 ms /     7 runs   (   87.99 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =     909.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brett Doyle\", \"Dr Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    16 runs   (    0.45 ms per token,  2212.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1401.74 ms /   184 tokens (    7.62 ms per token,   131.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.04 ms /    15 runs   (   80.07 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    2729.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"750 149 0663\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.48 ms /    15 runs   (    0.43 ms per token,  2314.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.28 ms /    25 tokens (   10.21 ms per token,    97.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.13 ms /    14 runs   (   82.08 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1516.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     4 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.81 ms /    23 tokens (   11.12 ms per token,    89.91 tokens per second)\n",
      "llama_print_timings:        eval time =     257.31 ms /     3 runs   (   85.77 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =     523.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.14 ms /     8 runs   (    0.27 ms per token,  3731.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.33 ms /    24 tokens (   10.72 ms per token,    93.27 tokens per second)\n",
      "llama_print_timings:        eval time =     582.89 ms /     7 runs   (   83.27 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     877.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Leontine Rutherford\", \"Dr. Blanche Bailey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    17 runs   (    0.46 ms per token,  2162.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1645.47 ms /   197 tokens (    8.35 ms per token,   119.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1292.96 ms /    16 runs   (   80.81 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    3075.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 396 3416\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    15 runs   (    0.51 ms per token,  1949.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.25 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.50 ms /    14 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1520.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6230.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.97 ms /    23 tokens (   11.13 ms per token,    89.86 tokens per second)\n",
      "llama_print_timings:        eval time =     106.31 ms /     1 runs   (  106.31 ms per token,     9.41 tokens per second)\n",
      "llama_print_timings:       total time =     367.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8163.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.26 ms /    24 tokens (   10.76 ms per token,    92.93 tokens per second)\n",
      "llama_print_timings:        eval time =      95.82 ms /     1 runs   (   95.82 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     357.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Eloy Ernser\", \"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    16 runs   (    0.53 ms per token,  1902.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3518.91 ms /   419 tokens (    8.40 ms per token,   119.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.39 ms /    15 runs   (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    4899.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"314 661 1099\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    15 runs   (    0.51 ms per token,  1958.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.95 ms /    25 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.06 ms /    14 runs   (   84.65 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1563.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6600.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.00 ms /    23 tokens (   11.30 ms per token,    88.46 tokens per second)\n",
      "llama_print_timings:        eval time =     104.73 ms /     1 runs   (  104.73 ms per token,     9.55 tokens per second)\n",
      "llama_print_timings:       total time =     375.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     8 runs   (    0.22 ms per token,  4595.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.73 ms /    24 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     601.98 ms /     7 runs   (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     895.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Merrill Carter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /     9 runs   (    0.46 ms per token,  2192.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3144.91 ms /   395 tokens (    7.96 ms per token,   125.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.72 ms /     8 runs   (   83.46 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =    3876.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"687 154 4100\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2228.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.10 ms /    25 tokens (   10.36 ms per token,    96.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.62 ms /    14 runs   (   84.97 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =    1570.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     9 runs   (    0.36 ms per token,  2788.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    23 tokens (   11.16 ms per token,    89.58 tokens per second)\n",
      "llama_print_timings:        eval time =     674.31 ms /     8 runs   (   84.29 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     984.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /     8 runs   (    0.28 ms per token,  3585.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.99 ms /    24 tokens (   10.62 ms per token,    94.12 tokens per second)\n",
      "llama_print_timings:        eval time =     595.35 ms /     7 runs   (   85.05 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     887.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Felix Rowe\", \"Dr. Palmer Kuphal\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    16 runs   (    0.47 ms per token,  2130.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1642.39 ms /   209 tokens (    7.86 ms per token,   127.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1197.05 ms /    15 runs   (   79.80 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    2966.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"623 839 4648\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    15 runs   (    0.59 ms per token,  1686.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    25 tokens (   10.12 ms per token,    98.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1142.12 ms /    14 runs   (   81.58 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1518.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     9 runs   (    0.24 ms per token,  4191.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.66 ms /    23 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =     666.54 ms /     8 runs   (   83.32 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     958.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.82 ms /     8 runs   (    0.23 ms per token,  4398.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.90 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =     580.53 ms /     7 runs   (   82.93 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     863.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Stanton Olson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.18 ms /     9 runs   (    0.35 ms per token,  2833.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.52 ms /   183 tokens (    7.63 ms per token,   131.13 tokens per second)\n",
      "llama_print_timings:        eval time =     640.83 ms /     8 runs   (   80.10 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    2091.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 646 919 9817\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.04 ms /    19 runs   (    0.58 ms per token,  1721.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    25 tokens (   10.10 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1452.40 ms /    18 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1857.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     7 runs   (    0.17 ms per token,  5766.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.05 ms /    23 tokens (   11.09 ms per token,    90.18 tokens per second)\n",
      "llama_print_timings:        eval time =     509.65 ms /     6 runs   (   84.94 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     790.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"respiratory therapy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     8 runs   (    0.22 ms per token,  4471.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.35 ms /    24 tokens (   10.64 ms per token,    93.99 tokens per second)\n",
      "llama_print_timings:        eval time =     582.15 ms /     7 runs   (   83.16 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     868.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Brian Trantow\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.83 ms /    18 runs   (    0.55 ms per token,  1830.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.05 ms /   164 tokens (    8.52 ms per token,   117.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1367.54 ms /    17 runs   (   80.44 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    2914.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"861 845 3081\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    15 runs   (    0.52 ms per token,  1909.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    25 tokens (   10.25 ms per token,    97.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.01 ms /    14 runs   (   82.21 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1528.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5665.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    23 tokens (   10.97 ms per token,    91.12 tokens per second)\n",
      "llama_print_timings:        eval time =      95.55 ms /     1 runs   (   95.55 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     353.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.21 ms /    11 runs   (    0.38 ms per token,  2615.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =     819.01 ms /    10 runs   (   81.90 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1159.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Luther Nikolaus\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /     7 runs   (    0.46 ms per token,  2176.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2412.90 ms /   289 tokens (    8.35 ms per token,   119.77 tokens per second)\n",
      "llama_print_timings:        eval time =     494.88 ms /     6 runs   (   82.48 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    2953.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 264 7353\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.83 ms /    15 runs   (    0.59 ms per token,  1699.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.59 ms /    25 tokens (   10.26 ms per token,    97.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.61 ms /    14 runs   (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1536.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.91 ms /    23 tokens (   11.21 ms per token,    89.18 tokens per second)\n",
      "llama_print_timings:        eval time =     104.24 ms /     1 runs   (  104.24 ms per token,     9.59 tokens per second)\n",
      "llama_print_timings:       total time =     367.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     8 runs   (    0.26 ms per token,  3802.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.22 ms /    24 tokens (   10.80 ms per token,    92.59 tokens per second)\n",
      "llama_print_timings:        eval time =     867.99 ms /     7 runs   (  124.00 ms per token,     8.06 tokens per second)\n",
      "llama_print_timings:       total time =    1165.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Miguelina VonRueden\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    12 runs   (    0.45 ms per token,  2235.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2438.76 ms /   262 tokens (    9.31 ms per token,   107.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1000.57 ms /    11 runs   (   90.96 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    3543.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"315 897 7942\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.00 ms /    15 runs   (    0.40 ms per token,  2498.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     270.96 ms /    25 tokens (   10.84 ms per token,    92.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1474.16 ms /    14 runs   (  105.30 ms per token,     9.50 tokens per second)\n",
      "llama_print_timings:       total time =    1842.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"23 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     7 runs   (    0.25 ms per token,  3970.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     281.92 ms /    23 tokens (   12.26 ms per token,    81.58 tokens per second)\n",
      "llama_print_timings:        eval time =     615.89 ms /     6 runs   (  102.65 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =     935.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11111.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     289.34 ms /    24 tokens (   12.06 ms per token,    82.95 tokens per second)\n",
      "llama_print_timings:        eval time =     112.59 ms /     1 runs   (  112.59 ms per token,     8.88 tokens per second)\n",
      "llama_print_timings:       total time =     406.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Julienne Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.45 ms /     9 runs   (    0.38 ms per token,  2607.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.10 ms /   147 tokens (    9.39 ms per token,   106.51 tokens per second)\n",
      "llama_print_timings:        eval time =     831.52 ms /     8 runs   (  103.94 ms per token,     9.62 tokens per second)\n",
      "llama_print_timings:       total time =    2269.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"641 919 0513\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.60 ms /    15 runs   (    0.51 ms per token,  1973.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     313.78 ms /    25 tokens (   12.55 ms per token,    79.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1222.97 ms /    14 runs   (   87.36 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    1652.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2540.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     655.59 ms /     8 runs   (   81.95 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =     961.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.46 ms /     8 runs   (    0.18 ms per token,  5479.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     566.90 ms /     7 runs   (   80.99 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =     842.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Adah Krajcik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     9 runs   (    0.34 ms per token,  2936.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1376.05 ms /   172 tokens (    8.00 ms per token,   125.00 tokens per second)\n",
      "llama_print_timings:        eval time =     636.15 ms /     8 runs   (   79.52 ms per token,    12.58 tokens per second)\n",
      "llama_print_timings:       total time =    2066.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 585 4182\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    15 runs   (    0.58 ms per token,  1732.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.97 ms /    25 tokens (   10.08 ms per token,    99.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.72 ms /    14 runs   (   79.41 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    1482.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     8 runs   (    0.33 ms per token,  3018.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.15 ms /    23 tokens (   10.88 ms per token,    91.95 tokens per second)\n",
      "llama_print_timings:        eval time =     606.68 ms /     7 runs   (   86.67 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     894.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4232.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.86 ms /    24 tokens (   10.45 ms per token,    95.67 tokens per second)\n",
      "llama_print_timings:        eval time =     495.69 ms /     6 runs   (   82.61 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     772.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Georgiana Jerde\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.02 ms /    13 runs   (    0.31 ms per token,  3232.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1409.29 ms /   192 tokens (    7.34 ms per token,   136.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1003.06 ms /    12 runs   (   83.59 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    2484.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"402 448 0695\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.60 ms /    15 runs   (    0.37 ms per token,  2678.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.16 ms /    25 tokens (   10.29 ms per token,    97.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.29 ms /    14 runs   (   81.09 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1485.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    23 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =      95.87 ms /     1 runs   (   95.87 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =     351.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     8 runs   (    0.25 ms per token,  3976.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    24 tokens (   10.47 ms per token,    95.48 tokens per second)\n",
      "llama_print_timings:        eval time =     576.16 ms /     7 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =     862.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo McKenzie\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.74 ms /    17 runs   (    0.46 ms per token,  2196.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1377.99 ms /   164 tokens (    8.40 ms per token,   119.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.96 ms /    16 runs   (   78.56 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =    2773.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 999 5708\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    15 runs   (    0.47 ms per token,  2114.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.22 ms /    25 tokens (   10.05 ms per token,    99.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.15 ms /    14 runs   (   79.08 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    1462.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     6 runs   (    0.16 ms per token,  6243.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.58 ms /    23 tokens (   10.85 ms per token,    92.15 tokens per second)\n",
      "llama_print_timings:        eval time =     414.14 ms /     5 runs   (   82.83 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     683.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.26 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =      91.57 ms /     1 runs   (   91.57 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =     347.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jim Ebert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.17 ms /     7 runs   (    0.31 ms per token,  3221.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1378.62 ms /   176 tokens (    7.83 ms per token,   127.66 tokens per second)\n",
      "llama_print_timings:        eval time =     473.76 ms /     6 runs   (   78.96 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =    1888.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 439 2175\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.05 ms /    15 runs   (    0.60 ms per token,  1657.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.74 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.29 ms /    14 runs   (   80.16 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1497.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7142.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.78 ms /    23 tokens (   10.86 ms per token,    92.08 tokens per second)\n",
      "llama_print_timings:        eval time =      90.83 ms /     1 runs   (   90.83 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =     346.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.61 ms /     7 runs   (    0.23 ms per token,  4337.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.79 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =     493.47 ms /     6 runs   (   82.24 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =     767.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Domingo Mohr\", \"Dr Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /    14 runs   (    0.21 ms per token,  4797.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1383.80 ms /   169 tokens (    8.19 ms per token,   122.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.48 ms /    13 runs   (   88.11 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    2589.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 399 0706\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.77 ms /    15 runs   (    0.38 ms per token,  2600.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.98 ms /    25 tokens (   10.44 ms per token,    95.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.93 ms /    14 runs   (   84.07 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1528.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6756.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.74 ms /    23 tokens (   11.03 ms per token,    90.65 tokens per second)\n",
      "llama_print_timings:        eval time =     102.50 ms /     1 runs   (  102.50 ms per token,     9.76 tokens per second)\n",
      "llama_print_timings:       total time =     361.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10362.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.12 ms /    24 tokens (   10.55 ms per token,    94.82 tokens per second)\n",
      "llama_print_timings:        eval time =      96.75 ms /     1 runs   (   96.75 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =     353.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lizabeth Bradtke\", \"Antonette Tromp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.18 ms /    20 runs   (    0.36 ms per token,  2786.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.98 ms /   178 tokens (    7.94 ms per token,   125.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1561.19 ms /    19 runs   (   82.17 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    3100.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"675 496 9113\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.91 ms /    15 runs   (    0.33 ms per token,  3054.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.49 ms /    25 tokens (   10.22 ms per token,    97.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1177.78 ms /    14 runs   (   84.13 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =    1516.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7722.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.71 ms /    23 tokens (   10.94 ms per token,    91.37 tokens per second)\n",
      "llama_print_timings:        eval time =      94.21 ms /     1 runs   (   94.21 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     350.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token,  9900.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     100.13 ms /     1 runs   (  100.13 ms per token,     9.99 tokens per second)\n",
      "llama_print_timings:       total time =     354.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Roberto Stark\", \"Dr. Hildegarde Johns\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.08 ms /    18 runs   (    0.62 ms per token,  1624.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.65 ms /   156 tokens (    7.53 ms per token,   132.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1364.58 ms /    17 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    2702.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"231 955 3843\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.76 ms /    15 runs   (    0.58 ms per token,  1713.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.64 ms /    25 tokens (   10.23 ms per token,    97.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.12 ms /    14 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1524.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"62 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     8 runs   (    0.19 ms per token,  5228.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.26 ms /    23 tokens (   11.05 ms per token,    90.46 tokens per second)\n",
      "llama_print_timings:        eval time =     585.52 ms /     7 runs   (   83.65 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     869.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /    11 runs   (    0.41 ms per token,  2429.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.94 ms /    24 tokens (   10.58 ms per token,    94.51 tokens per second)\n",
      "llama_print_timings:        eval time =     828.85 ms /    10 runs   (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1163.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Richie Kulas\", \"Doctor Latoria Eichmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    17 runs   (    0.48 ms per token,  2090.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.78 ms /   195 tokens (    8.43 ms per token,   118.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1303.93 ms /    16 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    3083.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 157 2976\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    15 runs   (    0.45 ms per token,  2204.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.54 ms /    25 tokens (   10.30 ms per token,    97.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.13 ms /    14 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1518.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.18 ms /    23 tokens (   11.05 ms per token,    90.49 tokens per second)\n",
      "llama_print_timings:        eval time =      97.15 ms /     1 runs   (   97.15 ms per token,    10.29 tokens per second)\n",
      "llama_print_timings:       total time =     356.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"respiratory therapy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     8 runs   (    0.25 ms per token,  3958.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =     587.78 ms /     7 runs   (   83.97 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     875.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Chloe Johnson\", \"Dr Harland Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    16 runs   (    0.49 ms per token,  2036.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.72 ms /   142 tokens (    8.20 ms per token,   122.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.61 ms /    15 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2506.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"416 224 6757\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.66 ms /    15 runs   (    0.44 ms per token,  2253.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.43 ms /    25 tokens (   10.22 ms per token,    97.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.31 ms /    14 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1499.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     7 runs   (    0.30 ms per token,  3327.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.64 ms /    23 tokens (   11.03 ms per token,    90.68 tokens per second)\n",
      "llama_print_timings:        eval time =     492.78 ms /     6 runs   (   82.13 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     782.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /     8 runs   (    0.19 ms per token,  5232.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.32 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =     602.09 ms /     7 runs   (   86.01 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     889.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Carey Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.15 ms /    10 runs   (    0.42 ms per token,  2409.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.63 ms /   152 tokens (    7.71 ms per token,   129.62 tokens per second)\n",
      "llama_print_timings:        eval time =     737.03 ms /     9 runs   (   81.89 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1977.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"788 233 5814\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    15 runs   (    0.48 ms per token,  2081.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    25 tokens (   10.25 ms per token,    97.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.41 ms /    14 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1522.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     7 runs   (    0.27 ms per token,  3703.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.41 ms /    23 tokens (   11.10 ms per token,    90.05 tokens per second)\n",
      "llama_print_timings:        eval time =     514.32 ms /     6 runs   (   85.72 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     802.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.33 ms /     2 runs   (    0.16 ms per token,  6153.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.76 ms /    24 tokens (   10.62 ms per token,    94.21 tokens per second)\n",
      "llama_print_timings:        eval time =      99.78 ms /     1 runs   (   99.78 ms per token,    10.02 tokens per second)\n",
      "llama_print_timings:       total time =     360.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nola Jacobi\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /     7 runs   (    0.21 ms per token,  4752.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.57 ms /   156 tokens (    7.53 ms per token,   132.81 tokens per second)\n",
      "llama_print_timings:        eval time =     497.32 ms /     6 runs   (   82.89 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1705.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"687 906 0545\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.43 ms /    15 runs   (    0.56 ms per token,  1778.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.03 ms /    25 tokens (   10.20 ms per token,    98.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.78 ms /    14 runs   (   81.70 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1515.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.50 ms /     4 runs   (    0.13 ms per token,  7984.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.65 ms /    23 tokens (   11.07 ms per token,    90.32 tokens per second)\n",
      "llama_print_timings:        eval time =     270.64 ms /     3 runs   (   90.21 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     539.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /    11 runs   (    0.27 ms per token,  3665.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.80 ms /    24 tokens (   10.62 ms per token,    94.19 tokens per second)\n",
      "llama_print_timings:        eval time =     826.07 ms /    10 runs   (   82.61 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1141.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kelvin Skiles\", \"Dr. Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.60 ms /    17 runs   (    0.62 ms per token,  1603.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3236.94 ms /   387 tokens (    8.36 ms per token,   119.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1330.89 ms /    16 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =    4712.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"578 375 3127\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.32 ms /    15 runs   (    0.55 ms per token,  1803.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.95 ms /    25 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1181.36 ms /    14 runs   (   84.38 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =    1565.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /     9 runs   (    0.40 ms per token,  2495.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.05 ms /    23 tokens (   11.18 ms per token,    89.48 tokens per second)\n",
      "llama_print_timings:        eval time =     690.75 ms /     8 runs   (   86.34 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1003.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6920.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.31 ms /    24 tokens (   10.80 ms per token,    92.56 tokens per second)\n",
      "llama_print_timings:        eval time =     101.72 ms /     1 runs   (  101.72 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =     367.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Elwood Smitham\", \"Doctor Dooley\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    16 runs   (    0.45 ms per token,  2233.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.82 ms /   174 tokens (    8.04 ms per token,   124.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.24 ms /    15 runs   (   81.22 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    2735.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"699 565 3857\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    15 runs   (    0.50 ms per token,  2002.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.13 ms /    25 tokens (   10.21 ms per token,    97.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.74 ms /    14 runs   (   82.12 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1520.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6872.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.64 ms /    23 tokens (   11.07 ms per token,    90.33 tokens per second)\n",
      "llama_print_timings:        eval time =      95.14 ms /     1 runs   (   95.14 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =     355.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.37 ms /    11 runs   (    0.40 ms per token,  2520.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.65 ms /    24 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =     825.25 ms /    10 runs   (   82.53 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1150.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Pete Moen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     9 runs   (    0.40 ms per token,  2486.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.02 ms /   149 tokens (    7.86 ms per token,   127.24 tokens per second)\n",
      "llama_print_timings:        eval time =     658.69 ms /     8 runs   (   82.34 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1888.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"328 816 3672\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.37 ms /    15 runs   (    0.36 ms per token,  2795.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.05 ms /    25 tokens (   10.24 ms per token,    97.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.23 ms /    14 runs   (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    1531.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     7 runs   (    0.31 ms per token,  3243.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.36 ms /    23 tokens (   11.06 ms per token,    90.42 tokens per second)\n",
      "llama_print_timings:        eval time =     514.08 ms /     6 runs   (   85.68 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     803.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7843.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    24 tokens (   10.62 ms per token,    94.15 tokens per second)\n",
      "llama_print_timings:        eval time =      97.00 ms /     1 runs   (   97.00 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =     356.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hee Rosenbaum\", \"Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    17 runs   (    0.44 ms per token,  2261.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.45 ms /   166 tokens (    8.42 ms per token,   118.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1293.20 ms /    16 runs   (   80.83 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2825.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"667 179 4627\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    15 runs   (    0.50 ms per token,  1998.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    25 tokens (   10.23 ms per token,    97.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.88 ms /    14 runs   (   82.28 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1531.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     9 runs   (    0.29 ms per token,  3441.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.42 ms /    23 tokens (   11.06 ms per token,    90.40 tokens per second)\n",
      "llama_print_timings:        eval time =     674.03 ms /     8 runs   (   84.25 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     978.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /     8 runs   (    0.29 ms per token,  3455.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.01 ms /    24 tokens (   10.58 ms per token,    94.49 tokens per second)\n",
      "llama_print_timings:        eval time =     601.85 ms /     7 runs   (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     898.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Janell Rohan\", \"Dr. Chun Armstrong\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.83 ms /    19 runs   (    0.57 ms per token,  1754.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1668.56 ms /   210 tokens (    7.95 ms per token,   125.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1459.19 ms /    18 runs   (   81.07 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    3290.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"705 685 3418\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.24 ms /    15 runs   (    0.48 ms per token,  2070.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.64 ms /    25 tokens (   10.35 ms per token,    96.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1167.01 ms /    14 runs   (   83.36 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1547.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     5 runs   (    0.19 ms per token,  5170.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.50 ms /    23 tokens (   11.02 ms per token,    90.73 tokens per second)\n",
      "llama_print_timings:        eval time =     337.28 ms /     4 runs   (   84.32 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     609.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.39 ms /     8 runs   (    0.30 ms per token,  3354.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.91 ms /    24 tokens (   10.66 ms per token,    93.78 tokens per second)\n",
      "llama_print_timings:        eval time =     585.01 ms /     7 runs   (   83.57 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     887.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Chance Jacobson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2714.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1670.71 ms /   213 tokens (    7.84 ms per token,   127.49 tokens per second)\n",
      "llama_print_timings:        eval time =     651.99 ms /     8 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2378.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"536 599 9413\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    15 runs   (    0.53 ms per token,  1875.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.69 ms /    14 runs   (   82.26 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1527.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     9 runs   (    0.39 ms per token,  2534.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.15 ms /    23 tokens (   11.09 ms per token,    90.14 tokens per second)\n",
      "llama_print_timings:        eval time =     668.17 ms /     8 runs   (   83.52 ms per token,    11.97 tokens per second)\n",
      "llama_print_timings:       total time =     974.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.17 ms /    13 runs   (    0.47 ms per token,  2107.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.41 ms /    24 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =     992.35 ms /    12 runs   (   82.70 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1333.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Linda Thompson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.28 ms /     9 runs   (    0.48 ms per token,  2103.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1906.97 ms /   232 tokens (    8.22 ms per token,   121.66 tokens per second)\n",
      "llama_print_timings:        eval time =     655.02 ms /     8 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    2623.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"925 256 9727\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    15 runs   (    0.58 ms per token,  1731.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.00 ms /    25 tokens (   10.32 ms per token,    96.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.01 ms /    14 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1529.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.54 ms /     9 runs   (    0.50 ms per token,  1982.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.45 ms /    23 tokens (   11.11 ms per token,    90.04 tokens per second)\n",
      "llama_print_timings:        eval time =     673.35 ms /     8 runs   (   84.17 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     993.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.17 ms /     8 runs   (    0.52 ms per token,  1918.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.65 ms /    24 tokens (   10.69 ms per token,    93.51 tokens per second)\n",
      "llama_print_timings:        eval time =     588.61 ms /     7 runs   (   84.09 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     903.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marcus Kihn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.35 ms /     8 runs   (    0.29 ms per token,  3408.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.80 ms /   191 tokens (    7.45 ms per token,   134.15 tokens per second)\n",
      "llama_print_timings:        eval time =     569.77 ms /     7 runs   (   81.40 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2036.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"476 337 5840\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.37 ms /    15 runs   (    0.56 ms per token,  1792.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    25 tokens (   10.30 ms per token,    97.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1158.94 ms /    14 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1536.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2716.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.93 ms /    23 tokens (   11.08 ms per token,    90.22 tokens per second)\n",
      "llama_print_timings:        eval time =     675.96 ms /     8 runs   (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     985.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.41 ms /     8 runs   (    0.30 ms per token,  3318.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.52 ms /    24 tokens (   10.69 ms per token,    93.56 tokens per second)\n",
      "llama_print_timings:        eval time =     588.61 ms /     7 runs   (   84.09 ms per token,    11.89 tokens per second)\n",
      "llama_print_timings:       total time =     888.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Monte Schmeler MD\", \"Dr. Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.74 ms /    18 runs   (    0.49 ms per token,  2059.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.91 ms /   151 tokens (    7.77 ms per token,   128.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1385.41 ms /    17 runs   (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2714.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"544 346 0661\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.23 ms /    15 runs   (    0.48 ms per token,  2074.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.18 ms /    25 tokens (   10.25 ms per token,    97.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.03 ms /    14 runs   (   81.79 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1513.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     5 runs   (    0.14 ms per token,  7072.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.47 ms /    23 tokens (   11.06 ms per token,    90.39 tokens per second)\n",
      "llama_print_timings:        eval time =     346.36 ms /     4 runs   (   86.59 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     612.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     8 runs   (    0.24 ms per token,  4173.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    24 tokens (   10.58 ms per token,    94.56 tokens per second)\n",
      "llama_print_timings:        eval time =     579.64 ms /     7 runs   (   82.81 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     886.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Felicitas Kuvalis\", \"Dr. Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.37 ms /    19 runs   (    0.60 ms per token,  1670.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1901.47 ms /   229 tokens (    8.30 ms per token,   120.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1458.42 ms /    18 runs   (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    3523.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"346 541 2717\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    15 runs   (    0.49 ms per token,  2050.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.99 ms /    25 tokens (   10.28 ms per token,    97.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.83 ms /    14 runs   (   82.99 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1548.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.23 ms /    23 tokens (   11.10 ms per token,    90.11 tokens per second)\n",
      "llama_print_timings:        eval time =      96.03 ms /     1 runs   (   96.03 ms per token,    10.41 tokens per second)\n",
      "llama_print_timings:       total time =     357.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10204.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.62 ms /    24 tokens (   10.73 ms per token,    93.16 tokens per second)\n",
      "llama_print_timings:        eval time =     107.52 ms /     1 runs   (  107.52 ms per token,     9.30 tokens per second)\n",
      "llama_print_timings:       total time =     368.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ismael Berge\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     8 runs   (    0.25 ms per token,  4028.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1389.67 ms /   162 tokens (    8.58 ms per token,   116.57 tokens per second)\n",
      "llama_print_timings:        eval time =     566.47 ms /     7 runs   (   80.92 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1996.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9997558068\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.45 ms /    13 runs   (    0.50 ms per token,  2015.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    25 tokens (   10.24 ms per token,    97.61 tokens per second)\n",
      "llama_print_timings:        eval time =     988.91 ms /    12 runs   (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1334.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     5 runs   (    0.16 ms per token,  6385.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    23 tokens (   11.03 ms per token,    90.62 tokens per second)\n",
      "llama_print_timings:        eval time =     343.24 ms /     4 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     619.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /     7 runs   (    0.20 ms per token,  5065.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    24 tokens (   10.61 ms per token,    94.28 tokens per second)\n",
      "llama_print_timings:        eval time =     502.66 ms /     6 runs   (   83.78 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     782.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Clora Effertz\", \"Dr Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2339.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1391.09 ms /   163 tokens (    8.53 ms per token,   117.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.69 ms /    15 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2728.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"212 411 7530\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.47 ms /    15 runs   (    0.50 ms per token,  2008.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.76 ms /    25 tokens (   10.15 ms per token,    98.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.53 ms /    14 runs   (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1515.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     9 runs   (    0.35 ms per token,  2869.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.40 ms /    23 tokens (   11.06 ms per token,    90.41 tokens per second)\n",
      "llama_print_timings:        eval time =     665.16 ms /     8 runs   (   83.15 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     974.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     8 runs   (    0.22 ms per token,  4537.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    24 tokens (   10.60 ms per token,    94.35 tokens per second)\n",
      "llama_print_timings:        eval time =     590.23 ms /     7 runs   (   84.32 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     874.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Damian Runolfsson\", \"Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    16 runs   (    0.44 ms per token,  2248.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.78 ms /   143 tokens (    8.13 ms per token,   122.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.54 ms /    15 runs   (   81.57 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2498.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"733 607 6160\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    15 runs   (    0.43 ms per token,  2323.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.54 ms /    25 tokens (   10.22 ms per token,    97.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1137.40 ms /    14 runs   (   81.24 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    1490.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     5 runs   (    0.15 ms per token,  6849.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.49 ms /    23 tokens (   11.02 ms per token,    90.73 tokens per second)\n",
      "llama_print_timings:        eval time =     353.30 ms /     4 runs   (   88.32 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     619.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /     8 runs   (    0.37 ms per token,  2675.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.92 ms /    24 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =     588.05 ms /     7 runs   (   84.01 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =     892.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jed Daniel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     6 runs   (    0.27 ms per token,  3656.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.55 ms /   141 tokens (    8.22 ms per token,   121.60 tokens per second)\n",
      "llama_print_timings:        eval time =     418.16 ms /     5 runs   (   83.63 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    1608.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"243 433 5920\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    15 runs   (    0.47 ms per token,  2133.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    25 tokens (   10.24 ms per token,    97.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.72 ms /    14 runs   (   81.84 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1500.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     9 runs   (    0.34 ms per token,  2959.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.40 ms /    23 tokens (   10.97 ms per token,    91.13 tokens per second)\n",
      "llama_print_timings:        eval time =     664.71 ms /     8 runs   (   83.09 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     968.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6968.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.36 ms /    24 tokens (   10.52 ms per token,    95.10 tokens per second)\n",
      "llama_print_timings:        eval time =      96.78 ms /     1 runs   (   96.78 ms per token,    10.33 tokens per second)\n",
      "llama_print_timings:       total time =     354.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Luella Macejkovic\", \"Dr. Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.19 ms /    23 runs   (    0.49 ms per token,  2055.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.91 ms /   158 tokens (    7.44 ms per token,   134.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1777.36 ms /    22 runs   (   80.79 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    3150.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 702 291 2427\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.63 ms /    19 runs   (    0.45 ms per token,  2201.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.26 ms /    25 tokens (   10.21 ms per token,    97.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1466.47 ms /    18 runs   (   81.47 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1857.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.24 ms /     9 runs   (    0.36 ms per token,  2778.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.59 ms /    23 tokens (   11.07 ms per token,    90.34 tokens per second)\n",
      "llama_print_timings:        eval time =     671.60 ms /     8 runs   (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     983.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.12 ms per token,  8064.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.63 ms /    24 tokens (   10.61 ms per token,    94.25 tokens per second)\n",
      "llama_print_timings:        eval time =      92.17 ms /     1 runs   (   92.17 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     352.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Sierra Abbott\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     9 runs   (    0.36 ms per token,  2785.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.17 ms /   139 tokens (    8.36 ms per token,   119.60 tokens per second)\n",
      "llama_print_timings:        eval time =     651.88 ms /     8 runs   (   81.48 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1866.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"387 608 6335\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.08 ms /    15 runs   (    0.47 ms per token,  2118.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.73 ms /    25 tokens (   10.19 ms per token,    98.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1138.94 ms /    14 runs   (   81.35 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    1497.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     7 runs   (    0.32 ms per token,  3174.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.90 ms /    23 tokens (   10.95 ms per token,    91.30 tokens per second)\n",
      "llama_print_timings:        eval time =     515.81 ms /     6 runs   (   85.97 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     799.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.26 ms /    24 tokens (   10.55 ms per token,    94.76 tokens per second)\n",
      "llama_print_timings:        eval time =      93.91 ms /     1 runs   (   93.91 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =     352.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mark Bruen\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    17 runs   (    0.46 ms per token,  2185.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.66 ms /   185 tokens (    7.65 ms per token,   130.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1288.97 ms /    16 runs   (   80.56 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2831.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"283 119 6672\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.01 ms /    15 runs   (    0.47 ms per token,  2141.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.82 ms /    25 tokens (   10.27 ms per token,    97.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.25 ms /    14 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1512.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.24 ms /     6 runs   (    0.21 ms per token,  4823.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.56 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     429.03 ms /     5 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     706.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    24 tokens (   10.62 ms per token,    94.15 tokens per second)\n",
      "llama_print_timings:        eval time =      93.87 ms /     1 runs   (   93.87 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =     353.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Duncan Walter\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     7 runs   (    0.25 ms per token,  4018.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.71 ms /   165 tokens (    8.47 ms per token,   118.05 tokens per second)\n",
      "llama_print_timings:        eval time =     482.17 ms /     6 runs   (   80.36 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1913.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 197 8207\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    15 runs   (    0.52 ms per token,  1941.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.61 ms /    25 tokens (   10.18 ms per token,    98.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.67 ms /    14 runs   (   81.98 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1513.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.07 ms /    23 tokens (   11.09 ms per token,    90.17 tokens per second)\n",
      "llama_print_timings:        eval time =      97.00 ms /     1 runs   (   97.00 ms per token,    10.31 tokens per second)\n",
      "llama_print_timings:       total time =     356.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.34 ms /    12 runs   (    0.28 ms per token,  3592.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.97 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =     901.18 ms /    11 runs   (   81.93 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1216.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Donnetta Bednar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /    11 runs   (    0.32 ms per token,  3095.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.68 ms /   168 tokens (    8.31 ms per token,   120.29 tokens per second)\n",
      "llama_print_timings:        eval time =     807.02 ms /    10 runs   (   80.70 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2268.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"100 147 2186\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.46 ms /    15 runs   (    0.56 ms per token,  1772.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.90 ms /    25 tokens (   10.20 ms per token,    98.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.88 ms /    14 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1520.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2667.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.65 ms /    23 tokens (   11.07 ms per token,    90.32 tokens per second)\n",
      "llama_print_timings:        eval time =     664.50 ms /     8 runs   (   83.06 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =     981.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /    12 runs   (    0.41 ms per token,  2425.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.81 ms /    24 tokens (   10.62 ms per token,    94.19 tokens per second)\n",
      "llama_print_timings:        eval time =     908.75 ms /    11 runs   (   82.61 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1247.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sherman Zieme\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     8 runs   (    0.33 ms per token,  3066.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.07 ms /   165 tokens (    8.47 ms per token,   118.10 tokens per second)\n",
      "llama_print_timings:        eval time =     580.38 ms /     7 runs   (   82.91 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    2024.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 265 0462\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    15 runs   (    0.51 ms per token,  1943.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.95 ms /    25 tokens (   10.20 ms per token,    98.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.59 ms /    14 runs   (   82.61 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1522.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.88 ms /    23 tokens (   10.99 ms per token,    90.95 tokens per second)\n",
      "llama_print_timings:        eval time =      98.37 ms /     1 runs   (   98.37 ms per token,    10.17 tokens per second)\n",
      "llama_print_timings:       total time =     356.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.12 ms /     8 runs   (    0.26 ms per token,  3778.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    24 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =     578.64 ms /     7 runs   (   82.66 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     871.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leo Howe\", \"Dr. Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    16 runs   (    0.54 ms per token,  1858.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1408.28 ms /   181 tokens (    7.78 ms per token,   128.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.04 ms /    15 runs   (   80.40 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    2737.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"480 157 8476\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    15 runs   (    0.50 ms per token,  1997.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.76 ms /    25 tokens (   10.23 ms per token,    97.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.72 ms /    14 runs   (   81.84 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1518.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2579.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    23 tokens (   11.04 ms per token,    90.60 tokens per second)\n",
      "llama_print_timings:        eval time =     667.75 ms /     8 runs   (   83.47 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     977.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /    11 runs   (    0.38 ms per token,  2616.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    24 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =     829.38 ms /    10 runs   (   82.94 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1156.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Goldie Rodriguez\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    11 runs   (    0.52 ms per token,  1915.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.70 ms /   152 tokens (    7.72 ms per token,   129.50 tokens per second)\n",
      "llama_print_timings:        eval time =     822.62 ms /    10 runs   (   82.26 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    2068.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"430 102 4668\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    15 runs   (    0.54 ms per token,  1840.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.55 ms /    25 tokens (   10.22 ms per token,    97.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.42 ms /    14 runs   (   82.03 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1518.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     9 runs   (    0.27 ms per token,  3714.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.65 ms /    23 tokens (   11.07 ms per token,    90.32 tokens per second)\n",
      "llama_print_timings:        eval time =     661.87 ms /     8 runs   (   82.73 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =     952.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /    11 runs   (    0.41 ms per token,  2418.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.72 ms /    24 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =     825.75 ms /    10 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1159.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Garrett Zieme\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    18 runs   (    0.49 ms per token,  2024.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.50 ms /   173 tokens (    8.08 ms per token,   123.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1364.51 ms /    17 runs   (   80.27 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    2910.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"320 152 2328\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    15 runs   (    0.52 ms per token,  1907.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.42 ms /    25 tokens (   10.26 ms per token,    97.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.45 ms /    14 runs   (   82.10 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1530.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     7 runs   (    0.17 ms per token,  5833.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.41 ms /    23 tokens (   11.02 ms per token,    90.76 tokens per second)\n",
      "llama_print_timings:        eval time =     506.48 ms /     6 runs   (   84.41 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     789.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8264.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.55 ms /    24 tokens (   10.61 ms per token,    94.29 tokens per second)\n",
      "llama_print_timings:        eval time =      95.47 ms /     1 runs   (   95.47 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     355.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raleigh O'Kon\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.57 ms /    20 runs   (    0.53 ms per token,  1892.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1412.28 ms /   179 tokens (    7.89 ms per token,   126.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1529.87 ms /    19 runs   (   80.52 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    3111.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 933 0957\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    15 runs   (    0.54 ms per token,  1853.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.78 ms /    25 tokens (   10.27 ms per token,    97.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.86 ms /    14 runs   (   82.20 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1527.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     9 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.93 ms /    23 tokens (   11.08 ms per token,    90.22 tokens per second)\n",
      "llama_print_timings:        eval time =     669.19 ms /     8 runs   (   83.65 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =     960.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.96 ms /    24 tokens (   10.58 ms per token,    94.50 tokens per second)\n",
      "llama_print_timings:        eval time =      95.12 ms /     1 runs   (   95.12 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =     355.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Blake Schumm\", \"Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    17 runs   (    0.43 ms per token,  2333.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.49 ms /   191 tokens (    7.44 ms per token,   134.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1285.04 ms /    16 runs   (   80.32 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2833.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"325 983 8078\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    15 runs   (    0.54 ms per token,  1844.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.76 ms /    25 tokens (   10.27 ms per token,    97.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.11 ms /    14 runs   (   82.44 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1528.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3638.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.91 ms /    23 tokens (   11.08 ms per token,    90.23 tokens per second)\n",
      "llama_print_timings:        eval time =     506.92 ms /     6 runs   (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     798.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.71 ms /    24 tokens (   10.65 ms per token,    93.86 tokens per second)\n",
      "llama_print_timings:        eval time =      98.46 ms /     1 runs   (   98.46 ms per token,    10.16 tokens per second)\n",
      "llama_print_timings:       total time =     360.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Warner Spencer\", \"Doctor Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.69 ms /    16 runs   (    0.48 ms per token,  2080.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.98 ms /   183 tokens (    7.77 ms per token,   128.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.48 ms /    15 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2759.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"645 349 5160\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.02 ms /    15 runs   (    0.60 ms per token,  1663.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.09 ms /    25 tokens (   10.24 ms per token,    97.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.60 ms /    14 runs   (   82.19 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1525.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"72 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     8 runs   (    0.27 ms per token,  3696.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.37 ms /    23 tokens (   11.10 ms per token,    90.07 tokens per second)\n",
      "llama_print_timings:        eval time =     587.65 ms /     7 runs   (   83.95 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     876.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  7017.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.78 ms /    24 tokens (   10.66 ms per token,    93.83 tokens per second)\n",
      "llama_print_timings:        eval time =      93.19 ms /     1 runs   (   93.19 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =     354.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr Craig Beahan\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.20 ms /    16 runs   (    0.51 ms per token,  1950.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.84 ms /   144 tokens (    8.10 ms per token,   123.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.41 ms /    15 runs   (   80.96 ms per token,    12.35 tokens per second)\n",
      "llama_print_timings:       total time =    2520.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"398 412 8146\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.46 ms /    15 runs   (    0.50 ms per token,  2010.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.43 ms /    25 tokens (   10.18 ms per token,    98.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1154.96 ms /    14 runs   (   82.50 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1530.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     5 runs   (    0.13 ms per token,  7800.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.57 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     346.75 ms /     4 runs   (   86.69 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     612.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.24 ms /     8 runs   (    0.28 ms per token,  3565.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.39 ms /    24 tokens (   10.56 ms per token,    94.71 tokens per second)\n",
      "llama_print_timings:        eval time =     591.50 ms /     7 runs   (   84.50 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     888.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Beverly Heller\", \"Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.35 ms /    17 runs   (    0.55 ms per token,  1818.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1955.47 ms /   248 tokens (    7.88 ms per token,   126.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1303.35 ms /    16 runs   (   81.46 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    3406.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"478 716 3610\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2042.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.70 ms /    25 tokens (   10.27 ms per token,    97.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1166.61 ms /    14 runs   (   83.33 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1540.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.22 ms /     7 runs   (    0.32 ms per token,  3153.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.53 ms /    23 tokens (   11.15 ms per token,    89.66 tokens per second)\n",
      "llama_print_timings:        eval time =     513.33 ms /     6 runs   (   85.56 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =     801.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.34 ms /     2 runs   (    0.17 ms per token,  5917.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.48 ms /    24 tokens (   10.73 ms per token,    93.21 tokens per second)\n",
      "llama_print_timings:        eval time =     102.70 ms /     1 runs   (  102.70 ms per token,     9.74 tokens per second)\n",
      "llama_print_timings:       total time =     365.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Darron Bernhard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /     9 runs   (    0.45 ms per token,  2223.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1180.01 ms /   159 tokens (    7.42 ms per token,   134.74 tokens per second)\n",
      "llama_print_timings:        eval time =     664.36 ms /     8 runs   (   83.04 ms per token,    12.04 tokens per second)\n",
      "llama_print_timings:       total time =    1904.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 197 3022\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    15 runs   (    0.43 ms per token,  2319.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.52 ms /    14 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1497.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.53 ms /     7 runs   (    0.36 ms per token,  2766.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.84 ms /    23 tokens (   10.99 ms per token,    90.97 tokens per second)\n",
      "llama_print_timings:        eval time =     511.31 ms /     6 runs   (   85.22 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     797.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    11 runs   (    0.37 ms per token,  2720.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.83 ms /    24 tokens (   10.53 ms per token,    94.93 tokens per second)\n",
      "llama_print_timings:        eval time =     828.01 ms /    10 runs   (   82.80 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1140.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gonzalo Hoeger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2276.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2163.27 ms /   263 tokens (    8.23 ms per token,   121.58 tokens per second)\n",
      "llama_print_timings:        eval time =     737.27 ms /     9 runs   (   81.92 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    2971.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"821 869 1508\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.21 ms /    15 runs   (    0.55 ms per token,  1827.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.05 ms /    25 tokens (   10.36 ms per token,    96.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1156.18 ms /    14 runs   (   82.58 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =    1537.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6896.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.31 ms /    23 tokens (   11.14 ms per token,    89.74 tokens per second)\n",
      "llama_print_timings:        eval time =     104.45 ms /     1 runs   (  104.45 ms per token,     9.57 tokens per second)\n",
      "llama_print_timings:       total time =     365.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"victim of intimate partner abuse\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.90 ms /    19 runs   (    0.47 ms per token,  2134.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.03 ms /    24 tokens (   10.83 ms per token,    92.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1492.36 ms /    18 runs   (   82.91 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1906.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stefania Blanda\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.82 ms /    10 runs   (    0.48 ms per token,  2073.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.87 ms /   160 tokens (    7.29 ms per token,   137.24 tokens per second)\n",
      "llama_print_timings:        eval time =     735.16 ms /     9 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1975.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"578 871 0609\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.70 ms /    15 runs   (    0.58 ms per token,  1723.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.13 ms /    25 tokens (   10.25 ms per token,    97.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.65 ms /    14 runs   (   82.05 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1526.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     8 runs   (    0.23 ms per token,  4310.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.51 ms /    23 tokens (   11.07 ms per token,    90.37 tokens per second)\n",
      "llama_print_timings:        eval time =     591.42 ms /     7 runs   (   84.49 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     873.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\", \"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    17 runs   (    0.39 ms per token,  2546.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.53 ms /    24 tokens (   10.61 ms per token,    94.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1300.85 ms /    16 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    1685.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Pablo Cruickshank\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2620.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1644.30 ms /   195 tokens (    8.43 ms per token,   118.59 tokens per second)\n",
      "llama_print_timings:        eval time =     652.00 ms /     8 runs   (   81.50 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2357.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 517 2946\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    15 runs   (    0.58 ms per token,  1732.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.73 ms /    25 tokens (   10.31 ms per token,    97.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1158.89 ms /    14 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    1541.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7812.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.42 ms /    23 tokens (   11.06 ms per token,    90.40 tokens per second)\n",
      "llama_print_timings:        eval time =      95.79 ms /     1 runs   (   95.79 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     355.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.49 ms /     8 runs   (    0.31 ms per token,  3215.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.86 ms /    24 tokens (   10.66 ms per token,    93.80 tokens per second)\n",
      "llama_print_timings:        eval time =     571.71 ms /     7 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     875.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Sherron Beier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /    12 runs   (    0.46 ms per token,  2188.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.72 ms /   143 tokens (    8.17 ms per token,   122.36 tokens per second)\n",
      "llama_print_timings:        eval time =     896.64 ms /    11 runs   (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    2157.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"484 444 7434\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    15 runs   (    0.49 ms per token,  2022.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.88 ms /    25 tokens (   10.16 ms per token,    98.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.87 ms /    14 runs   (   81.92 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1508.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     7 runs   (    0.29 ms per token,  3491.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.84 ms /    23 tokens (   11.04 ms per token,    90.61 tokens per second)\n",
      "llama_print_timings:        eval time =     505.19 ms /     6 runs   (   84.20 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     793.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7299.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.01 ms /    24 tokens (   10.58 ms per token,    94.48 tokens per second)\n",
      "llama_print_timings:        eval time =      95.01 ms /     1 runs   (   95.01 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =     354.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kristan Feil\", \"Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.52 ms /    16 runs   (    0.47 ms per token,  2129.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1420.55 ms /   191 tokens (    7.44 ms per token,   134.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.40 ms /    15 runs   (   80.56 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    2752.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"456 237 3945\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2127.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.92 ms /    25 tokens (   10.28 ms per token,    97.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.65 ms /    14 runs   (   82.69 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1528.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7547.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.50 ms /    23 tokens (   11.07 ms per token,    90.37 tokens per second)\n",
      "llama_print_timings:        eval time =      93.47 ms /     1 runs   (   93.47 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =     353.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9345.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.71 ms /    24 tokens (   10.61 ms per token,    94.23 tokens per second)\n",
      "llama_print_timings:        eval time =     104.99 ms /     1 runs   (  104.99 ms per token,     9.52 tokens per second)\n",
      "llama_print_timings:       total time =     363.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Santa Cartwright\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     8 runs   (    0.33 ms per token,  3001.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1395.80 ms /   162 tokens (    8.62 ms per token,   116.06 tokens per second)\n",
      "llama_print_timings:        eval time =     568.87 ms /     7 runs   (   81.27 ms per token,    12.31 tokens per second)\n",
      "llama_print_timings:       total time =    2011.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 597 0616\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.99 ms /    15 runs   (    0.60 ms per token,  1669.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    25 tokens (   10.25 ms per token,    97.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1157.06 ms /    14 runs   (   82.65 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1543.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.00 ms /    23 tokens (   11.04 ms per token,    90.55 tokens per second)\n",
      "llama_print_timings:        eval time =      96.14 ms /     1 runs   (   96.14 ms per token,    10.40 tokens per second)\n",
      "llama_print_timings:       total time =     356.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10152.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.33 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =     103.46 ms /     1 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     359.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jarred Kassulke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /    10 runs   (    0.38 ms per token,  2649.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.25 ms /   185 tokens (    7.66 ms per token,   130.53 tokens per second)\n",
      "llama_print_timings:        eval time =     727.74 ms /     9 runs   (   80.86 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2211.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 215 6274\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    15 runs   (    0.56 ms per token,  1788.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.68 ms /    25 tokens (   10.27 ms per token,    97.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1147.60 ms /    14 runs   (   81.97 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    1521.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /     8 runs   (    0.33 ms per token,  3056.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.16 ms /    23 tokens (   11.09 ms per token,    90.14 tokens per second)\n",
      "llama_print_timings:        eval time =     594.89 ms /     7 runs   (   84.98 ms per token,    11.77 tokens per second)\n",
      "llama_print_timings:       total time =     897.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.66 ms /    24 tokens (   10.61 ms per token,    94.25 tokens per second)\n",
      "llama_print_timings:        eval time =      96.49 ms /     1 runs   (   96.49 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     356.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Honey Tromp\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.49 ms /    17 runs   (    0.56 ms per token,  1791.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.41 ms /   141 tokens (    8.26 ms per token,   121.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1282.76 ms /    16 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2593.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"727 581 9998\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    15 runs   (    0.51 ms per token,  1946.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    25 tokens (   10.24 ms per token,    97.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1139.73 ms /    14 runs   (   81.41 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1515.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     7 runs   (    0.14 ms per token,  6923.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.57 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     506.87 ms /     6 runs   (   84.48 ms per token,    11.84 tokens per second)\n",
      "llama_print_timings:       total time =     782.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.34 ms /    24 tokens (   10.60 ms per token,    94.36 tokens per second)\n",
      "llama_print_timings:        eval time =      95.40 ms /     1 runs   (   95.40 ms per token,    10.48 tokens per second)\n",
      "llama_print_timings:       total time =     355.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Elias Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2354.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.88 ms /   173 tokens (    8.10 ms per token,   123.49 tokens per second)\n",
      "llama_print_timings:        eval time =     645.61 ms /     8 runs   (   80.70 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    2105.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"154 756 0487\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2107.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.63 ms /    25 tokens (   10.27 ms per token,    97.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.24 ms /    14 runs   (   81.80 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1515.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"25 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     7 runs   (    0.27 ms per token,  3661.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.03 ms /    23 tokens (   11.00 ms per token,    90.90 tokens per second)\n",
      "llama_print_timings:        eval time =     507.63 ms /     6 runs   (   84.60 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     791.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2678.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =     826.70 ms /    10 runs   (   82.67 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =    1144.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alden Russel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     8 runs   (    0.35 ms per token,  2844.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.18 ms /   168 tokens (    8.30 ms per token,   120.50 tokens per second)\n",
      "llama_print_timings:        eval time =     573.98 ms /     7 runs   (   82.00 ms per token,    12.20 tokens per second)\n",
      "llama_print_timings:       total time =    2015.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 792 6301\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.53 ms /    15 runs   (    0.44 ms per token,  2297.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    25 tokens (   10.20 ms per token,    98.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1155.43 ms /    14 runs   (   82.53 ms per token,    12.12 tokens per second)\n",
      "llama_print_timings:       total time =    1501.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     6 runs   (    0.21 ms per token,  4705.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.02 ms /    23 tokens (   11.04 ms per token,    90.55 tokens per second)\n",
      "llama_print_timings:        eval time =     429.73 ms /     5 runs   (   85.95 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     710.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8658.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.71 ms /    24 tokens (   10.61 ms per token,    94.23 tokens per second)\n",
      "llama_print_timings:        eval time =     100.24 ms /     1 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =     359.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jamal Tillman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.58 ms /     9 runs   (    0.51 ms per token,  1967.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.26 ms /   147 tokens (    7.96 ms per token,   125.61 tokens per second)\n",
      "llama_print_timings:        eval time =     659.29 ms /     8 runs   (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    1894.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"463 369 9493\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /    15 runs   (    0.41 ms per token,  2410.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.13 ms /    25 tokens (   10.21 ms per token,    97.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.82 ms /    14 runs   (   81.56 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    1491.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.13 ms /     5 runs   (    0.23 ms per token,  4428.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    23 tokens (   10.97 ms per token,    91.15 tokens per second)\n",
      "llama_print_timings:        eval time =     338.45 ms /     4 runs   (   84.61 ms per token,    11.82 tokens per second)\n",
      "llama_print_timings:       total time =     608.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9174.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    24 tokens (   10.68 ms per token,    93.62 tokens per second)\n",
      "llama_print_timings:        eval time =      96.36 ms /     1 runs   (   96.36 ms per token,    10.38 tokens per second)\n",
      "llama_print_timings:       total time =     356.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Wilson Schamberger\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    16 runs   (    0.51 ms per token,  1967.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.82 ms /   216 tokens (    7.74 ms per token,   129.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.14 ms /    15 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    3016.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"640 313 3332\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    15 runs   (    0.47 ms per token,  2133.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.15 ms /    25 tokens (   10.29 ms per token,    97.22 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.10 ms /    14 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1518.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.30 ms /     2 runs   (    0.15 ms per token,  6666.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    23 tokens (   11.03 ms per token,    90.69 tokens per second)\n",
      "llama_print_timings:        eval time =      95.50 ms /     1 runs   (   95.50 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     355.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4422.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    24 tokens (   10.75 ms per token,    93.05 tokens per second)\n",
      "llama_print_timings:        eval time =     585.09 ms /     7 runs   (   83.58 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     873.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Sammie Predovic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.90 ms /    11 runs   (    0.35 ms per token,  2821.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.41 ms /   138 tokens (    8.40 ms per token,   119.03 tokens per second)\n",
      "llama_print_timings:        eval time =     813.22 ms /    10 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2041.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"389 646 5779\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2069.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.11 ms /    25 tokens (   10.20 ms per token,    98.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.29 ms /    14 runs   (   81.74 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1509.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     7 runs   (    0.28 ms per token,  3510.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.20 ms /    23 tokens (   11.05 ms per token,    90.48 tokens per second)\n",
      "llama_print_timings:        eval time =     511.45 ms /     6 runs   (   85.24 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =     801.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.02 ms /     8 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.25 ms /    24 tokens (   10.59 ms per token,    94.40 tokens per second)\n",
      "llama_print_timings:        eval time =     585.35 ms /     7 runs   (   83.62 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     881.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Felton Littel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /     9 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1155.29 ms /   130 tokens (    8.89 ms per token,   112.53 tokens per second)\n",
      "llama_print_timings:        eval time =     664.82 ms /     8 runs   (   83.10 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =    1881.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 124 0156\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    15 runs   (    0.45 ms per token,  2208.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.80 ms /    25 tokens (   10.15 ms per token,    98.50 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.34 ms /    14 runs   (   81.17 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1485.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /     9 runs   (    0.47 ms per token,  2112.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.43 ms /    23 tokens (   10.93 ms per token,    91.48 tokens per second)\n",
      "llama_print_timings:        eval time =     671.45 ms /     8 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =     979.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     8 runs   (    0.28 ms per token,  3541.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.91 ms /    24 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =     581.95 ms /     7 runs   (   83.14 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     870.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Tracey Moore\", \"Jude Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.26 ms /    16 runs   (    0.45 ms per token,  2204.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.85 ms /   177 tokens (    7.94 ms per token,   125.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.59 ms /    15 runs   (   80.84 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2742.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"248 417 8598\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.48 ms /    15 runs   (    0.50 ms per token,  2005.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.79 ms /    25 tokens (   10.27 ms per token,    97.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.56 ms /    14 runs   (   82.11 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =    1521.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /     9 runs   (    0.28 ms per token,  3634.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.26 ms /    23 tokens (   10.97 ms per token,    91.18 tokens per second)\n",
      "llama_print_timings:        eval time =     666.47 ms /     8 runs   (   83.31 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     962.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary complaint\", \"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    16 runs   (    0.37 ms per token,  2678.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.04 ms /    24 tokens (   10.54 ms per token,    94.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1235.51 ms /    15 runs   (   82.37 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1592.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jasper Murazik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /    10 runs   (    0.32 ms per token,  3105.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1165.58 ms /   141 tokens (    8.27 ms per token,   120.97 tokens per second)\n",
      "llama_print_timings:        eval time =     735.09 ms /     9 runs   (   81.68 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1952.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"517 601 1858\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.78 ms /    15 runs   (    0.45 ms per token,  2214.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.31 ms /    25 tokens (   10.21 ms per token,    97.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.36 ms /    14 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1497.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.37 ms /     2 runs   (    0.18 ms per token,  5434.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.20 ms /    23 tokens (   11.05 ms per token,    90.48 tokens per second)\n",
      "llama_print_timings:        eval time =      95.77 ms /     1 runs   (   95.77 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =     355.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /    11 runs   (    0.37 ms per token,  2677.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.89 ms /    24 tokens (   10.58 ms per token,    94.53 tokens per second)\n",
      "llama_print_timings:        eval time =     822.94 ms /    10 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1154.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marcelino Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     9 runs   (    0.30 ms per token,  3290.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.16 ms /   179 tokens (    7.88 ms per token,   126.85 tokens per second)\n",
      "llama_print_timings:        eval time =     652.64 ms /     8 runs   (   81.58 ms per token,    12.26 tokens per second)\n",
      "llama_print_timings:       total time =    2112.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 294 1485\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    15 runs   (    0.52 ms per token,  1933.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.22 ms /    25 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.56 ms /    14 runs   (   82.25 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1509.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.05 ms /     9 runs   (    0.23 ms per token,  4388.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.44 ms /    23 tokens (   11.02 ms per token,    90.75 tokens per second)\n",
      "llama_print_timings:        eval time =     667.46 ms /     8 runs   (   83.43 ms per token,    11.99 tokens per second)\n",
      "llama_print_timings:       total time =     960.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.58 ms /     8 runs   (    0.20 ms per token,  5063.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.13 ms /    24 tokens (   10.59 ms per token,    94.44 tokens per second)\n",
      "llama_print_timings:        eval time =     582.80 ms /     7 runs   (   83.26 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =     865.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Otto Murphy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     8 runs   (    0.40 ms per token,  2479.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1643.62 ms /   194 tokens (    8.47 ms per token,   118.03 tokens per second)\n",
      "llama_print_timings:        eval time =     569.08 ms /     7 runs   (   81.30 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =    2255.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"248 616 6772\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    15 runs   (    0.51 ms per token,  1970.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.65 ms /    25 tokens (   10.27 ms per token,    97.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1152.30 ms /    14 runs   (   82.31 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    1524.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     9 runs   (    0.38 ms per token,  2626.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.30 ms /    23 tokens (   10.97 ms per token,    91.16 tokens per second)\n",
      "llama_print_timings:        eval time =     668.91 ms /     8 runs   (   83.61 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =     974.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.80 ms /     7 runs   (    0.26 ms per token,  3882.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    24 tokens (   10.66 ms per token,    93.85 tokens per second)\n",
      "llama_print_timings:        eval time =     512.73 ms /     6 runs   (   85.46 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     798.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Walter Rolfson\", \"Dr. Reggie Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    16 runs   (    0.47 ms per token,  2131.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1398.29 ms /   171 tokens (    8.18 ms per token,   122.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.71 ms /    15 runs   (   80.85 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2749.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 495 5864\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.33 ms /    15 runs   (    0.56 ms per token,  1800.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.60 ms /    25 tokens (   10.26 ms per token,    97.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.87 ms /    14 runs   (   81.85 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1513.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.32 ms /     2 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.61 ms /    23 tokens (   11.07 ms per token,    90.33 tokens per second)\n",
      "llama_print_timings:        eval time =     101.98 ms /     1 runs   (  101.98 ms per token,     9.81 tokens per second)\n",
      "llama_print_timings:       total time =     363.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     7 runs   (    0.27 ms per token,  3711.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.03 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     502.72 ms /     6 runs   (   83.79 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     793.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Karl Watsica\", \"Dr. Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    16 runs   (    0.42 ms per token,  2382.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1400.52 ms /   174 tokens (    8.05 ms per token,   124.24 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.33 ms /    15 runs   (   81.02 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2735.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 205 0877\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    15 runs   (    0.54 ms per token,  1850.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.73 ms /    25 tokens (   10.23 ms per token,    97.76 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.54 ms /    14 runs   (   82.18 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1525.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.39 ms /     9 runs   (    0.38 ms per token,  2652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.24 ms /    23 tokens (   11.01 ms per token,    90.82 tokens per second)\n",
      "llama_print_timings:        eval time =     678.49 ms /     8 runs   (   84.81 ms per token,    11.79 tokens per second)\n",
      "llama_print_timings:       total time =    1005.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7575.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.59 ms /    24 tokens (   10.61 ms per token,    94.27 tokens per second)\n",
      "llama_print_timings:        eval time =      95.02 ms /     1 runs   (   95.02 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =     354.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ila Kovacek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     9 runs   (    0.40 ms per token,  2486.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3141.58 ms /   393 tokens (    7.99 ms per token,   125.10 tokens per second)\n",
      "llama_print_timings:        eval time =     669.53 ms /     8 runs   (   83.69 ms per token,    11.95 tokens per second)\n",
      "llama_print_timings:       total time =    3869.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 274 269 1901\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    19 runs   (    0.58 ms per token,  1728.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.79 ms /    25 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1515.40 ms /    18 runs   (   84.19 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =    1930.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /     9 runs   (    0.34 ms per token,  2923.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.51 ms /    23 tokens (   11.24 ms per token,    88.97 tokens per second)\n",
      "llama_print_timings:        eval time =     689.37 ms /     8 runs   (   86.17 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    1007.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     8 runs   (    0.34 ms per token,  2932.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.80 ms /    24 tokens (   10.78 ms per token,    92.73 tokens per second)\n",
      "llama_print_timings:        eval time =     606.96 ms /     7 runs   (   86.71 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     916.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Isis Kilback\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.07 ms /     7 runs   (    0.30 ms per token,  3378.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1394.88 ms /   165 tokens (    8.45 ms per token,   118.29 tokens per second)\n",
      "llama_print_timings:        eval time =     497.28 ms /     6 runs   (   82.88 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    1927.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 856 9431\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.11 ms /    15 runs   (    0.54 ms per token,  1849.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.20 ms /    25 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.54 ms /    14 runs   (   82.04 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1523.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5730.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.27 ms /    23 tokens (   11.06 ms per token,    90.46 tokens per second)\n",
      "llama_print_timings:        eval time =      91.72 ms /     1 runs   (   91.72 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =     351.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.13 ms per token,  7434.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.54 ms /    24 tokens (   10.61 ms per token,    94.29 tokens per second)\n",
      "llama_print_timings:        eval time =     108.39 ms /     1 runs   (  108.39 ms per token,     9.23 tokens per second)\n",
      "llama_print_timings:       total time =     371.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Danny Leffler\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.84 ms /    16 runs   (    0.43 ms per token,  2340.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1938.89 ms /   251 tokens (    7.72 ms per token,   129.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.62 ms /    15 runs   (   83.64 ms per token,    11.96 tokens per second)\n",
      "llama_print_timings:       total time =    3318.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"604 662 0721\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    15 runs   (    0.54 ms per token,  1865.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.20 ms /    25 tokens (   10.33 ms per token,    96.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.53 ms /    14 runs   (   83.75 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =    1553.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /     9 runs   (    0.43 ms per token,  2313.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.03 ms /    23 tokens (   11.09 ms per token,    90.18 tokens per second)\n",
      "llama_print_timings:        eval time =     676.34 ms /     8 runs   (   84.54 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     992.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /    11 runs   (    0.38 ms per token,  2657.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    24 tokens (   10.68 ms per token,    93.66 tokens per second)\n",
      "llama_print_timings:        eval time =     840.12 ms /    10 runs   (   84.01 ms per token,    11.90 tokens per second)\n",
      "llama_print_timings:       total time =    1170.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Deon Halvorson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.23 ms /     9 runs   (    0.47 ms per token,  2125.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1392.88 ms /   161 tokens (    8.65 ms per token,   115.59 tokens per second)\n",
      "llama_print_timings:        eval time =     662.01 ms /     8 runs   (   82.75 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =    2130.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 955 5542\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    15 runs   (    0.52 ms per token,  1914.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.17 ms /    25 tokens (   10.25 ms per token,    97.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.16 ms /    14 runs   (   81.80 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1508.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     8 runs   (    0.44 ms per token,  2274.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.35 ms /    23 tokens (   11.06 ms per token,    90.43 tokens per second)\n",
      "llama_print_timings:        eval time =     590.16 ms /     7 runs   (   84.31 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     892.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5698.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.78 ms /    24 tokens (   10.62 ms per token,    94.20 tokens per second)\n",
      "llama_print_timings:        eval time =      95.10 ms /     1 runs   (   95.10 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =     355.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Gregory Mosciski\", \"Dr Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.16 ms /    16 runs   (    0.57 ms per token,  1745.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.06 ms /   158 tokens (    7.44 ms per token,   134.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.69 ms /    15 runs   (   80.91 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2528.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 259 9368\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.61 ms /    15 runs   (    0.51 ms per token,  1971.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.38 ms /    25 tokens (   10.21 ms per token,    97.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.79 ms /    14 runs   (   81.49 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1502.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     8 runs   (    0.17 ms per token,  5956.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.57 ms /    23 tokens (   11.07 ms per token,    90.35 tokens per second)\n",
      "llama_print_timings:        eval time =     586.33 ms /     7 runs   (   83.76 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     863.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     9 runs   (    0.25 ms per token,  4070.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.41 ms /    24 tokens (   10.60 ms per token,    94.34 tokens per second)\n",
      "llama_print_timings:        eval time =     680.49 ms /     8 runs   (   85.06 ms per token,    11.76 tokens per second)\n",
      "llama_print_timings:       total time =     981.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Karey Mayer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    11 runs   (    0.50 ms per token,  1997.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.71 ms /   160 tokens (    7.27 ms per token,   137.49 tokens per second)\n",
      "llama_print_timings:        eval time =     824.17 ms /    10 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2072.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"103 854 3520\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2068.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.68 ms /    25 tokens (   10.19 ms per token,    98.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.94 ms /    14 runs   (   82.21 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1508.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     9 runs   (    0.36 ms per token,  2739.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.74 ms /    23 tokens (   11.03 ms per token,    90.64 tokens per second)\n",
      "llama_print_timings:        eval time =     667.92 ms /     8 runs   (   83.49 ms per token,    11.98 tokens per second)\n",
      "llama_print_timings:       total time =     974.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.72 ms /    24 tokens (   10.61 ms per token,    94.22 tokens per second)\n",
      "llama_print_timings:        eval time =      94.74 ms /     1 runs   (   94.74 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     354.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Gus Ortiz\", \"Dr. Jerrell Rippin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.26 ms /    18 runs   (    0.63 ms per token,  1598.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.36 ms /   150 tokens (    7.82 ms per token,   127.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1375.35 ms /    17 runs   (   80.90 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    2703.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"134 509 4964\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.14 ms /    15 runs   (    0.48 ms per token,  2100.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    25 tokens (   10.25 ms per token,    97.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1145.98 ms /    14 runs   (   81.86 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1510.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.29 ms /    23 tokens (   11.01 ms per token,    90.80 tokens per second)\n",
      "llama_print_timings:        eval time =      94.85 ms /     1 runs   (   94.85 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =     354.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.71 ms /    24 tokens (   10.61 ms per token,    94.23 tokens per second)\n",
      "llama_print_timings:        eval time =      99.31 ms /     1 runs   (   99.31 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =     357.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Florentino Marks\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.88 ms /    10 runs   (    0.49 ms per token,  2050.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.99 ms /   150 tokens (    7.81 ms per token,   128.10 tokens per second)\n",
      "llama_print_timings:        eval time =     736.48 ms /     9 runs   (   81.83 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1980.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"263 208 2931\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.40 ms /    15 runs   (    0.56 ms per token,  1785.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.71 ms /    25 tokens (   10.23 ms per token,    97.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1148.19 ms /    14 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1527.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     9 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.45 ms /    23 tokens (   11.06 ms per token,    90.39 tokens per second)\n",
      "llama_print_timings:        eval time =     669.76 ms /     8 runs   (   83.72 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     972.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    11 runs   (    0.30 ms per token,  3318.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.62 ms /    24 tokens (   10.53 ms per token,    95.01 tokens per second)\n",
      "llama_print_timings:        eval time =     828.45 ms /    10 runs   (   82.84 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    1137.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Ouida MacGyver\", \"Dr.\", \"Leoma Jaskolski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      13.74 ms /    25 runs   (    0.55 ms per token,  1819.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.55 ms /   155 tokens (    7.58 ms per token,   131.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1941.29 ms /    24 runs   (   80.89 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    3337.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"725 599 3190\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    15 runs   (    0.45 ms per token,  2235.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.21 ms /    25 tokens (   10.21 ms per token,    97.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1149.90 ms /    14 runs   (   82.14 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1504.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.11 ms /     7 runs   (    0.16 ms per token,  6306.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    23 tokens (   11.04 ms per token,    90.61 tokens per second)\n",
      "llama_print_timings:        eval time =     507.97 ms /     6 runs   (   84.66 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     783.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.18 ms /     8 runs   (    0.27 ms per token,  3676.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.76 ms /    24 tokens (   10.62 ms per token,    94.21 tokens per second)\n",
      "llama_print_timings:        eval time =     590.28 ms /     7 runs   (   84.33 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     877.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Glory Strosin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.81 ms /     9 runs   (    0.42 ms per token,  2359.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.99 ms /   130 tokens (    8.88 ms per token,   112.55 tokens per second)\n",
      "llama_print_timings:        eval time =     661.72 ms /     8 runs   (   82.72 ms per token,    12.09 tokens per second)\n",
      "llama_print_timings:       total time =    1877.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 189 6610\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    15 runs   (    0.49 ms per token,  2051.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.68 ms /    25 tokens (   10.23 ms per token,    97.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1141.14 ms /    14 runs   (   81.51 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1509.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     7 runs   (    0.27 ms per token,  3709.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.18 ms /    23 tokens (   11.05 ms per token,    90.49 tokens per second)\n",
      "llama_print_timings:        eval time =     506.22 ms /     6 runs   (   84.37 ms per token,    11.85 tokens per second)\n",
      "llama_print_timings:       total time =     804.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     8 runs   (    0.44 ms per token,  2281.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.85 ms /    24 tokens (   10.58 ms per token,    94.54 tokens per second)\n",
      "llama_print_timings:        eval time =     590.33 ms /     7 runs   (   84.33 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     892.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Isaias Greenholt\", \"Dr. Chun Armstrong\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    19 runs   (    0.56 ms per token,  1796.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.92 ms /   149 tokens (    7.85 ms per token,   127.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1465.06 ms /    18 runs   (   81.39 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    2795.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"544 265 3814\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.86 ms /    15 runs   (    0.46 ms per token,  2185.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    25 tokens (   10.21 ms per token,    97.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.03 ms /    14 runs   (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1501.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7968.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.37 ms /    23 tokens (   11.06 ms per token,    90.42 tokens per second)\n",
      "llama_print_timings:        eval time =      95.64 ms /     1 runs   (   95.64 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =     355.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bacterial sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /    11 runs   (    0.44 ms per token,  2263.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.31 ms /    24 tokens (   10.60 ms per token,    94.37 tokens per second)\n",
      "llama_print_timings:        eval time =     818.22 ms /    10 runs   (   81.82 ms per token,    12.22 tokens per second)\n",
      "llama_print_timings:       total time =    1150.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rhett Connelly\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.75 ms /    10 runs   (    0.37 ms per token,  2670.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1173.18 ms /   152 tokens (    7.72 ms per token,   129.56 tokens per second)\n",
      "llama_print_timings:        eval time =     738.11 ms /     9 runs   (   82.01 ms per token,    12.19 tokens per second)\n",
      "llama_print_timings:       total time =    1969.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"296 678 0774\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.79 ms /    15 runs   (    0.45 ms per token,  2208.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.22 ms /    25 tokens (   10.25 ms per token,    97.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.54 ms /    14 runs   (   81.75 ms per token,    12.23 tokens per second)\n",
      "llama_print_timings:       total time =    1503.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"age\", \"35\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /     8 runs   (    0.19 ms per token,  5312.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.81 ms /    23 tokens (   11.04 ms per token,    90.62 tokens per second)\n",
      "llama_print_timings:        eval time =     583.37 ms /     7 runs   (   83.34 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     864.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    11 runs   (    0.36 ms per token,  2811.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.70 ms /    24 tokens (   10.61 ms per token,    94.23 tokens per second)\n",
      "llama_print_timings:        eval time =     833.49 ms /    10 runs   (   83.35 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =    1155.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Victoria Auer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     9 runs   (    0.45 ms per token,  2236.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.04 ms /   171 tokens (    8.16 ms per token,   122.49 tokens per second)\n",
      "llama_print_timings:        eval time =     659.34 ms /     8 runs   (   82.42 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =    2122.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"788 868 5797\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.18 ms /    15 runs   (    0.55 ms per token,  1833.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.45 ms /    25 tokens (   10.22 ms per token,    97.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.95 ms /    14 runs   (   81.71 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1517.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     9 runs   (    0.31 ms per token,  3182.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.06 ms /    23 tokens (   11.05 ms per token,    90.53 tokens per second)\n",
      "llama_print_timings:        eval time =     673.38 ms /     8 runs   (   84.17 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     974.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     8 runs   (    0.34 ms per token,  2926.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.69 ms /    24 tokens (   10.57 ms per token,    94.61 tokens per second)\n",
      "llama_print_timings:        eval time =     582.59 ms /     7 runs   (   83.23 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     874.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Drucilla Fisher\", \"Doctor Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    19 runs   (    0.52 ms per token,  1940.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1640.38 ms /   202 tokens (    8.12 ms per token,   123.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1448.37 ms /    18 runs   (   80.47 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    3255.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"657 589 9565\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.80 ms /    15 runs   (    0.45 ms per token,  2205.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.28 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.49 ms /    14 runs   (   82.39 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1516.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"29 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.25 ms /     7 runs   (    0.18 ms per token,  5595.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.94 ms /    23 tokens (   11.08 ms per token,    90.22 tokens per second)\n",
      "llama_print_timings:        eval time =     512.84 ms /     6 runs   (   85.47 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     792.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.91 ms /    24 tokens (   10.58 ms per token,    94.52 tokens per second)\n",
      "llama_print_timings:        eval time =      95.09 ms /     1 runs   (   95.09 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =     354.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dorathy Lockman\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    17 runs   (    0.45 ms per token,  2208.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1417.15 ms /   184 tokens (    7.70 ms per token,   129.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1296.50 ms /    16 runs   (   81.03 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2845.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 377 8159\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    15 runs   (    0.61 ms per token,  1627.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.73 ms /    25 tokens (   10.27 ms per token,    97.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1153.00 ms /    14 runs   (   82.36 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =    1528.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /     8 runs   (    0.23 ms per token,  4422.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.09 ms /    23 tokens (   11.00 ms per token,    90.88 tokens per second)\n",
      "llama_print_timings:        eval time =     587.21 ms /     7 runs   (   83.89 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     872.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     8 runs   (    0.25 ms per token,  4014.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.06 ms /    24 tokens (   10.63 ms per token,    94.09 tokens per second)\n",
      "llama_print_timings:        eval time =     589.09 ms /     7 runs   (   84.16 ms per token,    11.88 tokens per second)\n",
      "llama_print_timings:       total time =     878.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosanna Lowe\", \"Doctor Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    18 runs   (    0.45 ms per token,  2203.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1892.40 ms /   234 tokens (    8.09 ms per token,   123.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1385.79 ms /    17 runs   (   81.52 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    3414.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"328 518 0410\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.64 ms /    15 runs   (    0.51 ms per token,  1963.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.72 ms /    25 tokens (   10.27 ms per token,    97.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1160.32 ms /    14 runs   (   82.88 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =    1534.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"68-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     9 runs   (    0.31 ms per token,  3260.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.19 ms /    23 tokens (   11.10 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =     670.50 ms /     8 runs   (   83.81 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     964.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.51 ms /    13 runs   (    0.50 ms per token,  1996.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.23 ms /    24 tokens (   10.63 ms per token,    94.03 tokens per second)\n",
      "llama_print_timings:        eval time =     998.78 ms /    12 runs   (   83.23 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1344.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Adalberto Abbott\", \"Dr. Iva O'Keefe\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      11.81 ms /    20 runs   (    0.59 ms per token,  1693.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.82 ms /   152 tokens (    7.75 ms per token,   129.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1536.44 ms /    19 runs   (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    2880.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"808 589 2563\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.36 ms /    15 runs   (    0.42 ms per token,  2359.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.90 ms /    25 tokens (   10.24 ms per token,    97.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1146.30 ms /    14 runs   (   81.88 ms per token,    12.21 tokens per second)\n",
      "llama_print_timings:       total time =    1499.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.25 ms /     9 runs   (    0.25 ms per token,  4003.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.38 ms /    23 tokens (   11.06 ms per token,    90.41 tokens per second)\n",
      "llama_print_timings:        eval time =     673.93 ms /     8 runs   (   84.24 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     968.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5665.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.62 ms /    24 tokens (   10.57 ms per token,    94.63 tokens per second)\n",
      "llama_print_timings:        eval time =      93.67 ms /     1 runs   (   93.67 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =     353.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Georgianna Jacobi\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /     9 runs   (    0.43 ms per token,  2300.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2475.28 ms /   309 tokens (    8.01 ms per token,   124.83 tokens per second)\n",
      "llama_print_timings:        eval time =     663.72 ms /     8 runs   (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    3198.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 356 1119\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.97 ms /    15 runs   (    0.60 ms per token,  1671.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.14 ms /    25 tokens (   10.37 ms per token,    96.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1175.03 ms /    14 runs   (   83.93 ms per token,    11.91 tokens per second)\n",
      "llama_print_timings:       total time =    1556.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.85 ms /    23 tokens (   11.17 ms per token,    89.55 tokens per second)\n",
      "llama_print_timings:        eval time =      94.59 ms /     1 runs   (   94.59 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     356.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.26 ms /    24 tokens (   10.76 ms per token,    92.93 tokens per second)\n",
      "llama_print_timings:        eval time =      99.37 ms /     1 runs   (   99.37 ms per token,    10.06 tokens per second)\n",
      "llama_print_timings:       total time =     363.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Amos Stamm\", \"Dr. Marth Mayer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.01 ms /    17 runs   (    0.47 ms per token,  2122.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1390.22 ms /   162 tokens (    8.58 ms per token,   116.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1287.27 ms /    16 runs   (   80.45 ms per token,    12.43 tokens per second)\n",
      "llama_print_timings:       total time =    2817.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"579 966 1982\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    15 runs   (    0.52 ms per token,  1933.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.06 ms /    25 tokens (   10.28 ms per token,    97.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.28 ms /    14 runs   (   82.23 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1526.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     7 runs   (    0.20 ms per token,  5102.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.75 ms /    23 tokens (   11.08 ms per token,    90.29 tokens per second)\n",
      "llama_print_timings:        eval time =     505.65 ms /     6 runs   (   84.28 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =     791.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /     8 runs   (    0.28 ms per token,  3539.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.45 ms /    24 tokens (   10.48 ms per token,    95.45 tokens per second)\n",
      "llama_print_timings:        eval time =     586.13 ms /     7 runs   (   83.73 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     871.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Noella Tillman MD\", \"full-time\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    16 runs   (    0.41 ms per token,  2429.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.90 ms /   142 tokens (    8.20 ms per token,   121.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1216.45 ms /    15 runs   (   81.10 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    2500.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"784 411 1304\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    15 runs   (    0.49 ms per token,  2049.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.62 ms /    25 tokens (   10.22 ms per token,    97.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1144.18 ms /    14 runs   (   81.73 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =    1515.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     9 runs   (    0.39 ms per token,  2539.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.87 ms /    23 tokens (   11.04 ms per token,    90.60 tokens per second)\n",
      "llama_print_timings:        eval time =     670.72 ms /     8 runs   (   83.84 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =     984.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"intimate partner abuse\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.96 ms /     8 runs   (    0.37 ms per token,  2703.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.87 ms /    24 tokens (   10.54 ms per token,    94.91 tokens per second)\n",
      "llama_print_timings:        eval time =     587.11 ms /     7 runs   (   83.87 ms per token,    11.92 tokens per second)\n",
      "llama_print_timings:       total time =     888.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Trenton Jast\", \"Dr. Shannon Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.91 ms /    19 runs   (    0.31 ms per token,  3212.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.91 ms /   181 tokens (    7.83 ms per token,   127.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1600.22 ms /    18 runs   (   88.90 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    3140.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"750 128 1416\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    15 runs   (    0.30 ms per token,  3344.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.11 ms /    25 tokens (   10.24 ms per token,    97.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.04 ms /    14 runs   (   89.72 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1616.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     9 runs   (    0.20 ms per token,  5033.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.75 ms /    23 tokens (   11.60 ms per token,    86.22 tokens per second)\n",
      "llama_print_timings:        eval time =     722.57 ms /     8 runs   (   90.32 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1028.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.97 ms /    24 tokens (   10.54 ms per token,    94.87 tokens per second)\n",
      "llama_print_timings:        eval time =      96.00 ms /     1 runs   (   96.00 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =     353.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jetta Lockman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.06 ms /     7 runs   (    0.29 ms per token,  3404.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2461.33 ms /   316 tokens (    7.79 ms per token,   128.39 tokens per second)\n",
      "llama_print_timings:        eval time =     537.80 ms /     6 runs   (   89.63 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    3030.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 937 9409\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.70 ms /    15 runs   (    0.51 ms per token,  1948.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.55 ms /    25 tokens (   10.26 ms per token,    97.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.86 ms /    14 runs   (   84.70 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =    1549.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     6 runs   (    0.16 ms per token,  6172.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.83 ms /    23 tokens (   11.08 ms per token,    90.26 tokens per second)\n",
      "llama_print_timings:        eval time =     434.74 ms /     5 runs   (   86.95 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     710.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /     8 runs   (    0.26 ms per token,  3804.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.02 ms /    24 tokens (   10.63 ms per token,    94.11 tokens per second)\n",
      "llama_print_timings:        eval time =     606.50 ms /     7 runs   (   86.64 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     899.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Angel Ondricka\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /     9 runs   (    0.37 ms per token,  2689.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1402.32 ms /   179 tokens (    7.83 ms per token,   127.65 tokens per second)\n",
      "llama_print_timings:        eval time =     642.43 ms /     8 runs   (   80.30 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    2105.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 843 9005\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    15 runs   (    0.44 ms per token,  2286.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.70 ms /    25 tokens (   10.19 ms per token,    98.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1151.21 ms /    14 runs   (   82.23 ms per token,    12.16 tokens per second)\n",
      "llama_print_timings:       total time =    1513.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7936.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    23 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =      99.33 ms /     1 runs   (   99.33 ms per token,    10.07 tokens per second)\n",
      "llama_print_timings:       total time =     355.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     8 runs   (    0.27 ms per token,  3659.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.86 ms /    24 tokens (   10.49 ms per token,    95.29 tokens per second)\n",
      "llama_print_timings:        eval time =     603.20 ms /     7 runs   (   86.17 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     898.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rey Jakubowski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.30 ms /     9 runs   (    0.37 ms per token,  2725.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1397.54 ms /   164 tokens (    8.52 ms per token,   117.35 tokens per second)\n",
      "llama_print_timings:        eval time =     639.68 ms /     8 runs   (   79.96 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2096.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"442 485 8838\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    15 runs   (    0.54 ms per token,  1846.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.31 ms /    25 tokens (   10.13 ms per token,    98.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1126.94 ms /    14 runs   (   80.50 ms per token,    12.42 tokens per second)\n",
      "llama_print_timings:       total time =    1497.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6993.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.28 ms /    23 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =      92.00 ms /     1 runs   (   92.00 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     348.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.57 ms /    24 tokens (   10.44 ms per token,    95.78 tokens per second)\n",
      "llama_print_timings:        eval time =     103.78 ms /     1 runs   (  103.78 ms per token,     9.64 tokens per second)\n",
      "llama_print_timings:       total time =     358.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Eloy Schoen\", \"Nicholas Greenfelder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.22 ms /    16 runs   (    0.45 ms per token,  2216.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1164.55 ms /   159 tokens (    7.32 ms per token,   136.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1185.64 ms /    15 runs   (   79.04 ms per token,    12.65 tokens per second)\n",
      "llama_print_timings:       total time =    2478.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"631 177 4407\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.77 ms /    15 runs   (    0.45 ms per token,  2215.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.79 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1143.08 ms /    14 runs   (   81.65 ms per token,    12.25 tokens per second)\n",
      "llama_print_timings:       total time =    1496.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     9 runs   (    0.30 ms per token,  3342.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    23 tokens (   10.92 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     650.57 ms /     8 runs   (   81.32 ms per token,    12.30 tokens per second)\n",
      "llama_print_timings:       total time =     943.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.29 ms /     8 runs   (    0.41 ms per token,  2433.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.82 ms /    24 tokens (   10.45 ms per token,    95.69 tokens per second)\n",
      "llama_print_timings:        eval time =     580.03 ms /     7 runs   (   82.86 ms per token,    12.07 tokens per second)\n",
      "llama_print_timings:       total time =     877.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Benedict Leuschke\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /    10 runs   (    0.39 ms per token,  2532.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1617.18 ms /   201 tokens (    8.05 ms per token,   124.29 tokens per second)\n",
      "llama_print_timings:        eval time =     714.27 ms /     9 runs   (   79.36 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    2401.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"350 248 8191\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.71 ms /    15 runs   (    0.51 ms per token,  1945.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.95 ms /    25 tokens (   10.12 ms per token,    98.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.27 ms /    14 runs   (   80.88 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =    1500.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     5 runs   (    0.22 ms per token,  4612.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    23 tokens (   10.94 ms per token,    91.42 tokens per second)\n",
      "llama_print_timings:        eval time =     332.39 ms /     4 runs   (   83.10 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     599.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.68 ms /    24 tokens (   10.49 ms per token,    95.36 tokens per second)\n",
      "llama_print_timings:        eval time =      94.56 ms /     1 runs   (   94.56 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     350.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Maria Daugherty\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.78 ms /    17 runs   (    0.46 ms per token,  2184.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1148.72 ms /   142 tokens (    8.09 ms per token,   123.62 tokens per second)\n",
      "llama_print_timings:        eval time =    1269.16 ms /    16 runs   (   79.32 ms per token,    12.61 tokens per second)\n",
      "llama_print_timings:       total time =    2553.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 505 7391\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    15 runs   (    0.54 ms per token,  1855.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.54 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.91 ms /    14 runs   (   80.64 ms per token,    12.40 tokens per second)\n",
      "llama_print_timings:       total time =    1493.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /     8 runs   (    0.41 ms per token,  2447.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.00 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     576.63 ms /     7 runs   (   82.38 ms per token,    12.14 tokens per second)\n",
      "llama_print_timings:       total time =     871.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5649.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.51 ms /    24 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =      92.66 ms /     1 runs   (   92.66 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =     348.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Maida Reynolds\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.80 ms /    10 runs   (    0.58 ms per token,  1722.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2393.80 ms /   320 tokens (    7.48 ms per token,   133.68 tokens per second)\n",
      "llama_print_timings:        eval time =     729.10 ms /     9 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    3194.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"518 887 1093\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.19 ms /    15 runs   (    0.55 ms per token,  1832.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.16 ms /    25 tokens (   10.25 ms per token,    97.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1150.75 ms /    14 runs   (   82.20 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =    1520.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.90 ms /     9 runs   (    0.32 ms per token,  3103.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.81 ms /    23 tokens (   11.04 ms per token,    90.62 tokens per second)\n",
      "llama_print_timings:        eval time =     670.17 ms /     8 runs   (   83.77 ms per token,    11.94 tokens per second)\n",
      "llama_print_timings:       total time =     967.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6825.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.62 ms /    24 tokens (   10.61 ms per token,    94.26 tokens per second)\n",
      "llama_print_timings:        eval time =      96.52 ms /     1 runs   (   96.52 ms per token,    10.36 tokens per second)\n",
      "llama_print_timings:       total time =     356.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Berenice Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    11 runs   (    0.52 ms per token,  1910.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1140.94 ms /   133 tokens (    8.58 ms per token,   116.57 tokens per second)\n",
      "llama_print_timings:        eval time =     787.25 ms /    10 runs   (   78.73 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    2010.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"176 995 1097\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.67 ms /    15 runs   (    0.44 ms per token,  2249.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.11 ms /    25 tokens (   10.08 ms per token,    99.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.35 ms /    14 runs   (   80.31 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1480.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7194.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.17 ms /    23 tokens (   10.88 ms per token,    91.94 tokens per second)\n",
      "llama_print_timings:        eval time =      91.70 ms /     1 runs   (   91.70 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     347.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8547.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.61 ms /    24 tokens (   10.40 ms per token,    96.15 tokens per second)\n",
      "llama_print_timings:        eval time =     100.27 ms /     1 runs   (  100.27 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     354.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Ming O'Kon\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.46 ms /    13 runs   (    0.50 ms per token,  2012.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3112.67 ms /   398 tokens (    7.82 ms per token,   127.86 tokens per second)\n",
      "llama_print_timings:        eval time =     976.65 ms /    12 runs   (   81.39 ms per token,    12.29 tokens per second)\n",
      "llama_print_timings:       total time =    4196.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"512 797 0198\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.98 ms /    15 runs   (    0.53 ms per token,  1878.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.29 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1160.83 ms /    14 runs   (   82.92 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =    1527.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8733.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.15 ms /    23 tokens (   11.09 ms per token,    90.14 tokens per second)\n",
      "llama_print_timings:        eval time =      97.59 ms /     1 runs   (   97.59 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =     357.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10204.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.01 ms /    24 tokens (   10.63 ms per token,    94.11 tokens per second)\n",
      "llama_print_timings:        eval time =     103.46 ms /     1 runs   (  103.46 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =     361.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nickolas Stark\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     8 runs   (    0.30 ms per token,  3367.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.99 ms /   156 tokens (    7.43 ms per token,   134.60 tokens per second)\n",
      "llama_print_timings:        eval time =     564.79 ms /     7 runs   (   80.68 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1765.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 519 1201\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    15 runs   (    0.45 ms per token,  2230.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.43 ms /    25 tokens (   10.10 ms per token,    99.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.77 ms /    14 runs   (   80.13 ms per token,    12.48 tokens per second)\n",
      "llama_print_timings:       total time =    1467.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"8 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     6 runs   (    0.16 ms per token,  6198.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.23 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     423.20 ms /     5 runs   (   84.64 ms per token,    11.81 tokens per second)\n",
      "llama_print_timings:       total time =     691.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.17 ms per token,  5763.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.37 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =      91.69 ms /     1 runs   (   91.69 ms per token,    10.91 tokens per second)\n",
      "llama_print_timings:       total time =     347.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kylee Heaney\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /    12 runs   (    0.43 ms per token,  2322.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.17 ms /   137 tokens (    8.35 ms per token,   119.74 tokens per second)\n",
      "llama_print_timings:        eval time =     875.64 ms /    11 runs   (   79.60 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    2108.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"223 363 5372\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.55 ms /    15 runs   (    0.44 ms per token,  2291.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1117.52 ms /    14 runs   (   79.82 ms per token,    12.53 tokens per second)\n",
      "llama_print_timings:       total time =    1466.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7168.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.29 ms /    23 tokens (   10.88 ms per token,    91.89 tokens per second)\n",
      "llama_print_timings:        eval time =      91.49 ms /     1 runs   (   91.49 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =     347.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     8 runs   (    0.24 ms per token,  4162.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.02 ms /    24 tokens (   10.46 ms per token,    95.61 tokens per second)\n",
      "llama_print_timings:        eval time =     574.66 ms /     7 runs   (   82.09 ms per token,    12.18 tokens per second)\n",
      "llama_print_timings:       total time =     856.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosalyn Wunsch\", \"doctor Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.01 ms /    20 runs   (    0.50 ms per token,  1997.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1158.27 ms /   153 tokens (    7.57 ms per token,   132.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1502.86 ms /    19 runs   (   79.10 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2836.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"348 635 8707\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    15 runs   (    0.53 ms per token,  1875.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.60 ms /    14 runs   (   80.26 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1483.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     9 runs   (    0.24 ms per token,  4189.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.96 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     657.30 ms /     8 runs   (   82.16 ms per token,    12.17 tokens per second)\n",
      "llama_print_timings:       total time =     948.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     7 runs   (    0.15 ms per token,  6603.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.84 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     496.67 ms /     6 runs   (   82.78 ms per token,    12.08 tokens per second)\n",
      "llama_print_timings:       total time =     768.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shannon Cartwright\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    10 runs   (    0.32 ms per token,  3164.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1144.55 ms /   136 tokens (    8.42 ms per token,   118.82 tokens per second)\n",
      "llama_print_timings:        eval time =     715.89 ms /     9 runs   (   79.54 ms per token,    12.57 tokens per second)\n",
      "llama_print_timings:       total time =    1917.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"635 872 2521\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.76 ms /    15 runs   (    0.45 ms per token,  2218.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.73 ms /    25 tokens (   10.07 ms per token,    99.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1123.63 ms /    14 runs   (   80.26 ms per token,    12.46 tokens per second)\n",
      "llama_print_timings:       total time =    1485.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.65 ms /     7 runs   (    0.24 ms per token,  4252.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.12 ms /    23 tokens (   10.87 ms per token,    91.96 tokens per second)\n",
      "llama_print_timings:        eval time =     495.73 ms /     6 runs   (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     774.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7067.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =      97.40 ms /     1 runs   (   97.40 ms per token,    10.27 tokens per second)\n",
      "llama_print_timings:       total time =     353.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Les Mitchell\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.89 ms /     5 runs   (    0.38 ms per token,  2646.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.44 ms /   151 tokens (    7.67 ms per token,   130.46 tokens per second)\n",
      "llama_print_timings:        eval time =     332.08 ms /     4 runs   (   83.02 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1512.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"275 746 8162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.95 ms /    15 runs   (    0.46 ms per token,  2159.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.78 ms /    25 tokens (   10.11 ms per token,    98.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.36 ms /    14 runs   (   81.45 ms per token,    12.28 tokens per second)\n",
      "llama_print_timings:       total time =    1501.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"59 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       1.86 ms /     7 runs   (    0.27 ms per token,  3767.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    23 tokens (   10.92 ms per token,    91.54 tokens per second)\n",
      "llama_print_timings:        eval time =     514.86 ms /     6 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     794.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.40 ms /     2 runs   (    0.20 ms per token,  5037.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.21 ms /    24 tokens (   10.47 ms per token,    95.54 tokens per second)\n",
      "llama_print_timings:        eval time =      91.93 ms /     1 runs   (   91.93 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     349.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Keitha Bayer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2671.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1159.45 ms /   156 tokens (    7.43 ms per token,   134.55 tokens per second)\n",
      "llama_print_timings:        eval time =     645.53 ms /     8 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1863.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"366 737 1105\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.35 ms /    15 runs   (    0.49 ms per token,  2040.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.99 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1124.91 ms /    14 runs   (   80.35 ms per token,    12.45 tokens per second)\n",
      "llama_print_timings:       total time =    1486.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     9 runs   (    0.34 ms per token,  2963.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.01 ms /    23 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     659.28 ms /     8 runs   (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_print_timings:       total time =     962.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     8 runs   (    0.37 ms per token,  2709.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.53 ms /    24 tokens (   10.44 ms per token,    95.80 tokens per second)\n",
      "llama_print_timings:        eval time =     581.75 ms /     7 runs   (   83.11 ms per token,    12.03 tokens per second)\n",
      "llama_print_timings:       total time =     875.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Margarito Collins\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =      10.71 ms /    18 runs   (    0.59 ms per token,  1681.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1623.79 ms /   197 tokens (    8.24 ms per token,   121.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1350.73 ms /    17 runs   (   79.45 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    3132.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"705 419 9342\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    15 runs   (    0.49 ms per token,  2028.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.02 ms /    25 tokens (   10.12 ms per token,    98.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1130.62 ms /    14 runs   (   80.76 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1503.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /     8 runs   (    0.27 ms per token,  3646.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.29 ms /    23 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_print_timings:        eval time =     582.24 ms /     7 runs   (   83.18 ms per token,    12.02 tokens per second)\n",
      "llama_print_timings:       total time =     872.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7092.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.34 ms /    24 tokens (   10.51 ms per token,    95.11 tokens per second)\n",
      "llama_print_timings:        eval time =      90.73 ms /     1 runs   (   90.73 ms per token,    11.02 tokens per second)\n",
      "llama_print_timings:       total time =     348.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Charlie Hettinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    10 runs   (    0.47 ms per token,  2133.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1161.10 ms /   157 tokens (    7.40 ms per token,   135.22 tokens per second)\n",
      "llama_print_timings:        eval time =     726.17 ms /     9 runs   (   80.69 ms per token,    12.39 tokens per second)\n",
      "llama_print_timings:       total time =    1957.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"137 115 8110\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    15 runs   (    0.46 ms per token,  2167.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.41 ms /    25 tokens (   10.10 ms per token,    99.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1121.11 ms /    14 runs   (   80.08 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =    1473.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.95 ms /     9 runs   (    0.44 ms per token,  2281.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.82 ms /    23 tokens (   10.91 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =     676.19 ms /     8 runs   (   84.52 ms per token,    11.83 tokens per second)\n",
      "llama_print_timings:       total time =     982.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /    11 runs   (    0.32 ms per token,  3121.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.27 ms /    24 tokens (   10.47 ms per token,    95.52 tokens per second)\n",
      "llama_print_timings:        eval time =     811.56 ms /    10 runs   (   81.16 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1123.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stefany Hand\", \"Dr. Winston McCullough\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    19 runs   (    0.45 ms per token,  2207.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.85 ms /   145 tokens (    7.94 ms per token,   125.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1439.14 ms /    18 runs   (   79.95 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =    2750.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"686 286 2000\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2162.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1131.20 ms /    14 runs   (   80.80 ms per token,    12.38 tokens per second)\n",
      "llama_print_timings:       total time =    1495.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.58 ms /     9 runs   (    0.29 ms per token,  3481.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.01 ms /    23 tokens (   10.87 ms per token,    92.00 tokens per second)\n",
      "llama_print_timings:        eval time =     660.99 ms /     8 runs   (   82.62 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     957.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     8 runs   (    0.36 ms per token,  2814.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.36 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =     578.21 ms /     7 runs   (   82.60 ms per token,    12.11 tokens per second)\n",
      "llama_print_timings:       total time =     871.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ignacio Spinka\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       4.74 ms /    11 runs   (    0.43 ms per token,  2322.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1152.93 ms /   146 tokens (    7.90 ms per token,   126.63 tokens per second)\n",
      "llama_print_timings:        eval time =     801.96 ms /    10 runs   (   80.20 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2028.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"146 618 6996\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       6.33 ms /    15 runs   (    0.42 ms per token,  2367.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.32 ms /    25 tokens (   10.09 ms per token,    99.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1125.69 ms /    14 runs   (   80.41 ms per token,    12.44 tokens per second)\n",
      "llama_print_timings:       total time =    1473.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /     7 runs   (    0.33 ms per token,  3064.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.27 ms /    23 tokens (   10.84 ms per token,    92.27 tokens per second)\n",
      "llama_print_timings:        eval time =     495.96 ms /     6 runs   (   82.66 ms per token,    12.10 tokens per second)\n",
      "llama_print_timings:       total time =     776.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    1938.27 ms\n",
      "llama_print_timings:      sample time =       0.35 ms /     2 runs   (    0.18 ms per token,  5698.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.38 ms /    24 tokens (   10.43 ms per token,    95.86 tokens per second)\n",
      "llama_print_timings:        eval time =      91.95 ms /     1 runs   (   91.95 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     347.35 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "data = load_llm_data()\n",
    "\n",
    "patients_entities = generate_patients_entities(data, [\"person\", \"NHS number\", \"age\", \"diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('patient_entities.pickle', 'wb') as f:\n",
    "    pickle.dump(patients_entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('patient_entities.pickle', \"rb\") as f:\n",
    "    saved_patients_entities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_values = []\n",
    "llm_data = load_llm_data()\n",
    "for id, patient_entities in saved_patients_entities.items():\n",
    "    text = llm_data[id].strip()\n",
    "    for entity_name, outputs in patient_entities.items():\n",
    "        output_type = (outputs[\"output_type\"] == type(list()))\n",
    "        if output_type:\n",
    "            output_length = len(outputs[\"output\"])\n",
    "        else:\n",
    "            output_length = np.nan\n",
    "                \n",
    "        output = {\n",
    "            \"patient_id\": id,\n",
    "            \"entity_name\": entity_name,\n",
    "            \"output\": outputs[\"output\"],\n",
    "            \"output_length\": output_length,\n",
    "            \"output_type\": int(output_type),\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "        patient_values.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>output</th>\n",
       "      <th>output_length</th>\n",
       "      <th>output_type</th>\n",
       "      <th>text</th>\n",
       "      <th>output_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Brandon McLaughlin]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NHS number</td>\n",
       "      <td>[568 968 0803]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>age</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[acute bronchitis]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Esteban Altenwerth]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Esteban Altenwerth is a 20-year-old White ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>998</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[viral sinusitis]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Stefany Hand (NHS number: 686 286 2000, D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>999</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Ignacio Spinka]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>999</td>\n",
       "      <td>NHS number</td>\n",
       "      <td>[146 618 6996]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>999</td>\n",
       "      <td>age</td>\n",
       "      <td>[70 year old]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>999</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id entity_name                    output  output_length  \\\n",
       "0              0      person  [Mr. Brandon McLaughlin]              1   \n",
       "1              0  NHS number            [568 968 0803]              1   \n",
       "2              0         age                        []              0   \n",
       "3              0   diagnosis        [acute bronchitis]              1   \n",
       "4              1      person  [Mr. Esteban Altenwerth]              1   \n",
       "...          ...         ...                       ...            ...   \n",
       "3995         998   diagnosis         [viral sinusitis]              1   \n",
       "3996         999      person      [Mr. Ignacio Spinka]              1   \n",
       "3997         999  NHS number            [146 618 6996]              1   \n",
       "3998         999         age             [70 year old]              1   \n",
       "3999         999   diagnosis                        []              0   \n",
       "\n",
       "      output_type                                               text  \\\n",
       "0               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "1               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "2               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "3               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "4               1  Mr. Esteban Altenwerth is a 20-year-old White ...   \n",
       "...           ...                                                ...   \n",
       "3995            1  Mrs. Stefany Hand (NHS number: 686 286 2000, D...   \n",
       "3996            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3997            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3998            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3999            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "\n",
       "      output_any  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "3995           1  \n",
       "3996           1  \n",
       "3997           1  \n",
       "3998           1  \n",
       "3999           0  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_table = pd.DataFrame(patient_values)\n",
    "entity_table[\"output_any\"] = entity_table[\"output_length\"] >= 1\n",
    "entity_table[\"output_any\"] = entity_table[\"output_any\"].astype(int)\n",
    "entity_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NHS number</th>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             output_any\n",
       "entity_name            \n",
       "NHS number        0.999\n",
       "age               0.751\n",
       "diagnosis         0.583\n",
       "person            0.990"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_prevalence = entity_table[[\"entity_name\", \"output_any\"]].groupby(\"entity_name\").sum(\"output_any\")/1000\n",
    "entity_prevalence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='entity_name'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entity_prevalence.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
