{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "from data_ingestion import load_llm_data\n",
    "from universal_ner import upload_quantised_universal_ner, get_universal_ner_entity, generate_patients_entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 21 key-value pairs and 291 tensors from ../../models/quantized_q4_1.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = .\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 2048\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 11008\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 32\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000001\n",
      "llama_model_loader: - kv  10:                          general.file_type u32              = 3\n",
      "llama_model_loader: - kv  11:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  12:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  14:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  15:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  17:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  18:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  19:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  20:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_1:  225 tensors\n",
      "llama_model_loader: - type q6_K:    1 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V3 (latest)\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 2048\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 32\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_gqa            = 1\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-06\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 11008\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 2048\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_1\n",
      "llm_load_print_meta: model params     = 6.74 B\n",
      "llm_load_print_meta: model size       = 3.95 GiB (5.03 BPW) \n",
      "llm_load_print_meta: general.name     = .\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: PAD token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "ggml_backend_metal_buffer_from_ptr: allocated buffer, size =  4042.39 MiB, ( 4042.45 / 10922.67)\n",
      "llm_load_tensors: system memory used  = 4041.79 MiB\n",
      "..................................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 512\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M1\n",
      "ggml_metal_init: picking default device: Apple M1\n",
      "ggml_metal_init: default.metallib not found, loading from source\n",
      "ggml_metal_init: GGML_METAL_PATH_RESOURCES = nil\n",
      "ggml_metal_init: loading '/Users/scarlettkynoch/miniconda3/envs/ner_pipeline/lib/python3.8/site-packages/llama_cpp/ggml-metal.metal'\n",
      "ggml_metal_init: GPU name:   Apple M1\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple7 (1007)\n",
      "ggml_metal_init: hasUnifiedMemory              = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: maxTransferRate               = built-in GPU\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =   256.00 MiB, ( 4300.02 / 10922.67)\n",
      "llama_new_context_with_model: KV self size  =  256.00 MiB, K (f16):  128.00 MiB, V (f16):  128.00 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =     0.02 MiB, ( 4300.03 / 10922.67)\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "llama_new_context_with_model: compute buffer total size = 73.69 MiB\n",
      "ggml_backend_metal_buffer_type_alloc_buffer: allocated buffer, size =    70.50 MiB, ( 4370.52 / 10922.67)\n",
      "AVX = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brandon McLaughlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /    11 runs   (    0.17 ms per token,  5756.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    7255.56 ms /   160 tokens (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_print_timings:        eval time =     838.05 ms /    10 runs   (   83.81 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    8137.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"568 968 0803\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.60 ms /    15 runs   (    0.11 ms per token,  9363.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.10 ms /    25 tokens (   10.56 ms per token,    94.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1257.85 ms /    14 runs   (   89.85 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    1554.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     9 runs   (    0.10 ms per token, 10452.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.88 ms /    23 tokens (   11.13 ms per token,    89.88 tokens per second)\n",
      "llama_print_timings:        eval time =     693.05 ms /     8 runs   (   86.63 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     968.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.87 ms /     8 runs   (    0.11 ms per token,  9237.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.41 ms /    24 tokens (   10.81 ms per token,    92.52 tokens per second)\n",
      "llama_print_timings:        eval time =     632.80 ms /     7 runs   (   90.40 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =     908.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Esteban Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.53 ms /    12 runs   (    0.13 ms per token,  7822.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1162.57 ms /   150 tokens (    7.75 ms per token,   129.02 tokens per second)\n",
      "llama_print_timings:        eval time =     882.08 ms /    11 runs   (   80.19 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2072.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"201 826 4805\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.81 ms /    15 runs   (    0.12 ms per token,  8301.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.60 ms /    25 tokens (   10.06 ms per token,    99.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.94 ms /    14 runs   (   86.07 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1490.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.00 ms /     9 runs   (    0.22 ms per token,  4509.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.06 ms /    23 tokens (   11.35 ms per token,    88.10 tokens per second)\n",
      "llama_print_timings:        eval time =     827.54 ms /     8 runs   (  103.44 ms per token,     9.67 tokens per second)\n",
      "llama_print_timings:       total time =    1179.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.36 ms /     2 runs   (    0.18 ms per token,  5617.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.52 ms /    24 tokens (   10.86 ms per token,    92.12 tokens per second)\n",
      "llama_print_timings:        eval time =     102.04 ms /     1 runs   (  102.04 ms per token,     9.80 tokens per second)\n",
      "llama_print_timings:       total time =     369.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ervin O'Connell\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /    20 runs   (    0.34 ms per token,  2973.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1226.39 ms /   155 tokens (    7.91 ms per token,   126.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1650.88 ms /    19 runs   (   86.89 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    2995.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"862 334 6633\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.26 ms /    15 runs   (    0.28 ms per token,  3517.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.09 ms /    25 tokens (   10.36 ms per token,    96.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1161.52 ms /    14 runs   (   82.97 ms per token,    12.05 tokens per second)\n",
      "llama_print_timings:       total time =    1490.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32 years old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.03 ms /     7 runs   (    0.29 ms per token,  3453.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.79 ms /    23 tokens (   11.12 ms per token,    89.92 tokens per second)\n",
      "llama_print_timings:        eval time =     578.65 ms /     6 runs   (   96.44 ms per token,    10.37 tokens per second)\n",
      "llama_print_timings:       total time =     865.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     8 runs   (    0.28 ms per token,  3624.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.54 ms /    24 tokens (   10.56 ms per token,    94.66 tokens per second)\n",
      "llama_print_timings:        eval time =     566.50 ms /     7 runs   (   80.93 ms per token,    12.36 tokens per second)\n",
      "llama_print_timings:       total time =     859.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Pam Boehm\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    10 runs   (    0.34 ms per token,  2955.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.70 ms /   135 tokens (    8.57 ms per token,   116.71 tokens per second)\n",
      "llama_print_timings:        eval time =     727.84 ms /     9 runs   (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =    1938.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"639 189 7032\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    15 runs   (    0.31 ms per token,  3199.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.98 ms /    25 tokens (   10.40 ms per token,    96.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1165.90 ms /    14 runs   (   83.28 ms per token,    12.01 tokens per second)\n",
      "llama_print_timings:       total time =    1562.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.56 ms /     9 runs   (    0.17 ms per token,  5784.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.76 ms /    23 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =     666.54 ms /     8 runs   (   83.32 ms per token,    12.00 tokens per second)\n",
      "llama_print_timings:       total time =     949.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\", \"stress\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.10 ms /    12 runs   (    0.18 ms per token,  5711.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.29 ms /    24 tokens (   10.47 ms per token,    95.51 tokens per second)\n",
      "llama_print_timings:        eval time =     977.65 ms /    11 runs   (   88.88 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1275.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mirta Mosciski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.48 ms /    11 runs   (    0.41 ms per token,  2454.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1157.08 ms /   135 tokens (    8.57 ms per token,   116.67 tokens per second)\n",
      "llama_print_timings:        eval time =     810.12 ms /    10 runs   (   81.01 ms per token,    12.34 tokens per second)\n",
      "llama_print_timings:       total time =    2039.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"231 157 0705\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.27 ms /    15 runs   (    0.55 ms per token,  1812.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.64 ms /    25 tokens (   10.11 ms per token,    98.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1101.19 ms /    14 runs   (   78.66 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =    1475.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.75 ms /     5 runs   (    0.35 ms per token,  2863.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.40 ms /    23 tokens (   10.89 ms per token,    91.85 tokens per second)\n",
      "llama_print_timings:        eval time =     326.69 ms /     4 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     604.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /     8 runs   (    0.53 ms per token,  1903.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.61 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =     543.72 ms /     7 runs   (   77.67 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =     848.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Pierre Hyatt\", \"Doctor Mercy Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.94 ms /    18 runs   (    0.50 ms per token,  2012.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1399.05 ms /   185 tokens (    7.56 ms per token,   132.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1344.66 ms /    17 runs   (   79.10 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    2882.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"476 859 5816\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    15 runs   (    0.65 ms per token,  1540.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.07 ms /    25 tokens (   10.12 ms per token,    98.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.33 ms /    14 runs   (   80.17 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    1515.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.62 ms /     9 runs   (    0.62 ms per token,  1601.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.12 ms /    23 tokens (   10.92 ms per token,    91.59 tokens per second)\n",
      "llama_print_timings:        eval time =     639.55 ms /     8 runs   (   79.94 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     961.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.57 ms /     8 runs   (    0.57 ms per token,  1751.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.16 ms /    24 tokens (   10.46 ms per token,    95.56 tokens per second)\n",
      "llama_print_timings:        eval time =     547.79 ms /     7 runs   (   78.26 ms per token,    12.78 tokens per second)\n",
      "llama_print_timings:       total time =     858.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Angela Collier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.42 ms /    10 runs   (    0.74 ms per token,  1347.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1373.85 ms /   167 tokens (    8.23 ms per token,   121.56 tokens per second)\n",
      "llama_print_timings:        eval time =     692.62 ms /     9 runs   (   76.96 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =    2166.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"590 161 4272\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.30 ms /    15 runs   (    0.62 ms per token,  1613.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.99 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1085.15 ms /    14 runs   (   77.51 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    1472.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /     8 runs   (    0.59 ms per token,  1695.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.60 ms /    23 tokens (   10.90 ms per token,    91.78 tokens per second)\n",
      "llama_print_timings:        eval time =     537.38 ms /     7 runs   (   76.77 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =     860.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis with seasonal variation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.20 ms /    16 runs   (    0.64 ms per token,  1568.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.91 ms /    24 tokens (   10.45 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1168.47 ms /    15 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1574.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Shannon Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.82 ms /     9 runs   (    0.76 ms per token,  1320.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1149.59 ms /   148 tokens (    7.77 ms per token,   128.74 tokens per second)\n",
      "llama_print_timings:        eval time =     612.63 ms /     8 runs   (   76.58 ms per token,    13.06 tokens per second)\n",
      "llama_print_timings:       total time =    1850.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"122 273 9962\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.28 ms /    15 runs   (    0.75 ms per token,  1330.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.78 ms /    25 tokens (   10.07 ms per token,    99.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1075.82 ms /    14 runs   (   76.84 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    1480.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     7 runs   (    0.37 ms per token,  2686.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.71 ms /    23 tokens (   10.90 ms per token,    91.74 tokens per second)\n",
      "llama_print_timings:        eval time =     473.91 ms /     6 runs   (   78.99 ms per token,    12.66 tokens per second)\n",
      "llama_print_timings:       total time =     763.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.22 ms /     8 runs   (    0.78 ms per token,  1285.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.99 ms /    24 tokens (   10.42 ms per token,    96.01 tokens per second)\n",
      "llama_print_timings:        eval time =     539.15 ms /     7 runs   (   77.02 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =     861.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Delmy Halvorson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.69 ms /     9 runs   (    0.63 ms per token,  1581.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1151.47 ms /   153 tokens (    7.53 ms per token,   132.87 tokens per second)\n",
      "llama_print_timings:        eval time =     621.25 ms /     8 runs   (   77.66 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =    1850.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 774 0304\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.02 ms /    15 runs   (    0.73 ms per token,  1361.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.64 ms /    25 tokens (   10.07 ms per token,    99.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1090.55 ms /    14 runs   (   77.90 ms per token,    12.84 tokens per second)\n",
      "llama_print_timings:       total time =    1477.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"9 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /     6 runs   (    0.67 ms per token,  1485.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.20 ms /    23 tokens (   10.88 ms per token,    91.93 tokens per second)\n",
      "llama_print_timings:        eval time =     389.65 ms /     5 runs   (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =     697.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.34 ms /     2 runs   (    0.67 ms per token,  1494.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.69 ms /    24 tokens (   10.45 ms per token,    95.74 tokens per second)\n",
      "llama_print_timings:        eval time =      77.40 ms /     1 runs   (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     345.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Myra Schamberger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.96 ms /    11 runs   (    0.45 ms per token,  2215.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1232.03 ms /   158 tokens (    7.80 ms per token,   128.24 tokens per second)\n",
      "llama_print_timings:        eval time =     842.23 ms /    10 runs   (   84.22 ms per token,    11.87 tokens per second)\n",
      "llama_print_timings:       total time =    2159.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"855 311 5624\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.99 ms /    15 runs   (    0.73 ms per token,  1364.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.80 ms /    25 tokens (   10.47 ms per token,    95.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1081.72 ms /    14 runs   (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    1494.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.22 ms per token,  4464.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.80 ms /    23 tokens (   10.90 ms per token,    91.71 tokens per second)\n",
      "llama_print_timings:        eval time =      94.33 ms /     1 runs   (   94.33 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =     352.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    11 runs   (    0.53 ms per token,  1891.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     275.54 ms /    24 tokens (   11.48 ms per token,    87.10 tokens per second)\n",
      "llama_print_timings:        eval time =     898.88 ms /    10 runs   (   89.89 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =    1256.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cristy Robel\", \"Dr Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.91 ms /    15 runs   (    0.66 ms per token,  1513.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1396.92 ms /   178 tokens (    7.85 ms per token,   127.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1075.56 ms /    14 runs   (   76.83 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time =    2624.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 251 4401\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.37 ms /    15 runs   (    0.69 ms per token,  1446.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.03 ms /    25 tokens (   10.16 ms per token,    98.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1079.90 ms /    14 runs   (   77.14 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1469.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.06 ms /    23 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =      77.72 ms /     1 runs   (   77.72 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =     344.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.48 ms /     7 runs   (    0.78 ms per token,  1276.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    24 tokens (   10.43 ms per token,    95.90 tokens per second)\n",
      "llama_print_timings:        eval time =     459.83 ms /     6 runs   (   76.64 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:       total time =     780.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dorie Baumbach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.73 ms /     8 runs   (    0.84 ms per token,  1189.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1372.71 ms /   167 tokens (    8.22 ms per token,   121.66 tokens per second)\n",
      "llama_print_timings:        eval time =     537.49 ms /     7 runs   (   76.78 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time =    1992.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"447 249 2567\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      12.01 ms /    15 runs   (    0.80 ms per token,  1248.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.04 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1078.54 ms /    14 runs   (   77.04 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =    1484.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.05 ms /     9 runs   (    0.56 ms per token,  1781.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.85 ms /    23 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =     619.16 ms /     8 runs   (   77.39 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     943.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /     8 runs   (    0.73 ms per token,  1361.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.62 ms /    24 tokens (   10.44 ms per token,    95.76 tokens per second)\n",
      "llama_print_timings:        eval time =     537.60 ms /     7 runs   (   76.80 ms per token,    13.02 tokens per second)\n",
      "llama_print_timings:       total time =     863.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Deidra Corkery\", \"Almeda Okuneva\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      14.05 ms /    20 runs   (    0.70 ms per token,  1423.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1606.30 ms /   202 tokens (    7.95 ms per token,   125.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1473.61 ms /    19 runs   (   77.56 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =    3269.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"328 659 9956\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    15 runs   (    0.52 ms per token,  1933.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.75 ms /    25 tokens (   10.11 ms per token,    98.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.66 ms /    14 runs   (   81.12 ms per token,    12.33 tokens per second)\n",
      "llama_print_timings:       total time =    1507.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /     7 runs   (    0.63 ms per token,  1587.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.05 ms /    23 tokens (   10.96 ms per token,    91.25 tokens per second)\n",
      "llama_print_timings:        eval time =     462.05 ms /     6 runs   (   77.01 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =     777.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.14 ms per token,  6920.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.88 ms /    24 tokens (   10.49 ms per token,    95.28 tokens per second)\n",
      "llama_print_timings:        eval time =     100.24 ms /     1 runs   (  100.24 ms per token,     9.98 tokens per second)\n",
      "llama_print_timings:       total time =     360.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Wendell Oberbrunner\", \"Dr. Ivette Wunsch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      14.29 ms /    20 runs   (    0.71 ms per token,  1399.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1381.42 ms /   178 tokens (    7.76 ms per token,   128.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1472.55 ms /    19 runs   (   77.50 ms per token,    12.90 tokens per second)\n",
      "llama_print_timings:       total time =    3061.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 595 1633\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    15 runs   (    0.71 ms per token,  1418.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.98 ms /    25 tokens (   10.12 ms per token,    98.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1088.60 ms /    14 runs   (   77.76 ms per token,    12.86 tokens per second)\n",
      "llama_print_timings:       total time =    1480.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1962.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.97 ms /    23 tokens (   10.87 ms per token,    92.01 tokens per second)\n",
      "llama_print_timings:        eval time =      76.70 ms /     1 runs   (   76.70 ms per token,    13.04 tokens per second)\n",
      "llama_print_timings:       total time =     341.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.29 ms /     2 runs   (    0.15 ms per token,  6802.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.63 ms /    24 tokens (   10.48 ms per token,    95.38 tokens per second)\n",
      "llama_print_timings:        eval time =      77.03 ms /     1 runs   (   77.03 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =     334.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ethan Kutch\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    14 runs   (    0.63 ms per token,  1575.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.55 ms /   142 tokens (    8.05 ms per token,   124.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1001.99 ms /    13 runs   (   77.08 ms per token,    12.97 tokens per second)\n",
      "llama_print_timings:       total time =    2271.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 126 7519\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    15 runs   (    0.69 ms per token,  1439.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.62 ms /    25 tokens (   10.06 ms per token,    99.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1078.25 ms /    14 runs   (   77.02 ms per token,    12.98 tokens per second)\n",
      "llama_print_timings:       total time =    1464.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     6 runs   (    0.58 ms per token,  1729.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.21 ms /    23 tokens (   10.84 ms per token,    92.29 tokens per second)\n",
      "llama_print_timings:        eval time =     392.91 ms /     5 runs   (   78.58 ms per token,    12.73 tokens per second)\n",
      "llama_print_timings:       total time =     685.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1556.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.45 ms /    24 tokens (   10.44 ms per token,    95.83 tokens per second)\n",
      "llama_print_timings:        eval time =      77.85 ms /     1 runs   (   77.85 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     340.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lupe Cassin\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.12 ms /    17 runs   (    0.65 ms per token,  1528.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.39 ms /   157 tokens (    7.37 ms per token,   135.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.73 ms /    16 runs   (   76.73 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =    2553.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"120 506 4336\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.36 ms /    15 runs   (    0.62 ms per token,  1602.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.44 ms /    25 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1076.43 ms /    14 runs   (   76.89 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    1468.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"74 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     6 runs   (    0.54 ms per token,  1866.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.55 ms /    23 tokens (   10.89 ms per token,    91.80 tokens per second)\n",
      "llama_print_timings:        eval time =     384.98 ms /     5 runs   (   77.00 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =     691.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.75 ms /     2 runs   (    0.37 ms per token,  2673.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.65 ms /    24 tokens (   10.44 ms per token,    95.75 tokens per second)\n",
      "llama_print_timings:        eval time =      76.44 ms /     1 runs   (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:       total time =     337.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Logan Schaden\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    10 runs   (    0.90 ms per token,  1107.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.47 ms /   143 tokens (    8.00 ms per token,   125.06 tokens per second)\n",
      "llama_print_timings:        eval time =     696.41 ms /     9 runs   (   77.38 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =    1945.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"169 421 2926\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      12.80 ms /    15 runs   (    0.85 ms per token,  1171.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.34 ms /    25 tokens (   10.05 ms per token,    99.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1070.44 ms /    14 runs   (   76.46 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:       total time =    1478.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /     9 runs   (    0.60 ms per token,  1653.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.77 ms /    23 tokens (   10.86 ms per token,    92.09 tokens per second)\n",
      "llama_print_timings:        eval time =     624.44 ms /     8 runs   (   78.05 ms per token,    12.81 tokens per second)\n",
      "llama_print_timings:       total time =     945.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1727.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.21 ms /    24 tokens (   10.43 ms per token,    95.92 tokens per second)\n",
      "llama_print_timings:        eval time =      76.77 ms /     1 runs   (   76.77 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =     340.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jaime Sauer\", \"Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.85 ms /    15 runs   (    0.59 ms per token,  1695.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1143.45 ms /   145 tokens (    7.89 ms per token,   126.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1082.59 ms /    14 runs   (   77.33 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =    2362.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"355 112 3923\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.30 ms /    15 runs   (    0.69 ms per token,  1455.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.27 ms /    25 tokens (   10.09 ms per token,    99.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1074.74 ms /    14 runs   (   76.77 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =    1477.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /     8 runs   (    0.53 ms per token,  1885.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.02 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     535.07 ms /     7 runs   (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:       total time =     847.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /     8 runs   (    0.52 ms per token,  1912.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.32 ms /    24 tokens (   10.43 ms per token,    95.88 tokens per second)\n",
      "llama_print_timings:        eval time =     543.42 ms /     7 runs   (   77.63 ms per token,    12.88 tokens per second)\n",
      "llama_print_timings:       total time =     850.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Reggie Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /     7 runs   (    0.76 ms per token,  1321.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1136.29 ms /   134 tokens (    8.48 ms per token,   117.93 tokens per second)\n",
      "llama_print_timings:        eval time =     459.65 ms /     6 runs   (   76.61 ms per token,    13.05 tokens per second)\n",
      "llama_print_timings:       total time =    1667.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 367 0222\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.71 ms /    15 runs   (    0.65 ms per token,  1544.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.53 ms /    25 tokens (   10.06 ms per token,    99.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1078.05 ms /    14 runs   (   77.00 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =    1458.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /     7 runs   (    0.79 ms per token,  1270.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.02 ms /    23 tokens (   10.87 ms per token,    91.99 tokens per second)\n",
      "llama_print_timings:        eval time =     458.62 ms /     6 runs   (   76.44 ms per token,    13.08 tokens per second)\n",
      "llama_print_timings:       total time =     775.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.83 ms /     8 runs   (    0.85 ms per token,  1171.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.16 ms /    24 tokens (   10.42 ms per token,    95.94 tokens per second)\n",
      "llama_print_timings:        eval time =     541.81 ms /     7 runs   (   77.40 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     870.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Luann Hills\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.96 ms /    16 runs   (    0.69 ms per token,  1459.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1599.14 ms /   194 tokens (    8.24 ms per token,   121.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1198.54 ms /    15 runs   (   79.90 ms per token,    12.52 tokens per second)\n",
      "llama_print_timings:       total time =    2932.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 395 1923\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      12.13 ms /    15 runs   (    0.81 ms per token,  1236.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.44 ms /    25 tokens (   10.10 ms per token,    99.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1080.13 ms /    14 runs   (   77.15 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =    1484.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"19-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.96 ms /     9 runs   (    0.66 ms per token,  1511.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    23 tokens (   10.91 ms per token,    91.65 tokens per second)\n",
      "llama_print_timings:        eval time =     631.12 ms /     8 runs   (   78.89 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =     955.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.83 ms /     7 runs   (    0.69 ms per token,  1449.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.55 ms /    24 tokens (   10.48 ms per token,    95.41 tokens per second)\n",
      "llama_print_timings:        eval time =     461.98 ms /     6 runs   (   77.00 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =     775.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Meta Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.87 ms /     6 runs   (    0.48 ms per token,  2092.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.55 ms /   140 tokens (    8.16 ms per token,   122.53 tokens per second)\n",
      "llama_print_timings:        eval time =     386.34 ms /     5 runs   (   77.27 ms per token,    12.94 tokens per second)\n",
      "llama_print_timings:       total time =    1572.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 201 4341\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.52 ms /    15 runs   (    0.63 ms per token,  1575.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.52 ms /    25 tokens (   10.10 ms per token,    99.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1093.42 ms /    14 runs   (   78.10 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =    1472.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.57 ms /     6 runs   (    0.59 ms per token,  1682.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.87 ms /    23 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     414.52 ms /     5 runs   (   82.90 ms per token,    12.06 tokens per second)\n",
      "llama_print_timings:       total time =     717.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /     8 runs   (    0.68 ms per token,  1461.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.48 ms /    24 tokens (   10.52 ms per token,    95.06 tokens per second)\n",
      "llama_print_timings:        eval time =     541.84 ms /     7 runs   (   77.41 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     877.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Louis Considine\", \"Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.22 ms /    16 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1163.03 ms /   159 tokens (    7.31 ms per token,   136.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1172.53 ms /    15 runs   (   78.17 ms per token,    12.79 tokens per second)\n",
      "llama_print_timings:       total time =    2476.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"850 729 2109\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.51 ms /    15 runs   (    0.70 ms per token,  1427.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.20 ms /    25 tokens (   10.09 ms per token,    99.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1313.04 ms /    14 runs   (   93.79 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =    1699.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /     7 runs   (    0.53 ms per token,  1878.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.52 ms /    23 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =     476.47 ms /     6 runs   (   79.41 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =     777.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      16.21 ms /     8 runs   (    2.03 ms per token,   493.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.47 ms /    24 tokens (   10.44 ms per token,    95.82 tokens per second)\n",
      "llama_print_timings:        eval time =     557.26 ms /     7 runs   (   79.61 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     884.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Danilo Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /     7 runs   (    0.37 ms per token,  2685.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3013.96 ms /   376 tokens (    8.02 ms per token,   124.75 tokens per second)\n",
      "llama_print_timings:        eval time =     493.74 ms /     6 runs   (   82.29 ms per token,    12.15 tokens per second)\n",
      "llama_print_timings:       total time =    3550.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"359 865 0271\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.04 ms /    15 runs   (    0.60 ms per token,  1659.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    25 tokens (   10.27 ms per token,    97.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.93 ms /    14 runs   (   81.14 ms per token,    12.32 tokens per second)\n",
      "llama_print_timings:       total time =    1535.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.46 ms /     7 runs   (    0.64 ms per token,  1567.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.24 ms /    23 tokens (   11.10 ms per token,    90.11 tokens per second)\n",
      "llama_print_timings:        eval time =     480.23 ms /     6 runs   (   80.04 ms per token,    12.49 tokens per second)\n",
      "llama_print_timings:       total time =     803.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"ex-smoker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     7 runs   (    0.54 ms per token,  1850.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.21 ms /    24 tokens (   10.63 ms per token,    94.04 tokens per second)\n",
      "llama_print_timings:        eval time =     490.05 ms /     6 runs   (   81.67 ms per token,    12.24 tokens per second)\n",
      "llama_print_timings:       total time =     798.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Herman Von\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.42 ms /     6 runs   (    0.74 ms per token,  1355.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1368.43 ms /   161 tokens (    8.50 ms per token,   117.65 tokens per second)\n",
      "llama_print_timings:        eval time =     398.04 ms /     5 runs   (   79.61 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =    1823.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 889 0744\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.56 ms /    15 runs   (    0.70 ms per token,  1420.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.51 ms /    25 tokens (   10.06 ms per token,    99.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1092.38 ms /    14 runs   (   78.03 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    1478.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.84 ms /     6 runs   (    0.64 ms per token,  1561.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     253.79 ms /    23 tokens (   11.03 ms per token,    90.63 tokens per second)\n",
      "llama_print_timings:        eval time =     384.95 ms /     5 runs   (   76.99 ms per token,    12.99 tokens per second)\n",
      "llama_print_timings:       total time =     689.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    11 runs   (    0.70 ms per token,  1424.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.78 ms /    24 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =     768.72 ms /    10 runs   (   76.87 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =    1128.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Wade Ondricka\", \"Dr.\", \"Lloyd Wuckert\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      14.31 ms /    22 runs   (    0.65 ms per token,  1537.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1154.12 ms /   152 tokens (    7.59 ms per token,   131.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1631.83 ms /    21 runs   (   77.71 ms per token,    12.87 tokens per second)\n",
      "llama_print_timings:       total time =    2990.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"270 156 8089\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.35 ms /    15 runs   (    0.69 ms per token,  1449.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.87 ms /    25 tokens (   10.07 ms per token,    99.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1077.17 ms /    14 runs   (   76.94 ms per token,    13.00 tokens per second)\n",
      "llama_print_timings:       total time =    1482.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.20 ms /     9 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.96 ms /    23 tokens (   10.95 ms per token,    91.29 tokens per second)\n",
      "llama_print_timings:        eval time =     619.42 ms /     8 runs   (   77.43 ms per token,    12.92 tokens per second)\n",
      "llama_print_timings:       total time =     939.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /     8 runs   (    0.71 ms per token,  1412.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.50 ms /    24 tokens (   10.44 ms per token,    95.81 tokens per second)\n",
      "llama_print_timings:        eval time =     542.92 ms /     7 runs   (   77.56 ms per token,    12.89 tokens per second)\n",
      "llama_print_timings:       total time =     860.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Walton Conroy\", \"Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.17 ms /    14 runs   (    0.51 ms per token,  1953.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1862.22 ms /   240 tokens (    7.76 ms per token,   128.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1031.83 ms /    13 runs   (   79.37 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =    3009.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"781 485 9913\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.62 ms /    15 runs   (    0.71 ms per token,  1412.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.99 ms /    25 tokens (   10.12 ms per token,    98.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1107.70 ms /    14 runs   (   79.12 ms per token,    12.64 tokens per second)\n",
      "llama_print_timings:       total time =    1504.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"63\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.42 ms /     5 runs   (    0.48 ms per token,  2066.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.37 ms /    23 tokens (   10.93 ms per token,    91.50 tokens per second)\n",
      "llama_print_timings:        eval time =     316.62 ms /     4 runs   (   79.16 ms per token,    12.63 tokens per second)\n",
      "llama_print_timings:       total time =     609.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.80 ms /     8 runs   (    0.48 ms per token,  2105.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.29 ms /    24 tokens (   10.51 ms per token,    95.13 tokens per second)\n",
      "llama_print_timings:        eval time =     554.68 ms /     7 runs   (   79.24 ms per token,    12.62 tokens per second)\n",
      "llama_print_timings:       total time =     869.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Barney Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /     9 runs   (    0.90 ms per token,  1116.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1387.40 ms /   186 tokens (    7.46 ms per token,   134.06 tokens per second)\n",
      "llama_print_timings:        eval time =     624.04 ms /     8 runs   (   78.01 ms per token,    12.82 tokens per second)\n",
      "llama_print_timings:       total time =    2108.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"229 118 4234\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.72 ms /    15 runs   (    0.71 ms per token,  1398.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.03 ms /    25 tokens (   10.08 ms per token,    99.19 tokens per second)\n",
      "llama_print_timings:        eval time =    1096.19 ms /    14 runs   (   78.30 ms per token,    12.77 tokens per second)\n",
      "llama_print_timings:       total time =    1479.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /     7 runs   (    0.76 ms per token,  1311.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.25 ms /    23 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     463.00 ms /     6 runs   (   77.17 ms per token,    12.96 tokens per second)\n",
      "llama_print_timings:       total time =     776.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.32 ms /     2 runs   (    0.66 ms per token,  1517.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.59 ms /    24 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =      76.77 ms /     1 runs   (   76.77 ms per token,    13.03 tokens per second)\n",
      "llama_print_timings:       total time =     344.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Felton Ryan\", \"Doctor Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    16 runs   (    0.50 ms per token,  1988.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1156.11 ms /   158 tokens (    7.32 ms per token,   136.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.64 ms /    15 runs   (   78.44 ms per token,    12.75 tokens per second)\n",
      "llama_print_timings:       total time =    2468.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"546 932 4334\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.58 ms /    15 runs   (    0.71 ms per token,  1417.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.35 ms /    25 tokens (   10.05 ms per token,    99.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1080.76 ms /    14 runs   (   77.20 ms per token,    12.95 tokens per second)\n",
      "llama_print_timings:       total time =    1487.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /     9 runs   (    0.33 ms per token,  3032.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.50 ms /    23 tokens (   10.93 ms per token,    91.45 tokens per second)\n",
      "llama_print_timings:        eval time =     624.85 ms /     8 runs   (   78.11 ms per token,    12.80 tokens per second)\n",
      "llama_print_timings:       total time =     935.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.22 ms /     8 runs   (    0.65 ms per token,  1531.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.83 ms /    24 tokens (   10.45 ms per token,    95.68 tokens per second)\n",
      "llama_print_timings:        eval time =     538.01 ms /     7 runs   (   76.86 ms per token,    13.01 tokens per second)\n",
      "llama_print_timings:       total time =     859.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ezra Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.61 ms /     9 runs   (    0.51 ms per token,  1951.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1142.08 ms /   139 tokens (    8.22 ms per token,   121.71 tokens per second)\n",
      "llama_print_timings:        eval time =     631.04 ms /     8 runs   (   78.88 ms per token,    12.68 tokens per second)\n",
      "llama_print_timings:       total time =    1848.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"326 138 7517\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.07 ms /    15 runs   (    0.47 ms per token,  2120.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.58 ms /    25 tokens (   10.22 ms per token,    97.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.72 ms /    14 runs   (   81.48 ms per token,    12.27 tokens per second)\n",
      "llama_print_timings:       total time =    1505.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"25-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.36 ms /     9 runs   (    0.60 ms per token,  1680.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.44 ms /    23 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =     618.86 ms /     8 runs   (   77.36 ms per token,    12.93 tokens per second)\n",
      "llama_print_timings:       total time =     950.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.58 ms /     8 runs   (    0.45 ms per token,  2237.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     249.84 ms /    24 tokens (   10.41 ms per token,    96.06 tokens per second)\n",
      "llama_print_timings:        eval time =     550.82 ms /     7 runs   (   78.69 ms per token,    12.71 tokens per second)\n",
      "llama_print_timings:       total time =     857.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Darwin Aufderhar\", \"Dr. Clayton Jast\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.11 ms /    17 runs   (    0.59 ms per token,  1681.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1380.51 ms /   177 tokens (    7.80 ms per token,   128.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.42 ms /    16 runs   (   77.96 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    2785.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 946 0098\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    15 runs   (    0.58 ms per token,  1735.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.76 ms /    25 tokens (   10.07 ms per token,    99.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1102.13 ms /    14 runs   (   78.72 ms per token,    12.70 tokens per second)\n",
      "llama_print_timings:       total time =    1471.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3738.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.48 ms /    23 tokens (   10.89 ms per token,    91.82 tokens per second)\n",
      "llama_print_timings:        eval time =      77.80 ms /     1 runs   (   77.80 ms per token,    12.85 tokens per second)\n",
      "llama_print_timings:       total time =     337.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.53 ms /     7 runs   (    0.65 ms per token,  1543.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.97 ms /    24 tokens (   10.46 ms per token,    95.63 tokens per second)\n",
      "llama_print_timings:        eval time =     464.59 ms /     6 runs   (   77.43 ms per token,    12.91 tokens per second)\n",
      "llama_print_timings:       total time =     778.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Mauro Paucek\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.70 ms /    18 runs   (    0.65 ms per token,  1538.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2879.06 ms /   379 tokens (    7.60 ms per token,   131.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1350.44 ms /    17 runs   (   79.44 ms per token,    12.59 tokens per second)\n",
      "llama_print_timings:       total time =    4413.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"183 236 1107\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.42 ms /    15 runs   (    0.69 ms per token,  1439.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.28 ms /    25 tokens (   10.25 ms per token,    97.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1173.41 ms /    14 runs   (   83.82 ms per token,    11.93 tokens per second)\n",
      "llama_print_timings:       total time =    1560.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     2 runs   (    0.25 ms per token,  3944.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.12 ms /    23 tokens (   11.05 ms per token,    90.51 tokens per second)\n",
      "llama_print_timings:        eval time =      79.34 ms /     1 runs   (   79.34 ms per token,    12.60 tokens per second)\n",
      "llama_print_timings:       total time =     341.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.55 ms /     8 runs   (    0.57 ms per token,  1756.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.53 ms /    24 tokens (   10.65 ms per token,    93.92 tokens per second)\n",
      "llama_print_timings:        eval time =     559.37 ms /     7 runs   (   79.91 ms per token,    12.51 tokens per second)\n",
      "llama_print_timings:       total time =     882.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Odis Heidenreich\", \"Dr. Kai Mann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.10 ms /    17 runs   (    0.65 ms per token,  1530.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1370.69 ms /   170 tokens (    8.06 ms per token,   124.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.87 ms /    16 runs   (   77.93 ms per token,    12.83 tokens per second)\n",
      "llama_print_timings:       total time =    2763.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"659 488 7423\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.92 ms /    15 runs   (    0.53 ms per token,  1894.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.91 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.47 ms /    14 runs   (   80.60 ms per token,    12.41 tokens per second)\n",
      "llama_print_timings:       total time =    1493.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.97 ms /     9 runs   (    0.44 ms per token,  2266.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     251.77 ms /    23 tokens (   10.95 ms per token,    91.35 tokens per second)\n",
      "llama_print_timings:        eval time =     646.96 ms /     8 runs   (   80.87 ms per token,    12.37 tokens per second)\n",
      "llama_print_timings:       total time =     950.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.56 ms /     8 runs   (    0.44 ms per token,  2249.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     250.42 ms /    24 tokens (   10.43 ms per token,    95.84 tokens per second)\n",
      "llama_print_timings:        eval time =     557.10 ms /     7 runs   (   79.59 ms per token,    12.56 tokens per second)\n",
      "llama_print_timings:       total time =     870.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rex Hessel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /     9 runs   (    0.45 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.02 ms /   179 tokens (    7.84 ms per token,   127.49 tokens per second)\n",
      "llama_print_timings:        eval time =     641.76 ms /     8 runs   (   80.22 ms per token,    12.47 tokens per second)\n",
      "llama_print_timings:       total time =    2104.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /     6 runs   (    0.21 ms per token,  4780.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.83 ms /    25 tokens (   10.19 ms per token,    98.10 tokens per second)\n",
      "llama_print_timings:        eval time =     489.95 ms /     5 runs   (   97.99 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =     765.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"62-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /     9 runs   (    0.36 ms per token,  2782.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.30 ms /    23 tokens (   11.14 ms per token,    89.74 tokens per second)\n",
      "llama_print_timings:        eval time =     743.68 ms /     8 runs   (   92.96 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =    1042.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.22 ms per token,  4618.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.37 ms /    24 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =     117.73 ms /     1 runs   (  117.73 ms per token,     8.49 tokens per second)\n",
      "llama_print_timings:       total time =     386.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. My Haag\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    17 runs   (    0.40 ms per token,  2517.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1404.69 ms /   165 tokens (    8.51 ms per token,   117.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1409.36 ms /    16 runs   (   88.08 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    2932.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"646 863 5903\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      34.59 ms /    15 runs   (    2.31 ms per token,   433.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     252.00 ms /    25 tokens (   10.08 ms per token,    99.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1300.99 ms /    14 runs   (   92.93 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =    1683.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     5 runs   (    0.27 ms per token,  3652.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.14 ms /    23 tokens (   11.22 ms per token,    89.10 tokens per second)\n",
      "llama_print_timings:        eval time =     466.74 ms /     4 runs   (  116.69 ms per token,     8.57 tokens per second)\n",
      "llama_print_timings:       total time =     815.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    11 runs   (    0.30 ms per token,  3313.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.76 ms /    24 tokens (   11.87 ms per token,    84.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1132.02 ms /    10 runs   (  113.20 ms per token,     8.83 tokens per second)\n",
      "llama_print_timings:       total time =    1481.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2389.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.81 ms /   186 tokens (    7.81 ms per token,   128.12 tokens per second)\n",
      "llama_print_timings:        eval time =      88.33 ms /     1 runs   (   88.33 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    1552.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 223 9424\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    15 runs   (    0.43 ms per token,  2344.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.09 ms /    25 tokens (   10.32 ms per token,    96.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.70 ms /    14 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1600.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2351.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.60 ms /    23 tokens (   11.20 ms per token,    89.29 tokens per second)\n",
      "llama_print_timings:        eval time =     692.09 ms /     8 runs   (   86.51 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1011.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.49 ms /     8 runs   (    0.44 ms per token,  2290.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.65 ms /    24 tokens (   10.78 ms per token,    92.79 tokens per second)\n",
      "llama_print_timings:        eval time =     614.62 ms /     7 runs   (   87.80 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =     922.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.76 ms /     2 runs   (    0.38 ms per token,  2642.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3114.95 ms /   376 tokens (    8.28 ms per token,   120.71 tokens per second)\n",
      "llama_print_timings:        eval time =      94.95 ms /     1 runs   (   94.95 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =    3220.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"481 704 3507\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.15 ms /    15 runs   (    0.41 ms per token,  2439.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.87 ms /    25 tokens (   10.55 ms per token,    94.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.02 ms /    14 runs   (   93.43 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =    1666.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9132.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.23 ms /    23 tokens (   11.44 ms per token,    87.38 tokens per second)\n",
      "llama_print_timings:        eval time =     100.34 ms /     1 runs   (  100.34 ms per token,     9.97 tokens per second)\n",
      "llama_print_timings:       total time =     372.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\", \"Social isolation\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.16 ms /    14 runs   (    0.44 ms per token,  2272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.18 ms /    24 tokens (   10.92 ms per token,    91.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.15 ms /    13 runs   (   95.93 ms per token,    10.42 tokens per second)\n",
      "llama_print_timings:       total time =    1604.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Manual Moore\", \"Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.01 ms /    13 runs   (    0.31 ms per token,  3238.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1485.41 ms /   180 tokens (    8.25 ms per token,   121.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1136.78 ms /    12 runs   (   94.73 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =    2689.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 591 0998\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2069.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.35 ms /    25 tokens (   10.33 ms per token,    96.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.04 ms /    14 runs   (   90.29 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1616.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     2 runs   (    0.63 ms per token,  1577.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.56 ms /    23 tokens (   11.50 ms per token,    86.94 tokens per second)\n",
      "llama_print_timings:        eval time =     107.87 ms /     1 runs   (  107.87 ms per token,     9.27 tokens per second)\n",
      "llama_print_timings:       total time =     381.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     7 runs   (    0.45 ms per token,  2227.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    24 tokens (   10.67 ms per token,    93.71 tokens per second)\n",
      "llama_print_timings:        eval time =     518.97 ms /     6 runs   (   86.50 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     819.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Isiah Lehner\", \"Dr. Randa Ritchie\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    18 runs   (    0.42 ms per token,  2400.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.92 ms /   182 tokens (    7.94 ms per token,   125.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1531.42 ms /    17 runs   (   90.08 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    3081.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"464 313 0197\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.66 ms /    15 runs   (    0.38 ms per token,  2648.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.41 ms /    25 tokens (   10.58 ms per token,    94.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.55 ms /    14 runs   (   93.18 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =    1658.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     2 runs   (    0.33 ms per token,  3053.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.27 ms /    23 tokens (   11.19 ms per token,    89.40 tokens per second)\n",
      "llama_print_timings:        eval time =      89.59 ms /     1 runs   (   89.59 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =     355.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2844.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.36 ms /    24 tokens (   10.72 ms per token,    93.26 tokens per second)\n",
      "llama_print_timings:        eval time =      90.61 ms /     1 runs   (   90.61 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     359.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Colleen Kemmer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.69 ms /    12 runs   (    0.31 ms per token,  3250.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1754.68 ms /   217 tokens (    8.09 ms per token,   123.67 tokens per second)\n",
      "llama_print_timings:        eval time =    1064.12 ms /    11 runs   (   96.74 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    2903.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"168 761 2950\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.47 ms /    15 runs   (    0.43 ms per token,  2316.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.92 ms /    25 tokens (   10.64 ms per token,    94.01 tokens per second)\n",
      "llama_print_timings:        eval time =    1392.99 ms /    14 runs   (   99.50 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    1751.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.44 ms /     2 runs   (    0.22 ms per token,  4587.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.03 ms /    23 tokens (   11.18 ms per token,    89.48 tokens per second)\n",
      "llama_print_timings:        eval time =     100.73 ms /     1 runs   (  100.73 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =     365.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\", \"chronic obstructive bronchitis\", \"anemia\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.04 ms /    25 runs   (    0.44 ms per token,  2264.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.23 ms /    24 tokens (   10.76 ms per token,    92.94 tokens per second)\n",
      "llama_print_timings:        eval time =    2090.37 ms /    24 runs   (   87.10 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    2526.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lona Cruickshank\", \"Dr. Thanh Weber\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    17 runs   (    0.41 ms per token,  2435.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.19 ms /   139 tokens (    8.45 ms per token,   118.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1404.96 ms /    16 runs   (   87.81 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    2694.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 901 4234\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.10 ms /    15 runs   (    0.61 ms per token,  1648.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.98 ms /    25 tokens (   10.28 ms per token,    97.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1224.38 ms /    14 runs   (   87.46 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =    1597.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.25 ms /     2 runs   (    0.13 ms per token,  7905.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.52 ms /    23 tokens (   11.11 ms per token,    90.01 tokens per second)\n",
      "llama_print_timings:        eval time =     101.32 ms /     1 runs   (  101.32 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =     360.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /     8 runs   (    0.54 ms per token,  1848.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.04 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     613.24 ms /     7 runs   (   87.61 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     928.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Noel Herman\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.72 ms /    17 runs   (    0.51 ms per token,  1948.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2760.98 ms /   352 tokens (    7.84 ms per token,   127.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1432.40 ms /    16 runs   (   89.53 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    4320.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"564 185 3103\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    15 runs   (    0.37 ms per token,  2700.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.81 ms /    25 tokens (   10.55 ms per token,    94.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1258.33 ms /    14 runs   (   89.88 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    1603.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     9 runs   (    0.37 ms per token,  2670.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.29 ms /    23 tokens (   11.32 ms per token,    88.36 tokens per second)\n",
      "llama_print_timings:        eval time =     711.99 ms /     8 runs   (   89.00 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1031.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4796.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.81 ms /    24 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =     103.60 ms /     1 runs   (  103.60 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     371.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Eleonore Moore\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.66 ms /    15 runs   (    0.58 ms per token,  1732.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.46 ms /   185 tokens (    7.73 ms per token,   129.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1225.19 ms /    14 runs   (   87.51 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =    2762.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 352 1355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.04 ms /    15 runs   (    0.54 ms per token,  1864.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.00 ms /    25 tokens (   10.36 ms per token,    96.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1231.78 ms /    14 runs   (   87.98 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    1580.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"0 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.73 ms /     6 runs   (    0.46 ms per token,  2193.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    23 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =     432.82 ms /     5 runs   (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     729.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.96 ms /     7 runs   (    0.57 ms per token,  1767.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.71 ms /    24 tokens (   10.74 ms per token,    93.13 tokens per second)\n",
      "llama_print_timings:        eval time =     523.94 ms /     6 runs   (   87.32 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     827.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Cole Monahan\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.78 ms /    16 runs   (    0.55 ms per token,  1821.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.68 ms /   167 tokens (    8.45 ms per token,   118.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.00 ms /    15 runs   (   87.40 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2830.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"836 256 9640\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.15 ms /    15 runs   (    0.54 ms per token,  1840.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.18 ms /    25 tokens (   10.33 ms per token,    96.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1219.31 ms /    14 runs   (   87.09 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    1575.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /     9 runs   (    0.41 ms per token,  2457.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    23 tokens (   11.16 ms per token,    89.58 tokens per second)\n",
      "llama_print_timings:        eval time =     700.59 ms /     8 runs   (   87.57 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    1010.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.25 ms /     8 runs   (    0.66 ms per token,  1523.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.44 ms /    24 tokens (   10.69 ms per token,    93.59 tokens per second)\n",
      "llama_print_timings:        eval time =     609.49 ms /     7 runs   (   87.07 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     922.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Raymonde Ryan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /    10 runs   (    0.39 ms per token,  2587.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.12 ms /   191 tokens (    7.57 ms per token,   132.08 tokens per second)\n",
      "llama_print_timings:        eval time =     784.83 ms /     9 runs   (   87.20 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    2290.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"222 237 3271\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.02 ms /    15 runs   (    0.53 ms per token,  1870.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.60 ms /    25 tokens (   10.42 ms per token,    95.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.50 ms /    14 runs   (   86.96 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1576.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.76 ms /     9 runs   (    0.31 ms per token,  3259.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.02 ms /    23 tokens (   11.17 ms per token,    89.49 tokens per second)\n",
      "llama_print_timings:        eval time =     714.51 ms /     8 runs   (   89.31 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1023.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.78 ms /     8 runs   (    0.47 ms per token,  2114.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.69 ms /    24 tokens (   10.78 ms per token,    92.78 tokens per second)\n",
      "llama_print_timings:        eval time =     613.41 ms /     7 runs   (   87.63 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     927.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Theron Langworth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     8 runs   (    0.43 ms per token,  2335.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.09 ms /   150 tokens (    7.89 ms per token,   126.79 tokens per second)\n",
      "llama_print_timings:        eval time =     622.90 ms /     7 runs   (   88.99 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1844.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 675 6694\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.72 ms /    15 runs   (    0.51 ms per token,  1943.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.83 ms /    25 tokens (   10.31 ms per token,    96.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.49 ms /    14 runs   (   88.53 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    1593.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"2-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /     8 runs   (    0.58 ms per token,  1726.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    23 tokens (   11.14 ms per token,    89.80 tokens per second)\n",
      "llama_print_timings:        eval time =     605.56 ms /     7 runs   (   86.51 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     921.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     2 runs   (    0.34 ms per token,  2919.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.94 ms /    24 tokens (   10.96 ms per token,    91.28 tokens per second)\n",
      "llama_print_timings:        eval time =     113.56 ms /     1 runs   (  113.56 ms per token,     8.81 tokens per second)\n",
      "llama_print_timings:       total time =     386.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Odis Boehm\", \"Dr. Kala Wolf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.61 ms /    15 runs   (    0.17 ms per token,  5747.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1446.18 ms /   161 tokens (    8.98 ms per token,   111.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1311.71 ms /    14 runs   (   93.69 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    2813.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 565 5337\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.88 ms /    15 runs   (    0.19 ms per token,  5201.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.27 ms /    25 tokens (   10.53 ms per token,    94.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1299.70 ms /    14 runs   (   92.84 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =    1614.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.11 ms per token,  8888.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.99 ms /    23 tokens (   11.17 ms per token,    89.50 tokens per second)\n",
      "llama_print_timings:        eval time =     101.81 ms /     1 runs   (  101.81 ms per token,     9.82 tokens per second)\n",
      "llama_print_timings:       total time =     362.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.21 ms /    24 tokens (   10.76 ms per token,    92.95 tokens per second)\n",
      "llama_print_timings:        eval time =      94.51 ms /     1 runs   (   94.51 ms per token,    10.58 tokens per second)\n",
      "llama_print_timings:       total time =     357.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Reynaldo Marvin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /    10 runs   (    0.21 ms per token,  4775.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3033.21 ms /   366 tokens (    8.29 ms per token,   120.66 tokens per second)\n",
      "llama_print_timings:        eval time =     862.67 ms /     9 runs   (   95.85 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    3924.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"686 337 6118\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.34 ms /    15 runs   (    0.16 ms per token,  6402.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.85 ms /    25 tokens (   10.59 ms per token,    94.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1325.60 ms /    14 runs   (   94.69 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =    1644.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     9 runs   (    0.09 ms per token, 10588.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.61 ms /    23 tokens (   11.46 ms per token,    87.25 tokens per second)\n",
      "llama_print_timings:        eval time =     764.97 ms /     8 runs   (   95.62 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =    1052.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    11 runs   (    0.15 ms per token,  6790.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.54 ms /    24 tokens (   10.98 ms per token,    91.07 tokens per second)\n",
      "llama_print_timings:        eval time =     957.84 ms /    10 runs   (   95.78 ms per token,    10.44 tokens per second)\n",
      "llama_print_timings:       total time =    1256.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ricardo Tillman\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /    17 runs   (    0.13 ms per token,  7678.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.21 ms /   172 tokens (    8.30 ms per token,   120.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1471.37 ms /    16 runs   (   91.96 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =    2951.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"926 266 0702\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /    15 runs   (    0.13 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.72 ms /    25 tokens (   10.39 ms per token,    96.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1308.62 ms /    14 runs   (   93.47 ms per token,    10.70 tokens per second)\n",
      "llama_print_timings:       total time =    1605.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     9 runs   (    0.11 ms per token,  9118.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.10 ms /    23 tokens (   11.22 ms per token,    89.11 tokens per second)\n",
      "llama_print_timings:        eval time =     740.22 ms /     8 runs   (   92.53 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =    1018.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     8 runs   (    0.11 ms per token,  9478.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.07 ms /    24 tokens (   10.71 ms per token,    93.36 tokens per second)\n",
      "llama_print_timings:        eval time =     646.56 ms /     7 runs   (   92.37 ms per token,    10.83 tokens per second)\n",
      "llama_print_timings:       total time =     920.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Spencer Treutel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     9 runs   (    0.10 ms per token, 10452.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.43 ms /   136 tokens (    8.61 ms per token,   116.10 tokens per second)\n",
      "llama_print_timings:        eval time =     746.89 ms /     8 runs   (   93.36 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =    1944.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 396 6418\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /    15 runs   (    0.15 ms per token,  6513.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.40 ms /    25 tokens (   10.38 ms per token,    96.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1303.24 ms /    14 runs   (   93.09 ms per token,    10.74 tokens per second)\n",
      "llama_print_timings:       total time =    1612.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10526.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.60 ms /    23 tokens (   11.11 ms per token,    89.99 tokens per second)\n",
      "llama_print_timings:        eval time =     116.81 ms /     1 runs   (  116.81 ms per token,     8.56 tokens per second)\n",
      "llama_print_timings:       total time =     376.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10810.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.06 ms /    24 tokens (   10.71 ms per token,    93.37 tokens per second)\n",
      "llama_print_timings:        eval time =     101.67 ms /     1 runs   (  101.67 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =     363.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosalba Balistreri\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.51 ms /    12 runs   (    0.13 ms per token,  7936.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.92 ms /   133 tokens (    8.80 ms per token,   113.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1025.16 ms /    11 runs   (   93.20 ms per token,    10.73 tokens per second)\n",
      "llama_print_timings:       total time =    2241.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"877 766 2864\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /    15 runs   (    0.26 ms per token,  3811.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     275.59 ms /    25 tokens (   11.02 ms per token,    90.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1493.73 ms /    14 runs   (  106.69 ms per token,     9.37 tokens per second)\n",
      "llama_print_timings:       total time =    1897.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     9 runs   (    0.31 ms per token,  3208.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.87 ms /    23 tokens (   11.60 ms per token,    86.19 tokens per second)\n",
      "llama_print_timings:        eval time =     773.51 ms /     8 runs   (   96.69 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    1087.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     8 runs   (    0.33 ms per token,  3001.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.23 ms /    24 tokens (   10.68 ms per token,    93.67 tokens per second)\n",
      "llama_print_timings:        eval time =     703.19 ms /     7 runs   (  100.46 ms per token,     9.95 tokens per second)\n",
      "llama_print_timings:       total time =     994.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Saul Hickle\", \"Dr. Carlton Koch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.40 ms /    17 runs   (    0.38 ms per token,  2657.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1492.32 ms /   186 tokens (    8.02 ms per token,   124.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1484.12 ms /    16 runs   (   92.76 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    3082.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"296 223 0294\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    15 runs   (    0.39 ms per token,  2560.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     273.75 ms /    25 tokens (   10.95 ms per token,    91.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1483.58 ms /    14 runs   (  105.97 ms per token,     9.44 tokens per second)\n",
      "llama_print_timings:       total time =    1839.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /     9 runs   (    0.31 ms per token,  3211.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.59 ms /    23 tokens (   12.55 ms per token,    79.70 tokens per second)\n",
      "llama_print_timings:        eval time =     788.85 ms /     8 runs   (   98.61 ms per token,    10.14 tokens per second)\n",
      "llama_print_timings:       total time =    1120.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2148.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.59 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =      89.86 ms /     1 runs   (   89.86 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =     358.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jamison Dare\", \"Alpha Yost\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    13 runs   (    0.51 ms per token,  1973.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.93 ms /   175 tokens (    8.23 ms per token,   121.53 tokens per second)\n",
      "llama_print_timings:        eval time =    1162.47 ms /    12 runs   (   96.87 ms per token,    10.32 tokens per second)\n",
      "llama_print_timings:       total time =    2680.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 489 5792\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    15 runs   (    0.39 ms per token,  2582.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.76 ms /    25 tokens (   10.43 ms per token,    95.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1395.88 ms /    14 runs   (   99.71 ms per token,    10.03 tokens per second)\n",
      "llama_print_timings:       total time =    1740.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"6 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.15 ms /     6 runs   (    0.36 ms per token,  2790.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.43 ms /    23 tokens (   11.37 ms per token,    87.98 tokens per second)\n",
      "llama_print_timings:        eval time =     446.72 ms /     5 runs   (   89.34 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =     742.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /    13 runs   (    0.31 ms per token,  3186.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.82 ms /    24 tokens (   10.87 ms per token,    92.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1111.35 ms /    12 runs   (   92.61 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =    1435.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alphonse Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.74 ms /    12 runs   (    0.48 ms per token,  2089.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1205.32 ms /   148 tokens (    8.14 ms per token,   122.79 tokens per second)\n",
      "llama_print_timings:        eval time =     965.50 ms /    11 runs   (   87.77 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    2254.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"305 184 3465\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.75 ms /    15 runs   (    0.45 ms per token,  2220.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.94 ms /    25 tokens (   10.36 ms per token,    96.55 tokens per second)\n",
      "llama_print_timings:        eval time =    1265.69 ms /    14 runs   (   90.41 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =    1618.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /     9 runs   (    0.47 ms per token,  2108.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.94 ms /    23 tokens (   11.17 ms per token,    89.52 tokens per second)\n",
      "llama_print_timings:        eval time =     695.59 ms /     8 runs   (   86.95 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     997.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.11 ms /     8 runs   (    0.51 ms per token,  1948.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.69 ms /    24 tokens (   10.65 ms per token,    93.86 tokens per second)\n",
      "llama_print_timings:        eval time =     603.45 ms /     7 runs   (   86.21 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     912.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Roberta Jenkins\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /     9 runs   (    0.58 ms per token,  1719.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.58 ms /   163 tokens (    8.66 ms per token,   115.47 tokens per second)\n",
      "llama_print_timings:        eval time =     693.64 ms /     8 runs   (   86.71 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    2165.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"638 551 4355\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    15 runs   (    0.46 ms per token,  2172.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.94 ms /    25 tokens (   10.28 ms per token,    97.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1328.27 ms /    14 runs   (   94.88 ms per token,    10.54 tokens per second)\n",
      "llama_print_timings:       total time =    1681.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     4 runs   (    0.37 ms per token,  2675.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.49 ms /    23 tokens (   11.50 ms per token,    86.96 tokens per second)\n",
      "llama_print_timings:        eval time =     302.38 ms /     3 runs   (  100.79 ms per token,     9.92 tokens per second)\n",
      "llama_print_timings:       total time =     583.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.18 ms /    11 runs   (    0.38 ms per token,  2633.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.38 ms /    24 tokens (   10.81 ms per token,    92.53 tokens per second)\n",
      "llama_print_timings:        eval time =     903.72 ms /    10 runs   (   90.37 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1225.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Garth Kuhlman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.43 ms /    10 runs   (    0.64 ms per token,  1554.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1489.88 ms /   163 tokens (    9.14 ms per token,   109.41 tokens per second)\n",
      "llama_print_timings:        eval time =     791.49 ms /     9 runs   (   87.94 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    2358.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 979 6136\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.78 ms /    15 runs   (    0.39 ms per token,  2593.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     268.45 ms /    25 tokens (   10.74 ms per token,    93.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.97 ms /    14 runs   (   95.28 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =    1701.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /     7 runs   (    0.52 ms per token,  1905.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.64 ms /    23 tokens (   11.16 ms per token,    89.62 tokens per second)\n",
      "llama_print_timings:        eval time =     524.78 ms /     6 runs   (   87.46 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     829.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chief complaint\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.70 ms /     7 runs   (    0.24 ms per token,  4124.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.23 ms /    24 tokens (   10.76 ms per token,    92.94 tokens per second)\n",
      "llama_print_timings:        eval time =     573.31 ms /     6 runs   (   95.55 ms per token,    10.47 tokens per second)\n",
      "llama_print_timings:       total time =     860.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Micaela McLaughlin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    13 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1730.16 ms /   202 tokens (    8.57 ms per token,   116.75 tokens per second)\n",
      "llama_print_timings:        eval time =    1140.14 ms /    12 runs   (   95.01 ms per token,    10.53 tokens per second)\n",
      "llama_print_timings:       total time =    2943.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"872 109 4607\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    15 runs   (    0.36 ms per token,  2772.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.57 ms /    25 tokens (   10.38 ms per token,    96.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1301.50 ms /    14 runs   (   92.96 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =    1674.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"34-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /     9 runs   (    0.43 ms per token,  2320.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.52 ms /    23 tokens (   11.20 ms per token,    89.31 tokens per second)\n",
      "llama_print_timings:        eval time =     707.31 ms /     8 runs   (   88.41 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =    1023.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.94 ms /    13 runs   (    0.46 ms per token,  2187.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.59 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1057.82 ms /    12 runs   (   88.15 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1395.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Tammara McDermott\", \"Doctor Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.73 ms /    21 runs   (    0.46 ms per token,  2157.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.17 ms /   157 tokens (    7.57 ms per token,   132.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1751.24 ms /    20 runs   (   87.56 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    3087.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"752 354 8769\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2257.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1287.04 ms /    14 runs   (   91.93 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =    1645.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     2 runs   (    0.33 ms per token,  3003.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.73 ms /    23 tokens (   11.25 ms per token,    88.90 tokens per second)\n",
      "llama_print_timings:        eval time =      94.28 ms /     1 runs   (   94.28 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     361.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     8 runs   (    0.39 ms per token,  2541.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    24 tokens (   10.70 ms per token,    93.43 tokens per second)\n",
      "llama_print_timings:        eval time =     633.51 ms /     7 runs   (   90.50 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =     928.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Daryl Rosenbaum\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2560.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1176.31 ms /   140 tokens (    8.40 ms per token,   119.02 tokens per second)\n",
      "llama_print_timings:        eval time =     797.22 ms /     9 runs   (   88.58 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    2038.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 122 3984\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2127.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.02 ms /    25 tokens (   10.32 ms per token,    96.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.45 ms /    14 runs   (   87.68 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    1586.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.45 ms /     2 runs   (    0.23 ms per token,  4434.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.26 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =      93.61 ms /     1 runs   (   93.61 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =     360.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /     8 runs   (    0.35 ms per token,  2886.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.13 ms /    24 tokens (   10.67 ms per token,    93.70 tokens per second)\n",
      "llama_print_timings:        eval time =     612.48 ms /     7 runs   (   87.50 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     911.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ezekiel Bogan\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.81 ms /    15 runs   (    0.45 ms per token,  2202.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2745.94 ms /   349 tokens (    7.87 ms per token,   127.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.89 ms /    14 runs   (   89.35 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    4104.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 954 2980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.13 ms /    15 runs   (    0.54 ms per token,  1845.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.37 ms /    25 tokens (   10.57 ms per token,    94.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.85 ms /    14 runs   (   88.99 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1611.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.08 ms /    23 tokens (   11.35 ms per token,    88.10 tokens per second)\n",
      "llama_print_timings:        eval time =      88.83 ms /     1 runs   (   88.83 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     360.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.29 ms /     8 runs   (    0.29 ms per token,  3491.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.07 ms /    24 tokens (   10.92 ms per token,    91.58 tokens per second)\n",
      "llama_print_timings:        eval time =     630.57 ms /     7 runs   (   90.08 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =     925.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Jena Ruecker\", \"doctor Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.27 ms /    21 runs   (    0.54 ms per token,  1863.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1170.14 ms /   136 tokens (    8.60 ms per token,   116.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1717.54 ms /    20 runs   (   85.88 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    3054.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"521 691 9427\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.13 ms /    15 runs   (    0.41 ms per token,  2448.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.20 ms /    25 tokens (   10.37 ms per token,    96.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1229.57 ms /    14 runs   (   87.83 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    1574.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     2 runs   (    0.33 ms per token,  2989.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.51 ms /    23 tokens (   11.11 ms per token,    90.02 tokens per second)\n",
      "llama_print_timings:        eval time =      87.18 ms /     1 runs   (   87.18 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =     353.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.71 ms /     2 runs   (    0.35 ms per token,  2820.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.29 ms /    24 tokens (   10.72 ms per token,    93.28 tokens per second)\n",
      "llama_print_timings:        eval time =      87.08 ms /     1 runs   (   87.08 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     353.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Clarence Jast\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.18 ms /    17 runs   (    0.54 ms per token,  1852.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.05 ms /   184 tokens (    7.85 ms per token,   127.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1391.31 ms /    16 runs   (   86.96 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    2964.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"285 135 3102\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.58 ms /    15 runs   (    0.44 ms per token,  2280.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.26 ms /    25 tokens (   10.37 ms per token,    96.43 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.97 ms /    14 runs   (   88.07 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    1588.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.32 ms per token,  3159.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.64 ms /    23 tokens (   11.16 ms per token,    89.62 tokens per second)\n",
      "llama_print_timings:        eval time =      88.29 ms /     1 runs   (   88.29 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     353.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     8 runs   (    0.50 ms per token,  2010.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.99 ms /    24 tokens (   10.75 ms per token,    93.03 tokens per second)\n",
      "llama_print_timings:        eval time =     603.31 ms /     7 runs   (   86.19 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     914.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mi Rogahn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.00 ms /     9 runs   (    0.44 ms per token,  2250.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.11 ms /   153 tokens (    7.77 ms per token,   128.78 tokens per second)\n",
      "llama_print_timings:        eval time =     704.54 ms /     8 runs   (   88.07 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    1945.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"295 375 7998\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.68 ms /    15 runs   (    0.51 ms per token,  1953.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.78 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.47 ms /    14 runs   (   86.32 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1566.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /     7 runs   (    0.43 ms per token,  2300.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.82 ms /    23 tokens (   11.17 ms per token,    89.56 tokens per second)\n",
      "llama_print_timings:        eval time =     532.15 ms /     6 runs   (   88.69 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     840.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     2 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.90 ms /    24 tokens (   10.66 ms per token,    93.79 tokens per second)\n",
      "llama_print_timings:        eval time =      90.17 ms /     1 runs   (   90.17 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     355.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Shira Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.72 ms /    10 runs   (    0.47 ms per token,  2119.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.64 ms /   155 tokens (    7.64 ms per token,   130.84 tokens per second)\n",
      "llama_print_timings:        eval time =     778.90 ms /     9 runs   (   86.54 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    2032.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"798 647 4893\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    15 runs   (    0.41 ms per token,  2423.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.66 ms /    25 tokens (   10.31 ms per token,    97.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1230.36 ms /    14 runs   (   87.88 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1575.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"41 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.15 ms /     7 runs   (    0.45 ms per token,  2224.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.75 ms /    23 tokens (   11.08 ms per token,    90.29 tokens per second)\n",
      "llama_print_timings:        eval time =     515.36 ms /     6 runs   (   85.89 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     818.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2376.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.35 ms /    24 tokens (   10.68 ms per token,    93.62 tokens per second)\n",
      "llama_print_timings:        eval time =     607.29 ms /     7 runs   (   86.76 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     916.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Christina Treutel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /    11 runs   (    0.45 ms per token,  2204.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1928.10 ms /   228 tokens (    8.46 ms per token,   118.25 tokens per second)\n",
      "llama_print_timings:        eval time =     879.92 ms /    10 runs   (   87.99 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    2884.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"874 976 7362\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    15 runs   (    0.49 ms per token,  2053.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.10 ms /    25 tokens (   10.36 ms per token,    96.49 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.29 ms /    14 runs   (   87.02 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    1579.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.98 ms /     9 runs   (    0.44 ms per token,  2258.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.97 ms /    23 tokens (   11.17 ms per token,    89.50 tokens per second)\n",
      "llama_print_timings:        eval time =     694.73 ms /     8 runs   (   86.84 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    1018.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     8 runs   (    0.44 ms per token,  2259.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.00 ms /    24 tokens (   10.75 ms per token,    93.02 tokens per second)\n",
      "llama_print_timings:        eval time =     606.11 ms /     7 runs   (   86.59 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     923.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Marquis Pfeffer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.47 ms /     8 runs   (    0.68 ms per token,  1462.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.41 ms /   176 tokens (    8.06 ms per token,   124.00 tokens per second)\n",
      "llama_print_timings:        eval time =     603.30 ms /     7 runs   (   86.19 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    2075.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 912 7729\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1991.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.87 ms /    25 tokens (   10.35 ms per token,    96.57 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.44 ms /    14 runs   (   85.75 ms per token,    11.66 tokens per second)\n",
      "llama_print_timings:       total time =    1560.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.51 ms /     8 runs   (    0.56 ms per token,  1775.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.56 ms /    23 tokens (   11.15 ms per token,    89.65 tokens per second)\n",
      "llama_print_timings:        eval time =     597.97 ms /     7 runs   (   85.42 ms per token,    11.71 tokens per second)\n",
      "llama_print_timings:       total time =     913.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.30 ms /     7 runs   (    0.33 ms per token,  3038.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.91 ms /    24 tokens (   10.79 ms per token,    92.70 tokens per second)\n",
      "llama_print_timings:        eval time =     529.82 ms /     6 runs   (   88.30 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     822.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Norman Littel\", \"Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.02 ms /    15 runs   (    0.47 ms per token,  2136.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.97 ms /   146 tokens (    8.08 ms per token,   123.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.07 ms /    14 runs   (   88.00 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    2515.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"605 825 5445\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.73 ms /    15 runs   (    0.52 ms per token,  1940.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.30 ms /    25 tokens (   10.29 ms per token,    97.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1234.39 ms /    14 runs   (   88.17 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1592.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8264.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.86 ms /    23 tokens (   11.12 ms per token,    89.89 tokens per second)\n",
      "llama_print_timings:        eval time =      96.23 ms /     1 runs   (   96.23 ms per token,    10.39 tokens per second)\n",
      "llama_print_timings:       total time =     356.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.65 ms /     8 runs   (    0.58 ms per token,  1721.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.72 ms /    24 tokens (   10.65 ms per token,    93.85 tokens per second)\n",
      "llama_print_timings:        eval time =     605.45 ms /     7 runs   (   86.49 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     909.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Susan Cummings\", \"Doctor Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.41 ms /    22 runs   (    0.38 ms per token,  2614.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1435.29 ms /   191 tokens (    7.51 ms per token,   133.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1811.79 ms /    21 runs   (   86.28 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    3388.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"354 521 2431\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.05 ms /    15 runs   (    0.47 ms per token,  2127.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.96 ms /    25 tokens (   10.36 ms per token,    96.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1220.84 ms /    14 runs   (   87.20 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    1570.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     2 runs   (    0.52 ms per token,  1913.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.12 ms /    23 tokens (   11.18 ms per token,    89.45 tokens per second)\n",
      "llama_print_timings:        eval time =      86.10 ms /     1 runs   (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     356.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.02 ms /     2 runs   (    0.51 ms per token,  1968.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.08 ms /    24 tokens (   10.71 ms per token,    93.35 tokens per second)\n",
      "llama_print_timings:        eval time =      86.25 ms /     1 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     357.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rudolf Schmitt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.14 ms /     8 runs   (    0.52 ms per token,  1933.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2695.82 ms /   331 tokens (    8.14 ms per token,   122.78 tokens per second)\n",
      "llama_print_timings:        eval time =     615.53 ms /     7 runs   (   87.93 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    3372.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"528 628 8338\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    15 runs   (    0.47 ms per token,  2116.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.20 ms /    25 tokens (   10.49 ms per token,    95.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.41 ms /    14 runs   (   89.39 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1608.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  2000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.35 ms /    23 tokens (   11.36 ms per token,    88.01 tokens per second)\n",
      "llama_print_timings:        eval time =      90.22 ms /     1 runs   (   90.22 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     367.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.79 ms /     2 runs   (    0.40 ms per token,  2531.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.37 ms /    24 tokens (   10.85 ms per token,    92.18 tokens per second)\n",
      "llama_print_timings:        eval time =      88.97 ms /     1 runs   (   88.97 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =     367.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lamont Kuhn\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /     9 runs   (    0.53 ms per token,  1889.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1426.25 ms /   177 tokens (    8.06 ms per token,   124.10 tokens per second)\n",
      "llama_print_timings:        eval time =     689.18 ms /     8 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    2172.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"883 864 0266\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2105.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.13 ms /    25 tokens (   10.29 ms per token,    97.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.25 ms /    14 runs   (   88.02 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    1586.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.43 ms /     7 runs   (    0.49 ms per token,  2042.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    23 tokens (   11.14 ms per token,    89.80 tokens per second)\n",
      "llama_print_timings:        eval time =     516.00 ms /     6 runs   (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     826.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     2 runs   (    0.64 ms per token,  1561.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    24 tokens (   10.75 ms per token,    93.05 tokens per second)\n",
      "llama_print_timings:        eval time =      86.65 ms /     1 runs   (   86.65 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     360.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Yolanda Wuckert\", \"Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    19 runs   (    0.49 ms per token,  2026.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.74 ms /   156 tokens (    7.63 ms per token,   131.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1556.74 ms /    18 runs   (   86.49 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    2866.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"452 999 2855\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.58 ms /    15 runs   (    0.51 ms per token,  1977.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.93 ms /    25 tokens (   10.32 ms per token,    96.93 tokens per second)\n",
      "llama_print_timings:        eval time =    1203.94 ms /    14 runs   (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1560.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     5 runs   (    0.54 ms per token,  1843.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.55 ms /    23 tokens (   11.15 ms per token,    89.65 tokens per second)\n",
      "llama_print_timings:        eval time =     347.89 ms /     4 runs   (   86.97 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     635.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chronic Sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2373.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.01 ms /    24 tokens (   10.71 ms per token,    93.38 tokens per second)\n",
      "llama_print_timings:        eval time =     612.15 ms /     7 runs   (   87.45 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     920.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Calvin Stehr\", \"Dr. Tesha Johnston\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.56 ms /    18 runs   (    0.48 ms per token,  2102.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1671.40 ms /   207 tokens (    8.07 ms per token,   123.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1494.84 ms /    17 runs   (   87.93 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    3292.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"749 831 1277\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.99 ms /    15 runs   (    0.27 ms per token,  3761.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.05 ms /    25 tokens (   10.32 ms per token,    96.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1486.58 ms /    14 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    1824.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9478.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.46 ms /    23 tokens (   11.19 ms per token,    89.34 tokens per second)\n",
      "llama_print_timings:        eval time =     100.72 ms /     1 runs   (  100.72 ms per token,     9.93 tokens per second)\n",
      "llama_print_timings:       total time =     364.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.58 ms /     6 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.73 ms /    24 tokens (   10.86 ms per token,    92.05 tokens per second)\n",
      "llama_print_timings:        eval time =     466.97 ms /     5 runs   (   93.39 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     740.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Rudolf Prohaska\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    20 runs   (    0.13 ms per token,  7800.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.45 ms /   140 tokens (    8.42 ms per token,   118.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1766.77 ms /    19 runs   (   92.99 ms per token,    10.75 tokens per second)\n",
      "llama_print_timings:       total time =    3003.69 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"279 306 7622\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.82 ms /    15 runs   (    0.19 ms per token,  5319.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.28 ms /    25 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1268.58 ms /    14 runs   (   90.61 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =    1580.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     7 runs   (    0.10 ms per token, 10510.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.62 ms /    23 tokens (   11.11 ms per token,    89.98 tokens per second)\n",
      "llama_print_timings:        eval time =     535.24 ms /     6 runs   (   89.21 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =     812.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.07 ms /     8 runs   (    0.13 ms per token,  7455.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.25 ms /    24 tokens (   10.64 ms per token,    94.03 tokens per second)\n",
      "llama_print_timings:        eval time =     624.02 ms /     7 runs   (   89.15 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =     903.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Galen Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.30 ms /     7 runs   (    0.19 ms per token,  5380.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.20 ms /   173 tokens (    8.20 ms per token,   121.90 tokens per second)\n",
      "llama_print_timings:        eval time =     541.49 ms /     6 runs   (   90.25 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1987.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 265 1339\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.04 ms /    15 runs   (    0.20 ms per token,  4934.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.53 ms /    25 tokens (   10.38 ms per token,    96.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.10 ms /    14 runs   (   89.36 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1562.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"10 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.78 ms /     7 runs   (    0.11 ms per token,  9009.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.94 ms /    23 tokens (   11.17 ms per token,    89.51 tokens per second)\n",
      "llama_print_timings:        eval time =     533.53 ms /     6 runs   (   88.92 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     810.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     8 runs   (    0.16 ms per token,  6319.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.03 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     639.98 ms /     7 runs   (   91.43 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     917.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Andrea Altenwerth\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    11 runs   (    0.27 ms per token,  3690.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1451.37 ms /   188 tokens (    7.72 ms per token,   129.53 tokens per second)\n",
      "llama_print_timings:        eval time =     894.11 ms /    10 runs   (   89.41 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    2395.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 909 5156\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.63 ms /    15 runs   (    0.18 ms per token,  5701.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.22 ms /    25 tokens (   10.41 ms per token,    96.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1272.16 ms /    14 runs   (   90.87 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    1578.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"24-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.02 ms /     9 runs   (    0.22 ms per token,  4446.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.20 ms /    23 tokens (   11.18 ms per token,    89.42 tokens per second)\n",
      "llama_print_timings:        eval time =     712.48 ms /     8 runs   (   89.06 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1000.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.21 ms /     8 runs   (    0.15 ms per token,  6606.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.03 ms /    24 tokens (   10.75 ms per token,    93.01 tokens per second)\n",
      "llama_print_timings:        eval time =     656.85 ms /     7 runs   (   93.84 ms per token,    10.66 tokens per second)\n",
      "llama_print_timings:       total time =     936.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms Terrell Feest\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /     9 runs   (    0.48 ms per token,  2063.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2271.44 ms /   265 tokens (    8.57 ms per token,   116.67 tokens per second)\n",
      "llama_print_timings:        eval time =     701.55 ms /     8 runs   (   87.69 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =    3042.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 546 5193\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    15 runs   (    0.50 ms per token,  1980.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.33 ms /    25 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1261.58 ms /    14 runs   (   90.11 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    1618.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"15-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.64 ms /     9 runs   (    0.52 ms per token,  1941.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.67 ms /    23 tokens (   11.25 ms per token,    88.92 tokens per second)\n",
      "llama_print_timings:        eval time =     735.05 ms /     8 runs   (   91.88 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =    1056.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.21 ms /     2 runs   (    0.11 ms per token,  9345.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.34 ms /    24 tokens (   10.89 ms per token,    91.84 tokens per second)\n",
      "llama_print_timings:        eval time =      99.47 ms /     1 runs   (   99.47 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =     366.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kathryne Wolff\", \"Doctor Kayla Klein\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.24 ms /    16 runs   (    0.39 ms per token,  2564.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.68 ms /   169 tokens (    8.40 ms per token,   119.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1323.78 ms /    15 runs   (   88.25 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =    2852.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"790 291 9512\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    15 runs   (    0.56 ms per token,  1797.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.66 ms /    25 tokens (   10.39 ms per token,    96.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1230.66 ms /    14 runs   (   87.90 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1589.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.74 ms /     7 runs   (    0.25 ms per token,  4020.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    23 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =     535.61 ms /     6 runs   (   89.27 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =     828.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3129.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.62 ms /    24 tokens (   10.73 ms per token,    93.16 tokens per second)\n",
      "llama_print_timings:        eval time =      86.51 ms /     1 runs   (   86.51 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     354.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Christopher Crona\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.68 ms /     9 runs   (    0.63 ms per token,  1585.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1189.55 ms /   156 tokens (    7.63 ms per token,   131.14 tokens per second)\n",
      "llama_print_timings:        eval time =     715.68 ms /     8 runs   (   89.46 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    1973.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"770 816 8518\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1992.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.17 ms /    25 tokens (   10.37 ms per token,    96.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.73 ms /    14 runs   (   86.62 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =    1571.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.44 ms /     7 runs   (    0.63 ms per token,  1578.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.68 ms /    23 tokens (   11.16 ms per token,    89.61 tokens per second)\n",
      "llama_print_timings:        eval time =     521.22 ms /     6 runs   (   86.87 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     828.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.07 ms /     8 runs   (    0.51 ms per token,  1967.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =     603.59 ms /     7 runs   (   86.23 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     911.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Melvin Tillman\", \"Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    15 runs   (    0.51 ms per token,  1969.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.45 ms /   160 tokens (    7.37 ms per token,   135.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1203.05 ms /    14 runs   (   85.93 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    2486.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"539 593 8988\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    15 runs   (    0.52 ms per token,  1936.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.21 ms /    25 tokens (   10.29 ms per token,    97.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.95 ms /    14 runs   (   86.71 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1564.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     7 runs   (    0.49 ms per token,  2033.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.55 ms /    23 tokens (   11.15 ms per token,    89.65 tokens per second)\n",
      "llama_print_timings:        eval time =     519.23 ms /     6 runs   (   86.54 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =     826.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.15 ms /     2 runs   (    0.58 ms per token,  1734.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.53 ms /    24 tokens (   10.69 ms per token,    93.56 tokens per second)\n",
      "llama_print_timings:        eval time =      86.22 ms /     1 runs   (   86.22 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     357.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Duane Abernathy\", \"Rochell Stehr\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    18 runs   (    0.43 ms per token,  2352.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1692.93 ms /   220 tokens (    7.70 ms per token,   129.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1472.99 ms /    17 runs   (   86.65 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =    3288.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"111 385 3040\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.98 ms /    15 runs   (    0.60 ms per token,  1669.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.27 ms /    25 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.65 ms /    14 runs   (   87.40 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1603.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1672.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.57 ms /    23 tokens (   11.20 ms per token,    89.30 tokens per second)\n",
      "llama_print_timings:        eval time =      89.91 ms /     1 runs   (   89.91 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     364.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"respiratory\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.85 ms /     6 runs   (    0.31 ms per token,  3241.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.54 ms /    24 tokens (   10.77 ms per token,    92.83 tokens per second)\n",
      "llama_print_timings:        eval time =     435.21 ms /     5 runs   (   87.04 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     721.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ervin Renner\", \"Dr. Tereasa Mueller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.27 ms /    16 runs   (    0.45 ms per token,  2202.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.94 ms /   150 tokens (    7.90 ms per token,   126.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1288.81 ms /    15 runs   (   85.92 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    2589.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 126 8977\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    15 runs   (    0.54 ms per token,  1860.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.02 ms /    25 tokens (   10.32 ms per token,    96.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.84 ms /    14 runs   (   86.06 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1569.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.69 ms /     8 runs   (    0.34 ms per token,  2969.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.41 ms /    23 tokens (   11.19 ms per token,    89.35 tokens per second)\n",
      "llama_print_timings:        eval time =     612.68 ms /     7 runs   (   87.53 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     911.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Perennial allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.92 ms /    12 runs   (    0.58 ms per token,  1733.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.65 ms /    24 tokens (   10.74 ms per token,    93.15 tokens per second)\n",
      "llama_print_timings:        eval time =     944.65 ms /    11 runs   (   85.88 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    1290.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Bryce D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.53 ms /    11 runs   (    0.50 ms per token,  1990.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.65 ms /   208 tokens (    8.01 ms per token,   124.80 tokens per second)\n",
      "llama_print_timings:        eval time =     862.49 ms /    10 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    2605.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"493 447 7578\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.69 ms /    15 runs   (    0.45 ms per token,  2241.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.76 ms /    25 tokens (   10.35 ms per token,    96.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.98 ms /    14 runs   (   87.07 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    1570.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"69-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.32 ms /     9 runs   (    0.48 ms per token,  2083.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.42 ms /    23 tokens (   11.24 ms per token,    89.00 tokens per second)\n",
      "llama_print_timings:        eval time =     696.37 ms /     8 runs   (   87.05 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    1015.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"part-time employment\", \"severe anxiety\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.68 ms /    14 runs   (    0.48 ms per token,  2095.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.65 ms /    24 tokens (   10.74 ms per token,    93.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1122.35 ms /    13 runs   (   86.33 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1478.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Nikita Murphy\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.30 ms /     8 runs   (    0.66 ms per token,  1510.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.37 ms /   134 tokens (    8.75 ms per token,   114.30 tokens per second)\n",
      "llama_print_timings:        eval time =     620.18 ms /     7 runs   (   88.60 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    1849.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 419 4980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.38 ms /    15 runs   (    0.63 ms per token,  1599.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.47 ms /    25 tokens (   10.30 ms per token,    97.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1221.02 ms /    14 runs   (   87.22 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =    1594.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /     7 runs   (    0.58 ms per token,  1724.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    23 tokens (   11.13 ms per token,    89.84 tokens per second)\n",
      "llama_print_timings:        eval time =     525.11 ms /     6 runs   (   87.52 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     826.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     8 runs   (    0.44 ms per token,  2268.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.16 ms /    24 tokens (   10.72 ms per token,    93.33 tokens per second)\n",
      "llama_print_timings:        eval time =     611.73 ms /     7 runs   (   87.39 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     910.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leslie Osinski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /    10 runs   (    0.55 ms per token,  1801.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1668.72 ms /   197 tokens (    8.47 ms per token,   118.05 tokens per second)\n",
      "llama_print_timings:        eval time =     783.70 ms /     9 runs   (   87.08 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    2524.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"349 161 3928\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.36 ms /    15 runs   (    0.56 ms per token,  1793.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.42 ms /    25 tokens (   10.34 ms per token,    96.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.04 ms /    14 runs   (   86.07 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1568.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.54 ms /     2 runs   (    0.27 ms per token,  3676.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.12 ms /    23 tokens (   11.22 ms per token,    89.11 tokens per second)\n",
      "llama_print_timings:        eval time =      86.83 ms /     1 runs   (   86.83 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =     351.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.84 ms /     2 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.96 ms /    24 tokens (   10.75 ms per token,    93.04 tokens per second)\n",
      "llama_print_timings:        eval time =      86.42 ms /     1 runs   (   86.42 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     354.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Ignacio Becker\", \"Doctor Kim Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.05 ms /    17 runs   (    0.47 ms per token,  2111.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1174.46 ms /   141 tokens (    8.33 ms per token,   120.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1363.69 ms /    16 runs   (   85.23 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =    2654.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"873 251 9754\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.97 ms /    15 runs   (    0.40 ms per token,  2514.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.23 ms /    25 tokens (   10.33 ms per token,    96.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.11 ms /    14 runs   (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1559.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"50 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     7 runs   (    0.38 ms per token,  2645.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.52 ms /    23 tokens (   11.15 ms per token,    89.66 tokens per second)\n",
      "llama_print_timings:        eval time =     515.03 ms /     6 runs   (   85.84 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     813.36 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.32 ms per token,  3154.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    24 tokens (   10.67 ms per token,    93.71 tokens per second)\n",
      "llama_print_timings:        eval time =      87.56 ms /     1 runs   (   87.56 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     355.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Zenobia Legros\", \"Reggie Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.32 ms /    18 runs   (    0.41 ms per token,  2459.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.10 ms /   182 tokens (    7.86 ms per token,   127.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1481.04 ms /    17 runs   (   87.12 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    3025.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"173 622 0471\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.59 ms /    15 runs   (    0.44 ms per token,  2276.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.23 ms /    25 tokens (   10.37 ms per token,    96.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.42 ms /    14 runs   (   86.39 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1577.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2377.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.40 ms /    23 tokens (   11.19 ms per token,    89.36 tokens per second)\n",
      "llama_print_timings:        eval time =     606.57 ms /     7 runs   (   86.65 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     917.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     8 runs   (    0.45 ms per token,  2209.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.70 ms /    24 tokens (   10.70 ms per token,    93.49 tokens per second)\n",
      "llama_print_timings:        eval time =     616.05 ms /     7 runs   (   88.01 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =     917.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alphonse Simonis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.39 ms /    10 runs   (    0.44 ms per token,  2279.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1172.69 ms /   139 tokens (    8.44 ms per token,   118.53 tokens per second)\n",
      "llama_print_timings:        eval time =     775.50 ms /     9 runs   (   86.17 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    2026.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"278 139 8298\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.85 ms /    15 runs   (    0.52 ms per token,  1910.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.78 ms /    25 tokens (   10.23 ms per token,    97.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1205.58 ms /    14 runs   (   86.11 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1566.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /     7 runs   (    0.34 ms per token,  2943.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.69 ms /    23 tokens (   11.20 ms per token,    89.25 tokens per second)\n",
      "llama_print_timings:        eval time =     515.38 ms /     6 runs   (   85.90 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     807.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3139.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.85 ms /    24 tokens (   10.66 ms per token,    93.81 tokens per second)\n",
      "llama_print_timings:        eval time =      84.34 ms /     1 runs   (   84.34 ms per token,    11.86 tokens per second)\n",
      "llama_print_timings:       total time =     351.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Mafalda Shanahan\", \"Dr. Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.74 ms /    21 runs   (    0.46 ms per token,  2155.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.50 ms /   148 tokens (    7.98 ms per token,   125.26 tokens per second)\n",
      "llama_print_timings:        eval time =    1713.13 ms /    20 runs   (   85.66 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    3038.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"189 932 0941\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.90 ms /    15 runs   (    0.39 ms per token,  2544.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.61 ms /    25 tokens (   10.30 ms per token,    97.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.95 ms /    14 runs   (   86.07 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1561.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  1998.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.21 ms /    23 tokens (   11.10 ms per token,    90.12 tokens per second)\n",
      "llama_print_timings:        eval time =      87.43 ms /     1 runs   (   87.43 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     355.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /     8 runs   (    0.55 ms per token,  1806.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.46 ms /    24 tokens (   10.64 ms per token,    93.95 tokens per second)\n",
      "llama_print_timings:        eval time =     601.13 ms /     7 runs   (   85.88 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     914.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rhett Fahey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /    10 runs   (    0.38 ms per token,  2612.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.27 ms /   154 tokens (    7.70 ms per token,   129.82 tokens per second)\n",
      "llama_print_timings:        eval time =     786.23 ms /     9 runs   (   87.36 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    2034.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"533 386 3196\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.49 ms /    15 runs   (    0.50 ms per token,  2003.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.97 ms /    25 tokens (   10.32 ms per token,    96.91 tokens per second)\n",
      "llama_print_timings:        eval time =    1199.03 ms /    14 runs   (   85.64 ms per token,    11.68 tokens per second)\n",
      "llama_print_timings:       total time =    1564.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     7 runs   (    0.36 ms per token,  2795.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.10 ms /    23 tokens (   11.13 ms per token,    89.81 tokens per second)\n",
      "llama_print_timings:        eval time =     521.56 ms /     6 runs   (   86.93 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     818.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     8 runs   (    0.43 ms per token,  2349.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.90 ms /    24 tokens (   10.70 ms per token,    93.42 tokens per second)\n",
      "Llama.generate: prefix-match hit\n",
      "llama_print_timings:        eval time =     606.33 ms /     7 runs   (   86.62 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     912.80 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lane Cummerata\", \"Dr. Delois Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.75 ms /    18 runs   (    0.43 ms per token,  2323.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1415.27 ms /   168 tokens (    8.42 ms per token,   118.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1521.45 ms /    17 runs   (   89.50 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    3059.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"469 664 4984\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    15 runs   (    0.46 ms per token,  2164.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.78 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.90 ms /    14 runs   (   86.49 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1565.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10204.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.89 ms /    23 tokens (   11.17 ms per token,    89.53 tokens per second)\n",
      "llama_print_timings:        eval time =      94.72 ms /     1 runs   (   94.72 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =     359.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.01 ms /     2 runs   (    0.51 ms per token,  1974.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.33 ms /    24 tokens (   10.64 ms per token,    94.00 tokens per second)\n",
      "llama_print_timings:        eval time =      86.56 ms /     1 runs   (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     355.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Otilia Keeling\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.83 ms /    19 runs   (    0.41 ms per token,  2426.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.17 ms /   145 tokens (    8.13 ms per token,   122.97 tokens per second)\n",
      "llama_print_timings:        eval time =    1571.56 ms /    18 runs   (   87.31 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    2872.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"755 783 9490\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.94 ms /    15 runs   (    0.46 ms per token,  2162.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    25 tokens (   10.26 ms per token,    97.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.62 ms /    14 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1607.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"75\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.49 ms /     5 runs   (    0.30 ms per token,  3360.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.70 ms /    23 tokens (   11.12 ms per token,    89.95 tokens per second)\n",
      "llama_print_timings:        eval time =     343.91 ms /     4 runs   (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     627.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3134.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.32 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =      87.62 ms /     1 runs   (   87.62 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     352.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Rickie Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.18 ms /    10 runs   (    0.52 ms per token,  1929.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.85 ms /   137 tokens (    8.55 ms per token,   116.91 tokens per second)\n",
      "llama_print_timings:        eval time =     779.53 ms /     9 runs   (   86.61 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    2018.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"555 387 7506\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    15 runs   (    0.54 ms per token,  1860.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.25 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1227.10 ms /    14 runs   (   87.65 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =    1585.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.63 ms /     2 runs   (    0.31 ms per token,  3184.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.00 ms /    23 tokens (   11.17 ms per token,    89.49 tokens per second)\n",
      "llama_print_timings:        eval time =      86.04 ms /     1 runs   (   86.04 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =     353.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.99 ms /     2 runs   (    0.50 ms per token,  2018.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.87 ms /    24 tokens (   10.66 ms per token,    93.80 tokens per second)\n",
      "llama_print_timings:        eval time =      86.37 ms /     1 runs   (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     356.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Anna Hintz\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    19 runs   (    0.40 ms per token,  2521.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.54 ms /   164 tokens (    8.84 ms per token,   113.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1669.10 ms /    18 runs   (   92.73 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    3245.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"671 974 2423\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.00 ms /    15 runs   (    0.47 ms per token,  2141.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.00 ms /    25 tokens (   10.64 ms per token,    93.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1285.41 ms /    14 runs   (   91.82 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =    1650.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.47 ms /     5 runs   (    0.49 ms per token,  2026.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.99 ms /    23 tokens (   11.39 ms per token,    87.79 tokens per second)\n",
      "llama_print_timings:        eval time =     358.97 ms /     4 runs   (   89.74 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     651.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.27 ms /     2 runs   (    0.14 ms per token,  7407.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.57 ms /    24 tokens (   10.90 ms per token,    91.76 tokens per second)\n",
      "llama_print_timings:        eval time =      98.99 ms /     1 runs   (   98.99 ms per token,    10.10 tokens per second)\n",
      "llama_print_timings:       total time =     368.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Kathryne Ullrich\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.51 ms /    10 runs   (    0.55 ms per token,  1814.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1440.24 ms /   163 tokens (    8.84 ms per token,   113.18 tokens per second)\n",
      "llama_print_timings:        eval time =     780.17 ms /     9 runs   (   86.69 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =    2290.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 688 1306\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.76 ms /    15 runs   (    0.52 ms per token,  1931.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.81 ms /    25 tokens (   10.27 ms per token,    97.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.83 ms /    14 runs   (   86.35 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1567.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.61 ms /     2 runs   (    0.30 ms per token,  3278.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.12 ms /    23 tokens (   11.09 ms per token,    90.15 tokens per second)\n",
      "llama_print_timings:        eval time =     101.66 ms /     1 runs   (  101.66 ms per token,     9.84 tokens per second)\n",
      "llama_print_timings:       total time =     368.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  2008.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    24 tokens (   10.69 ms per token,    93.56 tokens per second)\n",
      "llama_print_timings:        eval time =      85.96 ms /     1 runs   (   85.96 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     355.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Stephen Collier\", \"Bernie Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.71 ms /    16 runs   (    0.42 ms per token,  2385.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.92 ms /   194 tokens (    8.58 ms per token,   116.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1303.78 ms /    15 runs   (   86.92 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    3077.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"784 279 6550\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.43 ms /    15 runs   (    0.50 ms per token,  2019.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.17 ms /    25 tokens (   10.33 ms per token,    96.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.70 ms /    14 runs   (   86.69 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1575.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /     7 runs   (    0.30 ms per token,  3281.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.32 ms /    23 tokens (   11.23 ms per token,    89.04 tokens per second)\n",
      "llama_print_timings:        eval time =     525.71 ms /     6 runs   (   87.62 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     818.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3120.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.99 ms /    24 tokens (   10.83 ms per token,    92.31 tokens per second)\n",
      "llama_print_timings:        eval time =      86.81 ms /     1 runs   (   86.81 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =     358.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Preston Vandervort\", \"Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.37 ms /    16 runs   (    0.40 ms per token,  2510.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1432.77 ms /   183 tokens (    7.83 ms per token,   127.72 tokens per second)\n",
      "llama_print_timings:        eval time =    1293.00 ms /    15 runs   (   86.20 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    2826.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 851 4936\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.21 ms /    15 runs   (    0.48 ms per token,  2080.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.54 ms /    25 tokens (   10.34 ms per token,    96.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1219.33 ms /    14 runs   (   87.10 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =    1575.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     2 runs   (    0.49 ms per token,  2044.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.87 ms /    23 tokens (   11.17 ms per token,    89.54 tokens per second)\n",
      "llama_print_timings:        eval time =      88.40 ms /     1 runs   (   88.40 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     356.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"primary diagnosis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     6 runs   (    0.47 ms per token,  2110.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.58 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =     433.12 ms /     5 runs   (   86.62 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     729.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tatyana Haag\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.94 ms /     8 runs   (    0.49 ms per token,  2032.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.03 ms /   146 tokens (    8.09 ms per token,   123.62 tokens per second)\n",
      "llama_print_timings:        eval time =     604.18 ms /     7 runs   (   86.31 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1837.30 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 683 8591\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.74 ms /    15 runs   (    0.45 ms per token,  2224.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.25 ms /    25 tokens (   10.29 ms per token,    97.18 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.48 ms /    14 runs   (   86.96 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1574.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"11-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /     9 runs   (    0.42 ms per token,  2355.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.20 ms /    23 tokens (   11.14 ms per token,    89.77 tokens per second)\n",
      "llama_print_timings:        eval time =     683.75 ms /     8 runs   (   85.47 ms per token,    11.70 tokens per second)\n",
      "llama_print_timings:       total time =     997.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     6 runs   (    0.42 ms per token,  2395.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.33 ms /    24 tokens (   10.68 ms per token,    93.63 tokens per second)\n",
      "llama_print_timings:        eval time =     448.66 ms /     5 runs   (   89.73 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     740.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Suk Padberg\", \"Dr.\", \"Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.67 ms /    21 runs   (    0.51 ms per token,  1968.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1411.77 ms /   170 tokens (    8.30 ms per token,   120.42 tokens per second)\n",
      "llama_print_timings:        eval time =    1726.09 ms /    20 runs   (   86.30 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    3282.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"710 375 0519\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.11 ms /    15 runs   (    0.47 ms per token,  2109.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.87 ms /    25 tokens (   10.31 ms per token,    96.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1212.69 ms /    14 runs   (   86.62 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =    1562.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.52 ms /     9 runs   (    0.39 ms per token,  2554.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.29 ms /    23 tokens (   11.10 ms per token,    90.09 tokens per second)\n",
      "llama_print_timings:        eval time =     695.17 ms /     8 runs   (   86.90 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    1012.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.72 ms /     2 runs   (    0.36 ms per token,  2773.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.35 ms /    24 tokens (   10.72 ms per token,    93.26 tokens per second)\n",
      "llama_print_timings:        eval time =      87.39 ms /     1 runs   (   87.39 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     354.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Alvaro Lesch\", \"Dr. Randy Bergstrom\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.82 ms /    19 runs   (    0.41 ms per token,  2431.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.54 ms /   155 tokens (    7.66 ms per token,   130.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1634.81 ms /    18 runs   (   90.82 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    2933.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"574 614 8059\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.81 ms /    15 runs   (    0.39 ms per token,  2583.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.13 ms /    25 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1305.51 ms /    14 runs   (   93.25 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =    1657.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2639.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.03 ms /    23 tokens (   11.18 ms per token,    89.48 tokens per second)\n",
      "llama_print_timings:        eval time =     734.77 ms /     8 runs   (   91.85 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =    1056.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4796.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.43 ms /    24 tokens (   10.98 ms per token,    91.10 tokens per second)\n",
      "llama_print_timings:        eval time =     101.76 ms /     1 runs   (  101.76 ms per token,     9.83 tokens per second)\n",
      "llama_print_timings:       total time =     372.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2865.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.26 ms /   171 tokens (    8.31 ms per token,   120.32 tokens per second)\n",
      "llama_print_timings:        eval time =      94.72 ms /     1 runs   (   94.72 ms per token,    10.56 tokens per second)\n",
      "llama_print_timings:       total time =    1524.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"582 727 9617\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.33 ms /    15 runs   (    0.49 ms per token,  2045.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.71 ms /    25 tokens (   10.35 ms per token,    96.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.50 ms /    14 runs   (   89.39 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1604.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.00 ms /     7 runs   (    0.43 ms per token,  2335.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.03 ms /    23 tokens (   11.13 ms per token,    89.83 tokens per second)\n",
      "llama_print_timings:        eval time =     523.76 ms /     6 runs   (   87.29 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =     830.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.12 ms /     2 runs   (    0.56 ms per token,  1792.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.35 ms /    24 tokens (   10.76 ms per token,    92.90 tokens per second)\n",
      "llama_print_timings:        eval time =      87.01 ms /     1 runs   (   87.01 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     364.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Jaye Larson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /    10 runs   (    0.47 ms per token,  2130.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.98 ms /   134 tokens (    8.73 ms per token,   114.53 tokens per second)\n",
      "llama_print_timings:        eval time =     776.98 ms /     9 runs   (   86.33 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    2011.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"484 719 8232\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.39 ms /    15 runs   (    0.49 ms per token,  2030.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.93 ms /    25 tokens (   10.28 ms per token,    97.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.75 ms /    14 runs   (   86.05 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1564.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"64-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.51 ms /     9 runs   (    0.39 ms per token,  2564.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.27 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =     703.25 ms /     8 runs   (   87.91 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1012.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.06 ms /    24 tokens (   10.75 ms per token,    93.00 tokens per second)\n",
      "llama_print_timings:        eval time =      92.17 ms /     1 runs   (   92.17 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     353.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leigh Mosciski\", \"Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.08 ms /    16 runs   (    0.50 ms per token,  1980.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3113.77 ms /   373 tokens (    8.35 ms per token,   119.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1357.39 ms /    15 runs   (   90.49 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    4600.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"779 895 0751\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.87 ms /    15 runs   (    0.52 ms per token,  1907.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.54 ms /    25 tokens (   10.58 ms per token,    94.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1262.55 ms /    14 runs   (   90.18 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =    1636.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"60 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.68 ms /     6 runs   (    0.28 ms per token,  3575.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.74 ms /    23 tokens (   11.55 ms per token,    86.55 tokens per second)\n",
      "llama_print_timings:        eval time =     456.84 ms /     5 runs   (   91.37 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     757.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.60 ms /     8 runs   (    0.58 ms per token,  1737.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.26 ms /    24 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =     627.54 ms /     7 runs   (   89.65 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     953.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Thanh Conroy\", \"Dr.\", \"Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      11.95 ms /    20 runs   (    0.60 ms per token,  1674.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1436.55 ms /   186 tokens (    7.72 ms per token,   129.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1650.77 ms /    19 runs   (   86.88 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    3233.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"371 768 1921\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2015.59 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.27 ms /    25 tokens (   10.41 ms per token,    96.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.08 ms /    14 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1573.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.69 ms /     7 runs   (    0.67 ms per token,  1491.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.36 ms /    23 tokens (   11.23 ms per token,    89.02 tokens per second)\n",
      "llama_print_timings:        eval time =     514.89 ms /     6 runs   (   85.81 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =     818.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.47 ms /     2 runs   (    0.74 ms per token,  1359.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.24 ms /    24 tokens (   10.72 ms per token,    93.30 tokens per second)\n",
      "llama_print_timings:        eval time =      87.75 ms /     1 runs   (   87.75 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     356.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Deon Zemlak\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.29 ms /    11 runs   (    0.48 ms per token,  2077.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.15 ms /   140 tokens (    8.37 ms per token,   119.54 tokens per second)\n",
      "llama_print_timings:        eval time =     852.32 ms /    10 runs   (   85.23 ms per token,    11.73 tokens per second)\n",
      "llama_print_timings:       total time =    2101.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"691 903 7516\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.57 ms /    15 runs   (    0.44 ms per token,  2281.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.85 ms /    25 tokens (   10.31 ms per token,    96.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.49 ms /    14 runs   (   86.32 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1562.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"13-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2388.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.11 ms /    23 tokens (   11.09 ms per token,    90.16 tokens per second)\n",
      "llama_print_timings:        eval time =     687.83 ms /     8 runs   (   85.98 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =    1000.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.08 ms /     8 runs   (    0.51 ms per token,  1961.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.42 ms /    24 tokens (   10.68 ms per token,    93.60 tokens per second)\n",
      "llama_print_timings:        eval time =     603.40 ms /     7 runs   (   86.20 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     913.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Katharina Dicki\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.62 ms /    16 runs   (    0.48 ms per token,  2100.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1414.70 ms /   173 tokens (    8.18 ms per token,   122.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1294.82 ms /    15 runs   (   86.32 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    2817.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"375 777 6466\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.23 ms /    25 tokens (   10.37 ms per token,    96.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1204.56 ms /    14 runs   (   86.04 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    1560.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.09 ms /     9 runs   (    0.45 ms per token,  2197.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.60 ms /    23 tokens (   11.16 ms per token,    89.64 tokens per second)\n",
      "llama_print_timings:        eval time =     700.79 ms /     8 runs   (   87.60 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    1007.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     2 runs   (    0.49 ms per token,  2057.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.45 ms /    24 tokens (   10.73 ms per token,    93.22 tokens per second)\n",
      "llama_print_timings:        eval time =      86.15 ms /     1 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     353.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jerrold Lubowitz\", \"Doctor Damaris Funk\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.29 ms /    20 runs   (    0.51 ms per token,  1942.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.23 ms /   167 tokens (    8.46 ms per token,   118.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1635.70 ms /    19 runs   (   86.09 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    3184.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"793 873 3356\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.51 ms /    15 runs   (    0.50 ms per token,  1997.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.66 ms /    25 tokens (   10.31 ms per token,    97.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1215.45 ms /    14 runs   (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    1564.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"76-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /     9 runs   (    0.54 ms per token,  1853.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.95 ms /    23 tokens (   11.17 ms per token,    89.51 tokens per second)\n",
      "llama_print_timings:        eval time =     689.18 ms /     8 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1014.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.52 ms /    24 tokens (   10.69 ms per token,    93.56 tokens per second)\n",
      "llama_print_timings:        eval time =      88.45 ms /     1 runs   (   88.45 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     354.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Reyna Schiller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.88 ms /    10 runs   (    0.39 ms per token,  2579.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3382.42 ms /   402 tokens (    8.41 ms per token,   118.85 tokens per second)\n",
      "llama_print_timings:        eval time =     805.95 ms /     9 runs   (   89.55 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    4245.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"245 786 2665\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.12 ms /    15 runs   (    0.47 ms per token,  2106.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.97 ms /    25 tokens (   10.56 ms per token,    94.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.95 ms /    14 runs   (   89.00 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1619.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.41 ms /     9 runs   (    0.49 ms per token,  2043.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.02 ms /    23 tokens (   11.35 ms per token,    88.12 tokens per second)\n",
      "llama_print_timings:        eval time =     718.83 ms /     8 runs   (   89.85 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    1044.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.42 ms /     2 runs   (    0.21 ms per token,  4784.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.72 ms /    24 tokens (   10.95 ms per token,    91.35 tokens per second)\n",
      "llama_print_timings:        eval time =      94.80 ms /     1 runs   (   94.80 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     367.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jay Pfeffer\", \"Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.58 ms /    14 runs   (    0.40 ms per token,  2508.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3022.20 ms /   355 tokens (    8.51 ms per token,   117.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1176.70 ms /    13 runs   (   90.52 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    4303.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 455 2284\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1992.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.15 ms /    25 tokens (   10.57 ms per token,    94.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1248.29 ms /    14 runs   (   89.16 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    1614.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     7 runs   (    0.31 ms per token,  3237.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.86 ms /    23 tokens (   11.39 ms per token,    87.83 tokens per second)\n",
      "llama_print_timings:        eval time =     533.62 ms /     6 runs   (   88.94 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =     829.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3110.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.71 ms /    24 tokens (   10.90 ms per token,    91.70 tokens per second)\n",
      "llama_print_timings:        eval time =      88.13 ms /     1 runs   (   88.13 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     361.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kim Luettgen\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.34 ms /     9 runs   (    0.59 ms per token,  1686.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.00 ms /   145 tokens (    8.13 ms per token,   122.99 tokens per second)\n",
      "llama_print_timings:        eval time =     691.98 ms /     8 runs   (   86.50 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1936.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"641 763 8938\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.50 ms /    15 runs   (    0.50 ms per token,  2000.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.31 ms /    25 tokens (   10.33 ms per token,    96.78 tokens per second)\n",
      "llama_print_timings:        eval time =    1201.42 ms /    14 runs   (   85.82 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    1567.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"79 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /     7 runs   (    0.51 ms per token,  1979.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.48 ms /    23 tokens (   11.15 ms per token,    89.68 tokens per second)\n",
      "llama_print_timings:        eval time =     521.34 ms /     6 runs   (   86.89 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     828.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3125.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.40 ms /    24 tokens (   10.68 ms per token,    93.60 tokens per second)\n",
      "llama_print_timings:        eval time =      87.72 ms /     1 runs   (   87.72 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     353.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kenton Cormier\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.79 ms /    18 runs   (    0.43 ms per token,  2310.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.41 ms /   182 tokens (    7.88 ms per token,   126.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1466.86 ms /    17 runs   (   86.29 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    3024.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"842 528 1235\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.72 ms /    15 runs   (    0.38 ms per token,  2621.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.92 ms /    25 tokens (   10.44 ms per token,    95.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.41 ms /    14 runs   (   86.39 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1558.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26 year\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.27 ms /     6 runs   (    0.54 ms per token,  1835.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.51 ms /    23 tokens (   11.24 ms per token,    88.97 tokens per second)\n",
      "llama_print_timings:        eval time =     431.72 ms /     5 runs   (   86.34 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =     730.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.16 ms /     2 runs   (    0.58 ms per token,  1725.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.19 ms /    24 tokens (   10.72 ms per token,    93.31 tokens per second)\n",
      "llama_print_timings:        eval time =      86.00 ms /     1 runs   (   86.00 ms per token,    11.63 tokens per second)\n",
      "llama_print_timings:       total time =     356.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Lisabeth Goyette\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.77 ms /     9 runs   (    0.42 ms per token,  2386.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.66 ms /   180 tokens (    7.95 ms per token,   125.73 tokens per second)\n",
      "llama_print_timings:        eval time =     705.16 ms /     8 runs   (   88.14 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    2200.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 601 7152\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.09 ms /    15 runs   (    0.54 ms per token,  1853.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.07 ms /    25 tokens (   10.32 ms per token,    96.87 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.32 ms /    14 runs   (   88.52 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    1589.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.50 ms /     2 runs   (    0.75 ms per token,  1333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.21 ms /    23 tokens (   11.18 ms per token,    89.42 tokens per second)\n",
      "llama_print_timings:        eval time =      87.95 ms /     1 runs   (   87.95 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =     359.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.62 ms /     8 runs   (    0.58 ms per token,  1733.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =     606.60 ms /     7 runs   (   86.66 ms per token,    11.54 tokens per second)\n",
      "llama_print_timings:       total time =     915.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Han Grant\", \"Doctor Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.17 ms /    16 runs   (    0.51 ms per token,  1958.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.26 ms /   155 tokens (    7.65 ms per token,   130.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1301.54 ms /    15 runs   (   86.77 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    2595.46 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"484 852 4052\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.98 ms /    15 runs   (    0.47 ms per token,  2148.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.67 ms /    25 tokens (   10.35 ms per token,    96.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1234.96 ms /    14 runs   (   88.21 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1582.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.45 ms /     2 runs   (    0.73 ms per token,  1378.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.29 ms /    23 tokens (   11.14 ms per token,    89.74 tokens per second)\n",
      "llama_print_timings:        eval time =      88.12 ms /     1 runs   (   88.12 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =     356.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     2 runs   (    0.51 ms per token,  1949.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.52 ms /    24 tokens (   10.73 ms per token,    93.20 tokens per second)\n",
      "llama_print_timings:        eval time =      87.35 ms /     1 runs   (   87.35 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     364.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Harry Wehner\", \"Dr. Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.41 ms /    15 runs   (    0.49 ms per token,  2024.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1407.24 ms /   161 tokens (    8.74 ms per token,   114.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1200.15 ms /    14 runs   (   85.72 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =    2712.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"242 197 5106\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.34 ms /    15 runs   (    0.42 ms per token,  2364.07 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.38 ms /    25 tokens (   10.46 ms per token,    95.64 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.09 ms /    14 runs   (   86.22 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    1560.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     2 runs   (    0.46 ms per token,  2195.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.66 ms /    23 tokens (   11.12 ms per token,    89.96 tokens per second)\n",
      "llama_print_timings:        eval time =      88.62 ms /     1 runs   (   88.62 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     354.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /     7 runs   (    0.48 ms per token,  2080.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.22 ms /    24 tokens (   10.68 ms per token,    93.67 tokens per second)\n",
      "llama_print_timings:        eval time =     516.16 ms /     6 runs   (   86.03 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =     821.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr.\", \"Marcus Grimes\", \"Dr.\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.15 ms /    21 runs   (    0.44 ms per token,  2294.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1663.40 ms /   203 tokens (    8.19 ms per token,   122.04 tokens per second)\n",
      "llama_print_timings:        eval time =    1746.77 ms /    20 runs   (   87.34 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    3540.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"227 733 6070\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.12 ms /    15 runs   (    0.54 ms per token,  1847.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.51 ms /    25 tokens (   10.34 ms per token,    96.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1208.47 ms /    14 runs   (   86.32 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    1577.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.55 ms /     7 runs   (    0.51 ms per token,  1972.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.93 ms /    23 tokens (   11.26 ms per token,    88.83 tokens per second)\n",
      "llama_print_timings:        eval time =     518.52 ms /     6 runs   (   86.42 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     825.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /     8 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.10 ms /    24 tokens (   10.80 ms per token,    92.63 tokens per second)\n",
      "llama_print_timings:        eval time =     617.36 ms /     7 runs   (   88.19 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =     922.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raul Rutherford\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.46 ms /    10 runs   (    0.55 ms per token,  1831.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3242.60 ms /   394 tokens (    8.23 ms per token,   121.51 tokens per second)\n",
      "llama_print_timings:        eval time =     796.52 ms /     9 runs   (   88.50 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    4113.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"868 596 1389\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    15 runs   (    0.54 ms per token,  1861.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.18 ms /    25 tokens (   10.53 ms per token,    94.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.71 ms /    14 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =    1631.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"age\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.18 ms /     4 runs   (    0.30 ms per token,  3381.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     269.42 ms /    23 tokens (   11.71 ms per token,    85.37 tokens per second)\n",
      "llama_print_timings:        eval time =     276.26 ms /     3 runs   (   92.09 ms per token,    10.86 tokens per second)\n",
      "llama_print_timings:       total time =     565.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.80 ms /     8 runs   (    0.60 ms per token,  1665.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.92 ms /    24 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_print_timings:        eval time =     662.00 ms /     7 runs   (   94.57 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     988.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Maggie Abshire\", \"Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      22.27 ms /    18 runs   (    1.24 ms per token,   808.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1206.39 ms /   154 tokens (    7.83 ms per token,   127.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1591.28 ms /    17 runs   (   93.60 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =    2955.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"526 109 3877\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.89 ms /    15 runs   (    0.46 ms per token,  2178.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.43 ms /    25 tokens (   10.42 ms per token,    96.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.05 ms /    14 runs   (   88.86 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1594.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.69 ms /     2 runs   (    0.35 ms per token,  2886.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.69 ms /    23 tokens (   11.12 ms per token,    89.95 tokens per second)\n",
      "llama_print_timings:        eval time =      88.81 ms /     1 runs   (   88.81 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     353.27 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.32 ms per token,  3100.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.39 ms /    24 tokens (   10.72 ms per token,    93.24 tokens per second)\n",
      "llama_print_timings:        eval time =      88.95 ms /     1 runs   (   88.95 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =     355.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Delmer Swift\", \"Dr. Cletus Paucek\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.48 ms /    17 runs   (    0.50 ms per token,  2004.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1429.59 ms /   179 tokens (    7.99 ms per token,   125.21 tokens per second)\n",
      "llama_print_timings:        eval time =    1388.83 ms /    16 runs   (   86.80 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    2940.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 133 5875\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.65 ms /    15 runs   (    0.51 ms per token,  1960.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.50 ms /    25 tokens (   10.46 ms per token,    95.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.24 ms /    14 runs   (   86.16 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1559.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.32 ms per token,  3081.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.06 ms /    23 tokens (   11.13 ms per token,    89.82 tokens per second)\n",
      "llama_print_timings:        eval time =      87.70 ms /     1 runs   (   87.70 ms per token,    11.40 tokens per second)\n",
      "llama_print_timings:       total time =     354.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /     7 runs   (    0.64 ms per token,  1572.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.48 ms /    24 tokens (   10.69 ms per token,    93.57 tokens per second)\n",
      "llama_print_timings:        eval time =     517.75 ms /     6 runs   (   86.29 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     825.61 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tommie Kertzmann\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.91 ms /    10 runs   (    0.39 ms per token,  2556.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.32 ms /   150 tokens (    7.90 ms per token,   126.65 tokens per second)\n",
      "llama_print_timings:        eval time =     795.13 ms /     9 runs   (   88.35 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    2043.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 971 8297\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.44 ms /    15 runs   (    0.56 ms per token,  1776.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.43 ms /    25 tokens (   10.34 ms per token,    96.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1207.44 ms /    14 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =    1575.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"3 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.22 ms /     6 runs   (    0.54 ms per token,  1864.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.05 ms /    23 tokens (   11.13 ms per token,    89.83 tokens per second)\n",
      "llama_print_timings:        eval time =     430.39 ms /     5 runs   (   86.08 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =     731.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.95 ms /     2 runs   (    0.48 ms per token,  2100.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.46 ms /    24 tokens (   10.69 ms per token,    93.58 tokens per second)\n",
      "llama_print_timings:        eval time =      87.06 ms /     1 runs   (   87.06 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =     355.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Anh Quitzon\", \"Doctor Ciara Gibson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.25 ms /    19 runs   (    0.54 ms per token,  1854.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1188.05 ms /   152 tokens (    7.82 ms per token,   127.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1546.48 ms /    18 runs   (   85.92 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =    2869.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"816 401 4532\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.66 ms /    15 runs   (    0.51 ms per token,  1959.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.24 ms /    25 tokens (   10.33 ms per token,    96.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1223.39 ms /    14 runs   (   87.39 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    1587.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"27-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /     9 runs   (    0.38 ms per token,  2637.75 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.78 ms /    23 tokens (   11.21 ms per token,    89.22 tokens per second)\n",
      "llama_print_timings:        eval time =     694.01 ms /     8 runs   (   86.75 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1011.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.55 ms /     8 runs   (    0.69 ms per token,  1440.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.41 ms /    24 tokens (   10.68 ms per token,    93.60 tokens per second)\n",
      "llama_print_timings:        eval time =     605.11 ms /     7 runs   (   86.44 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =     917.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rob Nolan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.26 ms /     6 runs   (    0.21 ms per token,  4746.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2482.34 ms /   296 tokens (    8.39 ms per token,   119.24 tokens per second)\n",
      "llama_print_timings:        eval time =     456.86 ms /     5 runs   (   91.37 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =    2968.66 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 372 4743\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    15 runs   (    0.48 ms per token,  2068.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.37 ms /    25 tokens (   10.49 ms per token,    95.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1233.98 ms /    14 runs   (   88.14 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    1606.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2857.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.30 ms /    23 tokens (   11.27 ms per token,    88.70 tokens per second)\n",
      "llama_print_timings:        eval time =      88.17 ms /     1 runs   (   88.17 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =     357.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.10 ms /     8 runs   (    0.51 ms per token,  1951.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.81 ms /    24 tokens (   10.83 ms per token,    92.38 tokens per second)\n",
      "llama_print_timings:        eval time =     610.74 ms /     7 runs   (   87.25 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =     924.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Livia Monahan\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.54 ms /    19 runs   (    0.45 ms per token,  2224.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.28 ms /   174 tokens (    8.12 ms per token,   123.12 tokens per second)\n",
      "llama_print_timings:        eval time =    1549.04 ms /    18 runs   (   86.06 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =    3093.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"835 566 8503\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.03 ms /    15 runs   (    0.47 ms per token,  2134.62 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.65 ms /    25 tokens (   10.31 ms per token,    97.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.31 ms /    14 runs   (   86.95 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1571.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"39-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.17 ms /     9 runs   (    0.57 ms per token,  1740.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.52 ms /    23 tokens (   11.11 ms per token,    90.01 tokens per second)\n",
      "llama_print_timings:        eval time =     688.87 ms /     8 runs   (   86.11 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1015.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.82 ms /     2 runs   (    0.41 ms per token,  2439.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    24 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_print_timings:        eval time =      88.59 ms /     1 runs   (   88.59 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     354.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Roscoe Botsford\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.88 ms /    11 runs   (    0.53 ms per token,  1872.34 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3020.22 ms /   379 tokens (    7.97 ms per token,   125.49 tokens per second)\n",
      "llama_print_timings:        eval time =     898.51 ms /    10 runs   (   89.85 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    4004.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"357 783 4421\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.05 ms /    15 runs   (    0.40 ms per token,  2478.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.81 ms /    25 tokens (   10.51 ms per token,    95.13 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.65 ms /    14 runs   (   89.69 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1616.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.99 ms /     9 runs   (    0.55 ms per token,  1805.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.56 ms /    23 tokens (   11.37 ms per token,    87.94 tokens per second)\n",
      "llama_print_timings:        eval time =     710.36 ms /     8 runs   (   88.80 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =    1041.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.35 ms /    12 runs   (    0.53 ms per token,  1890.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.49 ms /    24 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =     969.81 ms /    11 runs   (   88.16 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1322.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chase Eichmann\", \"Dr. Leif Hane\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    16 runs   (    0.46 ms per token,  2172.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.81 ms /   155 tokens (    7.66 ms per token,   130.60 tokens per second)\n",
      "llama_print_timings:        eval time =    1304.49 ms /    15 runs   (   86.97 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    2607.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 553 6807\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.54 ms /    15 runs   (    0.44 ms per token,  2292.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.83 ms /    25 tokens (   10.27 ms per token,    97.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1210.20 ms /    14 runs   (   86.44 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =    1562.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     8 runs   (    0.36 ms per token,  2813.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.85 ms /    23 tokens (   11.12 ms per token,    89.90 tokens per second)\n",
      "llama_print_timings:        eval time =     616.15 ms /     7 runs   (   88.02 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =     924.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.03 ms /     8 runs   (    0.50 ms per token,  1987.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.42 ms /    24 tokens (   10.64 ms per token,    93.96 tokens per second)\n",
      "llama_print_timings:        eval time =     606.03 ms /     7 runs   (   86.58 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     918.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Erwin Schroeder\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.92 ms /    10 runs   (    0.59 ms per token,  1689.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1168.30 ms /   133 tokens (    8.78 ms per token,   113.84 tokens per second)\n",
      "llama_print_timings:        eval time =     787.82 ms /     9 runs   (   87.54 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    2030.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"295 958 8980\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.85 ms /    15 runs   (    0.39 ms per token,  2565.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.07 ms /    25 tokens (   10.28 ms per token,    97.25 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.86 ms /    14 runs   (   86.20 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =    1551.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"28 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /     7 runs   (    0.37 ms per token,  2690.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.74 ms /    23 tokens (   11.08 ms per token,    90.29 tokens per second)\n",
      "llama_print_timings:        eval time =     517.86 ms /     6 runs   (   86.31 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     819.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.24 ms /    11 runs   (    0.48 ms per token,  2099.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.31 ms /    24 tokens (   10.72 ms per token,    93.27 tokens per second)\n",
      "llama_print_timings:        eval time =     858.36 ms /    10 runs   (   85.84 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    1196.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Johnsie Muller\", \"Dr. Kim Hyatt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.17 ms /    19 runs   (    0.54 ms per token,  1868.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1431.14 ms /   181 tokens (    7.91 ms per token,   126.47 tokens per second)\n",
      "llama_print_timings:        eval time =    1561.56 ms /    18 runs   (   86.75 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    3125.64 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"387 374 1765\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.29 ms /    15 runs   (    0.55 ms per token,  1808.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.05 ms /    25 tokens (   10.32 ms per token,    96.88 tokens per second)\n",
      "llama_print_timings:        eval time =    1214.13 ms /    14 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1580.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"17 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /     7 runs   (    0.37 ms per token,  2725.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.24 ms /    23 tokens (   11.14 ms per token,    89.76 tokens per second)\n",
      "llama_print_timings:        eval time =     532.62 ms /     6 runs   (   88.77 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     823.80 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     8 runs   (    0.48 ms per token,  2079.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.74 ms /    24 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_print_timings:        eval time =     603.77 ms /     7 runs   (   86.25 ms per token,    11.59 tokens per second)\n",
      "llama_print_timings:       total time =     918.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Barbra O'Conner\", \"Dr.\", \"Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.13 ms /    23 runs   (    0.44 ms per token,  2269.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.18 ms /   138 tokens (    8.49 ms per token,   117.83 tokens per second)\n",
      "llama_print_timings:        eval time =    2166.74 ms /    22 runs   (   98.49 ms per token,    10.15 tokens per second)\n",
      "llama_print_timings:       total time =    3517.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"275 211 8024\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    15 runs   (    0.43 ms per token,  2310.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.53 ms /    25 tokens (   10.38 ms per token,    96.33 tokens per second)\n",
      "llama_print_timings:        eval time =    1260.60 ms /    14 runs   (   90.04 ms per token,    11.11 tokens per second)\n",
      "llama_print_timings:       total time =    1616.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.54 ms /     5 runs   (    0.51 ms per token,  1970.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.57 ms /    23 tokens (   11.20 ms per token,    89.30 tokens per second)\n",
      "llama_print_timings:        eval time =     355.49 ms /     4 runs   (   88.87 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     648.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2849.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.62 ms /    24 tokens (   10.78 ms per token,    92.80 tokens per second)\n",
      "llama_print_timings:        eval time =      91.08 ms /     1 runs   (   91.08 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =     360.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alfonso Miller\", \"Dr. Madelaine Walker\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.61 ms /    15 runs   (    0.57 ms per token,  1742.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1185.94 ms /   132 tokens (    8.98 ms per token,   111.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.03 ms /    14 runs   (   91.36 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =    2564.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 108 5285\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.53 ms /    15 runs   (    0.50 ms per token,  1991.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.48 ms /    25 tokens (   10.30 ms per token,    97.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.00 ms /    14 runs   (   89.07 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1604.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.65 ms /     9 runs   (    0.29 ms per token,  3398.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.18 ms /    23 tokens (   11.09 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =     715.14 ms /     8 runs   (   89.39 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1008.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.67 ms /     8 runs   (    0.46 ms per token,  2181.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.26 ms /    24 tokens (   10.72 ms per token,    93.29 tokens per second)\n",
      "llama_print_timings:        eval time =     619.07 ms /     7 runs   (   88.44 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     921.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Chris Casper\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.19 ms /     7 runs   (    0.46 ms per token,  2191.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1193.86 ms /   154 tokens (    7.75 ms per token,   128.99 tokens per second)\n",
      "llama_print_timings:        eval time =     536.09 ms /     6 runs   (   89.35 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1777.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"437 703 1629\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.44 ms /    15 runs   (    0.36 ms per token,  2756.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.42 ms /    25 tokens (   10.42 ms per token,    96.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1266.48 ms /    14 runs   (   90.46 ms per token,    11.05 tokens per second)\n",
      "llama_print_timings:       total time =    1615.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.20 ms /     9 runs   (    0.36 ms per token,  2816.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.98 ms /    23 tokens (   11.22 ms per token,    89.16 tokens per second)\n",
      "llama_print_timings:        eval time =     698.15 ms /     8 runs   (   87.27 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =    1007.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.42 ms per token,  2398.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.95 ms /    24 tokens (   10.71 ms per token,    93.40 tokens per second)\n",
      "llama_print_timings:        eval time =      89.91 ms /     1 runs   (   89.91 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     356.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Brant Schaden\", \"Dr. Gaston Grimes\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.06 ms /    17 runs   (    0.47 ms per token,  2109.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.34 ms /   149 tokens (    7.94 ms per token,   126.02 tokens per second)\n",
      "llama_print_timings:        eval time =    1433.88 ms /    16 runs   (   89.62 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    2726.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 691 6541\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.15 ms /    15 runs   (    0.48 ms per token,  2096.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.03 ms /    25 tokens (   10.36 ms per token,    96.51 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.63 ms /    14 runs   (   88.54 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    1591.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2092.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.42 ms /    23 tokens (   11.11 ms per token,    90.05 tokens per second)\n",
      "llama_print_timings:        eval time =      93.27 ms /     1 runs   (   93.27 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     358.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.21 ms /     8 runs   (    0.28 ms per token,  3626.47 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.67 ms /    24 tokens (   10.90 ms per token,    91.72 tokens per second)\n",
      "llama_print_timings:        eval time =     665.26 ms /     7 runs   (   95.04 ms per token,    10.52 tokens per second)\n",
      "llama_print_timings:       total time =     967.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Jordan Pollich\", \"Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.31 ms /    16 runs   (    0.46 ms per token,  2189.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1439.05 ms /   166 tokens (    8.67 ms per token,   115.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1376.63 ms /    15 runs   (   91.78 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    2914.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 618 0995\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.09 ms /    15 runs   (    0.41 ms per token,  2464.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.48 ms /    25 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.10 ms /    14 runs   (   91.36 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =    1631.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.86 ms /     2 runs   (    0.43 ms per token,  2314.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.14 ms /    23 tokens (   11.18 ms per token,    89.45 tokens per second)\n",
      "llama_print_timings:        eval time =      94.12 ms /     1 runs   (   94.12 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =     364.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3327.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.17 ms /    24 tokens (   10.67 ms per token,    93.69 tokens per second)\n",
      "llama_print_timings:        eval time =      89.77 ms /     1 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =     354.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Elida Veum\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.16 ms /     7 runs   (    0.31 ms per token,  3248.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2554.44 ms /   308 tokens (    8.29 ms per token,   120.57 tokens per second)\n",
      "llama_print_timings:        eval time =     547.52 ms /     6 runs   (   91.25 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =    3138.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 415 0139\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.77 ms /    15 runs   (    0.58 ms per token,  1711.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.39 ms /    25 tokens (   10.50 ms per token,    95.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1286.11 ms /    14 runs   (   91.87 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =    1663.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     2 runs   (    0.41 ms per token,  2412.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.26 ms /    23 tokens (   11.32 ms per token,    88.37 tokens per second)\n",
      "llama_print_timings:        eval time =      86.59 ms /     1 runs   (   86.59 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     360.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     8 runs   (    0.30 ms per token,  3337.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.02 ms /    24 tokens (   10.83 ms per token,    92.30 tokens per second)\n",
      "llama_print_timings:        eval time =     668.99 ms /     7 runs   (   95.57 ms per token,    10.46 tokens per second)\n",
      "llama_print_timings:       total time =     974.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Rosella Green\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     7 runs   (    0.49 ms per token,  2033.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1430.70 ms /   167 tokens (    8.57 ms per token,   116.73 tokens per second)\n",
      "llama_print_timings:        eval time =     527.67 ms /     6 runs   (   87.95 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    2003.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 659 6406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.44 ms /    15 runs   (    0.50 ms per token,  2016.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.96 ms /    25 tokens (   10.32 ms per token,    96.92 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.96 ms /    14 runs   (   88.93 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1609.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     6 runs   (    0.45 ms per token,  2244.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.34 ms /    23 tokens (   11.28 ms per token,    88.69 tokens per second)\n",
      "llama_print_timings:        eval time =     444.36 ms /     5 runs   (   88.87 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     743.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    11 runs   (    0.46 ms per token,  2165.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.15 ms /    24 tokens (   10.76 ms per token,    92.97 tokens per second)\n",
      "llama_print_timings:        eval time =     887.18 ms /    10 runs   (   88.72 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    1212.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Hong Haley\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.93 ms /    16 runs   (    0.43 ms per token,  2307.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.72 ms /   144 tokens (    8.16 ms per token,   122.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1332.13 ms /    15 runs   (   88.81 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =    2626.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"276 697 1899\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.34 ms /    15 runs   (    0.49 ms per token,  2043.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.48 ms /    25 tokens (   10.30 ms per token,    97.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.82 ms /    14 runs   (   88.56 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    1592.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /     9 runs   (    0.37 ms per token,  2719.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.45 ms /    23 tokens (   11.11 ms per token,    90.04 tokens per second)\n",
      "llama_print_timings:        eval time =     703.08 ms /     8 runs   (   87.89 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1011.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3338.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.12 ms /    24 tokens (   10.67 ms per token,    93.70 tokens per second)\n",
      "llama_print_timings:        eval time =      87.45 ms /     1 runs   (   87.45 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     352.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Vicente Beahan\", \"Doctor Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.96 ms /    17 runs   (    0.41 ms per token,  2444.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1442.01 ms /   180 tokens (    8.01 ms per token,   124.83 tokens per second)\n",
      "llama_print_timings:        eval time =    1427.98 ms /    16 runs   (   89.25 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    2982.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"232 522 6183\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.40 ms /    15 runs   (    0.49 ms per token,  2027.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.23 ms /    25 tokens (   10.53 ms per token,    94.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1241.46 ms /    14 runs   (   88.68 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =    1610.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"67-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.86 ms /     9 runs   (    0.43 ms per token,  2332.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.73 ms /    23 tokens (   11.29 ms per token,    88.55 tokens per second)\n",
      "llama_print_timings:        eval time =     717.47 ms /     8 runs   (   89.68 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1036.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.41 ms /     2 runs   (    0.21 ms per token,  4866.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.48 ms /    24 tokens (   10.73 ms per token,    93.21 tokens per second)\n",
      "llama_print_timings:        eval time =     104.36 ms /     1 runs   (  104.36 ms per token,     9.58 tokens per second)\n",
      "llama_print_timings:       total time =     369.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Jackie Predovic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.63 ms /    10 runs   (    0.46 ms per token,  2161.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1696.22 ms /   224 tokens (    7.57 ms per token,   132.06 tokens per second)\n",
      "llama_print_timings:        eval time =     806.19 ms /     9 runs   (   89.58 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    2565.82 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"612 597 0730\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.57 ms /    15 runs   (    0.37 ms per token,  2693.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.84 ms /    25 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1244.46 ms /    14 runs   (   88.89 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =    1597.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.66 ms /     2 runs   (    0.33 ms per token,  3039.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.98 ms /    23 tokens (   11.22 ms per token,    89.16 tokens per second)\n",
      "llama_print_timings:        eval time =      88.59 ms /     1 runs   (   88.59 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =     356.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Childhood asthma\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.33 ms /     8 runs   (    0.42 ms per token,  2401.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.78 ms /    24 tokens (   10.78 ms per token,    92.74 tokens per second)\n",
      "llama_print_timings:        eval time =     607.17 ms /     7 runs   (   86.74 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =     921.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Buddy Little\", \"Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    14 runs   (    0.45 ms per token,  2232.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1410.86 ms /   167 tokens (    8.45 ms per token,   118.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1119.65 ms /    13 runs   (   86.13 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    2622.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"450 204 0273\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.76 ms /    15 runs   (    0.38 ms per token,  2602.81 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.66 ms /    25 tokens (   10.31 ms per token,    97.03 tokens per second)\n",
      "llama_print_timings:        eval time =    1230.26 ms /    14 runs   (   87.88 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1570.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     8 runs   (    0.39 ms per token,  2577.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.20 ms /    23 tokens (   11.10 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =     619.44 ms /     7 runs   (   88.49 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =     921.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     2 runs   (    0.46 ms per token,  2164.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.53 ms /    24 tokens (   10.90 ms per token,    91.77 tokens per second)\n",
      "llama_print_timings:        eval time =      93.37 ms /     1 runs   (   93.37 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =     366.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Grayce Considine\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.94 ms /    11 runs   (    0.45 ms per token,  2224.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1229.57 ms /   137 tokens (    8.97 ms per token,   111.42 tokens per second)\n",
      "llama_print_timings:        eval time =     940.76 ms /    10 runs   (   94.08 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =    2232.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"177 185 3785\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.27 ms /    15 runs   (    0.42 ms per token,  2390.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.68 ms /    25 tokens (   10.63 ms per token,    94.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1284.93 ms /    14 runs   (   91.78 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    1641.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.62 ms /     9 runs   (    0.40 ms per token,  2484.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.67 ms /    23 tokens (   11.25 ms per token,    88.92 tokens per second)\n",
      "llama_print_timings:        eval time =     702.87 ms /     8 runs   (   87.86 ms per token,    11.38 tokens per second)\n",
      "llama_print_timings:       total time =    1015.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"anemia\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     5 runs   (    0.25 ms per token,  3949.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.54 ms /    24 tokens (   10.77 ms per token,    92.83 tokens per second)\n",
      "llama_print_timings:        eval time =     380.89 ms /     4 runs   (   95.22 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =     681.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Floy D'Amore\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.33 ms /    13 runs   (    0.33 ms per token,  3003.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3371.19 ms /   388 tokens (    8.69 ms per token,   115.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.41 ms /    12 runs   (  103.28 ms per token,     9.68 tokens per second)\n",
      "llama_print_timings:       total time =    4685.33 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.79 ms /     6 runs   (    0.30 ms per token,  3355.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.45 ms /    25 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =     452.79 ms /     5 runs   (   90.56 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     750.91 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.43 ms /     2 runs   (    0.21 ms per token,  4672.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.22 ms /    23 tokens (   11.36 ms per token,    88.05 tokens per second)\n",
      "llama_print_timings:        eval time =     105.47 ms /     1 runs   (  105.47 ms per token,     9.48 tokens per second)\n",
      "llama_print_timings:       total time =     374.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.44 ms /     8 runs   (    0.43 ms per token,  2323.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.23 ms /    24 tokens (   10.93 ms per token,    91.52 tokens per second)\n",
      "llama_print_timings:        eval time =     626.66 ms /     7 runs   (   89.52 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =     944.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Petra Upton\", \"Dr. Seth Dare\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.64 ms /    18 runs   (    0.48 ms per token,  2084.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1719.06 ms /   212 tokens (    8.11 ms per token,   123.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1508.44 ms /    17 runs   (   88.73 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    3353.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"809 906 2012\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.61 ms /    15 runs   (    0.37 ms per token,  2672.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.56 ms /    25 tokens (   10.38 ms per token,    96.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1247.03 ms /    14 runs   (   89.07 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1590.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"31 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /     7 runs   (    0.38 ms per token,  2617.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.60 ms /    23 tokens (   11.20 ms per token,    89.29 tokens per second)\n",
      "llama_print_timings:        eval time =     519.48 ms /     6 runs   (   86.58 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     823.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.47 ms /     8 runs   (    0.43 ms per token,  2308.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.01 ms /    24 tokens (   10.71 ms per token,    93.38 tokens per second)\n",
      "llama_print_timings:        eval time =     603.47 ms /     7 runs   (   86.21 ms per token,    11.60 tokens per second)\n",
      "llama_print_timings:       total time =     908.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Landon Schroeder\", \"Hyman Schmeler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.39 ms /    17 runs   (    0.49 ms per token,  2026.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.54 ms /   158 tokens (    7.54 ms per token,   132.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1418.07 ms /    16 runs   (   88.63 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =    2716.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"546 507 5173\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.22 ms /    15 runs   (    0.55 ms per token,  1823.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.86 ms /    25 tokens (   10.31 ms per token,    96.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1232.68 ms /    14 runs   (   88.05 ms per token,    11.36 tokens per second)\n",
      "llama_print_timings:       total time =    1582.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     9 runs   (    0.35 ms per token,  2872.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.92 ms /    23 tokens (   11.26 ms per token,    88.83 tokens per second)\n",
      "llama_print_timings:        eval time =     714.53 ms /     8 runs   (   89.32 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1024.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /     8 runs   (    0.39 ms per token,  2546.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.91 ms /    24 tokens (   10.70 ms per token,    93.42 tokens per second)\n",
      "llama_print_timings:        eval time =     666.13 ms /     7 runs   (   95.16 ms per token,    10.51 tokens per second)\n",
      "llama_print_timings:       total time =     964.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Erin Champlin\", \"Dr Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.51 ms /    18 runs   (    0.47 ms per token,  2114.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1678.68 ms /   200 tokens (    8.39 ms per token,   119.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1523.34 ms /    17 runs   (   89.61 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    3311.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"863 775 4730\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.28 ms /    15 runs   (    0.49 ms per token,  2060.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.62 ms /    25 tokens (   10.38 ms per token,    96.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1233.87 ms /    14 runs   (   88.13 ms per token,    11.35 tokens per second)\n",
      "llama_print_timings:       total time =    1588.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.70 ms /     2 runs   (    0.35 ms per token,  2836.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    23 tokens (   11.15 ms per token,    89.66 tokens per second)\n",
      "llama_print_timings:        eval time =      90.28 ms /     1 runs   (   90.28 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =     358.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.10 ms /     2 runs   (    0.55 ms per token,  1814.88 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.86 ms /    24 tokens (   10.74 ms per token,    93.07 tokens per second)\n",
      "llama_print_timings:        eval time =      88.69 ms /     1 runs   (   88.69 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =     357.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Betsey Satterfield\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.24 ms /    11 runs   (    0.39 ms per token,  2594.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1177.73 ms /   135 tokens (    8.72 ms per token,   114.63 tokens per second)\n",
      "llama_print_timings:        eval time =     928.30 ms /    10 runs   (   92.83 ms per token,    10.77 tokens per second)\n",
      "llama_print_timings:       total time =    2168.40 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"249 937 0755\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.97 ms /    15 runs   (    0.53 ms per token,  1881.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.85 ms /    25 tokens (   10.31 ms per token,    96.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1242.75 ms /    14 runs   (   88.77 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =    1609.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.71 ms /     5 runs   (    0.54 ms per token,  1842.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.25 ms /    23 tokens (   11.14 ms per token,    89.75 tokens per second)\n",
      "llama_print_timings:        eval time =     355.07 ms /     4 runs   (   88.77 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     645.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.03 ms /     2 runs   (    0.52 ms per token,  1932.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.66 ms /    24 tokens (   10.86 ms per token,    92.07 tokens per second)\n",
      "llama_print_timings:        eval time =      94.58 ms /     1 runs   (   94.58 ms per token,    10.57 tokens per second)\n",
      "llama_print_timings:       total time =     366.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Katina Gerhold\", \"Doctor Jules Emard\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.04 ms /    15 runs   (    0.34 ms per token,  2973.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1187.89 ms /   150 tokens (    7.92 ms per token,   126.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1340.05 ms /    14 runs   (   95.72 ms per token,    10.45 tokens per second)\n",
      "llama_print_timings:       total time =    2639.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"115 274 8841\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.86 ms /    15 runs   (    0.39 ms per token,  2558.42 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.05 ms /    25 tokens (   10.60 ms per token,    94.32 tokens per second)\n",
      "llama_print_timings:        eval time =    1259.40 ms /    14 runs   (   89.96 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =    1612.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"26 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3645.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.47 ms /    23 tokens (   11.11 ms per token,    90.03 tokens per second)\n",
      "llama_print_timings:        eval time =     529.18 ms /     6 runs   (   88.20 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =     826.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\", \"stress\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.87 ms /    12 runs   (    0.41 ms per token,  2465.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.36 ms /    24 tokens (   10.72 ms per token,    93.25 tokens per second)\n",
      "llama_print_timings:        eval time =     947.23 ms /    11 runs   (   86.11 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1279.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Hwa Berge\", \"Doctor Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.36 ms /    18 runs   (    0.41 ms per token,  2446.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2776.72 ms /   349 tokens (    7.96 ms per token,   125.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1537.59 ms /    17 runs   (   90.45 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =    4440.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"278 347 6239\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.86 ms /    15 runs   (    0.52 ms per token,  1908.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.58 ms /    25 tokens (   10.54 ms per token,    94.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1253.68 ms /    14 runs   (   89.55 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    1638.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     9 runs   (    0.39 ms per token,  2550.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.63 ms /    23 tokens (   11.33 ms per token,    88.25 tokens per second)\n",
      "llama_print_timings:        eval time =     714.27 ms /     8 runs   (   89.28 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1027.49 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.73 ms /     2 runs   (    0.37 ms per token,  2721.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.51 ms /    24 tokens (   10.85 ms per token,    92.13 tokens per second)\n",
      "llama_print_timings:        eval time =      89.46 ms /     1 runs   (   89.46 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =     360.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Alvaro Kertzmann\", \"Sergio Volkman\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.91 ms /    16 runs   (    0.49 ms per token,  2023.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2735.85 ms /   345 tokens (    7.93 ms per token,   126.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1351.72 ms /    15 runs   (   90.11 ms per token,    11.10 tokens per second)\n",
      "llama_print_timings:       total time =    4195.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 182 4708\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.19 ms /    15 runs   (    0.41 ms per token,  2424.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.01 ms /    25 tokens (   10.56 ms per token,    94.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.11 ms /    14 runs   (   89.01 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1597.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"4-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.12 ms /     8 runs   (    0.52 ms per token,  1941.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.96 ms /    23 tokens (   11.35 ms per token,    88.14 tokens per second)\n",
      "llama_print_timings:        eval time =     615.73 ms /     7 runs   (   87.96 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =     933.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.65 ms /     2 runs   (    0.33 ms per token,  3067.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.28 ms /    24 tokens (   10.93 ms per token,    91.51 tokens per second)\n",
      "llama_print_timings:        eval time =      97.93 ms /     1 runs   (   97.93 ms per token,    10.21 tokens per second)\n",
      "llama_print_timings:       total time =     369.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Aurelio Barrows\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.04 ms /    10 runs   (    0.40 ms per token,  2477.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1183.03 ms /   153 tokens (    7.73 ms per token,   129.33 tokens per second)\n",
      "llama_print_timings:        eval time =     786.65 ms /     9 runs   (   87.41 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2038.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"414 494 3924\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.00 ms /    15 runs   (    0.53 ms per token,  1875.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.34 ms /    25 tokens (   10.33 ms per token,    96.77 tokens per second)\n",
      "llama_print_timings:        eval time =    1198.10 ms /    14 runs   (   85.58 ms per token,    11.69 tokens per second)\n",
      "llama_print_timings:       total time =    1563.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.40 ms /     7 runs   (    0.34 ms per token,  2921.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    23 tokens (   11.15 ms per token,    89.68 tokens per second)\n",
      "llama_print_timings:        eval time =     514.05 ms /     6 runs   (   85.67 ms per token,    11.67 tokens per second)\n",
      "llama_print_timings:       total time =     810.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.20 ms /    24 tokens (   10.72 ms per token,    93.31 tokens per second)\n",
      "llama_print_timings:        eval time =     103.12 ms /     1 runs   (  103.12 ms per token,     9.70 tokens per second)\n",
      "llama_print_timings:       total time =     369.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Arlie McGlynn\", \"Kristopher Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.47 ms /    17 runs   (    0.50 ms per token,  2007.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1405.17 ms /   162 tokens (    8.67 ms per token,   115.29 tokens per second)\n",
      "llama_print_timings:        eval time =    1426.24 ms /    16 runs   (   89.14 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    2945.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"327 727 4771\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.10 ms /    15 runs   (    0.41 ms per token,  2460.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.01 ms /    25 tokens (   10.36 ms per token,    96.52 tokens per second)\n",
      "llama_print_timings:        eval time =    1279.28 ms /    14 runs   (   91.38 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =    1636.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"16 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /     7 runs   (    0.68 ms per token,  1470.90 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.35 ms /    23 tokens (   11.19 ms per token,    89.37 tokens per second)\n",
      "llama_print_timings:        eval time =     545.92 ms /     6 runs   (   90.99 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =     853.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.78 ms /     8 runs   (    0.60 ms per token,  1675.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    24 tokens (   10.69 ms per token,    93.58 tokens per second)\n",
      "llama_print_timings:        eval time =     602.49 ms /     7 runs   (   86.07 ms per token,    11.62 tokens per second)\n",
      "llama_print_timings:       total time =     913.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Trey Prohaska\", \"Daniel Wolff\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.49 ms /    13 runs   (    0.35 ms per token,  2897.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1672.79 ms /   203 tokens (    8.24 ms per token,   121.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1053.46 ms /    12 runs   (   87.79 ms per token,    11.39 tokens per second)\n",
      "llama_print_timings:       total time =    2802.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"490 117 3360\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.02 ms /    15 runs   (    0.40 ms per token,  2490.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.33 ms /    25 tokens (   10.45 ms per token,    95.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.45 ms /    14 runs   (   91.03 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    1633.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"12 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     7 runs   (    0.40 ms per token,  2486.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.22 ms /    23 tokens (   11.49 ms per token,    87.05 tokens per second)\n",
      "llama_print_timings:        eval time =     529.78 ms /     6 runs   (   88.30 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     842.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10101.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.33 ms /    24 tokens (   10.81 ms per token,    92.55 tokens per second)\n",
      "llama_print_timings:        eval time =      94.03 ms /     1 runs   (   94.03 ms per token,    10.64 tokens per second)\n",
      "llama_print_timings:       total time =     358.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rolf Orn\", \"Doctor Eldon Cassin\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.89 ms /    18 runs   (    0.49 ms per token,  2025.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1416.25 ms /   172 tokens (    8.23 ms per token,   121.45 tokens per second)\n",
      "llama_print_timings:        eval time =    1469.30 ms /    17 runs   (   86.43 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =    3029.83 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"199 288 5236\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.61 ms /    15 runs   (    0.44 ms per token,  2269.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.13 ms /    25 tokens (   10.25 ms per token,    97.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1217.82 ms /    14 runs   (   86.99 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =    1562.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"56-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.87 ms /     9 runs   (    0.43 ms per token,  2327.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.29 ms /    23 tokens (   11.10 ms per token,    90.10 tokens per second)\n",
      "llama_print_timings:        eval time =     692.80 ms /     8 runs   (   86.60 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =    1007.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.60 ms /     2 runs   (    0.30 ms per token,  3322.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.38 ms /    24 tokens (   10.72 ms per token,    93.25 tokens per second)\n",
      "llama_print_timings:        eval time =      87.23 ms /     1 runs   (   87.23 ms per token,    11.46 tokens per second)\n",
      "llama_print_timings:       total time =     354.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Beatrice Littel\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.79 ms /    18 runs   (    0.54 ms per token,  1839.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.99 ms /   154 tokens (    7.71 ms per token,   129.74 tokens per second)\n",
      "llama_print_timings:        eval time =    1468.22 ms /    17 runs   (   86.37 ms per token,    11.58 tokens per second)\n",
      "llama_print_timings:       total time =    2788.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"892 189 2474\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.49 ms /    15 runs   (    0.43 ms per token,  2310.54 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.38 ms /    25 tokens (   10.46 ms per token,    95.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1209.60 ms /    14 runs   (   86.40 ms per token,    11.57 tokens per second)\n",
      "llama_print_timings:       total time =    1559.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"38-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.63 ms /     9 runs   (    0.40 ms per token,  2477.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.32 ms /    23 tokens (   11.23 ms per token,    89.04 tokens per second)\n",
      "llama_print_timings:        eval time =     686.93 ms /     8 runs   (   85.87 ms per token,    11.65 tokens per second)\n",
      "llama_print_timings:       total time =    1002.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     2 runs   (    0.50 ms per token,  1998.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.11 ms /    24 tokens (   10.71 ms per token,    93.35 tokens per second)\n",
      "llama_print_timings:        eval time =      87.20 ms /     1 runs   (   87.20 ms per token,    11.47 tokens per second)\n",
      "llama_print_timings:       total time =     358.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Beatris Feest\", \"Doctor Florine Windler\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.14 ms /    18 runs   (    0.51 ms per token,  1968.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1666.60 ms /   203 tokens (    8.21 ms per token,   121.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1477.52 ms /    17 runs   (   86.91 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =    3275.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"440 905 7206\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.09 ms /    15 runs   (    0.61 ms per token,  1650.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.57 ms /    25 tokens (   10.38 ms per token,    96.31 tokens per second)\n",
      "llama_print_timings:        eval time =    1218.66 ms /    14 runs   (   87.05 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    1582.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"40 year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.50 ms /     8 runs   (    0.31 ms per token,  3200.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.12 ms /    23 tokens (   11.27 ms per token,    88.76 tokens per second)\n",
      "llama_print_timings:        eval time =     611.92 ms /     7 runs   (   87.42 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =     914.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.21 ms /     8 runs   (    0.40 ms per token,  2490.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.12 ms /    24 tokens (   10.71 ms per token,    93.34 tokens per second)\n",
      "llama_print_timings:        eval time =     608.26 ms /     7 runs   (   86.89 ms per token,    11.51 tokens per second)\n",
      "llama_print_timings:       total time =     914.35 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Charlott Bergstrom\", \"Dr. Carlena Feil\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =      10.64 ms /    20 runs   (    0.53 ms per token,  1879.17 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1179.35 ms /   147 tokens (    8.02 ms per token,   124.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1647.59 ms /    19 runs   (   86.72 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    2965.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"166 819 4979\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.80 ms /    15 runs   (    0.59 ms per token,  1704.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.10 ms /    25 tokens (   10.32 ms per token,    96.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1213.86 ms /    14 runs   (   86.70 ms per token,    11.53 tokens per second)\n",
      "llama_print_timings:       total time =    1583.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     2 runs   (    0.60 ms per token,  1661.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     254.96 ms /    23 tokens (   11.09 ms per token,    90.21 tokens per second)\n",
      "llama_print_timings:        eval time =      86.98 ms /     1 runs   (   86.98 ms per token,    11.50 tokens per second)\n",
      "llama_print_timings:       total time =     353.06 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.95 ms /     8 runs   (    0.62 ms per token,  1616.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.24 ms /    24 tokens (   10.72 ms per token,    93.30 tokens per second)\n",
      "llama_print_timings:        eval time =     601.28 ms /     7 runs   (   85.90 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     914.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Nickole Konopelski\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.06 ms /    20 runs   (    0.45 ms per token,  2207.02 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1184.01 ms /   150 tokens (    7.89 ms per token,   126.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1671.18 ms /    19 runs   (   87.96 ms per token,    11.37 tokens per second)\n",
      "llama_print_timings:       total time =    2995.72 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"753 859 9608\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.57 ms /    15 runs   (    0.50 ms per token,  1982.29 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.56 ms /    25 tokens (   10.30 ms per token,    97.07 tokens per second)\n",
      "llama_print_timings:        eval time =    1206.11 ms /    14 runs   (   86.15 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =    1557.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.92 ms /     7 runs   (    0.42 ms per token,  2396.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.17 ms /    23 tokens (   11.09 ms per token,    90.13 tokens per second)\n",
      "llama_print_timings:        eval time =     532.36 ms /     6 runs   (   88.73 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     827.42 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.86 ms /     8 runs   (    0.61 ms per token,  1646.09 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.02 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     605.92 ms /     7 runs   (   86.56 ms per token,    11.55 tokens per second)\n",
      "llama_print_timings:       total time =     923.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Curtis Schulist\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.53 ms /     9 runs   (    0.39 ms per token,  2546.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3346.40 ms /   391 tokens (    8.56 ms per token,   116.84 tokens per second)\n",
      "llama_print_timings:        eval time =     781.24 ms /     8 runs   (   97.65 ms per token,    10.24 tokens per second)\n",
      "llama_print_timings:       total time =    4199.88 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"407 892 6053\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.38 ms /    15 runs   (    0.43 ms per token,  2350.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.56 ms /    25 tokens (   10.62 ms per token,    94.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.32 ms /    14 runs   (   90.24 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1630.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"37 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.95 ms /     7 runs   (    0.42 ms per token,  2375.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.07 ms /    23 tokens (   11.39 ms per token,    87.76 tokens per second)\n",
      "llama_print_timings:        eval time =     547.51 ms /     6 runs   (   91.25 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =     852.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10695.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.25 ms /    24 tokens (   11.01 ms per token,    90.82 tokens per second)\n",
      "llama_print_timings:        eval time =      99.08 ms /     1 runs   (   99.08 ms per token,    10.09 tokens per second)\n",
      "llama_print_timings:       total time =     370.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Cassie Mertz\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.88 ms /    19 runs   (    0.41 ms per token,  2409.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1992.26 ms /   228 tokens (    8.74 ms per token,   114.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1656.35 ms /    18 runs   (   92.02 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =    3766.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"735 869 5162\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /    15 runs   (    0.36 ms per token,  2813.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.83 ms /    25 tokens (   10.43 ms per token,    95.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1309.85 ms /    14 runs   (   93.56 ms per token,    10.69 tokens per second)\n",
      "llama_print_timings:       total time =    1649.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"32-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.42 ms /     9 runs   (    0.38 ms per token,  2632.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.60 ms /    23 tokens (   11.33 ms per token,    88.26 tokens per second)\n",
      "llama_print_timings:        eval time =     727.42 ms /     8 runs   (   90.93 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    1037.58 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.25 ms /     8 runs   (    0.41 ms per token,  2462.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.80 ms /    24 tokens (   10.78 ms per token,    92.74 tokens per second)\n",
      "llama_print_timings:        eval time =     647.70 ms /     7 runs   (   92.53 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =     955.77 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rory Sawayn\", \"Dr. Dominic Miller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.16 ms /    17 runs   (    0.42 ms per token,  2374.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1958.12 ms /   233 tokens (    8.40 ms per token,   118.99 tokens per second)\n",
      "llama_print_timings:        eval time =    1494.30 ms /    16 runs   (   93.39 ms per token,    10.71 tokens per second)\n",
      "llama_print_timings:       total time =    3565.70 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"479 664 5598\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.64 ms /    15 runs   (    0.44 ms per token,  2260.40 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.40 ms /    25 tokens (   10.50 ms per token,    95.27 tokens per second)\n",
      "llama_print_timings:        eval time =    1262.73 ms /    14 runs   (   90.20 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =    1621.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"58-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.13 ms /     9 runs   (    0.35 ms per token,  2878.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.49 ms /    23 tokens (   11.54 ms per token,    86.63 tokens per second)\n",
      "llama_print_timings:        eval time =     795.65 ms /     8 runs   (   99.46 ms per token,    10.05 tokens per second)\n",
      "llama_print_timings:       total time =    1111.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.64 ms /     2 runs   (    0.32 ms per token,  3144.65 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.45 ms /    24 tokens (   10.77 ms per token,    92.86 tokens per second)\n",
      "llama_print_timings:        eval time =      87.55 ms /     1 runs   (   87.55 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     356.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Davida Predovic\", \"Dr. Rod Frami\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.25 ms /    17 runs   (    0.43 ms per token,  2344.83 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1748.68 ms /   221 tokens (    7.91 ms per token,   126.38 tokens per second)\n",
      "llama_print_timings:        eval time =    1427.46 ms /    16 runs   (   89.22 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =    3294.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 232 4477\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.99 ms /    15 runs   (    0.47 ms per token,  2145.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.67 ms /    25 tokens (   10.35 ms per token,    96.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1318.77 ms /    14 runs   (   94.20 ms per token,    10.62 tokens per second)\n",
      "llama_print_timings:       total time =    1671.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.96 ms /     2 runs   (    0.48 ms per token,  2085.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     265.38 ms /    23 tokens (   11.54 ms per token,    86.67 tokens per second)\n",
      "llama_print_timings:        eval time =     115.56 ms /     1 runs   (  115.56 ms per token,     8.65 tokens per second)\n",
      "llama_print_timings:       total time =     393.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.53 ms /     2 runs   (    0.27 ms per token,  3745.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.64 ms /    24 tokens (   10.99 ms per token,    91.03 tokens per second)\n",
      "llama_print_timings:        eval time =      91.80 ms /     1 runs   (   91.80 ms per token,    10.89 tokens per second)\n",
      "llama_print_timings:       total time =     362.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Bernard Nienow\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.27 ms /     9 runs   (    0.47 ms per token,  2106.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1202.10 ms /   148 tokens (    8.12 ms per token,   123.12 tokens per second)\n",
      "llama_print_timings:        eval time =     723.07 ms /     8 runs   (   90.38 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =    1985.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 272 0275\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    15 runs   (    0.41 ms per token,  2455.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.45 ms /    25 tokens (   10.54 ms per token,    94.90 tokens per second)\n",
      "llama_print_timings:        eval time =    1297.09 ms /    14 runs   (   92.65 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =    1659.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /     6 runs   (    0.52 ms per token,  1937.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.59 ms /    23 tokens (   11.20 ms per token,    89.29 tokens per second)\n",
      "llama_print_timings:        eval time =     455.40 ms /     5 runs   (   91.08 ms per token,    10.98 tokens per second)\n",
      "llama_print_timings:       total time =     756.86 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.51 ms /     2 runs   (    0.26 ms per token,  3906.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     264.93 ms /    24 tokens (   11.04 ms per token,    90.59 tokens per second)\n",
      "llama_print_timings:        eval time =     110.47 ms /     1 runs   (  110.47 ms per token,     9.05 tokens per second)\n",
      "llama_print_timings:       total time =     382.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Beatris Thompson\", \"doctor Margarite Koepp\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.90 ms /    21 runs   (    0.47 ms per token,  2121.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1294.23 ms /   159 tokens (    8.14 ms per token,   122.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1796.81 ms /    20 runs   (   89.84 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    3233.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"165 542 2930\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.41 ms /    15 runs   (    0.36 ms per token,  2773.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     290.51 ms /    25 tokens (   11.62 ms per token,    86.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1431.96 ms /    14 runs   (  102.28 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =    1807.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.87 ms /     5 runs   (    0.37 ms per token,  2675.23 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.80 ms /    23 tokens (   12.38 ms per token,    80.76 tokens per second)\n",
      "llama_print_timings:        eval time =     409.05 ms /     4 runs   (  102.26 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     724.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.62 ms /     2 runs   (    0.31 ms per token,  3200.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     288.34 ms /    24 tokens (   12.01 ms per token,    83.23 tokens per second)\n",
      "llama_print_timings:        eval time =     105.19 ms /     1 runs   (  105.19 ms per token,     9.51 tokens per second)\n",
      "llama_print_timings:       total time =     402.56 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Russel Aufderhar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.54 ms /    10 runs   (    0.35 ms per token,  2827.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1319.51 ms /   155 tokens (    8.51 ms per token,   117.47 tokens per second)\n",
      "llama_print_timings:        eval time =     900.18 ms /     9 runs   (  100.02 ms per token,    10.00 tokens per second)\n",
      "llama_print_timings:       total time =    2280.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 495 5015\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.65 ms /    15 runs   (    0.44 ms per token,  2254.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     291.37 ms /    25 tokens (   11.65 ms per token,    85.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1412.53 ms /    14 runs   (  100.89 ms per token,     9.91 tokens per second)\n",
      "llama_print_timings:       total time =    1792.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"14-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.84 ms /     9 runs   (    0.32 ms per token,  3170.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     284.95 ms /    23 tokens (   12.39 ms per token,    80.72 tokens per second)\n",
      "llama_print_timings:        eval time =     827.89 ms /     8 runs   (  103.49 ms per token,     9.66 tokens per second)\n",
      "llama_print_timings:       total time =    1159.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"respiratory\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.32 ms /     6 runs   (    0.39 ms per token,  2588.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     283.16 ms /    24 tokens (   11.80 ms per token,    84.76 tokens per second)\n",
      "llama_print_timings:        eval time =     506.46 ms /     5 runs   (  101.29 ms per token,     9.87 tokens per second)\n",
      "llama_print_timings:       total time =     825.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Lorraine Gleichner\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       9.03 ms /    18 runs   (    0.50 ms per token,  1994.46 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1322.29 ms /   154 tokens (    8.59 ms per token,   116.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1658.50 ms /    17 runs   (   97.56 ms per token,    10.25 tokens per second)\n",
      "llama_print_timings:       total time =    3096.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"345 873 8687\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.11 ms /    15 runs   (    0.41 ms per token,  2454.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.66 ms /    25 tokens (   10.35 ms per token,    96.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1272.12 ms /    14 runs   (   90.87 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    1614.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"49-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.33 ms /     9 runs   (    0.59 ms per token,  1688.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.84 ms /    23 tokens (   11.17 ms per token,    89.55 tokens per second)\n",
      "llama_print_timings:        eval time =     732.01 ms /     8 runs   (   91.50 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =    1051.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     2 runs   (    0.34 ms per token,  2967.36 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.61 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =      88.36 ms /     1 runs   (   88.36 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     354.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Leonard Barrows\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.83 ms /     8 runs   (    0.35 ms per token,  2831.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1169.19 ms /   132 tokens (    8.86 ms per token,   112.90 tokens per second)\n",
      "llama_print_timings:        eval time =     619.47 ms /     7 runs   (   88.50 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    1838.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"423 614 3892\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       7.09 ms /    15 runs   (    0.47 ms per token,  2114.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.28 ms /    25 tokens (   10.29 ms per token,    97.17 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.45 ms /    14 runs   (   90.32 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1624.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"70-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.85 ms /     9 runs   (    0.43 ms per token,  2339.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.48 ms /    23 tokens (   11.24 ms per token,    88.98 tokens per second)\n",
      "llama_print_timings:        eval time =     699.66 ms /     8 runs   (   87.46 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =    1006.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.85 ms /     2 runs   (    0.42 ms per token,  2361.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.40 ms /    24 tokens (   10.68 ms per token,    93.60 tokens per second)\n",
      "llama_print_timings:        eval time =      87.64 ms /     1 runs   (   87.64 ms per token,    11.41 tokens per second)\n",
      "llama_print_timings:       total time =     356.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Trena Hills\", \"Dr. Emory Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       8.35 ms /    18 runs   (    0.46 ms per token,  2155.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1182.11 ms /   150 tokens (    7.88 ms per token,   126.89 tokens per second)\n",
      "llama_print_timings:        eval time =    1479.53 ms /    17 runs   (   87.03 ms per token,    11.49 tokens per second)\n",
      "llama_print_timings:       total time =    2783.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"663 768 9279\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.90 ms /    15 runs   (    0.46 ms per token,  2172.97 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.59 ms /    25 tokens (   10.30 ms per token,    97.05 tokens per second)\n",
      "llama_print_timings:        eval time =    1222.94 ms /    14 runs   (   87.35 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    1573.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"20\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /     5 runs   (    0.42 ms per token,  2406.16 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.60 ms /    23 tokens (   11.24 ms per token,    88.94 tokens per second)\n",
      "llama_print_timings:        eval time =     344.39 ms /     4 runs   (   86.10 ms per token,    11.61 tokens per second)\n",
      "llama_print_timings:       total time =     629.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /     8 runs   (    0.42 ms per token,  2373.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.02 ms /    24 tokens (   10.67 ms per token,    93.74 tokens per second)\n",
      "llama_print_timings:        eval time =     601.49 ms /     7 runs   (   85.93 ms per token,    11.64 tokens per second)\n",
      "llama_print_timings:       total time =     908.38 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Librada Mertz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.83 ms /     9 runs   (    0.43 ms per token,  2349.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.86 ms /   149 tokens (    7.93 ms per token,   126.07 tokens per second)\n",
      "llama_print_timings:        eval time =     705.24 ms /     8 runs   (   88.16 ms per token,    11.34 tokens per second)\n",
      "llama_print_timings:       total time =    1946.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 396 5575\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.82 ms /    15 runs   (    0.39 ms per token,  2575.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.31 ms /    25 tokens (   10.37 ms per token,    96.41 tokens per second)\n",
      "llama_print_timings:        eval time =    1298.40 ms /    14 runs   (   92.74 ms per token,    10.78 tokens per second)\n",
      "llama_print_timings:       total time =    1635.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     278.06 ms /    23 tokens (   12.09 ms per token,    82.72 tokens per second)\n",
      "llama_print_timings:        eval time =     120.91 ms /     1 runs   (  120.91 ms per token,     8.27 tokens per second)\n",
      "llama_print_timings:       total time =     413.81 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute bronchitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     8 runs   (    0.15 ms per token,  6514.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.86 ms /    24 tokens (   10.79 ms per token,    92.72 tokens per second)\n",
      "llama_print_timings:        eval time =     676.15 ms /     7 runs   (   96.59 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =     956.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Kerry Ward\", \"Brandon Gerlach\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.94 ms /    14 runs   (    0.14 ms per token,  7205.35 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1214.28 ms /   149 tokens (    8.15 ms per token,   122.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.06 ms /    13 runs   (   96.62 ms per token,    10.35 tokens per second)\n",
      "llama_print_timings:       total time =    2507.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 205 8833\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.08 ms /    15 runs   (    0.14 ms per token,  7228.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.89 ms /    25 tokens (   10.40 ms per token,    96.20 tokens per second)\n",
      "llama_print_timings:        eval time =    1310.48 ms /    14 runs   (   93.61 ms per token,    10.68 tokens per second)\n",
      "llama_print_timings:       total time =    1607.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10638.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.41 ms /    23 tokens (   11.10 ms per token,    90.05 tokens per second)\n",
      "llama_print_timings:        eval time =      93.88 ms /     1 runs   (   93.88 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =     352.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.54 ms /    24 tokens (   10.73 ms per token,    93.19 tokens per second)\n",
      "llama_print_timings:        eval time =      97.06 ms /     1 runs   (   97.06 ms per token,    10.30 tokens per second)\n",
      "llama_print_timings:       total time =     360.59 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Bethany Kuhlman\", \"Dr. Nikia Williamson\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.13 ms /    19 runs   (    0.11 ms per token,  8911.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1217.53 ms /   157 tokens (    7.75 ms per token,   128.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1740.27 ms /    18 runs   (   96.68 ms per token,    10.34 tokens per second)\n",
      "llama_print_timings:       total time =    3010.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"230 102 6346\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.62 ms /    15 runs   (    0.11 ms per token,  9230.77 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.95 ms /    25 tokens (   10.36 ms per token,    96.54 tokens per second)\n",
      "llama_print_timings:        eval time =    1312.24 ms /    14 runs   (   93.73 ms per token,    10.67 tokens per second)\n",
      "llama_print_timings:       total time =    1604.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"46-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     9 runs   (    0.22 ms per token,  4479.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.74 ms /    23 tokens (   11.12 ms per token,    89.93 tokens per second)\n",
      "llama_print_timings:        eval time =     717.72 ms /     8 runs   (   89.72 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1009.19 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.99 ms /     8 runs   (    0.25 ms per token,  4022.12 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.62 ms /    24 tokens (   10.73 ms per token,    93.16 tokens per second)\n",
      "llama_print_timings:        eval time =     645.17 ms /     7 runs   (   92.17 ms per token,    10.85 tokens per second)\n",
      "llama_print_timings:       total time =     933.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Noe Beatty\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.64 ms /     9 runs   (    0.18 ms per token,  5491.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1171.08 ms /   140 tokens (    8.36 ms per token,   119.55 tokens per second)\n",
      "llama_print_timings:        eval time =     738.24 ms /     8 runs   (   92.28 ms per token,    10.84 tokens per second)\n",
      "llama_print_timings:       total time =    1937.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"839 984 2002\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.66 ms /    15 runs   (    0.18 ms per token,  5636.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.24 ms /    25 tokens (   10.45 ms per token,    95.70 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.20 ms /    14 runs   (   90.23 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1573.41 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.83 ms /     7 runs   (    0.12 ms per token,  8454.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.67 ms /    23 tokens (   11.12 ms per token,    89.96 tokens per second)\n",
      "llama_print_timings:        eval time =     540.90 ms /     6 runs   (   90.15 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     816.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.91 ms /     8 runs   (    0.24 ms per token,  4197.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.34 ms /    24 tokens (   10.64 ms per token,    93.99 tokens per second)\n",
      "llama_print_timings:        eval time =     618.15 ms /     7 runs   (   88.31 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     908.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Arnulfo Morissette PhD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    13 runs   (    0.21 ms per token,  4878.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.48 ms /   177 tokens (    8.10 ms per token,   123.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1061.03 ms /    12 runs   (   88.42 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =    2554.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"594 831 1488\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    15 runs   (    0.21 ms per token,  4862.24 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.61 ms /    25 tokens (   10.38 ms per token,    96.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.95 ms /    14 runs   (   91.71 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    1603.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.83 ms /    23 tokens (   11.12 ms per token,    89.90 tokens per second)\n",
      "llama_print_timings:        eval time =      91.01 ms /     1 runs   (   91.01 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =     351.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    12 runs   (    0.23 ms per token,  4410.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.52 ms /    24 tokens (   10.69 ms per token,    93.56 tokens per second)\n",
      "llama_print_timings:        eval time =     988.45 ms /    11 runs   (   89.86 ms per token,    11.13 tokens per second)\n",
      "llama_print_timings:       total time =    1295.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Genny Brekke\", \"Dr. Margaret Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    15 runs   (    0.19 ms per token,  5353.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1421.43 ms /   176 tokens (    8.08 ms per token,   123.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.58 ms /    14 runs   (   89.61 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    2733.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 165 6032\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.06 ms /    15 runs   (    0.20 ms per token,  4901.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.76 ms /    25 tokens (   10.35 ms per token,    96.61 tokens per second)\n",
      "llama_print_timings:        eval time =    1226.00 ms /    14 runs   (   87.57 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =    1539.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.75 ms /    23 tokens (   11.12 ms per token,    89.93 tokens per second)\n",
      "llama_print_timings:        eval time =     103.62 ms /     1 runs   (  103.62 ms per token,     9.65 tokens per second)\n",
      "llama_print_timings:       total time =     362.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.81 ms /     6 runs   (    0.14 ms per token,  7371.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.47 ms /    24 tokens (   10.64 ms per token,    93.94 tokens per second)\n",
      "llama_print_timings:        eval time =     436.86 ms /     5 runs   (   87.37 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =     714.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Laronda Wolf\", \"Dr. Blythe Heller\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.22 ms /    18 runs   (    0.23 ms per token,  4263.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1428.03 ms /   179 tokens (    7.98 ms per token,   125.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1486.97 ms /    17 runs   (   87.47 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =    2994.03 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"191 848 3406\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.77 ms /    15 runs   (    0.18 ms per token,  5421.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    25 tokens (   10.26 ms per token,    97.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1240.55 ms /    14 runs   (   88.61 ms per token,    11.29 tokens per second)\n",
      "llama_print_timings:       total time =    1552.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.23 ms /     2 runs   (    0.12 ms per token,  8620.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.63 ms /    23 tokens (   11.11 ms per token,    89.97 tokens per second)\n",
      "llama_print_timings:        eval time =      89.69 ms /     1 runs   (   89.69 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     351.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.52 ms /     8 runs   (    0.31 ms per token,  3180.91 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.35 ms /    24 tokens (   10.72 ms per token,    93.26 tokens per second)\n",
      "llama_print_timings:        eval time =     609.87 ms /     7 runs   (   87.12 ms per token,    11.48 tokens per second)\n",
      "llama_print_timings:       total time =     899.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Santo Crist\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     7 runs   (    0.17 ms per token,  5847.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3104.03 ms /   369 tokens (    8.41 ms per token,   118.88 tokens per second)\n",
      "llama_print_timings:        eval time =     543.54 ms /     6 runs   (   90.59 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =    3672.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"460 934 5153\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.99 ms /    15 runs   (    0.20 ms per token,  5013.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.13 ms /    25 tokens (   10.49 ms per token,    95.37 tokens per second)\n",
      "llama_print_timings:        eval time =    1255.53 ms /    14 runs   (   89.68 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1581.17 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 10989.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.67 ms /    23 tokens (   11.33 ms per token,    88.23 tokens per second)\n",
      "llama_print_timings:        eval time =     106.98 ms /     1 runs   (  106.98 ms per token,     9.35 tokens per second)\n",
      "llama_print_timings:       total time =     371.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Generalized Anxiety Disorder\", \"Alcohol Use Disorders\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.43 ms /    18 runs   (    0.25 ms per token,  4063.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.76 ms /    24 tokens (   10.91 ms per token,    91.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1529.32 ms /    17 runs   (   89.96 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =    1870.00 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Pierre Lubowitz\", \"Dr Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    16 runs   (    0.26 ms per token,  3869.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =    3268.24 ms /   395 tokens (    8.27 ms per token,   120.86 tokens per second)\n",
      "llama_print_timings:        eval time =    1353.57 ms /    15 runs   (   90.24 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    4703.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"249 158 2820\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.70 ms /    15 runs   (    0.25 ms per token,  4049.68 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.53 ms /    25 tokens (   10.46 ms per token,    95.59 tokens per second)\n",
      "llama_print_timings:        eval time =    1273.13 ms /    14 runs   (   90.94 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    1598.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8298.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.71 ms /    23 tokens (   11.34 ms per token,    88.22 tokens per second)\n",
      "llama_print_timings:        eval time =      91.88 ms /     1 runs   (   91.88 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     356.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.68 ms /    11 runs   (    0.24 ms per token,  4102.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.48 ms /    24 tokens (   10.89 ms per token,    91.79 tokens per second)\n",
      "llama_print_timings:        eval time =     895.38 ms /    10 runs   (   89.54 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    1206.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Rosalva Lemke\", \"Dr. Latasha Fay\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.61 ms /    19 runs   (    0.19 ms per token,  5258.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1937.89 ms /   227 tokens (    8.54 ms per token,   117.14 tokens per second)\n",
      "llama_print_timings:        eval time =    1573.07 ms /    18 runs   (   87.39 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    3592.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 728 0532\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.06 ms /    15 runs   (    0.27 ms per token,  3694.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.56 ms /    25 tokens (   10.34 ms per token,    96.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1235.30 ms /    14 runs   (   88.24 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =    1565.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"51-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.11 ms /     9 runs   (    0.12 ms per token,  8122.74 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.83 ms /    23 tokens (   11.38 ms per token,    87.84 tokens per second)\n",
      "llama_print_timings:        eval time =     712.65 ms /     8 runs   (   89.08 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1005.78 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Escherichia coli urinary tract infection\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.68 ms /    14 runs   (    0.26 ms per token,  3809.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.07 ms /    24 tokens (   10.75 ms per token,    93.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1135.62 ms /    13 runs   (   87.36 ms per token,    11.45 tokens per second)\n",
      "llama_print_timings:       total time =    1463.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Cliff O'Reilly\", \"Doctor Leoma Jaskolski\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.75 ms /    19 runs   (    0.30 ms per token,  3307.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1433.96 ms /   186 tokens (    7.71 ms per token,   129.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1575.07 ms /    18 runs   (   87.50 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =    3099.57 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 999 326 6601\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       5.08 ms /    19 runs   (    0.27 ms per token,  3737.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.91 ms /    25 tokens (   10.36 ms per token,    96.56 tokens per second)\n",
      "llama_print_timings:        eval time =    1592.32 ms /    18 runs   (   88.46 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    1937.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8230.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.16 ms /    23 tokens (   11.18 ms per token,    89.44 tokens per second)\n",
      "llama_print_timings:        eval time =      88.42 ms /     1 runs   (   88.42 ms per token,    11.31 tokens per second)\n",
      "llama_print_timings:       total time =     348.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8438.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.29 ms /    24 tokens (   10.68 ms per token,    93.65 tokens per second)\n",
      "llama_print_timings:        eval time =      91.41 ms /     1 runs   (   91.41 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     350.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Augustus Herman\", \"Doctor Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.50 ms /    16 runs   (    0.22 ms per token,  4574.04 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1413.75 ms /   171 tokens (    8.27 ms per token,   120.96 tokens per second)\n",
      "llama_print_timings:        eval time =    1310.69 ms /    15 runs   (   87.38 ms per token,    11.44 tokens per second)\n",
      "llama_print_timings:       total time =    2782.18 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 593 495 3201\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.76 ms /    19 runs   (    0.25 ms per token,  3994.11 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.72 ms /    25 tokens (   10.35 ms per token,    96.63 tokens per second)\n",
      "llama_print_timings:        eval time =    1601.27 ms /    18 runs   (   88.96 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1943.44 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"53 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.40 ms /     7 runs   (    0.20 ms per token,  4996.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.64 ms /    23 tokens (   11.11 ms per token,    89.97 tokens per second)\n",
      "llama_print_timings:        eval time =     524.92 ms /     6 runs   (   87.49 ms per token,    11.43 tokens per second)\n",
      "llama_print_timings:       total time =     807.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7751.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.75 ms /    24 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_print_timings:        eval time =      91.28 ms /     1 runs   (   91.28 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =     350.98 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Dana Schumm\", \"Bernie Borer\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.66 ms /    14 runs   (    0.26 ms per token,  3830.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.81 ms /   181 tokens (    7.93 ms per token,   126.15 tokens per second)\n",
      "llama_print_timings:        eval time =    1128.65 ms /    13 runs   (   86.82 ms per token,    11.52 tokens per second)\n",
      "llama_print_timings:       total time =    2625.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"759 101 5229\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.16 ms /    15 runs   (    0.21 ms per token,  4752.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.58 ms /    25 tokens (   10.34 ms per token,    96.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1237.01 ms /    14 runs   (   88.36 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =    1560.48 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.08 ms /     6 runs   (    0.18 ms per token,  5571.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.03 ms /    23 tokens (   11.13 ms per token,    89.83 tokens per second)\n",
      "llama_print_timings:        eval time =     457.77 ms /     5 runs   (   91.55 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =     737.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Seasonal allergic rhinitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.38 ms /    12 runs   (    0.20 ms per token,  5048.38 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.12 ms /    24 tokens (   10.88 ms per token,    91.91 tokens per second)\n",
      "llama_print_timings:        eval time =     984.71 ms /    11 runs   (   89.52 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    1288.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Kiyoko Schmidt\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.38 ms /    10 runs   (    0.14 ms per token,  7272.73 tokens per second)\n",
      "llama_print_timings: prompt eval time =     935.59 ms /   128 tokens (    7.31 ms per token,   136.81 tokens per second)\n",
      "llama_print_timings:        eval time =     802.24 ms /     9 runs   (   89.14 ms per token,    11.22 tokens per second)\n",
      "llama_print_timings:       total time =    1766.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 343 402 7925\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.34 ms /    19 runs   (    0.23 ms per token,  4378.89 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.59 ms /    25 tokens (   10.34 ms per token,    96.68 tokens per second)\n",
      "llama_print_timings:        eval time =    1557.68 ms /    18 runs   (   86.54 ms per token,    11.56 tokens per second)\n",
      "llama_print_timings:       total time =    1895.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"18 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.00 ms /     7 runs   (    0.14 ms per token,  7000.00 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.38 ms /    23 tokens (   11.19 ms per token,    89.36 tokens per second)\n",
      "llama_print_timings:        eval time =     568.94 ms /     6 runs   (   94.82 ms per token,    10.55 tokens per second)\n",
      "llama_print_timings:       total time =     844.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     8 runs   (    0.25 ms per token,  3976.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.30 ms /    24 tokens (   10.68 ms per token,    93.64 tokens per second)\n",
      "llama_print_timings:        eval time =     613.02 ms /     7 runs   (   87.57 ms per token,    11.42 tokens per second)\n",
      "llama_print_timings:       total time =     900.26 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Shameka Nitzsche\", \"Doctor Theo Rohan\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.36 ms /    18 runs   (    0.13 ms per token,  7617.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1450.48 ms /   180 tokens (    8.06 ms per token,   124.10 tokens per second)\n",
      "llama_print_timings:        eval time =    1553.12 ms /    17 runs   (   91.36 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =    3061.39 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 607 0525\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.03 ms /    15 runs   (    0.20 ms per token,  4952.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.99 ms /    25 tokens (   10.40 ms per token,    96.16 tokens per second)\n",
      "llama_print_timings:        eval time =    1370.23 ms /    14 runs   (   97.87 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =    1699.75 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.55 ms /     2 runs   (    0.27 ms per token,  3669.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.16 ms /    23 tokens (   11.14 ms per token,    89.79 tokens per second)\n",
      "llama_print_timings:        eval time =      88.74 ms /     1 runs   (   88.74 ms per token,    11.27 tokens per second)\n",
      "llama_print_timings:       total time =     350.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.28 ms /     7 runs   (    0.18 ms per token,  5464.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.72 ms /    24 tokens (   10.74 ms per token,    93.12 tokens per second)\n",
      "llama_print_timings:        eval time =     534.26 ms /     6 runs   (   89.04 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =     812.94 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Tressie Frami\", \"Dr. Michel Zulauf\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.97 ms /    17 runs   (    0.17 ms per token,  5721.98 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.97 ms /   160 tokens (    7.56 ms per token,   132.34 tokens per second)\n",
      "llama_print_timings:        eval time =    1698.93 ms /    16 runs   (  106.18 ms per token,     9.42 tokens per second)\n",
      "llama_print_timings:       total time =    2973.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"NHS number 712 719 6097\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       6.56 ms /    19 runs   (    0.35 ms per token,  2896.78 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.25 ms /    25 tokens (   10.37 ms per token,    96.43 tokens per second)\n",
      "llama_print_timings:        eval time =    2018.09 ms /    18 runs   (  112.12 ms per token,     8.92 tokens per second)\n",
      "llama_print_timings:       total time =    2495.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.17 ms /     2 runs   (    0.08 ms per token, 11834.32 tokens per second)\n",
      "llama_print_timings: prompt eval time =     274.50 ms /    23 tokens (   11.93 ms per token,    83.79 tokens per second)\n",
      "llama_print_timings:        eval time =     106.84 ms /     1 runs   (  106.84 ms per token,     9.36 tokens per second)\n",
      "llama_print_timings:       total time =     385.23 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10582.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =     267.97 ms /    24 tokens (   11.17 ms per token,    89.56 tokens per second)\n",
      "llama_print_timings:        eval time =      98.12 ms /     1 runs   (   98.12 ms per token,    10.19 tokens per second)\n",
      "llama_print_timings:       total time =     370.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Joshua Rice\", \"Dr. Harlan Langosh\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.45 ms /    17 runs   (    0.26 ms per token,  3816.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1208.93 ms /   158 tokens (    7.65 ms per token,   130.69 tokens per second)\n",
      "llama_print_timings:        eval time =    1481.38 ms /    16 runs   (   92.59 ms per token,    10.80 tokens per second)\n",
      "llama_print_timings:       total time =    2768.93 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"718 346 9026\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.47 ms /    15 runs   (    0.30 ms per token,  3357.21 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.78 ms /    25 tokens (   10.31 ms per token,    96.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1245.69 ms /    14 runs   (   88.98 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1573.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"45 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.76 ms /     7 runs   (    0.25 ms per token,  3984.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.08 ms /    23 tokens (   11.18 ms per token,    89.47 tokens per second)\n",
      "llama_print_timings:        eval time =     529.74 ms /     6 runs   (   88.29 ms per token,    11.33 tokens per second)\n",
      "llama_print_timings:       total time =     813.71 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.26 ms /     2 runs   (    0.13 ms per token,  7782.10 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.92 ms /    24 tokens (   10.83 ms per token,    92.34 tokens per second)\n",
      "llama_print_timings:        eval time =      98.28 ms /     1 runs   (   98.28 ms per token,    10.18 tokens per second)\n",
      "llama_print_timings:       total time =     373.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs.\", \"Georgiann Shields\", \"Dr.\", \"Willian Batz\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.14 ms /    23 runs   (    0.14 ms per token,  7322.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1186.58 ms /   151 tokens (    7.86 ms per token,   127.26 tokens per second)\n",
      "llama_print_timings:        eval time =    2065.14 ms /    22 runs   (   93.87 ms per token,    10.65 tokens per second)\n",
      "llama_print_timings:       total time =    3321.08 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"777 312 2501\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.72 ms /    15 runs   (    0.18 ms per token,  5506.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.79 ms /    25 tokens (   10.39 ms per token,    96.23 tokens per second)\n",
      "llama_print_timings:        eval time =    1274.19 ms /    14 runs   (   91.01 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    1587.54 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.93 ms /     5 runs   (    0.19 ms per token,  5387.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.44 ms /    23 tokens (   11.15 ms per token,    89.69 tokens per second)\n",
      "llama_print_timings:        eval time =     353.34 ms /     4 runs   (   88.33 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     626.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"chronic sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.27 ms /     8 runs   (    0.16 ms per token,  6294.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.40 ms /    24 tokens (   10.77 ms per token,    92.88 tokens per second)\n",
      "llama_print_timings:        eval time =     638.66 ms /     7 runs   (   91.24 ms per token,    10.96 tokens per second)\n",
      "llama_print_timings:       total time =     918.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Aleida Morar\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.72 ms /    10 runs   (    0.17 ms per token,  5810.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1181.63 ms /   146 tokens (    8.09 ms per token,   123.56 tokens per second)\n",
      "llama_print_timings:        eval time =     807.41 ms /     9 runs   (   89.71 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    2031.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"109 466 8126\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.85 ms /    15 runs   (    0.19 ms per token,  5253.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.67 ms /    25 tokens (   10.27 ms per token,    97.40 tokens per second)\n",
      "llama_print_timings:        eval time =    1256.08 ms /    14 runs   (   89.72 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1569.85 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"43 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.92 ms /     7 runs   (    0.27 ms per token,  3643.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.09 ms /    23 tokens (   11.09 ms per token,    90.16 tokens per second)\n",
      "llama_print_timings:        eval time =     532.86 ms /     6 runs   (   88.81 ms per token,    11.26 tokens per second)\n",
      "llama_print_timings:       total time =     822.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.53 ms /    24 tokens (   10.65 ms per token,    93.92 tokens per second)\n",
      "llama_print_timings:        eval time =      89.69 ms /     1 runs   (   89.69 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =     349.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Raymond Collier\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     8 runs   (    0.11 ms per token,  8938.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1178.78 ms /   160 tokens (    7.37 ms per token,   135.73 tokens per second)\n",
      "llama_print_timings:        eval time =     670.91 ms /     7 runs   (   95.84 ms per token,    10.43 tokens per second)\n",
      "llama_print_timings:       total time =    1869.53 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"562 467 4873\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.48 ms /    15 runs   (    0.17 ms per token,  6060.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.17 ms /    25 tokens (   10.41 ms per token,    96.09 tokens per second)\n",
      "llama_print_timings:        eval time =    1333.08 ms /    14 runs   (   95.22 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =    1656.96 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.20 ms /     7 runs   (    0.17 ms per token,  5828.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.86 ms /    23 tokens (   11.34 ms per token,    88.17 tokens per second)\n",
      "llama_print_timings:        eval time =     582.45 ms /     6 runs   (   97.07 ms per token,    10.30 tokens per second)\n",
      "llama_print_timings:       total time =     880.22 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.28 ms /     2 runs   (    0.14 ms per token,  7117.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.17 ms /    24 tokens (   10.88 ms per token,    91.90 tokens per second)\n",
      "llama_print_timings:        eval time =     102.25 ms /     1 runs   (  102.25 ms per token,     9.78 tokens per second)\n",
      "llama_print_timings:       total time =     367.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Marcelo Morar\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.98 ms /    18 runs   (    0.17 ms per token,  6042.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1223.25 ms /   146 tokens (    8.38 ms per token,   119.35 tokens per second)\n",
      "llama_print_timings:        eval time =    1753.92 ms /    17 runs   (  103.17 ms per token,     9.69 tokens per second)\n",
      "llama_print_timings:       total time =    3053.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"430 268 7673\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.36 ms /    15 runs   (    0.29 ms per token,  3443.53 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.58 ms /    25 tokens (   10.54 ms per token,    94.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1489.61 ms /    14 runs   (  106.40 ms per token,     9.40 tokens per second)\n",
      "llama_print_timings:       total time =    1800.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"71 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     7 runs   (    0.17 ms per token,  5751.85 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.37 ms /    23 tokens (   11.23 ms per token,    89.02 tokens per second)\n",
      "llama_print_timings:        eval time =     557.73 ms /     6 runs   (   92.95 ms per token,    10.76 tokens per second)\n",
      "llama_print_timings:       total time =     831.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Otitis media\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     7 runs   (    0.13 ms per token,  7675.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     263.65 ms /    24 tokens (   10.99 ms per token,    91.03 tokens per second)\n",
      "llama_print_timings:        eval time =     545.94 ms /     6 runs   (   90.99 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =     829.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rex Jones\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.81 ms /     8 runs   (    0.35 ms per token,  2851.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.26 ms /   151 tokens (    7.89 ms per token,   126.76 tokens per second)\n",
      "llama_print_timings:        eval time =     623.36 ms /     7 runs   (   89.05 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1856.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"292 402 9366\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.38 ms /    15 runs   (    0.23 ms per token,  4436.56 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.73 ms /    25 tokens (   10.31 ms per token,    97.00 tokens per second)\n",
      "llama_print_timings:        eval time =    1251.13 ms /    14 runs   (   89.37 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =    1570.95 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"36-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.06 ms /     9 runs   (    0.12 ms per token,  8514.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.55 ms /    23 tokens (   11.33 ms per token,    88.27 tokens per second)\n",
      "llama_print_timings:        eval time =     721.22 ms /     8 runs   (   90.15 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =    1021.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.97 ms /     8 runs   (    0.12 ms per token,  8205.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.50 ms /    24 tokens (   10.69 ms per token,    93.57 tokens per second)\n",
      "llama_print_timings:        eval time =     623.31 ms /     7 runs   (   89.04 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =     899.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Zachariah Emmerich\", \"Dr. Kristopher Roob\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    19 runs   (    0.17 ms per token,  5736.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1423.74 ms /   172 tokens (    8.28 ms per token,   120.81 tokens per second)\n",
      "llama_print_timings:        eval time =    1615.78 ms /    18 runs   (   89.77 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =    3108.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"204 405 0365\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.41 ms /    15 runs   (    0.23 ms per token,  4402.70 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.26 ms /    25 tokens (   10.33 ms per token,    96.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.68 ms /    14 runs   (   90.26 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1582.31 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"61-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.01 ms /     9 runs   (    0.22 ms per token,  4475.39 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.39 ms /    23 tokens (   11.19 ms per token,    89.36 tokens per second)\n",
      "llama_print_timings:        eval time =     717.41 ms /     8 runs   (   89.68 ms per token,    11.15 tokens per second)\n",
      "llama_print_timings:       total time =    1006.34 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8474.58 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.00 ms /    24 tokens (   10.67 ms per token,    93.75 tokens per second)\n",
      "llama_print_timings:        eval time =      90.17 ms /     1 runs   (   90.17 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =     349.21 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Bettina Zulauf JD\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.60 ms /    14 runs   (    0.19 ms per token,  5394.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1190.99 ms /   151 tokens (    7.89 ms per token,   126.79 tokens per second)\n",
      "llama_print_timings:        eval time =    1189.76 ms /    13 runs   (   91.52 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =    2430.79 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"238 498 7224\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.74 ms /    15 runs   (    0.18 ms per token,  5476.45 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.52 ms /    25 tokens (   10.30 ms per token,    97.08 tokens per second)\n",
      "llama_print_timings:        eval time =    1273.49 ms /    14 runs   (   90.96 ms per token,    10.99 tokens per second)\n",
      "llama_print_timings:       total time =    1584.11 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"44 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.12 ms /     7 runs   (    0.16 ms per token,  6227.76 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.78 ms /    23 tokens (   11.16 ms per token,    89.57 tokens per second)\n",
      "llama_print_timings:        eval time =     535.36 ms /     6 runs   (   89.23 ms per token,    11.21 tokens per second)\n",
      "llama_print_timings:       total time =     815.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.20 ms /     2 runs   (    0.10 ms per token, 10256.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.74 ms /    24 tokens (   10.74 ms per token,    93.12 tokens per second)\n",
      "llama_print_timings:        eval time =      91.41 ms /     1 runs   (   91.41 ms per token,    10.94 tokens per second)\n",
      "llama_print_timings:       total time =     352.90 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Dian Schuster\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.44 ms /    10 runs   (    0.14 ms per token,  6958.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.26 ms /   139 tokens (    8.46 ms per token,   118.27 tokens per second)\n",
      "llama_print_timings:        eval time =     815.88 ms /     9 runs   (   90.65 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =    2021.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"389 234 8672\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.28 ms /    15 runs   (    0.15 ms per token,  6590.51 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.47 ms /    25 tokens (   10.26 ms per token,    97.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1250.38 ms /    14 runs   (   89.31 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1562.87 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"54 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.91 ms /     7 runs   (    0.13 ms per token,  7726.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.54 ms /    23 tokens (   11.15 ms per token,    89.65 tokens per second)\n",
      "llama_print_timings:        eval time =     548.00 ms /     6 runs   (   91.33 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =     828.52 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     8 runs   (    0.17 ms per token,  6001.50 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.50 ms /    24 tokens (   10.69 ms per token,    93.57 tokens per second)\n",
      "llama_print_timings:        eval time =     622.41 ms /     7 runs   (   88.92 ms per token,    11.25 tokens per second)\n",
      "llama_print_timings:       total time =     902.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Sydney Harvey\", \"Dr. Bernardo Goldner\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    16 runs   (    0.21 ms per token,  4838.22 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1175.21 ms /   139 tokens (    8.45 ms per token,   118.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1342.49 ms /    15 runs   (   89.50 ms per token,    11.17 tokens per second)\n",
      "llama_print_timings:       total time =    2585.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 244 1470\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.32 ms /    15 runs   (    0.22 ms per token,  4516.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.44 ms /    25 tokens (   10.34 ms per token,    96.73 tokens per second)\n",
      "llama_print_timings:        eval time =    1252.77 ms /    14 runs   (   89.48 ms per token,    11.18 tokens per second)\n",
      "llama_print_timings:       total time =    1570.45 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"7 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.67 ms /     6 runs   (    0.11 ms per token,  8968.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.51 ms /    23 tokens (   11.15 ms per token,    89.67 tokens per second)\n",
      "llama_print_timings:        eval time =     466.36 ms /     5 runs   (   93.27 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     736.67 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.49 ms /     2 runs   (    0.25 ms per token,  4056.80 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.81 ms /    24 tokens (   10.66 ms per token,    93.82 tokens per second)\n",
      "llama_print_timings:        eval time =      92.00 ms /     1 runs   (   92.00 ms per token,    10.87 tokens per second)\n",
      "llama_print_timings:       total time =     352.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Sebrina Fahey\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    12 runs   (    0.21 ms per token,  4682.01 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.98 ms /   152 tokens (    7.84 ms per token,   127.52 tokens per second)\n",
      "llama_print_timings:        eval time =     979.62 ms /    11 runs   (   89.06 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    2215.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"339 369 6545\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    15 runs   (    0.17 ms per token,  5866.25 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.20 ms /    25 tokens (   10.45 ms per token,    95.71 tokens per second)\n",
      "llama_print_timings:        eval time =    1254.23 ms /    14 runs   (   89.59 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1573.97 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"21\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     5 runs   (    0.19 ms per token,  5330.49 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.92 ms /    23 tokens (   11.21 ms per token,    89.17 tokens per second)\n",
      "llama_print_timings:        eval time =     357.60 ms /     4 runs   (   89.40 ms per token,    11.19 tokens per second)\n",
      "llama_print_timings:       total time =     631.10 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.09 ms per token, 10695.19 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.95 ms /    24 tokens (   10.75 ms per token,    93.04 tokens per second)\n",
      "llama_print_timings:        eval time =      92.41 ms /     1 runs   (   92.41 ms per token,    10.82 tokens per second)\n",
      "llama_print_timings:       total time =     353.76 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Ethyl Hickle\", \"Dr. Federico Kuhic\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.73 ms /    20 runs   (    0.19 ms per token,  5361.93 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1192.70 ms /   152 tokens (    7.85 ms per token,   127.44 tokens per second)\n",
      "llama_print_timings:        eval time =    1691.75 ms /    19 runs   (   89.04 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    2969.63 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"312 672 4877\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.26 ms /    15 runs   (    0.15 ms per token,  6631.30 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.25 ms /    25 tokens (   10.33 ms per token,    96.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1269.82 ms /    14 runs   (   90.70 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =    1572.37 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10416.67 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.21 ms /    23 tokens (   11.18 ms per token,    89.42 tokens per second)\n",
      "llama_print_timings:        eval time =      90.37 ms /     1 runs   (   90.37 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =     350.74 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.94 ms /     8 runs   (    0.12 ms per token,  8556.15 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.07 ms /    24 tokens (   10.71 ms per token,    93.36 tokens per second)\n",
      "llama_print_timings:        eval time =     640.99 ms /     7 runs   (   91.57 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =     919.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Janell Reinger\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /     7 runs   (    0.13 ms per token,  7803.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1419.65 ms /   172 tokens (    8.25 ms per token,   121.16 tokens per second)\n",
      "llama_print_timings:        eval time =     555.22 ms /     6 runs   (   92.54 ms per token,    10.81 tokens per second)\n",
      "llama_print_timings:       total time =    1995.15 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 824 0229\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.62 ms /    15 runs   (    0.17 ms per token,  5736.14 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.61 ms /    25 tokens (   10.38 ms per token,    96.30 tokens per second)\n",
      "llama_print_timings:        eval time =    1246.58 ms /    14 runs   (   89.04 ms per token,    11.23 tokens per second)\n",
      "llama_print_timings:       total time =    1565.24 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.19 ms /     2 runs   (    0.10 ms per token, 10309.28 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.11 ms /    23 tokens (   11.18 ms per token,    89.46 tokens per second)\n",
      "llama_print_timings:        eval time =      89.90 ms /     1 runs   (   89.90 ms per token,    11.12 tokens per second)\n",
      "llama_print_timings:       total time =     350.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11049.72 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.94 ms /    24 tokens (   10.87 ms per token,    91.98 tokens per second)\n",
      "llama_print_timings:        eval time =      97.83 ms /     1 runs   (   97.83 ms per token,    10.22 tokens per second)\n",
      "llama_print_timings:       total time =     368.60 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Enoch Muller\", \"Dr. Gino Block\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.57 ms /    17 runs   (    0.15 ms per token,  6619.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1954.91 ms /   230 tokens (    8.50 ms per token,   117.65 tokens per second)\n",
      "llama_print_timings:        eval time =    1452.90 ms /    16 runs   (   90.81 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    3474.51 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"565 828 6161\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.37 ms /    15 runs   (    0.22 ms per token,  4447.08 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.47 ms /    25 tokens (   10.42 ms per token,    95.98 tokens per second)\n",
      "llama_print_timings:        eval time =    1334.73 ms /    14 runs   (   95.34 ms per token,    10.49 tokens per second)\n",
      "llama_print_timings:       total time =    1656.28 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.23 ms /     9 runs   (    0.14 ms per token,  7346.94 tokens per second)\n",
      "llama_print_timings: prompt eval time =     261.10 ms /    23 tokens (   11.35 ms per token,    88.09 tokens per second)\n",
      "llama_print_timings:        eval time =     725.57 ms /     8 runs   (   90.70 ms per token,    11.03 tokens per second)\n",
      "llama_print_timings:       total time =    1021.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11428.57 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.43 ms /    24 tokens (   10.73 ms per token,    93.23 tokens per second)\n",
      "llama_print_timings:        eval time =      94.28 ms /     1 runs   (   94.28 ms per token,    10.61 tokens per second)\n",
      "llama_print_timings:       total time =     354.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Ms. Artie Lynch\", \"Shannon Denesik\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.35 ms /    17 runs   (    0.20 ms per token,  5080.69 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1447.30 ms /   190 tokens (    7.62 ms per token,   131.28 tokens per second)\n",
      "llama_print_timings:        eval time =    1427.96 ms /    16 runs   (   89.25 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    2946.09 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"390 303 0377\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.23 ms /    15 runs   (    0.15 ms per token,  6714.41 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.16 ms /    25 tokens (   10.37 ms per token,    96.46 tokens per second)\n",
      "llama_print_timings:        eval time =    1263.80 ms /    14 runs   (   90.27 ms per token,    11.08 tokens per second)\n",
      "llama_print_timings:       total time =    1568.68 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"47-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.09 ms /     9 runs   (    0.23 ms per token,  4314.48 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.54 ms /    23 tokens (   11.20 ms per token,    89.31 tokens per second)\n",
      "llama_print_timings:        eval time =     716.73 ms /     8 runs   (   89.59 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    1008.62 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.24 ms /     2 runs   (    0.12 ms per token,  8333.33 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.35 ms /    24 tokens (   10.81 ms per token,    92.54 tokens per second)\n",
      "llama_print_timings:        eval time =      93.28 ms /     1 runs   (   93.28 ms per token,    10.72 tokens per second)\n",
      "llama_print_timings:       total time =     355.99 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Lance Pfeffer\", \"Dr. Kristopher Crooks\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.23 ms /    18 runs   (    0.18 ms per token,  5565.86 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1434.48 ms /   180 tokens (    7.97 ms per token,   125.48 tokens per second)\n",
      "llama_print_timings:        eval time =    1535.91 ms /    17 runs   (   90.35 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    3038.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"291 169 0842\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.46 ms /    15 runs   (    0.16 ms per token,  6087.66 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.21 ms /    25 tokens (   10.33 ms per token,    96.82 tokens per second)\n",
      "llama_print_timings:        eval time =    1283.92 ms /    14 runs   (   91.71 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    1589.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"33 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.35 ms /     7 runs   (    0.19 ms per token,  5169.87 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.92 ms /    23 tokens (   11.13 ms per token,    89.87 tokens per second)\n",
      "llama_print_timings:        eval time =     542.47 ms /     6 runs   (   90.41 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =     825.14 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.04 ms /     6 runs   (    0.17 ms per token,  5785.92 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.56 ms /    24 tokens (   10.69 ms per token,    93.55 tokens per second)\n",
      "llama_print_timings:        eval time =     446.26 ms /     5 runs   (   89.25 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =     726.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Stella Watsica\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.22 ms /     8 runs   (    0.15 ms per token,  6546.64 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2793.41 ms /   328 tokens (    8.52 ms per token,   117.42 tokens per second)\n",
      "llama_print_timings:        eval time =     636.48 ms /     7 runs   (   90.93 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    3457.55 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 832 4895\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.82 ms /    15 runs   (    0.25 ms per token,  3930.82 tokens per second)\n",
      "llama_print_timings: prompt eval time =     266.41 ms /    25 tokens (   10.66 ms per token,    93.84 tokens per second)\n",
      "llama_print_timings:        eval time =    1281.31 ms /    14 runs   (   91.52 ms per token,    10.93 tokens per second)\n",
      "llama_print_timings:       total time =    1619.16 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  9259.26 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.94 ms /    23 tokens (   11.35 ms per token,    88.14 tokens per second)\n",
      "llama_print_timings:        eval time =      91.88 ms /     1 runs   (   91.88 ms per token,    10.88 tokens per second)\n",
      "llama_print_timings:       total time =     357.73 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.18 ms /     2 runs   (    0.09 ms per token, 11299.44 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.94 ms /    24 tokens (   10.87 ms per token,    91.97 tokens per second)\n",
      "llama_print_timings:        eval time =      94.10 ms /     1 runs   (   94.10 ms per token,    10.63 tokens per second)\n",
      "llama_print_timings:       total time =     359.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Fernando Purdy\", \"Dr. Dylan Robel\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.80 ms /    17 runs   (    0.16 ms per token,  6073.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1444.85 ms /   183 tokens (    7.90 ms per token,   126.66 tokens per second)\n",
      "llama_print_timings:        eval time =    1433.30 ms /    16 runs   (   89.58 ms per token,    11.16 tokens per second)\n",
      "llama_print_timings:       total time =    2947.05 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"802 259 4927\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.31 ms /    15 runs   (    0.22 ms per token,  4528.99 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.25 ms /    25 tokens (   10.33 ms per token,    96.80 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.69 ms /    14 runs   (   89.26 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1574.12 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"42-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.63 ms /     9 runs   (    0.18 ms per token,  5535.06 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.99 ms /    23 tokens (   11.13 ms per token,    89.85 tokens per second)\n",
      "llama_print_timings:        eval time =     730.69 ms /     8 runs   (   91.34 ms per token,    10.95 tokens per second)\n",
      "llama_print_timings:       total time =    1016.65 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"acute viral pharyngitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.56 ms /    11 runs   (    0.23 ms per token,  4295.20 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.61 ms /    24 tokens (   10.73 ms per token,    93.17 tokens per second)\n",
      "llama_print_timings:        eval time =     889.96 ms /    10 runs   (   89.00 ms per token,    11.24 tokens per second)\n",
      "llama_print_timings:       total time =    1190.13 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mr. Rueben Glover\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.19 ms /    10 runs   (    0.22 ms per token,  4559.96 tokens per second)\n",
      "llama_print_timings: prompt eval time =    2512.91 ms /   295 tokens (    8.52 ms per token,   117.39 tokens per second)\n",
      "llama_print_timings:        eval time =     811.43 ms /     9 runs   (   90.16 ms per token,    11.09 tokens per second)\n",
      "llama_print_timings:       total time =    3373.84 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"159 633 7731\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.89 ms /    15 runs   (    0.26 ms per token,  3857.03 tokens per second)\n",
      "llama_print_timings: prompt eval time =     262.08 ms /    25 tokens (   10.48 ms per token,    95.39 tokens per second)\n",
      "llama_print_timings:        eval time =    1264.25 ms /    14 runs   (   90.30 ms per token,    11.07 tokens per second)\n",
      "llama_print_timings:       total time =    1597.47 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"30 year old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.92 ms /     7 runs   (    0.13 ms per token,  7650.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.50 ms /    23 tokens (   11.28 ms per token,    88.63 tokens per second)\n",
      "llama_print_timings:        eval time =     571.49 ms /     6 runs   (   95.25 ms per token,    10.50 tokens per second)\n",
      "llama_print_timings:       total time =     850.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    13 runs   (    0.21 ms per token,  4861.63 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.84 ms /    24 tokens (   10.83 ms per token,    92.36 tokens per second)\n",
      "llama_print_timings:        eval time =    1098.77 ms /    12 runs   (   91.56 ms per token,    10.92 tokens per second)\n",
      "llama_print_timings:       total time =    1412.02 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Maddie Abshire\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.33 ms /     8 runs   (    0.17 ms per token,  6033.18 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1194.51 ms /   158 tokens (    7.56 ms per token,   132.27 tokens per second)\n",
      "llama_print_timings:        eval time =     633.12 ms /     7 runs   (   90.45 ms per token,    11.06 tokens per second)\n",
      "llama_print_timings:       total time =    1850.01 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"999 952 7601\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.13 ms /    15 runs   (    0.28 ms per token,  3632.84 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.13 ms /    25 tokens (   10.33 ms per token,    96.85 tokens per second)\n",
      "llama_print_timings:        eval time =    1249.77 ms /    14 runs   (   89.27 ms per token,    11.20 tokens per second)\n",
      "llama_print_timings:       total time =    1578.89 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"5-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.98 ms /     8 runs   (    0.12 ms per token,  8171.60 tokens per second)\n",
      "llama_print_timings: prompt eval time =     255.41 ms /    23 tokens (   11.10 ms per token,    90.05 tokens per second)\n",
      "llama_print_timings:        eval time =     633.99 ms /     7 runs   (   90.57 ms per token,    11.04 tokens per second)\n",
      "llama_print_timings:       total time =     911.92 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"streptococcal sore throat\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.67 ms /    12 runs   (    0.22 ms per token,  4501.13 tokens per second)\n",
      "llama_print_timings: prompt eval time =     256.81 ms /    24 tokens (   10.70 ms per token,    93.46 tokens per second)\n",
      "llama_print_timings:        eval time =     974.99 ms /    11 runs   (   88.64 ms per token,    11.28 tokens per second)\n",
      "llama_print_timings:       total time =    1283.25 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Mrs. Kimber Hilpert\", \"Dr. Tracey Hamill\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.08 ms /    18 runs   (    0.17 ms per token,  5846.05 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1191.40 ms /   156 tokens (    7.64 ms per token,   130.94 tokens per second)\n",
      "llama_print_timings:        eval time =    1545.45 ms /    17 runs   (   90.91 ms per token,    11.00 tokens per second)\n",
      "llama_print_timings:       total time =    2809.29 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"801 894 9109\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.10 ms /    15 runs   (    0.21 ms per token,  4840.27 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.44 ms /    25 tokens (   10.30 ms per token,    97.11 tokens per second)\n",
      "llama_print_timings:        eval time =    1239.38 ms /    14 runs   (   88.53 ms per token,    11.30 tokens per second)\n",
      "llama_print_timings:       total time =    1554.43 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"48-year-old\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     9 runs   (    0.15 ms per token,  6564.55 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.29 ms /    23 tokens (   11.32 ms per token,    88.36 tokens per second)\n",
      "llama_print_timings:        eval time =     717.96 ms /     8 runs   (   89.75 ms per token,    11.14 tokens per second)\n",
      "llama_print_timings:       total time =    1006.04 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"viral sinusitis\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       2.31 ms /     8 runs   (    0.29 ms per token,  3458.71 tokens per second)\n",
      "llama_print_timings: prompt eval time =     257.17 ms /    24 tokens (   10.72 ms per token,    93.32 tokens per second)\n",
      "llama_print_timings:        eval time =     618.42 ms /     7 runs   (   88.35 ms per token,    11.32 tokens per second)\n",
      "llama_print_timings:       total time =     909.32 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"Vesta Labadie\", \"Chang Kutch\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       3.36 ms /    14 runs   (    0.24 ms per token,  4165.43 tokens per second)\n",
      "llama_print_timings: prompt eval time =    1941.01 ms /   227 tokens (    8.55 ms per token,   116.95 tokens per second)\n",
      "llama_print_timings:        eval time =    1180.33 ms /    13 runs   (   90.79 ms per token,    11.01 tokens per second)\n",
      "llama_print_timings:       total time =    3183.07 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"712 288 1542\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       4.05 ms /    15 runs   (    0.27 ms per token,  3707.37 tokens per second)\n",
      "llama_print_timings: prompt eval time =     260.25 ms /    25 tokens (   10.41 ms per token,    96.06 tokens per second)\n",
      "llama_print_timings:        eval time =    1284.15 ms /    14 runs   (   91.73 ms per token,    10.90 tokens per second)\n",
      "llama_print_timings:       total time =    1621.50 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [\"57\"]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       1.37 ms /     5 runs   (    0.27 ms per token,  3644.31 tokens per second)\n",
      "llama_print_timings: prompt eval time =     259.03 ms /    23 tokens (   11.26 ms per token,    88.79 tokens per second)\n",
      "llama_print_timings:        eval time =     370.64 ms /     4 runs   (   92.66 ms per token,    10.79 tokens per second)\n",
      "llama_print_timings:       total time =     652.20 ms\n",
      "Llama.generate: prefix-match hit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " []"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =    7255.65 ms\n",
      "llama_print_timings:      sample time =       0.22 ms /     2 runs   (    0.11 ms per token,  8968.61 tokens per second)\n",
      "llama_print_timings: prompt eval time =     258.38 ms /    24 tokens (   10.77 ms per token,    92.89 tokens per second)\n",
      "llama_print_timings:        eval time =      94.31 ms /     1 runs   (   94.31 ms per token,    10.60 tokens per second)\n",
      "llama_print_timings:       total time =     355.76 ms\n",
      "ggml_metal_free: deallocating\n"
     ]
    }
   ],
   "source": [
    "data = load_llm_data()\n",
    "data = data[0:200]\n",
    "\n",
    "patients_entities = generate_patients_entities(data, [\"person\", \"NHS number\", \"age\", \"diagnosis\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('patient_entities.pickle', 'wb') as f:\n",
    "    pickle.dump(patients_entities, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('patient_entities.pickle', \"rb\") as f:\n",
    "    saved_patients_entities = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_values = []\n",
    "llm_data = load_llm_data()\n",
    "for id, patient_entities in saved_patients_entities.items():\n",
    "    text = llm_data[id].strip()\n",
    "    for entity_name, outputs in patient_entities.items():\n",
    "        output_type = (outputs[\"output_type\"] == type(list()))\n",
    "        if output_type:\n",
    "            output_length = len(outputs[\"output\"])\n",
    "        else:\n",
    "            output_length = np.nan\n",
    "                \n",
    "        output = {\n",
    "            \"patient_id\": id,\n",
    "            \"entity_name\": entity_name,\n",
    "            \"output\": outputs[\"output\"],\n",
    "            \"output_length\": output_length,\n",
    "            \"output_type\": int(output_type),\n",
    "            \"text\": text\n",
    "        }\n",
    "\n",
    "        patient_values.append(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>output</th>\n",
       "      <th>output_length</th>\n",
       "      <th>output_type</th>\n",
       "      <th>text</th>\n",
       "      <th>output_any</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Brandon McLaughlin]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>NHS number</td>\n",
       "      <td>[568 968 0803]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>age</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[acute bronchitis]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Brandon McLaughlin is a 13-year-old male o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Esteban Altenwerth]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Esteban Altenwerth is a 20-year-old White ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>998</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[viral sinusitis]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mrs. Stefany Hand (NHS number: 686 286 2000, D...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>999</td>\n",
       "      <td>person</td>\n",
       "      <td>[Mr. Ignacio Spinka]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>999</td>\n",
       "      <td>NHS number</td>\n",
       "      <td>[146 618 6996]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>999</td>\n",
       "      <td>age</td>\n",
       "      <td>[70 year old]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>999</td>\n",
       "      <td>diagnosis</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Ignacio Spinka is a 70 year old male with ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      patient_id entity_name                    output  output_length  \\\n",
       "0              0      person  [Mr. Brandon McLaughlin]              1   \n",
       "1              0  NHS number            [568 968 0803]              1   \n",
       "2              0         age                        []              0   \n",
       "3              0   diagnosis        [acute bronchitis]              1   \n",
       "4              1      person  [Mr. Esteban Altenwerth]              1   \n",
       "...          ...         ...                       ...            ...   \n",
       "3995         998   diagnosis         [viral sinusitis]              1   \n",
       "3996         999      person      [Mr. Ignacio Spinka]              1   \n",
       "3997         999  NHS number            [146 618 6996]              1   \n",
       "3998         999         age             [70 year old]              1   \n",
       "3999         999   diagnosis                        []              0   \n",
       "\n",
       "      output_type                                               text  \\\n",
       "0               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "1               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "2               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "3               1  Mr. Brandon McLaughlin is a 13-year-old male o...   \n",
       "4               1  Mr. Esteban Altenwerth is a 20-year-old White ...   \n",
       "...           ...                                                ...   \n",
       "3995            1  Mrs. Stefany Hand (NHS number: 686 286 2000, D...   \n",
       "3996            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3997            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3998            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "3999            1  Mr. Ignacio Spinka is a 70 year old male with ...   \n",
       "\n",
       "      output_any  \n",
       "0              1  \n",
       "1              1  \n",
       "2              0  \n",
       "3              1  \n",
       "4              1  \n",
       "...          ...  \n",
       "3995           1  \n",
       "3996           1  \n",
       "3997           1  \n",
       "3998           1  \n",
       "3999           0  \n",
       "\n",
       "[4000 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_table = pd.DataFrame(patient_values)\n",
    "entity_table[\"output_any\"] = entity_table[\"output_length\"] >= 1\n",
    "entity_table[\"output_any\"] = entity_table[\"output_any\"].astype(int)\n",
    "entity_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>output_any</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>entity_name</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>NHS number</th>\n",
       "      <td>0.999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diagnosis</th>\n",
       "      <td>0.583</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>person</th>\n",
       "      <td>0.990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             output_any\n",
       "entity_name            \n",
       "NHS number        0.999\n",
       "age               0.751\n",
       "diagnosis         0.583\n",
       "person            0.990"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_prevalence = entity_table[[\"entity_name\", \"output_any\"]].groupby(\"entity_name\").sum(\"output_any\")/1000\n",
    "entity_prevalence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='entity_name'>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "entity_prevalence.plot.bar(rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ner_pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
