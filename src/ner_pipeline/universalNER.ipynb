{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/llm_dataset.json') as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "\n",
    "n_gpu_layers = 1\n",
    "n_batch = 512\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"/Users/scarlettkynoch/Documents/Projects/privfp-gen-experiments/models/quantized_q4_1.gguf\",\n",
    "    n_gpu_layers=n_gpu_layers,\n",
    "    n_batch=n_batch,\n",
    "    f16_kv=True,  # MUST set to True, otherwise you will run into problem after a couple of calls\n",
    "    callback_manager=callback_manager,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_dict = {}\n",
    "patient_nums = [0, 15, 30, 78, 165, 276, 345, 428, 567, 735, 852, 961]\n",
    "entities_list = [\"name of person\",\n",
    "                  \"location of visit\",\n",
    "                  \"marital status\",\n",
    "                  #\"alcohol consumption\",\n",
    "                  #\"allergies\", \n",
    "                  \"male, female or non-binary\",\n",
    "                  \"race ethnicity nationality\",\n",
    "                #   \"recreational drug use\",\n",
    "                #   \"tobacco use\",\n",
    "                  \"treatment procedure\",\n",
    "                  \"metric and metric value\",\n",
    "                  \"medical condition\",\n",
    "                  \"medication\",\n",
    "                  \"medication dosage\",\n",
    "                  \"address\",\n",
    "                  \"ID\",\n",
    "                  \"NHS Number\",\n",
    "                  \"date of birth\",\n",
    "                  \"visit date\"\n",
    "                  ]\n",
    "\n",
    "prompt_template = \"\"\"A virtual assistant answers questions from a user based on the provided text.\n",
    "USER: Text: {input_text}\n",
    "ASSISTANT: I’ve read this text.\n",
    "USER: What describes {entity_name} in the text?\n",
    "ASSISTANT: (model's predictions in JSON format)\n",
    "\"\"\"\n",
    "\n",
    "for patient_num in patient_nums:\n",
    "    text = data[patient_num].strip()\n",
    "\n",
    "    patient_entity_dict = {}\n",
    "    for entity in entities_list:\n",
    "        prompt = prompt_template.format_map({\"input_text\": text, \"entity_name\": entity})\n",
    "        output = llm(prompt)\n",
    "        patient_entity_dict[entity] = output\n",
    "\n",
    "    patient_dict[patient_num] = {\n",
    "        \"text\": text,\n",
    "        \"entity_dict\": patient_entity_dict \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"A virtual assistant answers questions from a user based on the provided text.\n",
    "USER: Text: {input_text}\n",
    "ASSISTANT: I’ve read this text.\n",
    "USER: What describes {entity_name} in the text?\n",
    "ASSISTANT: (model's predictions in JSON format)\n",
    "\"\"\"\n",
    "\n",
    "patient_nums = [0, 15, 30, 78, 165, 276, 345, 428, 567, 735, 852, 961]\n",
    "patient_num = patient_nums[5]\n",
    "text = data[patient_num].strip()\n",
    "entity = \"person full name\" # Metric - feed in metric value - get's value. Medication - medication name dosage - you get dosage.\n",
    "\n",
    "prompt = prompt_template.format_map({\"input_text\": text, \"entity_name\": entity})\n",
    "print(text)\n",
    "output = llm(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(patient_dict[patient_nums[2]]['text'])\n",
    "patient_dict[patient_nums[2]]['entity_dict']"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
