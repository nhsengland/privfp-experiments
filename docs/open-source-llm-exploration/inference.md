# Running inference

How do we run inference on an open source LLM? The following table contains a (non-exhaustive) list of methods to interact with an open source LLM.

=== "Command line"

    !!! info "Projects"

        === "llama.cpp"

            ![M1 MBP Tested](https://img.shields.io/badge/M1_MBP-Tested-brightgreen?logo=apple)

            Build and run quantised LLMs via the command line.

            [GitHub :material-github:](https://github.com/ggerganov/llama.cpp){ .md-button .md-button--primary }

        === "Ollama"

            ![M1 MBP Tested](https://img.shields.io/badge/M1_MBP-Tested-brightgreen?logo=apple)

            Serve and run any GGUF format LLM via the Ollama CLI.

            [Ollama](https://ollama.ai/){ .md-button .md-button--primary }

=== "Python library"

    !!! info "Projects"

        === "HF Transformers"

            HF Transformers provides APIs and tools to easily run inference on LLMs available from the HF Hub.

            [Hugging Face :hugging:](https://huggingface.co/docs/transformers/index){ .md-button .md-button--primary }

        === "LangChain"

            ![M1 MBP Tested](https://img.shields.io/badge/M1_MBP-Tested-brightgreen?logo=apple)

            A framework for developing applications powered by LLMs.

            [LangChain](https://python.langchain.com/docs/get_started/introduction){ .md-button .md-button--primary }

=== "Application"

    !!! info "Projects"

        === "HF Text generation inference"

            A toolkit for deploying and serving LLMs.

            [GitHub :material-github:](https://github.com/huggingface/text-generation-inference){ .md-button .md-button--primary }

        === "Text generation web UI"

            ![M1 MBP Tested](https://img.shields.io/badge/M1_MBP-Tested-brightgreen?logo=apple)

            A Gradio web UI for LLMs.

            [GitHub :material-github:](https://github.com/oobabooga/text-generation-webui){ .md-button .md-button--primary }

        === "LM Studio"

            An application to discover, download, and run local LLMs.

            [LM Studio](https://lmstudio.ai/){ .md-button .md-button--primary }

The Awesome-LLM repository also contains a useful list of tools for deploying LLMs.

[Deploying tools](https://github.com/Hannibal046/Awesome-LLM?tab=readme-ov-file#deploying-tools){ .md-button .md-button--primary }