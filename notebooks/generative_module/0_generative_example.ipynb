{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative example\n",
    "\n",
    "This example uses the LangChain framework with Ollama to generate synthetic clinical notes from synthetic structured data.\n",
    "\n",
    "Running this notebook requires an additional install of [Ollama](https://ollama.ai/) and the particular model used is `llama2:latest` (also named `llama2:7b-chat`) from the [Ollama model library](https://ollama.ai/library/llama2/tags).\n",
    "\n",
    "Open a terminal and run `ollama pull llama2` to download the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_input = \"../../data/synthea.json\"\n",
    "path_output = \"../../data/llm.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(path_input) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "batch = []\n",
    "\n",
    "for i in range(5):\n",
    "    batch.append({\"data\": json.dumps(data[i])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM\n",
    "\n",
    "The model used to run inference can be easily swapped out using LangChain and Ollama!\n",
    "\n",
    "Simply open a terminal and run `ollama pull <model_name:tag>` to retrieve any model from the Ollama model library and pass `<model_name:tag>` as the new argument when instantiating the LLM.\n",
    "\n",
    "For example, if you wanted to use Mistral instead of Llama2, you would need to run `ollama pull mistral` in a terminal and set `model=\"mistral\"` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = Ollama(model=\"llama2\", callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST]\n",
    "<<SYS>>\n",
    "You are a medical student answering an exam question about writing clinical notes for patients.\n",
    "<</SYS>>\n",
    "\n",
    "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
    "\n",
    "1. Use prose to write an example clinical note for this patient's doctor.\n",
    "2. Use less than three sentences.\n",
    "3. Do not provide a diagnosis or recommendations.\n",
    "4. Use the following information:\n",
    "\n",
    "{data}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clinical Note:\n",
      "Ms. Rachael Ankunding presents today with a 3-day history of right-sided otitis media. The patient reports difficulty hearing and mild discomfort in the affected ear. Medical history includes seasonal allergies and a previous episode of otitis media 6 months ago.Clinical Note:\n",
      "Mr. Gino Sawayn presents with acute bronchitis, as evident by his cough and chest tightness. His date of birth is August 5, 2019, and he has been experiencing symptoms for the past 3 days. Further evaluation and treatment are necessary to manage his symptoms and prevent any potential complications.Certainly! Here is an example clinical note for Jetta Greenholt based on the provided information:\n",
      "\n",
      "\"Patient presents with a fracture of the left clavicle. The patient was involved in a fall from a height of approximately 3 meters. Patient reports severe pain and limited mobility in the affected arm. NHS number is 3717400924, date of birth is June 22, 2004. Given name is Jetta, family name is Greenholt.\"Clinical Note:\n",
      "\n",
      "Mr. Malik Mante, a 26-year-old male patient, presented to the clinic today with a 3-day history of sore throat, fever, and difficulty swallowing. He was born on August 1st, 1996, and his NHS number is 9181374534. The diagnosis is streptococcal sore throat (disorder).Clinical Note:\n",
      "\n",
      "Patient Name: Shaun Zulauf\n",
      "NHS Number: 7269014760\n",
      "Date of Birth: July 22, 1982\n",
      "\n",
      "Presenting Complaint: Normal pregnancy as confirmed by ultrasound examination. No complaints of pain or discomfort."
     ]
    }
   ],
   "source": [
    "array = chain.batch(batch)\n",
    "output = json.dumps(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(path_output), exist_ok=True)\n",
    "\n",
    "with open(path_output, \"w\") as f:\n",
    "    f.write(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
