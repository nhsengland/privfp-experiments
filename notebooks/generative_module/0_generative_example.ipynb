{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generative example\n",
    "\n",
    "This example uses the LangChain framework with Ollama to generate synthetic clinical notes from synthetic structured data.\n",
    "\n",
    "Running this notebook requires an additional install of [Ollama](https://ollama.ai/) and the particular model used is `llama2:latest` (also named `llama2:7b-chat`) from the [Ollama model library](https://ollama.ai/library/llama2/tags).\n",
    "\n",
    "Open a terminal and run `ollama pull llama2` to download the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.llms import Ollama\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load input in batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = \"../../data/synthea_dataset.json\"\n",
    "\n",
    "with open(input_path) as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "batch = []\n",
    "\n",
    "for i in range(5):\n",
    "    batch.append({\"data\": json.dumps(data[i])})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load LLM\n",
    "\n",
    "The model used to run inference can be easily swapped out using LangChain and Ollama!\n",
    "\n",
    "Simply open a terminal and run `ollama pull <model_name:tag>` to retrieve any model from the Ollama model library and pass `<model_name:tag>` as the new argument when instantiating the LLM.\n",
    "\n",
    "For example, if you wanted to use Mistral instead of Llama2, you would need to run `ollama pull mistral` in a terminal and set `model=\"mistral\"` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
    "llm = Ollama(model=\"llama2\", callback_manager=callback_manager)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"[INST]\n",
    "<<SYS>>\n",
    "You are a medical student answering an exam question about writing clinical notes for patients.\n",
    "<</SYS>>\n",
    "\n",
    "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
    "\n",
    "1. Use prose to write an example clinical note for this patient's doctor.\n",
    "2. Use less than three sentences.\n",
    "3. Do not provide a diagnosis or recommendations.\n",
    "4. Use the following information:\n",
    "\n",
    "{data}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "chain = prompt | llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is an example clinical note for Mr. Brandon McLaughlin:\n",
      "\n",
      "\"Mr. McLaughlin presents with acute bronchitis, diagnosed based on symptoms of cough and fever. His medical history includes asthma and allergies. He is a single male, 58 years old, and his address is 649 Schaden Estate Suite 18, Southampton, SO15 9UN. His NHS number is 568 968 0803. The care plan includes respiratory therapy to help manage symptoms.\"Clinical Note:\n",
      "Mr. Esteban Altenwerth presented to the clinic on 10/29/2005 with symptoms of acute bacterial sinusitis. He is a married male, aged 20, with a history of chronic sinusitis. His NHS number is 201 826 4805 and his address is 1019 Hane Brook, Basingstoke, RG21 8DW. He reports a sudden onset of fever, headache, and nasal congestion. Provider: Dr. Mercy Kuhlman at Old Basing Health Centre.Mr. Ervin O'Connell, an 82-year-old male patient, presented to Ringwood Medical Centre on February 27, 1996, with a chief complaint of cough and chest congestion for the past week. His NHS number is 862 334 6633, and he resides at 551 Koepp Green, St Ives, BH24 1QU. He was born on April 14, 1964, and is married with a white British ethnicity. The provider is Dr. Randa Ritchie from Ringwood Medical Centre. Mr. O'Connell's visit type is an encounter for symptoms, and the visit date is February 27, 1996, at 15:12:03Z. His care plan includes respiratory therapy to manage his acute bronchitis.Clinical Note:\n",
      "Mrs. Pam Boehm, a 54-year-old female with an NHS number of 639 189 7032, presented to Bitterne Surgery on March 26th, 1975, for an encounter related to viral sinusitis. Her visit reason was accompanied by a finding of stress and the revelation that she has a criminal record. Further evaluation is necessary to assess her overall health and determine appropriate interventions.Clinical Note:\n",
      "Mrs. Mirta Mosciski, a 46-year-old female patient, presented to the Princess Anne Hospital on October 19th, 2017, with a chief complaint of viral sinusitis. She reported a 3-day history of fever, headache, and nasal congestion. Her medical history includes hypertension and asthma. The provider diagnosed viral sinusitis and prescribed antiviral medication and nasal decongestants. Further evaluation and management will be necessary to manage the patient's symptoms and prevent complications."
     ]
    }
   ],
   "source": [
    "outputs = chain.batch(batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
