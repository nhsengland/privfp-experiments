{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path_root = os.path.dirname(os.getcwd())\n",
    "\n",
    "if path_root not in sys.path:\n",
    "    sys.path.append(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config.prompt_template_handler import (\n",
    "    save_extraction_template_to_json,\n",
    "    save_generate_template_to_json,\n",
    "    load_and_validate_extraction_prompt_template,\n",
    "    load_and_validate_generate_prompt_template,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a prompt template Example for LLamma2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to make sure that you generate template has a **{data}** insert defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template saved to '../src/config/templates/generate/llama2_template.json'\n"
     ]
    }
   ],
   "source": [
    "generate_template_path = (\n",
    "    \"../src/config/templates/generate/llama2_template.json\"\n",
    ")\n",
    "\n",
    "generate_template = \"\"\"[INST]\n",
    "<<SYS>>\n",
    "You are a medical student answering an exam question about writing clinical notes for patients.\n",
    "<</SYS>>\n",
    "\n",
    "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
    "\n",
    "1. Use prose to write an example clinical note for this patient's doctor.\n",
    "2. Use less than three sentences.\n",
    "3. Do not provide a recommendations.\n",
    "4. Use the following information:\n",
    "\n",
    "{data}\n",
    "[/INST]\n",
    "\"\"\"\n",
    "\n",
    "save_generate_template_to_json(\n",
    "    template_str=generate_template, file_path=generate_template_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INST]\n",
      "<<SYS>>\n",
      "You are a medical student answering an exam question about writing clinical notes for patients.\n",
      "<</SYS>>\n",
      "\n",
      "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
      "\n",
      "1. Use prose to write an example clinical note for this patient's doctor.\n",
      "2. Use less than three sentences.\n",
      "3. Do not provide a recommendations.\n",
      "4. Use the following information:\n",
      "\n",
      "{data}\n",
      "[/INST]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "loaded_generate_template = load_and_validate_generate_prompt_template(\n",
    "    filename=generate_template_path\n",
    ")\n",
    "print(loaded_generate_template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a UniversalNER prompt Example for Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to ensure your template has **{input_text}** and **{entity_name}** as a prompt template insert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Template saved to '../src/config/templates/extraction/universal_ner_template.json'\n"
     ]
    }
   ],
   "source": [
    "extraction_template_path = (\n",
    "    \"../src/config/templates/extraction/universal_ner_template.json\"\n",
    ")\n",
    "\n",
    "universalner_prompt_template = \"\"\"\n",
    "    USER: Text: {input_text}\n",
    "    ASSISTANT: I’ve read this text.\n",
    "    USER: What describes {entity_name} in the text?\n",
    "    ASSISTANT: (model's predictions in JSON format)\n",
    "    \"\"\"\n",
    "\n",
    "save_extraction_template_to_json(\n",
    "    template_str=universalner_prompt_template,\n",
    "    file_path=extraction_template_path,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    USER: Text: {input_text}\n",
      "    ASSISTANT: I’ve read this text.\n",
      "    USER: What describes {entity_name} in the text?\n",
      "    ASSISTANT: (model's predictions in JSON format)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "loaded_extraction_template = load_and_validate_extraction_prompt_template(\n",
    "    filename=extraction_template_path\n",
    ")\n",
    "print(loaded_extraction_template)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
