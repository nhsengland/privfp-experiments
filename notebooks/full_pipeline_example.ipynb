{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": 12,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import sys\n",
            "\n",
            "path_root = os.path.dirname(os.getcwd())\n",
            "\n",
            "if path_root not in sys.path:\n",
            "    sys.path.append(path_root)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 13,
         "metadata": {},
         "outputs": [],
         "source": [
            "from src.config import (\n",
            "    path_output_synthea,\n",
            "    path_output_llm,\n",
            "    path_output_extraction,\n",
            "    path_output_standardisation,\n",
            ")\n",
            "from src.generate.synthea import GenerateSynthea\n",
            "from src.generate.llm import GenerateLLM\n",
            "from src.extraction.extraction import Extraction\n",
            "from src.standardise_extraction.standardise_extraction import (\n",
            "    StandardiseExtraction,\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Privacy Fingerprint End-to-End Overview\n",
            "\n",
            "The Pipeline has been broken down into four components:\n",
            "1. **GenerateSynthea**: This generates a list of dictionary of synthetic patient records.\n",
            "2. **GenerateLLM**: This generates medical notes using the outputs created from **GenerateSynthea**.\n",
            "3. **Extraction**: This currently uses an LLM that is specialised to extract given entities from the synthetic medical notes produced by **GenerativeLLM**\n",
            "4. **StandardiseExtraction**: This standardises the results extracted from the medical text.\n",
            "\n",
            "Each of these classes takes in a path_output, when save_output is set to True, it will save the output to this path_output defined.\n",
            "These paths have been defined in the src/config.py file:\n",
            "- path_output_synthea = data_folder + \"/synthea.json\"\n",
            "- path_output_llm = data_folder + \"/llm.json\"\n",
            "- path_output_extraction = data_folder + \"/generative.json\"\n",
            "- path_output_standardisation = data_folder + \"/standardisation.json\"\n",
            "\n",
            "Additionally each class will also take a path for the input required to create their output. This allows the user to break-up the pipeline and run from specific points in the pipeline."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1. GenerateSynthea: Generating Synthetic Patient Data using Synthea "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Synthea-international is an expansion of Synthea, which is an open-source synthetic patient generator that produces de-identified health records for synthetic patients.\n",
            "\n",
            "GenerateSynthea is a class used to run Synthea. You will need to follow the instructions on the README to ensure Synthea is installed.\n",
            "- \"./run_synthea\" is a command line input that calls to run synthea.\n",
            "- \"-p\" is a person flag\n",
            "- \"5\" Where 5 determines the number of patients you want to generate. (Alter this to generate more records.)\n",
            "- \"West Yorkshire\" Synthea only works on a regional basis, therefore you have to give county information so it can generate address type data.\n",
            "\n",
            "In the src/config.py there is some given config values:\n",
            "- path_synthea = \"../../synthea\" - This defines the location of where synthea is from the src folder.\n",
            "- path_csv = path_synthea + \"/output/csv\" - This defines the location where outputs are saved to when synthea is ran.\n",
            "- path_patients = path_csv + \"/patients.csv\" - This is a .csv that holds patients synthetic demographic information etc. \n",
            "- path_encounters = path_csv + \"/encounters.csv\" - This is a .csv that holds encounters, i.e., this holds multiple times a patient has gone for medical assessment/treatment.\n",
            "- cols_patients = [\"Id\", \"BIRTHDATE\", \"FIRST\", \"LAST\"] - This determines the columns we extract from path_patients.\n",
            "- cols_encounters = [\"PATIENT\", \"ENCOUNTERCLASS\", \"REASONDESCRIPTION\"] - This defines the columns we extract from path_encounters."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_synthea = GenerateSynthea(\n",
            "    path_output=path_output_synthea, save_output=True\n",
            ").run(\"./run_synthea\", \"-p\", \"5\", \"West Yorkshire\")\n",
            "output_synthea"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the model from path"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 14,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[{'NHS_NUMBER': '4568123739',\n",
                     "  'DATE_OF_BIRTH': '2017-12-26',\n",
                     "  'GIVEN_NAME': 'Troy',\n",
                     "  'FAMILY_NAME': 'Ratke',\n",
                     "  'DIAGNOSIS': 'Otitis media'},\n",
                     " {'NHS_NUMBER': '7598780129',\n",
                     "  'DATE_OF_BIRTH': '2008-09-24',\n",
                     "  'GIVEN_NAME': 'Masako',\n",
                     "  'FAMILY_NAME': 'Schmeler',\n",
                     "  'DIAGNOSIS': 'Streptococcal sore throat (disorder)'},\n",
                     " {'NHS_NUMBER': '3072901066',\n",
                     "  'DATE_OF_BIRTH': '1990-09-14',\n",
                     "  'GIVEN_NAME': 'Jamie',\n",
                     "  'FAMILY_NAME': 'Harris',\n",
                     "  'DIAGNOSIS': 'Impacted molars'},\n",
                     " {'NHS_NUMBER': '6561282051',\n",
                     "  'DATE_OF_BIRTH': '1984-02-01',\n",
                     "  'GIVEN_NAME': 'Keila',\n",
                     "  'FAMILY_NAME': 'Rosenbaum',\n",
                     "  'DIAGNOSIS': 'Impacted molars'},\n",
                     " {'NHS_NUMBER': '6800330531',\n",
                     "  'DATE_OF_BIRTH': '1955-09-15',\n",
                     "  'GIVEN_NAME': 'Eugene',\n",
                     "  'FAMILY_NAME': 'Blick',\n",
                     "  'DIAGNOSIS': 'Anemia (disorder)'}]"
                  ]
               },
               "execution_count": 14,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "output_synthea = GenerateSynthea(path_output=path_output_synthea).load()\n",
            "output_synthea"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. GenerateLLM: Generating Synthetic Patient Medical Notes "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Currenty GenerateLLM uses Ollama to run a range of pre-trained models you can use.\n",
            "- model - This determines the model you want to use.\n",
            "- template - This defines the prompt-template you want to give to the LLM model to generate each patients medical record.\n",
            "\n",
            "In the src/config.py file, there is a *cols* parameter. This parameter currently maps Synthea column names to names used in the template to generate these medical notes.\n",
            "\n",
            "```\n",
            "cols = {\n",
            "    \"NHS_NUMBER\": \"NHS_NUMBER\",\n",
            "    \"BIRTHDATE\": \"DATE_OF_BIRTH\",\n",
            "    \"FIRST\": \"GIVEN_NAME\",\n",
            "    \"LAST\": \"FAMILY_NAME\",\n",
            "    \"REASONDESCRIPTION\": \"DIAGNOSIS\",\n",
            "}\n",
            "```"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model = \"llama2\"\n",
            "template = \"\"\"[INST]\n",
            "<<SYS>>\n",
            "You are a medical student answering an exam question about writing clinical notes for patients.\n",
            "<</SYS>>\n",
            "\n",
            "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
            "\n",
            "1. Use prose to write an example clinical note for this patient's doctor.\n",
            "2. Use less than three sentences.\n",
            "3. Do not provide a recommendations.\n",
            "4. Use the following information:\n",
            "\n",
            "{data}\n",
            "[/INST]\n",
            "\"\"\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs GenerateLLM using the synthea output from the previous run, and saves the LLM output to the given path_output_llm."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_llm = GenerateLLM(\n",
            "    synthea_input=output_synthea, path_output=path_output_llm, save_output=True\n",
            ").run(model, template)\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs GenerateLLM using a pre-saved synthea output saved at path_output_synthea, and generates a local output_llm. In comparison to the run above this will produce slightly different results."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_llm = GenerateLLM(\n",
            "    synthea_path=path_output_synthea,\n",
            "    path_output=path_output_llm,\n",
            "    save_output=False,\n",
            ").run(model, template)\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the current saved output at path_output_llm."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 15,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "['Clinical Note:\\n\\nPatient: Kaila Reinger\\nNHS Number: 0495173827\\nDate of Birth: April 14, 2019\\n\\nDiagnosis: Otitis media\\n\\nNotes:\\n\\n* Presented with fever and ear pain\\n* Right ear redness and bulging\\n* Patient reports difficulty hearing\\n* History of allergies\\n\\nPlan:\\n\\n* Prescribe antibiotic and pain medication\\n* Schedule follow-up appointment in 2 days for reassessment\\n\\nNote: This is an example clinical note, please do not use it as a reference for actual patient care.',\n",
                     " 'Clinical Note:\\n\\nPatient Name: Amee Abbott\\nNHS Number: 5884764340\\nDate of Birth: February 11, 2016\\n\\nChief Complaint: Otitis media\\n\\nHistory of Present Illness: The patient presents with a 3-day history of ear pain and fever. She reports difficulty hearing and feeling unwell.\\n\\nAssessment: Examination reveals bulging of the tympanic membrane, and the presence of fluid in the middle ear.\\n\\nPlan: Prescription for antibiotic therapy and referral to an audiologist for further evaluation and management.',\n",
                     " 'Clinical Note:\\nMr. Aubrey Thiel, a 23-year-old male patient, presented on [date] with a primary complaint of persistent nasal congestion and itchy eyes for the past two weeks. His medical history reveals perennial allergic rhinitis with seasonal variation, which has been managed conservatively with antihistamines and nasal decongestants. Current symptoms are consistent with a flare-up of his allergy, likely triggered by the changing seasons. Recommendations include increased dosage of his existing medication and close monitoring for any worsening of symptoms.',\n",
                     " 'Clinical Note:\\nMs. Lissa Quigley, a 58-year-old female patient, presented to the clinic for her scheduled prenatal appointment. She is currently 36 weeks pregnant with no complications. Her NHS number is 3419414773 and she was born on January 23rd, 1964. The diagnosis is a normal pregnancy.']"
                  ]
               },
               "execution_count": 15,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "output_llm = GenerateLLM(path_output=path_output_llm).load()\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 3. Extraction: Re-extracting Entities from the Patient Medical Notes"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This uses a local quanitised UniversalNER model to extract entities from the synthetic medical notes. You will need to follow the README to host the UniversalNER model locally.\n",
            "\n",
            "In the src/config file:\n",
            "- entity_list = [\"person\", \"nhs number\", \"date of birth\", \"diagnosis\"] - This is the list of entities you want to extract from the synthetic medical notes.\n",
            "- universal_ner_path = \"../models/quantized_q4_1.gguf\" - This is the path to the quantized universal model located in a models folder on the top level of this repo.\n",
            "\n",
            "This runs the extraction class from an output generated in this notebook, and is save the extraction output to the path given."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_extraction = Extraction(\n",
            "    llm_input=output_llm, path_output=path_output_extraction, save_output=True\n",
            ").run()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs the extraction class from a pre-saved llm output, and creates an output_extraction locally. In comparison to the run above this will produce slightly different results."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_extraction = Extraction(\n",
            "    llm_path=path_output_llm,\n",
            "    path_output=path_output_extraction,\n",
            "    save_output=False,\n",
            ").run()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the extraction output at the given path."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 16,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "[{'Entities': [{'Text': 'Chung Lindgren',\n",
                     "    'Type': 'person',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[29, 43]]},\n",
                     "   {'Text': '9513154203',\n",
                     "    'Type': 'nhs number',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[56, 66]]},\n",
                     "   {'Text': 'July 10, 2020',\n",
                     "    'Type': 'date of birth',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[82, 95]]},\n",
                     "   {'Text': 'otitis media',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[295, 307]]}]},\n",
                     " {'Entities': [{'Text': 'Gregory Wehner',\n",
                     "    'Type': 'person',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[19, 33]]},\n",
                     "   {'Text': '9355110588',\n",
                     "    'Type': 'nhs number',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[262, 272]]},\n",
                     "   {'Text': 'acute viral pharyngitis',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 2,\n",
                     "    'Match_Indices': [[112, 135], [337, 360]]}]},\n",
                     " {'Entities': [{'Text': 'Patient Edwina Sauer',\n",
                     "    'Type': 'person',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[18, 38]]},\n",
                     "   {'Text': '2137087367',\n",
                     "    'Type': 'nhs number',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[165, 175]]},\n",
                     "   {'Text': 'cause',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[352, 357]]}]},\n",
                     " {'Entities': [{'Text': 'Ms. Luella Lueilwitz',\n",
                     "    'Type': 'person',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[15, 35]]},\n",
                     "   {'Text': '0352547316',\n",
                     "    'Type': 'nhs number',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[142, 152]]},\n",
                     "   {'Text': 'October 30, 1987',\n",
                     "    'Type': 'date of birth',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[171, 187]]},\n",
                     "   {'Text': 'normal pregnancy',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[268, 284]]}]},\n",
                     " {'Entities': [{'Text': 'Estrella Block',\n",
                     "    'Type': 'person',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[106, 120]]},\n",
                     "   {'Text': '3224303522',\n",
                     "    'Type': 'nhs number',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[133, 143]]},\n",
                     "   {'Text': 'October 18, 1962',\n",
                     "    'Type': 'date of birth',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[159, 175]]},\n",
                     "   {'Text': 'Acute bacterial sinusitis',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[199, 224]]},\n",
                     "   {'Text': 'Hypertension',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[413, 425]]},\n",
                     "   {'Text': 'hyperlipidemia',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[427, 441]]},\n",
                     "   {'Text': 'allergic rhinitis',\n",
                     "    'Type': 'diagnosis',\n",
                     "    'Match_Count': 1,\n",
                     "    'Match_Indices': [[458, 475]]}]}]"
                  ]
               },
               "execution_count": 16,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "output_extraction = Extraction(path_output=path_output_extraction).load()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4. StandardiseExtraction: Normalising Entities Extracted for Scoring"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This takes in the above List of Dictionary entities and begins to normalise the responses into a dataframe format.\n",
            "\n",
            "The standardisation process is broken down into many parts:\n",
            "1. Entities are extracted from the object created from **Extraction**, and a set of functions can be applied to clean them during this process.\n",
            "2. This creates a list of cleaned entities. Multiple entities can be extracted from the same person for a given entity type, for example diagnosis. Currently the codebase only takes the first entity given.\n",
            "3. Next the outputs are normalised i.e. Dates can be written in multiple formats but have the same meaning.\n",
            "4. Lastly the data is encoded and formatted as a numpy array ready for PyCorrectMatch\n",
            "\n",
            "In the src/config.py file:\n",
            "\n",
            "extra_preprocess_functions_per_entity defines how entities are cleaned while extracted from the extraction_output.\n",
            "\n",
            "```\n",
            "extra_preprocess_functions_per_entity = {\"person\": [clean_name.remove_titles]}\n",
            "```\n",
            "\n",
            "standardise_functions_per_entity defines how entities are extracted, and defines any normalisation process you may want on a column of entities.\n",
            "```\n",
            "standardise_functions_per_entity = {\n",
            "    \"person\": [extract_first_entity_from_list],\n",
            "    \"nhs number\": [extract_first_entity_from_list],\n",
            "    \"date of birth\": [\n",
            "        extract_first_entity_from_list,\n",
            "        normalise_columns.normalise_date_column,\n",
            "    ],\n",
            "    \"diagnosis\": [extract_first_entity_from_list],\n",
            "}\n",
            "```\n",
            "\n",
            "This uses the output_extraction value created by the **Extraction** class and saves the outputs of the normalisation process as a .csv to the given path."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    extraction_input=output_extraction,\n",
            "    path_output=path_output_standardisation,\n",
            "    save_output=True,\n",
            ").run()\n",
            "output_standards"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads an extraction input from the extraction_path provided, and creates the output_standards."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    extraction_path=path_output_extraction,\n",
            "    path_output=path_output_standardisation,\n",
            "    save_output=False,\n",
            ").run()\n",
            "output_standards"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads a pre-saved output_standards from the given path provided."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": 17,
         "metadata": {},
         "outputs": [
            {
               "data": {
                  "text/plain": [
                     "array([[1, 4, 3, 4],\n",
                     "       [3, 3, 0, 1],\n",
                     "       [0, 1, 0, 2],\n",
                     "       [4, 0, 2, 3],\n",
                     "       [2, 2, 1, 0]])"
                  ]
               },
               "execution_count": 17,
               "metadata": {},
               "output_type": "execute_result"
            }
         ],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    path_output=path_output_standardisation\n",
            ").load()\n",
            "output_standards"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.7"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
