{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "path_root = os.path.dirname(os.getcwd())\n",
    "\n",
    "if path_root not in sys.path:\n",
    "    sys.path.append(path_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.config import path_output_synthea, path_output_llm, path_output_extraction, path_output_standardisation\n",
    "from src.generate.synthea import GenerateSynthea\n",
    "from src.generate.llm import GenerateLLM\n",
    "from src.extraction.extraction import Extraction\n",
    "from src.standardise_extraction.standardise_extraction import StandardiseExtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_synthea = GenerateSynthea(path_output=path_output_synthea, save_output=True).run(\"./run_synthea\", \"-p\", \"5\", \"West Yorkshire\")\n",
    "output_synthea = GenerateSynthea(path_output=path_output_synthea).load()\n",
    "output_synthea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"llama2\"\n",
    "template = \"\"\"[INST]\n",
    "<<SYS>>\n",
    "You are a medical student answering an exam question about writing clinical notes for patients.\n",
    "<</SYS>>\n",
    "\n",
    "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
    "\n",
    "1. Use prose to write an example clinical note for this patient's doctor.\n",
    "2. Use less than three sentences.\n",
    "3. Do not provide a recommendations.\n",
    "4. Use the following information:\n",
    "\n",
    "{data}\n",
    "[/INST]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_llm =  GenerateLLM(synthea_input=output_synthea, path_output=path_output_llm, save_output=True).run(model, template)\n",
    "# output_llm =  GenerateLLM(synthea_path=path_output_synthea, path_output=path_output_llm, save_output=True).run(model, template)\n",
    "output_llm =  GenerateLLM(path_output=path_output_llm).load()\n",
    "output_llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output_extraction = Extraction(llm_input=output_llm, path_output=path_output_synthea, save_output=True).run()\n",
    "# output_extraction = Extraction(llm_path=path_output_llm, path_output=path_output_extraction, save_output=True).run()\n",
    "output_extraction=  Extraction(path_output=path_output_extraction).load()\n",
    "output_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_standards = StandardiseExtraction(extraction_input=output_extraction, path_output=path_output_standardisation, save_output=True).run()\n",
    "output_standards"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
