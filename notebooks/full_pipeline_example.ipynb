{
   "cells": [
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "import os\n",
            "import sys\n",
            "from spacy import displacy\n",
            "\n",
            "path_root = os.path.dirname(os.getcwd())\n",
            "\n",
            "if path_root not in sys.path:\n",
            "    sys.path.append(path_root)"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "from src.config import (\n",
            "    path_output_synthea,\n",
            "    path_output_llm,\n",
            "    path_output_extraction,\n",
            "    path_output_standardisation,\n",
            ")\n",
            "from src.generate.synthea import GenerateSynthea\n",
            "from src.generate.llm import GenerateLLM\n",
            "from src.extraction.extraction import Extraction\n",
            "from src.standardise_extraction.standardise_extraction import (\n",
            "    StandardiseExtraction,\n",
            ")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "# Privacy Fingerprint End-to-End Overview\n",
            "\n",
            "The Pipeline has been broken down into four components:\n",
            "1. **GenerateSynthea**: This generates a list of dictionary of synthetic patient records.\n",
            "2. **GenerateLLM**: This generates medical notes using the outputs created from **GenerateSynthea**.\n",
            "3. **Extraction**: This currently uses an LLM that is specialised to extract given entities from the synthetic medical notes produced by **GenerativeLLM**\n",
            "4. **StandardiseExtraction**: This standardises the results extracted from the medical text.\n",
            "\n",
            "Each of these classes takes in a path_output, when save_output is set to True, it will save the output to this path_output defined.\n",
            "These paths have been defined in the src/config.py file:\n",
            "- path_output_synthea = data_folder + \"/synthea.json\"\n",
            "- path_output_llm = data_folder + \"/llm.json\"\n",
            "- path_output_extraction = data_folder + \"/generative.json\"\n",
            "- path_output_standardisation = data_folder + \"/standardisation.json\"\n",
            "\n",
            "Additionally each class will also take a path for the input required to create their output. This allows the user to break-up the pipeline and run from specific points in the pipeline."
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 1. GenerateSynthea: Generating Synthetic Patient Data using Synthea "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Synthea-international is an expansion of Synthea, which is an open-source synthetic patient generator that produces de-identified health records for synthetic patients.\n",
            "\n",
            "GenerateSynthea is a class used to run Synthea. You will need to follow the instructions on the README to ensure Synthea is installed.\n",
            "- \"./run_synthea\" is a command line input that calls to run synthea.\n",
            "- \"-p\" is a person flag\n",
            "- \"5\" Where 5 determines the number of patients you want to generate. (Alter this to generate more records.)\n",
            "- \"West Yorkshire\" Synthea only works on a regional basis, therefore you have to give county information so it can generate address type data.\n",
            "\n",
            "In the src/config.py there is some given config values:\n",
            "- path_synthea = \"../../synthea\" - This defines the location of where synthea is from the src folder.\n",
            "- path_csv = path_synthea + \"/output/csv\" - This defines the location where outputs are saved to when synthea is ran.\n",
            "- path_patients = path_csv + \"/patients.csv\" - This is a .csv that holds patients synthetic demographic information etc. \n",
            "- path_encounters = path_csv + \"/encounters.csv\" - This is a .csv that holds encounters, i.e., this holds multiple times a patient has gone for medical assessment/treatment.\n",
            "- cols_patients = [\"Id\", \"BIRTHDATE\", \"FIRST\", \"LAST\"] - This determines the columns we extract from path_patients.\n",
            "- cols_encounters = [\"PATIENT\", \"ENCOUNTERCLASS\", \"REASONDESCRIPTION\"] - This defines the columns we extract from path_encounters."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_synthea = GenerateSynthea(\n",
            "    path_output=path_output_synthea, save_output=True\n",
            ").run(\"./run_synthea\", \"-p\", \"5\", \"West Yorkshire\")\n",
            "output_synthea"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the model from path"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_synthea = GenerateSynthea(path_output=path_output_synthea).load()\n",
            "output_synthea"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 2. GenerateLLM: Generating Synthetic Patient Medical Notes "
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "Currenty GenerateLLM uses Ollama to run a range of pre-trained models you can use.\n",
            "- model - This determines the model you want to use.\n",
            "- template - This defines the prompt-template you want to give to the LLM model to generate each patients medical record.\n",
            "\n",
            "In the src/config.py file, there is a *cols* parameter. This parameter currently maps Synthea column names to names used in the template to generate these medical notes.\n",
            "\n",
            "```\n",
            "cols = {\n",
            "    \"NHS_NUMBER\": \"NHS_NUMBER\",\n",
            "    \"BIRTHDATE\": \"DATE_OF_BIRTH\",\n",
            "    \"FIRST\": \"GIVEN_NAME\",\n",
            "    \"LAST\": \"FAMILY_NAME\",\n",
            "    \"REASONDESCRIPTION\": \"DIAGNOSIS\",\n",
            "}\n",
            "```"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "model = \"llama2\"\n",
            "template = \"\"\"[INST]\n",
            "<<SYS>>\n",
            "You are a medical student answering an exam question about writing clinical notes for patients.\n",
            "<</SYS>>\n",
            "\n",
            "Keep in mind that your answer will be asssessed based on incorporating all the provided information and the quality of prose.\n",
            "\n",
            "1. Use prose to write an example clinical note for this patient's doctor.\n",
            "2. Use less than three sentences.\n",
            "3. Do not provide a recommendations.\n",
            "4. Use the following information:\n",
            "\n",
            "{data}\n",
            "[/INST]\n",
            "\"\"\""
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs GenerateLLM using the synthea output from the previous run, and saves the LLM output to the given path_output_llm."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_llm = GenerateLLM(\n",
            "    synthea_input=output_synthea, path_output=path_output_llm, save_output=True\n",
            ").run(model, template)\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs GenerateLLM using a pre-saved synthea output saved at path_output_synthea, and generates a local output_llm. In comparison to the run above this will produce slightly different results."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_llm = GenerateLLM(\n",
            "    synthea_path=path_output_synthea,\n",
            "    path_output=path_output_llm,\n",
            "    save_output=False,\n",
            ").run(model, template)\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the current saved output at path_output_llm."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_llm = GenerateLLM(path_output=path_output_llm).load()\n",
            "output_llm"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 3. Extraction: Re-extracting Entities from the Patient Medical Notes"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This uses a local quanitised UniversalNER model to extract entities from the synthetic medical notes. You will need to follow the README to host the UniversalNER model locally.\n",
            "\n",
            "In the src/config file:\n",
            "- entity_list = [\"person\", \"nhs number\", \"date of birth\", \"diagnosis\"] - This is the list of entities you want to extract from the synthetic medical notes.\n",
            "- universal_ner_path = \"../models/quantized_q4_1.gguf\" - This is the path to the quantized universal model located in a models folder on the top level of this repo.\n",
            "\n",
            "This runs the extraction class from an output generated in this notebook, and is save the extraction output to the path given."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_extraction = Extraction(\n",
            "    llm_input=output_llm, path_output=path_output_extraction, save_output=True\n",
            ").run()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This runs the extraction class from a pre-saved llm output, and creates an output_extraction locally. In comparison to the run above this will produce slightly different results."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_extraction = Extraction(\n",
            "    llm_path=path_output_llm,\n",
            "    path_output=path_output_extraction,\n",
            "    save_output=False,\n",
            ").run()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads the extraction output at the given path."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_extraction = Extraction(path_output=path_output_extraction).load()\n",
            "output_extraction"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This visualises an the entities in an example clinical note using DisplaCy.\n",
            "\n",
            "We format the extracted entities into a dictionary compatable with DisplaCy, and display the string.\n"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "string_id = 1\n",
            "\n",
            "ents_dict = {\n",
            "    \"text\": output_llm[string_id],\n",
            "    \"ents\": output_extraction[string_id][\"Entities\"],\n",
            "}"
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "displacy.render(ents_dict, manual=True, style=\"ent\")"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "## 4. StandardiseExtraction: Normalising Entities Extracted for Scoring"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This takes in the above List of Dictionary entities and begins to normalise the responses into a dataframe format.\n",
            "\n",
            "The standardisation process is broken down into many parts:\n",
            "1. Entities are extracted from the object created from **Extraction**, and a set of functions can be applied to clean them during this process.\n",
            "2. This creates a list of cleaned entities. Multiple entities can be extracted from the same person for a given entity type, for example diagnosis. Currently the codebase only takes the first entity given.\n",
            "3. Next the outputs are normalised i.e. Dates can be written in multiple formats but have the same meaning.\n",
            "4. Lastly the data is encoded and formatted as a numpy array ready for PyCorrectMatch\n",
            "\n",
            "In the src/config.py file:\n",
            "\n",
            "extra_preprocess_functions_per_entity defines how entities are cleaned while extracted from the extraction_output.\n",
            "\n",
            "```\n",
            "extra_preprocess_functions_per_entity = {\"person\": [clean_name.remove_titles]}\n",
            "```\n",
            "\n",
            "standardise_functions_per_entity defines how entities are extracted, and defines any normalisation process you may want on a column of entities.\n",
            "```\n",
            "standardise_functions_per_entity = {\n",
            "    \"person\": [extract_first_entity_from_list],\n",
            "    \"nhs number\": [extract_first_entity_from_list],\n",
            "    \"date of birth\": [\n",
            "        extract_first_entity_from_list,\n",
            "        normalise_columns.normalise_date_column,\n",
            "    ],\n",
            "    \"diagnosis\": [extract_first_entity_from_list],\n",
            "}\n",
            "```\n",
            "\n",
            "This uses the output_extraction value created by the **Extraction** class and saves the outputs of the normalisation process as a .csv to the given path."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    extraction_input=output_extraction,\n",
            "    path_output=path_output_standardisation,\n",
            "    save_output=True,\n",
            ").run()\n",
            "output_standards"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads an extraction input from the extraction_path provided, and creates the output_standards."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    extraction_path=path_output_extraction,\n",
            "    path_output=path_output_standardisation,\n",
            "    save_output=False,\n",
            ").run()\n",
            "output_standards"
         ]
      },
      {
         "cell_type": "markdown",
         "metadata": {},
         "source": [
            "This loads a pre-saved output_standards from the given path provided."
         ]
      },
      {
         "cell_type": "code",
         "execution_count": null,
         "metadata": {},
         "outputs": [],
         "source": [
            "output_standards = StandardiseExtraction(\n",
            "    path_output=path_output_standardisation\n",
            ").load()\n",
            "output_standards"
         ]
      }
   ],
   "metadata": {
      "kernelspec": {
         "display_name": ".venv",
         "language": "python",
         "name": "python3"
      },
      "language_info": {
         "codemirror_mode": {
            "name": "ipython",
            "version": 3
         },
         "file_extension": ".py",
         "mimetype": "text/x-python",
         "name": "python",
         "nbconvert_exporter": "python",
         "pygments_lexer": "ipython3",
         "version": "3.11.0rc1"
      }
   },
   "nbformat": 4,
   "nbformat_minor": 2
}
